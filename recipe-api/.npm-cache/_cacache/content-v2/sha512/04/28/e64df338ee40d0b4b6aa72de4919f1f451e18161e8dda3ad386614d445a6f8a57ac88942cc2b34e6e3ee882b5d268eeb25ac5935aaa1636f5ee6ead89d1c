{"_id":"@crawlee/linkedom","_rev":"1103-f8074eadbee32f1b8f562965cf81c6b6","name":"@crawlee/linkedom","dist-tags":{"latest":"3.15.3","v4":"4.0.0-beta.18","next":"3.15.4-beta.18"},"versions":{"3.3.4-beta.6":{"name":"@crawlee/linkedom","version":"3.3.4-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"387dbdf41822d9afc1de8359c38f4abe567f3564","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.6.tgz","fileCount":13,"integrity":"sha512-i/ZbHVTMkMGDdvWh4Tl90r6lpC046pkNpEIrS+V/HXnLBOBPtnnS+KK1XYcSrkK1LVezZzY2W0DChONxVEY/og==","signatures":[{"sig":"MEUCIQDstEKzgRSxzee8yQ7hsy/LpV4eK1HQNypyyTn8zW414wIgDfh/ziX7nFs47v4uBX+hV7xJzNwqhyJySGTYZQbfgSs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183609},"main":"./index.js","types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"09f5f29d967046fa89b3f5c5fd63672812eea215","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/6.6.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.6","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.6_1686141079303_0.9622296990568822","host":"s3://npm-registry-packages"}},"3.3.4-beta.7":{"name":"@crawlee/linkedom","version":"3.3.4-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d309fe37b0c3b9304388fa64ca175a03de94190a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.7.tgz","fileCount":13,"integrity":"sha512-MVmWZ1YGm34cVCT3oGxLoVXKcVjk5cZrFVDUcw33L+d+gXunGgcZPOCRhwX0oQAkljZjcpNXhthrfofiW4sL/A==","signatures":[{"sig":"MEQCIFcwq/wiKYChBRHhfssGYCqTU+GbU+lwVCWUVmmK8N0bAiA5fahB5F8wN66ObV7aCRW+ZX54NxoMaFMPWzCL2tCqFQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183609},"main":"./index.js","types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"84c480294afd5e0979d3dcae95633bbba8dd9968","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/6.6.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.7","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.7_1686147933447_0.7344511210718463","host":"s3://npm-registry-packages"}},"3.3.4-beta.8":{"name":"@crawlee/linkedom","version":"3.3.4-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"10f5f512fba18ed644aaace44faf9855182122d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.8.tgz","fileCount":13,"integrity":"sha512-t0vq2vjqz9cQHA1jBBX5zd6qhT9FzsmOmnnwHz0k6S00x7qAdkKw3FtegIkjCCGvMihELejZ5p4nbjKfuOmnZg==","signatures":[{"sig":"MEQCIBUN30ulUba++2h5UBWQQQAFNYA1egv1wcw6eUgGdgL+AiBrP9Eo5N2YXpvJZ6naxY5/HQHFN8SWUHzlWJpTEZkHJw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183599},"main":"./index.js","types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1caa80b3beb6efb605b317ae936040e64df7252e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/6.6.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.8","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.8_1686152760324_0.21798023495303553","host":"s3://npm-registry-packages"}},"3.3.4-beta.9":{"name":"@crawlee/linkedom","version":"3.3.4-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3a462bcc49e0d89ab86bb0f2a4a26dc1459c7203","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.9.tgz","fileCount":13,"integrity":"sha512-vWQYvGsTa/R7nQO1Qysey2ID8lUeQ5O33MlMJgfGFpCvMRvzTGMirwLTYE7o+tcYFoVzQjskrz51Nk3hFihpBg==","signatures":[{"sig":"MEYCIQCxS55V997o+0akw6v7zdkbPUBB6+6Wt9e4ekQdjg5FJAIhAKG1bdpaZk2pTDGtdsusYrGCA4UXpSEIdrYsfBmla8pA","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183599},"main":"./index.js","types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8ea0c97689ed5d5dd4c6e2d1d6abfd81f66ae0e0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/6.6.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.9","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.9_1686281544594_0.10881423943127033","host":"s3://npm-registry-packages"}},"3.3.4-beta.10":{"name":"@crawlee/linkedom","version":"3.3.4-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5271d4c5bec1be03d6872fbbc2455cc9c3a1ea37","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.10.tgz","fileCount":13,"integrity":"sha512-IfcSnfe0OnFxB8xzceI1AWSAX3aRGRcUxZbxEXPVng3gZ3RZBFAh8tT2j16MKw+mocahSsAxGGe+YW2OLaf8Jg==","signatures":[{"sig":"MEQCIG7EF0jeJz9K8+gLpTg9ruPrkyUWSwI4GqWq+QKvbSkfAiBIuVIFnfBHEthB/Rxu6L3GP3l8qKFcQbRg1GVN5KyYOQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"a26174a1fdec465eabab5f81d96d42a862da626d","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.10","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.10_1686307392254_0.44449191104329766","host":"s3://npm-registry-packages"}},"3.3.4-beta.11":{"name":"@crawlee/linkedom","version":"3.3.4-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3f8894b8835ae0c3f9058260b79e18122bbede3d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.11.tgz","fileCount":13,"integrity":"sha512-5cLkZo2EaxZPkBeob8GHwktEhocljlix/9cqXvD0Y14C+ZaG6aOO0a4Skm7e2BDq1ssM1SMn+EFLrEwm1uMJxQ==","signatures":[{"sig":"MEUCIBU0LAzSAI6epTQeUpi9ToGtIqTyJhs4zZ5S9pCCdEYcAiEAjd7WlarkrN8AYJNTI3bzsFLSPgHuu4KHlCE+173nf6M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"378585d6a63171c7ad06fb1e7d025b49b08564fa","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.11","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.11_1686309178975_0.8002129390565351","host":"s3://npm-registry-packages"}},"3.3.4-beta.12":{"name":"@crawlee/linkedom","version":"3.3.4-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b0b97b89df885ac948b1ab62e9d67752c546d013","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.12.tgz","fileCount":13,"integrity":"sha512-Ya4FHWquqb8NG09LPuy7NdK9Sd+kj1BsuFLKaHTvcI9YAjQw9vk42Xv7Z4Mm4g065kSgPX4w6RY9HkTD+vFTuw==","signatures":[{"sig":"MEUCIQCpiPmhzZyheWvs+TslY1E7ZcDBGcUoKHDV4a5ly8kfbQIgYPbiA+pcFRgGaYqOUB5ipi8ZTlV3WpaUdMT7UpzMGF4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"d9960d64a6b50711d106a96d40b1c7fd340e509d","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.12","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.12_1686323559942_0.17201610554301605","host":"s3://npm-registry-packages"}},"3.3.4-beta.13":{"name":"@crawlee/linkedom","version":"3.3.4-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47f473670051e2d927970a2203b1ceb3a60ec364","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.13.tgz","fileCount":13,"integrity":"sha512-JCi81fgyQy+YqsTGyEyIK97AYIzg1Lc6NA8xW/lh801sFwXmrLUYuVsW5aXBvK6aNsZ3I9W7hcXeqyDy4QBB+g==","signatures":[{"sig":"MEQCIFKaWMlro1Ij/k5JyBGJYc4A1eFniz3j1z+ZJA4OisjoAiACoWzlceVV6CgtfF2eCa7GeOcNcFoYnt1cX+Hkqe1V7w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"c823613812d77e9eba7420fa4dccb8e83b154f13","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.13","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.13_1686355106033_0.5661666953318507","host":"s3://npm-registry-packages"}},"3.3.4-beta.14":{"name":"@crawlee/linkedom","version":"3.3.4-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8eda9bda17430bd016c49878d212a9b31c584de2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.14.tgz","fileCount":13,"integrity":"sha512-ATaBJfmAFYqrcWh9TXIqz4djTaczt+rSWKHbXJ4WGIqiLYmAjotPAovFvetyJfgGjNPYwVadIZBo66l/Y75c0A==","signatures":[{"sig":"MEYCIQCc9W/kuAXnUwLV1RVak9z4gLVQa2GAsbzM24xGc+bzqQIhAMICRrgMAxxpyZEl9n18md0STNz2oIZIPBnpNiRRkl7b","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"c3cff7ad29b304829e415fa35019ff28f42f6ccc","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.14","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.14_1686449363133_0.8354787823267136","host":"s3://npm-registry-packages"}},"3.3.4-beta.15":{"name":"@crawlee/linkedom","version":"3.3.4-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7647fe42b083a549b094c6c7a08f264d5da7291c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.15.tgz","fileCount":13,"integrity":"sha512-9BVmfk8xI/2w9N8ved0BjbsZi2kR2g8xxnvT3UYS6WKpeEUC4l2R+FxfzvPyZa+p9B0A+gJHOIPK4cIcTXeKJw==","signatures":[{"sig":"MEUCIBFc/OetvYbk9bqMS8xSCDQHKBaWA0nHYBfxib2VZJIWAiEAo8E4SQaXnw/LtcmWNGXD+gDsDl4jTsDhxkG+kIJw2jA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"85cec55b263164d79ef3aa5f7cc73b5669fa2272","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.15","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.15_1686530991309_0.458262776850928","host":"s3://npm-registry-packages"}},"3.3.4-beta.16":{"name":"@crawlee/linkedom","version":"3.3.4-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ce0645b0b3269b128a4d7b80d6dbc7e174c34f78","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.16.tgz","fileCount":13,"integrity":"sha512-ua5YinmEMH4bufPzhrNzRGCrpBcVVdBtqNcXStTPkRtnbQycwDDtTOQAD9CPXxebB5nSG+Rr1Bwk/8ylHL53Ag==","signatures":[{"sig":"MEYCIQD6Z9QAFpOKCidiFr4TMHr625pXgL2jMSYSqbjQv+jZtgIhAKF5zuKThpj28WRDYvYw6LAEEc7RvMoSbRVei2OHlh/R","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":180889},"main":"./dist/index.js","types":"./dist/index.d.ts","module":"./dist/index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./dist/index.d.ts","import":"./dist/index.mjs","require":"./dist/index.js"},"./package.json":"./package.json"},"gitHead":"67a826c104e2e29a65ff89ccabaecf8b078f2c98","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.16","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.16_1686574676359_0.9077627287802441","host":"s3://npm-registry-packages"}},"3.3.4-beta.17":{"name":"@crawlee/linkedom","version":"3.3.4-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.3.4-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e4dacd4d82a2a1d29ae8340d81af929d97067766","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.3.4-beta.17.tgz","fileCount":13,"integrity":"sha512-LcMYThWOXUE+vuPQ6DsAMvkG1Vhvj4X5FwnoaFm1j9lNd3D+86QXfAF+3qeLzUlDeVzvRAuMdQS/WOIKs6cnzA==","signatures":[{"sig":"MEQCIHCmRWPap/Pv5r7jE9o8mrELYvFfNF9eRJZXOSUR42EaAiBO8WwrQbQJ6mSJysZXWxRbkZGvGPKc/VBitxGGKSfW0g==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183583},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8bbc596f4dba0aa755df204d836c97c05fc94fca","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.3.4-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"^3.3.4-beta.17","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.3.4-beta.17_1686575482437_0.3705868692585934","host":"s3://npm-registry-packages"}},"3.4.0":{"name":"@crawlee/linkedom","version":"3.4.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"250d0b115ca7b81735d3982be84d4a4a137be16a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.0.tgz","fileCount":13,"integrity":"sha512-kBgjVbr9x2BwMix3+ux869bU9IL0bKQUx+Jbv7pBjEMIuVFARL4ydiI6BFi5bPq9NCqimuF69FKAufr/jvMXMg==","signatures":[{"sig":"MEYCIQCi+pY12OUOd5CczfoxK3+O3pfPEiyMv5T0spcbWca2OwIhAJAdthQLn5tKM6doeUSNjDaHMdZyd1zpznhJh8y90j6T","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183559},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"78bb2a880d768af49c6ada5d27775d1298b07621","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.0","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.0_1686580669023_0.3304490344070461","host":"s3://npm-registry-packages"}},"3.4.1-beta.0":{"name":"@crawlee/linkedom","version":"3.4.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ba14ca18d534e7c5c52ad71e2706a7d95cd3e023","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.0.tgz","fileCount":13,"integrity":"sha512-GykM/okQJc3J4bz4fh6xOl64ahNyen+0OZ8HsXp3hN7WtiXCU4UAgZbUf0h31y0N2Xzv99Dip+dVw9TqwlUl7A==","signatures":[{"sig":"MEYCIQD2B/l8jTf1a6B9O6izsirSVuSmDdBj5D7XUsiwhwgP5QIhAIjTv1siw/UqCuZbiuXue+oDfPZjt/TBEhHDSea7lglV","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183580},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4827b5a9e12430218454aaee1b427ea93c43f735","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.0","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.0_1686581746462_0.5364771922384219","host":"s3://npm-registry-packages"}},"3.4.1-beta.1":{"name":"@crawlee/linkedom","version":"3.4.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"87c503dfc218cbf9f4ff12be41c507e3b5b177e8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.1.tgz","fileCount":13,"integrity":"sha512-WYhbi7Atkuv39Z1kQaI0ckwMi7aN5ldOW5A5veUq7lKaeTNJshMHSxasdEVc6oBDeAR7AkFtGEwIO/xWN2Avnw==","signatures":[{"sig":"MEUCIQCWdzXKW3jIGLNFnzJew6QIm32fUY7DMLU3JirQ7NJLwgIgHtQb6Yrbtn7yMivLlbsn5sukUgCoO/XQsHxj3SgMUwQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183888},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"27942a3411ac95864f6567874620ba53af330a0e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.0/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.1","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.1_1686763895458_0.7792951283695801","host":"s3://npm-registry-packages"}},"3.4.1-beta.2":{"name":"@crawlee/linkedom","version":"3.4.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c02737976835065550f45ed3440dfc4ab175d48","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.2.tgz","fileCount":13,"integrity":"sha512-cCx7Iru5E44BW9IqvMV+eQTUHCr8Ctr8Jej79qanPs9Cpbgt2w5sgjFhlOYtbFd3nHWAK5giHYhGbybArHWedw==","signatures":[{"sig":"MEQCIHZCPFKdDDAsXjEmjTwdXAP9qX7W6TJs9RvbgxmJtg9aAiBcvg6ZtzxZ+CPkiIChSiCBsJdT+GyW3QkhbHm2FxcQ1A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1be45a6185b86ae7ea0b82195f7449948f6759b8","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.1/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.2","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.2_1686966892712_0.08397013692269395","host":"s3://npm-registry-packages"}},"3.4.1-beta.3":{"name":"@crawlee/linkedom","version":"3.4.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cbf2c569dcb169feb89509bd40c3ecd8b64022e8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.3.tgz","fileCount":13,"integrity":"sha512-xn+DyWeWXYLq+IZiAz1k7uOz6inDNhitVEawhq2QE9Z/WGMJzoheYU46spVfCtayEf9ojgCiZ8QkGxTT/wIMfQ==","signatures":[{"sig":"MEUCIAbxvwS7nUBkv+PBT3gxlasOCEFStrQeM+Q8DJFU2z57AiEAiDqj7YPBsir+maRhOKPvoPzZkmtuCKIFm2AznO7P0Gs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7b05e189008bfb6916f910a834f2fb46cee43249","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.3","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.3_1687054202159_0.24139381425239592","host":"s3://npm-registry-packages"}},"3.4.1-beta.4":{"name":"@crawlee/linkedom","version":"3.4.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1e31c7103ee2d2c0bc55a5a20edd154cce2be057","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.4.tgz","fileCount":13,"integrity":"sha512-am5lOOvCmuNb7EVv7dyta8qIv5ZAkFA7T1tDzdQCMmOXghIsk0h4NJ5Ci2Ci26xO3gSKFH4+u621v0R69K8HbA==","signatures":[{"sig":"MEUCIQClFH2L3We2l1TfuXp+DMjrHUHIl7MgR78cjmsX6EJODwIgBK9jN8im+/ZuxZqe2dSBt+poc/L2TCRhkUrOeL98bL8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c7a1a6b390b18bf91d54baa1e5ecdb39cf13fdb5","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.4","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.4_1687094408114_0.8839237563862117","host":"s3://npm-registry-packages"}},"3.4.1-beta.5":{"name":"@crawlee/linkedom","version":"3.4.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47b542ca12bcc9605b51585e3083bd0240b9e0c6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.5.tgz","fileCount":13,"integrity":"sha512-jTbB4gh3opZmpFIcqiB8TdXHRQ6qt9KFBZZ6yVHZxD7gAyr412vKON+FoTfrEA7KZaDBR5chOG8bzDhfbylljg==","signatures":[{"sig":"MEUCIQDCbvoccaELC3sn4bxjzrp60RJvo4bqGIJuC44G/3iF2wIgVBjq0zXPGxb0XDxQgMQvLiKN/tsOFI04WYrbhRkGN+o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0074cdf9c520a18efe20b4188e139ffdf75e6058","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.5","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.5_1687225907919_0.47151568785350917","host":"s3://npm-registry-packages"}},"3.4.1-beta.6":{"name":"@crawlee/linkedom","version":"3.4.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3cb7573906319f604dff49f0495cf8859bc0a91e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.6.tgz","fileCount":13,"integrity":"sha512-vRmZkmogAAOVcaGSWA0Cvz3cgnL8svot9i/QXjmFKZbRCIGByfQwBJ5m35KM5XNXfkhhvw/o5IHgDNhaKhKMgQ==","signatures":[{"sig":"MEUCIQDAlRN75DYja4ZELGexX+tgQYB+H3ogk8ZX/Z27stcLmAIgXP27S1eoqAdxUPh5vRkyoPPbXokWth74Pr0iESjOlPc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"29e82c3e968ff7182303926f076082c8e926f432","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.6","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.6_1687307209609_0.5433064457904087","host":"s3://npm-registry-packages"}},"3.4.1-beta.7":{"name":"@crawlee/linkedom","version":"3.4.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b530aef5e0683cd0301e4bb7cdccea28d9a2db6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.7.tgz","fileCount":13,"integrity":"sha512-4+jmxLyrziIxmNrf1+ECV45xtLRVKTarI8C7Dn7x1ghb6+06jPHeAnkz9cQEifFXhRTaoyXmyqDgH0zmC0kXzA==","signatures":[{"sig":"MEUCIQCyaw5/O57dRPwUGeoeTV/UQ42E+ig2jlhQNa4Xqs58GQIgdgU79WOqj9OPVmqxu+aKFgtjYT77gCAPov/PBnupEkM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"256e62b7e8f50a3ad2332b0c70297427fe9f8d61","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.7","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.7_1687349956938_0.14748077227096035","host":"s3://npm-registry-packages"}},"3.4.1-beta.8":{"name":"@crawlee/linkedom","version":"3.4.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c2a6d8c3ea13101699095b8ad5eed6fb019760f9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.8.tgz","fileCount":13,"integrity":"sha512-wulNxHEL46TOh2uEp0+fwQLZzh5J9O8TDhF+yMzdkN16eQqoENsAPtTgxot35pd4lx/AQOW48M5iucQGnbnW5w==","signatures":[{"sig":"MEUCIQDEFlzlAAzZQJ7ZZLH54mWIQ+qmjd4uVtxH/b64LisAaAIgM7qWioKx0R75rbPZ82RQcw3NszeOAg1cbTkgHkQYCfI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5af69d5f34460026868bc1dd5528b11676f017b6","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.8","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.8_1687382838470_0.221473150080568","host":"s3://npm-registry-packages"}},"3.4.1-beta.9":{"name":"@crawlee/linkedom","version":"3.4.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4f1079d6ec775052888526001c2220727a2df95b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.9.tgz","fileCount":13,"integrity":"sha512-boPDxltJq1DYYAIIgCAJDxdklXqHOkiwfoS8jp1cZENOpD9jax4SmYrc2Mb+0JfEYsdS1PlRkhuFlK4Pxqev6A==","signatures":[{"sig":"MEQCIELDq00G1HkwUED+RL+zomEHc6V6Lfoao4NUWPeegj/QAiBIgKMsAfuqrVe9ihKdoTCKWeGrkXaRPDHTbAlmnyHZ4Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184042},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5dd903c874cd1a4626cc290a89874d5badf5481f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.9","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.9_1687481452427_0.8690924226389116","host":"s3://npm-registry-packages"}},"3.4.1-beta.10":{"name":"@crawlee/linkedom","version":"3.4.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47051d47254b7ec42c438c718f6ab5904ca507cc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.10.tgz","fileCount":13,"integrity":"sha512-yvzis/94EWWJKA/3isn0I15FsuXEp2iPSJEIhUgBGDgqgmg7fqj7nrfFnB823bU9RsmlBym3WjK4NTKsA3a4cg==","signatures":[{"sig":"MEUCIQDAwtPfmcjdo4GNPcdhLEv/ba+vY22KTZtRCK8x9VQlnQIgBR3LLWuQJaRyZJzn/w2IRJZw+fZXU0OkfrMiwN3VUyw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184045},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c970861b06eadf24fdcf1f657b13ebdb81435c2e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.10","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.10_1687566995696_0.6121264631781651","host":"s3://npm-registry-packages"}},"3.4.1-beta.11":{"name":"@crawlee/linkedom","version":"3.4.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"716c7143e15808a007234c158376d696a809b3ae","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.11.tgz","fileCount":13,"integrity":"sha512-XWQqTMUO9y3JejOI1uWgxVyA73P6vS/pXo/+SYkv0M7xQVSlHc1J7saqus6F9KCtBLa9+LKb1fb8I837qlIyLw==","signatures":[{"sig":"MEQCIBr5V3k+uhUS7rd+4NDezYj7RfkcEbfhtUoq+rfjwGiNAiBp8Mx4v6CnGuJOdWLvFyrLF5PhoS6M7Tp/rKwprIGxpg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c31521f1e20ee89fb251ff34bd31c144f88e3094","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.11","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.11_1687656975089_0.0023174554674858516","host":"s3://npm-registry-packages"}},"3.4.1-beta.12":{"name":"@crawlee/linkedom","version":"3.4.1-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8e945fcae0b3df85fc2f72a227379054c0ae3053","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.12.tgz","fileCount":13,"integrity":"sha512-23zq6yHnNTE29NMvfuVEYiCqKAYOgniL9xQGNKby6bfly1m855isU17DR6cU6WmjogE+ttATudUcjX8+tPdc2g==","signatures":[{"sig":"MEUCIQD9bUfD9rNiCPUGwpjqLXyv/VhC4GBlLr6FO7qkYuIfrAIgJbQtMnrHlKB503bMAzvmOq/ih9YCCMfHrjroTRUzzw0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b16213ee7a816afbd4b669d49d094edd0c869b51","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.12","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.12_1687739522934_0.2706741719205319","host":"s3://npm-registry-packages"}},"3.4.1-beta.13":{"name":"@crawlee/linkedom","version":"3.4.1-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"457e9d919ad1e68c6c848f9f44e416caed769eef","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.13.tgz","fileCount":13,"integrity":"sha512-NIPOdFnTxgj8mTyKlq95q1BJOGOc7F9SXLyhqb7a8Hk9Ne+jwXt6HkEKEn7hUQfOIBKqAj2c2uBjE9rf606vKQ==","signatures":[{"sig":"MEUCIQCUq02QOLBCH7MCvI+HK5AU9U1PajPjTilv8oLCG9bXvgIgbDlVhhk1Dqmk/9v8bULLrtz3obM3oJWd4o47jvAMQzg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"53aa1fc20e07d18c93392087ec1d8d1d4a5f33db","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.13","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.13_1687754557098_0.01223121568989094","host":"s3://npm-registry-packages"}},"3.4.1-beta.14":{"name":"@crawlee/linkedom","version":"3.4.1-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"76f1222bef2968251ed9ccef1f73d2eb1291a47d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.14.tgz","fileCount":13,"integrity":"sha512-GiP56+uvIsGOncMRWCEne0g83MNnr2uAh3TzHVWi3pU06P5JoTJ6LUPwlVQ84FKkYUEnUnBT0bwZ1pNk0sqDEg==","signatures":[{"sig":"MEUCIQCt+yebAhZdNWKCIiT9H0lzFQYc17OHAtboDyPTfOAi6QIgGrPuqeBriiI84qYmRqY3qA2mOSUqkXLY3LrFw73rHzI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"117eaf75d67768f28ce675eb6860ab4e1533d171","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.0.2/node@v18.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.14","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.14_1687819997085_0.8884373270227925","host":"s3://npm-registry-packages"}},"3.4.1-beta.15":{"name":"@crawlee/linkedom","version":"3.4.1-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7550a8cb604f85a41f07fc5edf0a1541dc39d851","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.15.tgz","fileCount":13,"integrity":"sha512-oU+MJySO0D8mL1WUHVzOumOprs2gAvCnw82EO5M+COnSPq3x4Uftal/5vfroKLQWyRxrOBjEFWdVNHkOaOaQuQ==","signatures":[{"sig":"MEYCIQD6+ds95tCMcn8GqzC4gJZu/2h8E1RQLwlzaujkmJ08nAIhANtR5WFlajxPNIFzPy0PUj5JavrGj137DJb6TnaMMafO","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"36ea3920546318fa2a9f34436dbcb6371956843e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.0/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.15","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.15_1687917926800_0.8709160908966762","host":"s3://npm-registry-packages"}},"3.4.1-beta.16":{"name":"@crawlee/linkedom","version":"3.4.1-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b674738c96c8614265de6e80f519b76d220a7ae7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.16.tgz","fileCount":13,"integrity":"sha512-+5+YLmSP255GwUOWnnryii/12YipCaNa8o5oJl88RLhNFpyJs60/8asu9Dm5r80HvS1jhVUiXuht3V7rFRTBqw==","signatures":[{"sig":"MEQCIBtMjmcVWtl28Imv6rsszosBUiYd+6XhosNdkGUD6Kx6AiBq4Ev7hNJhl62CSYZgFX+ge85ls0aQ2VProq3MXJ0XOQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d292a53111ce202d0b099b72d0c1c442ad4951ed","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.0/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.16","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.16_1688069834591_0.6831577831744942","host":"s3://npm-registry-packages"}},"3.4.1-beta.17":{"name":"@crawlee/linkedom","version":"3.4.1-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"35f273e71a27764a040c765c44062d881085d14b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.17.tgz","fileCount":13,"integrity":"sha512-KIHMTgMdTMh/a1Vv3gcmqzIGaT66vdRwp4zi+k/+/w+fhjzNLoFqkDGldmOWRv0ptQ9zsuDX31VFtDEsL8RP+g==","signatures":[{"sig":"MEYCIQDRda7pN9Ar5Y8uhKG3xDum2c9SvZGQQiNRPORkq/UoxwIhAIi0pjMiC8WBDx2Y8t3KR3fAvgvAPH2dQRXUE8p9XlbN","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4673cab2dabac8c22cb1072391f20ddf37777059","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.17","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.17_1688258088339_0.7773138941576943","host":"s3://npm-registry-packages"}},"3.4.1-beta.18":{"name":"@crawlee/linkedom","version":"3.4.1-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d0f6c05c0cdedd2e292eab3d8f2da098e2009236","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.18.tgz","fileCount":13,"integrity":"sha512-VWqOBIsSZKQwdovKcsgGR/fgcOHF90rHXAD1sA70hXxDmdGwo7kSF37EnT9g+q9Nit7kzo1KdyxUy689LV/nog==","signatures":[{"sig":"MEYCIQDmApseJd0S8Oxk3irBn1HPOKUTKlzPR75slFZO3npAJQIhALoSbQgsCZK6gp4GOoH0cCVsjyrRN9ZzvNTlCge532tl","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6e1c8a277cabcffcb07ddec7979138de2f94b143","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.18","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.18_1688344104453_0.7810345165485557","host":"s3://npm-registry-packages"}},"3.4.1-beta.19":{"name":"@crawlee/linkedom","version":"3.4.1-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b5c4f293c098179d4164bcc003e51dc337091383","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.19.tgz","fileCount":13,"integrity":"sha512-qJBUVNUE8fyXF+VjQa8OzPDodB0ztOaHDYDCAX0z9s/Tadv8ueWSqqAGX5CbE3yen5WWl+lfK7omd2aLrNRmOg==","signatures":[{"sig":"MEYCIQCuVxFCPHtS89GoiUyHJZEnrCtp0Jk873NG2/fDQGZloAIhAL701DwKyY/K5olAODrGCFCN1sAOWMObRwcWoBDM25HY","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7cd109f2885b57de4ee1b7119945918ac25a48e1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.19","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.19_1688357386746_0.014037271453956945","host":"s3://npm-registry-packages"}},"3.4.1-beta.20":{"name":"@crawlee/linkedom","version":"3.4.1-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"54d980322b9f045b66c3a746b37cd98460e974db","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.20.tgz","fileCount":13,"integrity":"sha512-nrfB7y0HmU0f9E2RQOCwmLvWkmOJeo8xpQejLjGdcjSTL+X/mwMxLFQPtblcZBPRqI7Bb3wmQsgc945Tg1hDXg==","signatures":[{"sig":"MEYCIQDEdtoA43u0Pc4XRCnZiLDcXHL7H50T+a3efviAWMDjTwIhANlO16fE8hda/29zgwAgxwsVAYfPnZdeFlCBzwNKJSpR","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"17e29c713f5d8d3c026e50e0228a50c9a126a337","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.20","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.20_1688517219331_0.8949972744551749","host":"s3://npm-registry-packages"}},"3.4.1-beta.21":{"name":"@crawlee/linkedom","version":"3.4.1-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e3fc5518e986df35173f06c3b60c970190f2a345","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.21.tgz","fileCount":13,"integrity":"sha512-2q5dC4i09lJqOILYg73gcQ7Fz87s2w+8zRXveShQvQPSL2noE7PtIDDdHsoCYhhp/i0flku6+3Fbs6pCV91pdA==","signatures":[{"sig":"MEUCIGuzqXjco2dA7f2R8GPQqhH/kRP+b7LFbX+8rt/RzNOrAiEA9dNOmpzQAKcYCsxntNAyLn3NxxXeNpHKcSLW30hwJAA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"10cd3be062f5a682ad7a115611c8b54d3c5a218d","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.21","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.21_1688671289098_0.610608876007025","host":"s3://npm-registry-packages"}},"3.4.1-beta.22":{"name":"@crawlee/linkedom","version":"3.4.1-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2cbbc6865e96b63de06d76712fdcb02abe7696a2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.22.tgz","fileCount":13,"integrity":"sha512-x888CeRYtoDNBKEFMF3eP8tdQxkZVLYOOH5BqJxaj3Hp0tUNV8v8kjCi3bJaZWe7aR00SWcMXn7S6LTDe1N7yg==","signatures":[{"sig":"MEUCIHMK8el2DVu7AkOgCs18zTRsxyJJqY6eZUe/GyBq6C2kAiEAggc6QKeE5doFkTxv92UHIb0zBDmjyTDofI746TkW3kI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184197},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"19ebe99292bde7578fab43a02e3397ff4b06806c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.22","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.22_1688687496144_0.8111569315482934","host":"s3://npm-registry-packages"}},"3.4.1-beta.23":{"name":"@crawlee/linkedom","version":"3.4.1-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3613f82bc63bdc4c2dafe38c8188fe5937a407b0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.23.tgz","fileCount":13,"integrity":"sha512-RShysCafWxeNcSggTLqsF5LNXxQsZKJMnFksnKSc41yvb5J93iJvOmXDWx3PgiF0UqKujMAUWbz7auz+ARGoQQ==","signatures":[{"sig":"MEYCIQDKJUCH3JAFL1IcZACRZp2dcqIzbVSs+i+rwCP69TkrcQIhAPP28FkFtIgOYCjcWOr1JjIUbJi98wKszORqBRN7nRP/","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184197},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"60bc8a380f3e25b699e91d82c796c132492a607e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.23","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.23_1688867744867_0.7533239812570967","host":"s3://npm-registry-packages"}},"3.4.1-beta.24":{"name":"@crawlee/linkedom","version":"3.4.1-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"05c2f00bdb75d4823337ad16beccc861eb20a05f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.24.tgz","fileCount":13,"integrity":"sha512-aiUqnJJNmdIV0Xs+SqHVGAB/l19timGmIzQyDBTaMs5z/KlHi2p/AOanGt0pjhLaWhG3VCy7dEkeZzU8qP6Cdg==","signatures":[{"sig":"MEQCICpomIaBz4oEeVkx9Ha7aNuN0stLuKhZCRTlpzcoRiCbAiAlQNHrfShnOMNzoUB1KRgiU+TSHlz3TuWY9iZiANM6FQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184197},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6f25adb808bc7bdbb32cac4adc6c396636b736c1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.24","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.24_1688952942163_0.13056735718356594","host":"s3://npm-registry-packages"}},"3.4.1-beta.25":{"name":"@crawlee/linkedom","version":"3.4.1-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d8a4216cc61b1ee79b70097a79b53da6793b3299","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.25.tgz","fileCount":13,"integrity":"sha512-Ma3hN967YaRvkde96z6zf6/IXS1QEkiC3g+ukCYSIq8LVkibIQNd2oPn91VWXldscLbV2/pTAza1/p8QsWQWsw==","signatures":[{"sig":"MEQCIE3p8WP/ARHiJfsAhbpDcDd0BQa0BCS0uhyeFxuRXLCyAiBc2U6meOrp1h/xXSfr70dUvTe5eQF2zdOVN3cw+/gDJA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8961b80c6c25c9a8233c8b114e92978f6122940c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.25","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.25_1689040925980_0.9827033067047473","host":"s3://npm-registry-packages"}},"3.4.1-beta.26":{"name":"@crawlee/linkedom","version":"3.4.1-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"39de490728b01892c9e701f0577d4a49eb986e95","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.26.tgz","fileCount":13,"integrity":"sha512-QySikJjY5Mf3pKIJIZ3ZrbvZm4HUhkZNJCDa9iXVscU0MQV3qFKotXBsi/M1Tqa1yQHFyErp6H7RKJTe7I/wEw==","signatures":[{"sig":"MEUCIDofH2tqlGwgSWecBcqqF9L+wBu3+HkIxeSdRe95RISgAiEAjozwDuBZE4afNG+JH6OK1oTBba+rrj5GDVj/TD5If64=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"23ab80054a8b0e1fab29fcc04f4c49d083bef7fa","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.26","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.26_1689093385509_0.557888361773651","host":"s3://npm-registry-packages"}},"3.4.1-beta.27":{"name":"@crawlee/linkedom","version":"3.4.1-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a78e531947e4e589eea720c5d9131e889b00d6d0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.27.tgz","fileCount":13,"integrity":"sha512-f8oMS9p8yiqzHMU2iBOup4+GIy3kPWN+FbWb5gqxjYXou6CvNOsvvTBggds9OSWawcUvho6pWElKnLe4J18TUQ==","signatures":[{"sig":"MEUCIAePEBOUuRTMlimucPNIRAOeEBOfaaTAIjZY174XZ4cyAiEA+nk7TFf0SUvd+rWSLjHY4uk8YBnLRLC3mmFs+aXqriI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7334a041f53834b968e7a39b704751168b644e79","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.27","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.27_1689116667342_0.1464073406117148","host":"s3://npm-registry-packages"}},"3.4.1-beta.28":{"name":"@crawlee/linkedom","version":"3.4.1-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c7141ba123d2eef879b5a778994dff4c04d708d0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.28.tgz","fileCount":13,"integrity":"sha512-tAVaUdf1u6HXs79qm4UJJIkeuSKPd/zoW2EBlOprE52hYfgIg6WXRREVMphHtZMDoS7Z9ImEZjSzKMJDPcqFAA==","signatures":[{"sig":"MEUCIBoe/RzWYsuYHP/NWGVj2zhlqeqbE6cJ4TE6BxD5mQpwAiEAna+kfytD6Hor53GBoeLxkjkyi2dLOkVYr8wF3g/2ao0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5567fcf3904144dce6114a10503452081022e47c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.28","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.28_1689169818219_0.8623677774910852","host":"s3://npm-registry-packages"}},"3.4.1-beta.29":{"name":"@crawlee/linkedom","version":"3.4.1-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"58c8f2b1087b2ffe7aac6eaad55bb268c8355e64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.29.tgz","fileCount":13,"integrity":"sha512-wNxsOwWpVxkiIpnpwHeOTI/HtxpxjN3I8zyy6u/Uw1ykYcm3xYhdjXLD+f9deJnilIKnZXzbSW+BsS5pnYgvYA==","signatures":[{"sig":"MEUCIQD6pzF0Atj590BUqUD/vLR8qBWhbjUR3acWtPvP5y+96wIgI7AVt1ddrgBDNpovTREjsHODzQcFWCgkso0+YRPrGg4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0eb41f6a280b96ebc19fb4c16776c29a1387d25e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.29","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.29_1689170975562_0.14173493955268746","host":"s3://npm-registry-packages"}},"3.4.1-beta.30":{"name":"@crawlee/linkedom","version":"3.4.1-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"66c20af6cec6331e5ee5779ab9702a05c913bc70","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.30.tgz","fileCount":13,"integrity":"sha512-r6LY3mdyz/l7UQOW0EUpoCA/U1BGWvlNuUsBSAyxdLs135X7o8WKOV+ELgkT3rB/0jDqJIl6fk19qTaF3CBMmg==","signatures":[{"sig":"MEUCIQD9tZYCLWiiryYuMrCj8iG6Cq5LBdTWLS5LHvIV7GnsYgIgfSzlxvY7bFlSJfzuBJ06MYhIj7wm6uGSf460par6Iv0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80992e7ae947041cb96216e6b7db33b6698710ce","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.30","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.30_1689172608063_0.5020991858738164","host":"s3://npm-registry-packages"}},"3.4.1-beta.31":{"name":"@crawlee/linkedom","version":"3.4.1-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3db988d2222b98ab1cf5e712e00e6c8b07f80702","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1-beta.31.tgz","fileCount":13,"integrity":"sha512-xvpf9oj3gsyq2k9YE2b9xGW1cW+6KJzOCla3ptbfqeJvJv8aG7ZU1jL52kRNC/ZOhxJru3WYFIFLFoYqrUkoKw==","signatures":[{"sig":"MEUCIAiUomNlwNtk/76Or9pEKi6+CNuVzklu90x/gJPARj1/AiEA7MlzszZm3GXmNWrdVwAo1SSt/e315GUCEcYBYAmTvTU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184539},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fbd3d90d6c617c06d91ed65a5f1884631ed14433","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1-beta.31","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1-beta.31_1689250821496_0.8157947127839362","host":"s3://npm-registry-packages"}},"3.4.1":{"name":"@crawlee/linkedom","version":"3.4.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"54cba49f068ecf215bd88d46ff6a273a05194f83","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.1.tgz","fileCount":13,"integrity":"sha512-CtOBugsZt1MRR4RXXzP0Jc4CB8rAmcgSqExY/f7TrtnlxwbS4ZImOqzeu02692gUo2kvQKGfl27Kzib84xfmwg==","signatures":[{"sig":"MEUCIDBP74+gWYuZDbK+z5RwdtYzYddwe2NyeptI/K7yCNhlAiEAj7tCR5LuJL0n/cMK1119Fi+eIXkD7F2vm5NFLmQuiqQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184515},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"49ad03ef0573e3a9edabae5f4880b192cbb1e56f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.1","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.1_1689251011052_0.47039096382030454","host":"s3://npm-registry-packages"}},"3.4.2-beta.0":{"name":"@crawlee/linkedom","version":"3.4.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6522796ea95135faab0b3b389601214074294b51","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.0.tgz","fileCount":13,"integrity":"sha512-/5gDXABpkj2Hv2d7JyfPFRJ1WxfTBeOrblOV+e+2zCFRDG8O9pTtbDWlcbtdrtop8DVXWfBNCFXsoNEBe88QXg==","signatures":[{"sig":"MEQCIHhHDtv24XMTGjjZtTJzRIMzyOO4EzbURxqkB8LdT+mqAiAYaSEHgVL83NHGZyqwksGtW+KL2hhGZVul28+UF64qLA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184536},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8fc6d1528d3865baebfde4bfa5c3e5bc3639df60","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.0","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.0_1689252060179_0.6942169676778487","host":"s3://npm-registry-packages"}},"3.4.2-beta.1":{"name":"@crawlee/linkedom","version":"3.4.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bc252ddb12e72f2c4578c6a0cd6fe36393292dfa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.1.tgz","fileCount":13,"integrity":"sha512-TL1B1NJW1exYLPaG4Bmf6hTNLU2lXngfRTWaKisxY57IFi/ENKCPWQkbj5uIoiDVbIdM8yJAJkNohhXn3mlXzw==","signatures":[{"sig":"MEUCIBLujlnBoPAGa9/rv4R7G7UkNPbTaDxLQSzFhpQ9pvNGAiEAxjUJ/aiYpkxPQfm6z/nxFAyGTLIs0/ZBp1YUTm6cvjc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184536},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f76c91c9cb5bc5bbfce0549226ff2873b729b689","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.1","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.1_1689253609362_0.9807364656508997","host":"s3://npm-registry-packages"}},"3.4.2-beta.2":{"name":"@crawlee/linkedom","version":"3.4.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f6247d00dfa05b67dbb81eb40e88b22f57ed432d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.2.tgz","fileCount":13,"integrity":"sha512-ktOD1xAorDoWkHqR8cG7aHqNBeYQTr/xXQtS0bkGSsx4Pt2NtuBqxmwYs+dfZyCboHXcxo/1mnS+iE+1WfQ2hQ==","signatures":[{"sig":"MEUCIBZi8wnz3v2u9qHsSPmfekHJHZpbMPhJlmQlK4dzEiCOAiEA0LqUhZaUbsDHlWBF7jrAhV2X948CjpL7bzXHuXll2v4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184536},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5105a831a1f993321e6a672538c2a5bfe08c2cc3","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.1/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.2","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.2_1689562582008_0.09353338783162068","host":"s3://npm-registry-packages"}},"3.4.2-beta.3":{"name":"@crawlee/linkedom","version":"3.4.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72381baea6baa35a587e98cf5cdbd2bc54bca584","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.3.tgz","fileCount":13,"integrity":"sha512-mN7eXhPr5KX4Y/fwSQQgbgNAXciyzdtDyt9djqiBHsL/1zpE3xWIxKHAwO1xJJd9Lb8k1o+6B69tyilX/0Mz3g==","signatures":[{"sig":"MEYCIQD48AgSJF8xDQZn8yG6uO8P1aKRBjmQNCrbb9jW/HgqUwIhAKtT3+xMVuphMBicjekh/ItgaE3Up30/8+V+IEqIXMnt","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184532},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8c4a4abc05ac45a3d3c2d935d1aa0fa6850c5f78","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.3","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.3_1689572532966_0.4453929713720701","host":"s3://npm-registry-packages"}},"3.4.2-beta.4":{"name":"@crawlee/linkedom","version":"3.4.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4a23d75a89cefeff278c584b426fab684ed862e1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.4.tgz","fileCount":13,"integrity":"sha512-tbdaONVopG79QLHDIDJAWqUZxScp/8C3nPKxJ403Q+TSS47dQwvAWe5NwEcM3iKvbNTc6yxqmI9BonYztBa2/g==","signatures":[{"sig":"MEUCIEbjale6g3cLOGqfcCvKgEf2GzRq15xI+TuitYWp972JAiEAuwXqJfTWfOXBEZzF8xEKlcHKRLK2H23hI0caeeM7oF0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184536},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"99ee3fd6b6b77fac25f97034a61f182467f12c7b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.14.25","@crawlee/http":"^3.4.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.4","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.4_1689576712994_0.8490567627431354","host":"s3://npm-registry-packages"}},"3.4.2-beta.5":{"name":"@crawlee/linkedom","version":"3.4.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"38a3e291955e295fc00488a77cf73678a698eff6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.5.tgz","fileCount":13,"integrity":"sha512-jVkVz2NNPvvRSUZgVDHBf/pWA39qvXvUSilWWvMjG3dn9R+qIR++BvqF1OCwCINI9xuIhMusTgj9OKBwiwIYFQ==","signatures":[{"sig":"MEUCIQCwb6kxUvOF2kR700y3V6QRGx6e5M/JroLnh32eFfNC3wIgB5HT/ZD8RsuxPnRdoknZ/NIys6lND6afK7OfH//EveQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"28572c97a6e9b69b53fc10029f4c0025e9e5ed00","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.5","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.5_1689604876975_0.9168578277332131","host":"s3://npm-registry-packages"}},"3.4.2-beta.6":{"name":"@crawlee/linkedom","version":"3.4.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9e7b2b2500341ea49609f1f9590c93e4ef2d4ee7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.6.tgz","fileCount":13,"integrity":"sha512-9N2OVmpnO6l/kDbzgxMPvgBDxytxO5uKb2S3wtzzA27zLfeMdyfPqz7Lg/vASJOYNZCCVS8RldAmAQYVJvC/uQ==","signatures":[{"sig":"MEYCIQDkFYawyufZ40q/zm1F3a8EdVzX+B2/zD83Kuw9gB1rBQIhAMqeqA/j5LxAobO2OFalRpPtIbngQeRv2DExgTTKPBJn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e3b223aef9913d215fa882fceb15fa3f88d3ebac","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.6","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.6_1689612634468_0.13980389338381838","host":"s3://npm-registry-packages"}},"3.4.2-beta.7":{"name":"@crawlee/linkedom","version":"3.4.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"485177467f26da187f4ae9916515aa76301d065a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.7.tgz","fileCount":13,"integrity":"sha512-uQ3/ddPbHVzFIag64p3gIVj2cj4Wq++eeXgHC2pfGEshQVrtxyw3qUzH+vOQMmo5dgBOGQxkA4HijnCMGcLeQw==","signatures":[{"sig":"MEYCIQDVw2NPbW8Wkqz3bXaauYySuw6JyX+otXirSpI64edQtQIhAOAQDrECNrFZUjtroYtRo0OavZ0uC07yNUzXr/+TPWti","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e601a73a8e27c04c5fcb4d3c5032a7e7c42b6513","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.7","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.7_1689625222463_0.4582091315310848","host":"s3://npm-registry-packages"}},"3.4.2-beta.8":{"name":"@crawlee/linkedom","version":"3.4.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6fa77fddff28e0e0d8870d522328fa65c2a4091b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.8.tgz","fileCount":13,"integrity":"sha512-wVpHUh8fX0RaZI12IbPhgkMXWxRIiIY/JS9I7r7jHXSN1IU8UZydk/1+F8SDb+YiNp0Al1bsF1aFFnCGfyMLJQ==","signatures":[{"sig":"MEQCICbXN0Qy+mxmPyGcB143UDaCDd6Lui35p2z2OOlGo0zLAiAHp9siK5BbAReZiicx+9IvDlJ+KjBQhwLuuM8vXOiUcg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"42551fa604f8fbd8cae4203ff86b97349c4a964b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.8","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.8_1689697631525_0.6906865348915046","host":"s3://npm-registry-packages"}},"3.4.2-beta.9":{"name":"@crawlee/linkedom","version":"3.4.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9f1715619331b5eb203fad6eab9a90a40692ff67","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.9.tgz","fileCount":13,"integrity":"sha512-MfHZ73u9dWvxCPuLD9tTHzebhmEa1shj8kV7xh8AO+HxPkZ4VMgFjZ3ePm1xzc8btPKTJBNf1GRVjQWsvUj3Bw==","signatures":[{"sig":"MEYCIQD2TTDjt9Xkia5MOYcWDiCQoflG4zaO0anvDal8y9wOsAIhAPDnCRfkw1eSuHR1Hpip1mRM8Vl50bGp9uaga6hIfcIj","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"34b0bf98f08991b32d02139518fdbccd561db3ba","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.9","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.9_1689720534794_0.7283514870260808","host":"s3://npm-registry-packages"}},"3.4.2-beta.10":{"name":"@crawlee/linkedom","version":"3.4.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7df0929e928c577f0ee73abbcdcbf6843866f949","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.10.tgz","fileCount":13,"integrity":"sha512-JJdui9TYIYagXvAxEOKzKjJ6AasuqtyaZvunj8Rip4oWVADAWln25H0a6fdZCFKlVZHXkeZS8/c4cT/FkfPLQg==","signatures":[{"sig":"MEUCIHiVSiE6I+Nm4ls/Lm6LqXHvZIWf9NhxtkvJyNi5DiN7AiEAn5uugc9pSf63tYXkYz5C2ukza8lte/XjRqpITA1fP00=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184671},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"af5d07edece60751cccedb62ec11ffa7adafa6fe","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.10","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.10_1689769808173_0.5793588528860709","host":"s3://npm-registry-packages"}},"3.4.2-beta.11":{"name":"@crawlee/linkedom","version":"3.4.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f84a44e6274419c00dffda880595148353fd4f37","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.11.tgz","fileCount":13,"integrity":"sha512-siMnF0yRM65h52PqH5JmP0QcaIvxGnNs8G+dAKUnVOlqxdxP9MtNhqDoyCthNVHBmL30gJeRlYi9EFcv13y8og==","signatures":[{"sig":"MEYCIQD70e+IPna9QLnj/gY9hEC1YWrMGo52qLnHi2MJjmY5BAIhANR5NWXsEZFJVutVzRYTiAiTFxHj3gkAMW3AJOqZshYu","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184671},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b6a27caab7c192d1489fc2ac694e8910ea353f97","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.11","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.11_1689772823576_0.6325668774129105","host":"s3://npm-registry-packages"}},"3.4.2-beta.12":{"name":"@crawlee/linkedom","version":"3.4.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9ff97f038844540becc2c1b8f8c845e4af97338b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2-beta.12.tgz","fileCount":13,"integrity":"sha512-x9hYTmMT/geToF/xMThM4Tjc3Zv8g3izkwZ1gRVOYNVntMzwd9x+rlmj9SSzhJU88RejL6u0FZMnJo+85alX5Q==","signatures":[{"sig":"MEUCIQD/bASzETNKxdpdDo9AGJDoylu1BG0HQnys1rllOFejLAIgQ805ykFPvXZtABUH1v8Jj6qeD46teCKR5uCJEB/2kZQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184671},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f3d34d4fadfb0911ab0f8d0821eea05f0cdcd67d","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2-beta.12","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2-beta.12_1689775020977_0.6586829849025588","host":"s3://npm-registry-packages"}},"3.4.2":{"name":"@crawlee/linkedom","version":"3.4.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"374b9bc01c955ff77e9f16ce23825b45c88b23b2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.2.tgz","fileCount":13,"integrity":"sha512-bSaJ4cQpoj+jepLWjq/Hfv6L6tUwhNFvrzT7ogO9R5AhsQn1Ooqu7Y5um2alHNw9Ber6exzkZ2z581TydxQztA==","signatures":[{"sig":"MEUCIQCZUq6qPs8Y2YIIujeQDDYmnYiTERm5Y7lgZUFWjSt8SwIgUuySRuW2dRryoAAxv8fb2Dw7IJERqTnGjudpTF2Goz8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184647},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ef4cf657d13416c96acc667484f5389862a95b70","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.2","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.2_1689775928610_0.15748540986932702","host":"s3://npm-registry-packages"}},"3.4.3-beta.0":{"name":"@crawlee/linkedom","version":"3.4.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"682d2acd60b16f4b1f87953c7912e9936d8de89e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.0.tgz","fileCount":13,"integrity":"sha512-3F9boOqJUpgdrc2itCAqTu/LHIUbq8WdwU6p98lSFcSRKCBf1fK+TJkdsekbAzwz3dwmD9Y8jVzonz0vlPwbsQ==","signatures":[{"sig":"MEYCIQDWZR8Igk96DgHbRXuVjIpsiJVqKSqkv0YSLHc9lE5XMwIhAPlUwF3k/amREMEwxvlM41i1wNb007+L0QYEXdq+bwan","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3c0d9d27a06c1f6a16a50cedb0a0eca34130aff3","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.0","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.0_1689777002006_0.026003741434410532","host":"s3://npm-registry-packages"}},"3.4.3-beta.1":{"name":"@crawlee/linkedom","version":"3.4.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4655ee6dcd717af17b525460bb3322cf24a16b36","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.1.tgz","fileCount":13,"integrity":"sha512-Fy52biqr31PIgW61kT+mOmcBsT6wOHNav0d/ZV0CV7HVpHVIgh/hCMfaunen7//Zy6Ya4UKvfuLBipuWLqm0Sw==","signatures":[{"sig":"MEUCIQCUYxHp/8oBUE+5Ye0CzymwbCPTAwHR/jBDxApyETTMPAIgLRSJm3LPb20muvTp3pMCegQ4AJZpnhH2b35EFgdpSxk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f2e24509334f9ddb45ee2b9314e3b867e6ce8f8c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.1","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.1_1689778153850_0.33123572048535266","host":"s3://npm-registry-packages"}},"3.4.3-beta.2":{"name":"@crawlee/linkedom","version":"3.4.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"70dc7527c6157e0bcfdae399de21ce8f4c712e82","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.2.tgz","fileCount":13,"integrity":"sha512-8RjiXGKsDXE+BUkW48rz9i3vbxwXjjwu+ELOhrmtCU0GLF0L26yP+NCuhXsafPJt66Wk4Jc7UQ5YZWBlyPz2Ig==","signatures":[{"sig":"MEUCIEHPe27a9ebktanbCyOju7IOjsEFCQq9LT4PSY5aW+rCAiEAzyywZxsM1qOy7rRSinM7ufHG1PZMS7OGqgh8hx7wFD4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"81cf4dbd3d2f4ced6e19ef8d6eba93122ecf2347","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.2","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.2_1689780224520_0.5424584847969696","host":"s3://npm-registry-packages"}},"3.4.3-beta.3":{"name":"@crawlee/linkedom","version":"3.4.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"45b53d8802e885900b72cf31e8f9e84b1240bb53","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.3.tgz","fileCount":13,"integrity":"sha512-C8cCNHoe8qWxdsOxcR73yHu9peyszlPwFXuvBNJSa+e671Tl2Ln7madPKrpbtK4kWd4LBD8+5ZRiQ0gj98WkrQ==","signatures":[{"sig":"MEUCIQCTdlB0bKR90VaVP58Aze7303TlyDXXCr8/Zi8pzZTNcgIgcMxRQ7D/fUTFI80wnzbYtZLP9YsQgaGlPi1Jakk8a20=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57b00c5653caa0312226ea2458a2425aeed96b73","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.3","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.3_1689784331938_0.8030271233999973","host":"s3://npm-registry-packages"}},"3.4.3-beta.4":{"name":"@crawlee/linkedom","version":"3.4.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"efce1f01cf3316822e2ee349f55ae13e7421585d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.4.tgz","fileCount":13,"integrity":"sha512-JsitXSw3GIxKWJxQ8lz76yRGipnjvUhWKa4ZBRim6xPV8Btop1B/Wg7NfP0uuFBol3qY17HQ5iZV6fNH99OG3w==","signatures":[{"sig":"MEQCIGlBKq95Ka+HZSAzFps8UmAfgSFjWvRA5N1hZcza22jaAiBtXN6LPKJjlLSUNkKQGXaGwoFmK7tLitMhAVl8bObyrA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"14cc64c3593eea5cd78823d3e06b7c2f1664f20a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.4","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.4_1689804127231_0.021598960649886534","host":"s3://npm-registry-packages"}},"3.4.3-beta.5":{"name":"@crawlee/linkedom","version":"3.4.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4867a2688eadc84cd6b2834da47893ae5dc8972a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.5.tgz","fileCount":13,"integrity":"sha512-OtyAJn3hHLGmsqFF9QxtkDGVqsmr97+pAu+bWDnDMmhHZJs+bO+blSOLJJMu0qyV6TH9BAwfPIYnNgN/ybHU9g==","signatures":[{"sig":"MEQCIA/xBh1PiJEQRdIr0xLXKDuvCS/pAXGdvN3G0MH0kYDmAiBij8TSpzfvs28ZzKq2dL1DM2Av6SLdNG6yekTrgzgz4g==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"38cf72966370c5cb064478869f51f63374b26cd8","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.5","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.5_1689859788442_0.7811124803349216","host":"s3://npm-registry-packages"}},"3.4.3-beta.6":{"name":"@crawlee/linkedom","version":"3.4.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c05b7a62791762799e4ea503604c70a1823dd528","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.6.tgz","fileCount":13,"integrity":"sha512-HlgLXm5Buj1lZ+tuwBLj/+tHwSsOV4R0Ak+4qxzd2yJLRKelGmR+iA3EUTRgGw7oTg3AwgMwY/wlPPqJnNjBtQ==","signatures":[{"sig":"MEQCIDtps9q26LtqmClrIyqmyigWTzNLWYLu7Cfoy25PnEzVAiAr2Yc8GGlYCmwLUvC4XBNiIYc7bMBjZVsLViPWlrlGpg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"913fba71a1c37a2930e9d10c9180c1185e347e01","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.6","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.6_1689866712603_0.80997645578328","host":"s3://npm-registry-packages"}},"3.4.3-beta.7":{"name":"@crawlee/linkedom","version":"3.4.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"32657e776912fe89214cb1108551aa77abc1ac0a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.7.tgz","fileCount":13,"integrity":"sha512-sfQDOKcHUZOVN3mzsp6GTbyYzPE7zNApvj9esHWj4RBuiKycmcwBOkyPu5jzAC/MpPBY8Rof8w6H/Rnpp0ZrtQ==","signatures":[{"sig":"MEUCIE+k1ebdVzXbDjCsTXilvefwWcsCW85Oi1+gQ72yIDuQAiEA8L4evBhlMqjRE68Ltehuy2TgP35qfri8koje7Yq/kB0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184665},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2cd30af41f669e461c0827a3d39d75845f79af76","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.7","@apify/utilities":"^2.1.4"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.7_1689868916909_0.03228990774388496","host":"s3://npm-registry-packages"}},"3.4.3-beta.8":{"name":"@crawlee/linkedom","version":"3.4.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cf490e265cec96a245bb07768101fdddcdcf4422","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.8.tgz","fileCount":13,"integrity":"sha512-w7eJdnH2NHV4+OYyCXNZvi1/f8j3t3mrG8GVKO5udJnFHqge8nKhEymVwN276Gz/yjB0wVdGteb2cYuCJIzN8w==","signatures":[{"sig":"MEQCIBIvJYg+f21ThEKRdrAi255+QnJo0OrAAurbLKuP72lIAiBvfHcfTKVHkuGlJsw9e9sRuzVslEMyVPI4HhfslqaI5Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184666},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"187668b7af7b54ea884a83e2d1f55401197a4237","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.8_1689893281052_0.9391847297802989","host":"s3://npm-registry-packages"}},"3.4.3-beta.9":{"name":"@crawlee/linkedom","version":"3.4.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27b9c7e13ecbf3848f44dfa075076d76e4560982","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.9.tgz","fileCount":13,"integrity":"sha512-aPfZxxav56xQhVG4y2wzo0kePl0RRLtekiWL8OnYX/3PVgn8/Xnpghpe4a2ACq1SnXxh7nERKJVgloM/jYDg/g==","signatures":[{"sig":"MEUCIFXeKk7Xma9fn0IzycqDbXJrute9/8ci1oPs8pvi9MVpAiEAkPRNmIW/6bjXFm4va6uCJDkmFqneQ+IBm5Hzek0Y8vk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184666},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f458fae0d47abb8a086b91cac3db1aac4ac8b023","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.9_1689928382131_0.12831216935084466","host":"s3://npm-registry-packages"}},"3.4.3-beta.10":{"name":"@crawlee/linkedom","version":"3.4.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7b0257b2a75080438a35ec27c19aa647bc108f94","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.10.tgz","fileCount":13,"integrity":"sha512-/2r6KhZDFExQWz3OKxsnlc3xnr5uq+A2WT0/bHm8Ji5qgy44gzwtOJh4AmYoJx1EtyMpaY/uaSlxasbSRg3qHw==","signatures":[{"sig":"MEYCIQDtKl171lGeYhSvMiLZ9bh+GBrRFavd81fd85BVq0aOPAIhAK2DKB5EcGxjnaHo7sqcNXVef/8dh5ZDpOZXzFYXwzrk","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184669},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6e3aeec85c8c32d189dabd4b878ded760868e3ef","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.10_1690189540843_0.326213264604291","host":"s3://npm-registry-packages"}},"3.4.3-beta.11":{"name":"@crawlee/linkedom","version":"3.4.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f01c09dec3a0e80e78e2b3817023b1bb912d57d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.11.tgz","fileCount":13,"integrity":"sha512-X2oQ4wHr2bUThRd0fYxV1VD+eEX45a3wMYfnLNM5VD6/zqoOpYVm1Nxc8oxj8QShNarPgYsjKrDW5L8VgnNK5Q==","signatures":[{"sig":"MEUCIHcApV3Fye0sbgQX9pV0gynXudoCvm8sAs3O9e3aMOHSAiEA+YCERZd/tqRTPqqqAWMdE/SRXLNjZSsf0p9rc7cTq6c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184709},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"830b642fbd31c333bf4391f283fd2b381b10092c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.11_1690198717709_0.1998710774517587","host":"s3://npm-registry-packages"}},"3.4.3-beta.12":{"name":"@crawlee/linkedom","version":"3.4.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e5648cfd38c05dee0ea45cd5f0624ac82498722c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.12.tgz","fileCount":13,"integrity":"sha512-LkOePC0Imz8pK2shSl7Ydv28jZP8ejq2whEV4ZhFinzK6meqt9HEEllz5evvTbduwyVxFql6qgqiGj/N5zuqOA==","signatures":[{"sig":"MEQCIFUvlEJKu1HCbmkOKEBbPK/JkQOrtgLqiTZ3lxDBHOHkAiA0+k8T2T1TrRAtFtQ+gkSf5LOFBS8rxaQLluTQobMafg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184709},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f30d57ba2d4b900781874fa83f53e81b04a706ed","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.16.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.12_1690247648729_0.7988505729800133","host":"s3://npm-registry-packages"}},"3.4.3-beta.13":{"name":"@crawlee/linkedom","version":"3.4.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"690d962cdcc22e091c80a03beb90830f8fc16832","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.13.tgz","fileCount":13,"integrity":"sha512-r+n6FnmTaZzJgvNRyPAQbMCkzk+6BWQPk1uYkfcXNkIGCCeVKC84cLJ4Ou7fX69JbQujAetUd1P7FoZFH7yylw==","signatures":[{"sig":"MEUCIBB82jWmV3fVGH/e7/i6zcVLoIHCMbuMND96KOwvaHoCAiEAowOcKwxrbJ+vRFS3DPPAQq9yEcTJ8DxnYVCbeQFC7lc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184709},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eebf788cfd2e66f1200f9c84de60feddf5409753","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.13_1690348712682_0.40257164433200954","host":"s3://npm-registry-packages"}},"3.4.3-beta.14":{"name":"@crawlee/linkedom","version":"3.4.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ff01e11f09dc260f6c9ecadf5b1efa9b205179a0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.14.tgz","fileCount":13,"integrity":"sha512-iAhmi18wI6xA3CQOKlIOty4It9dhRF+S7Brrq0FeFgDBT2W6ae5phKxxS0tYbH97qp1jQLSYL2iMfhto+DhWSw==","signatures":[{"sig":"MEUCIQCgwiqmKtOntkSXd7dcnYsYTKu+gJFlhorouSPBz6rFugIgFnhlV5J55pZQdJM2nOlKDfFiue1m+qDmqEpBb339ejg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184755},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c1c66c64d0ecd5cad33aaba3390178e2ba621bf1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.14_1690382013590_0.29342336111512535","host":"s3://npm-registry-packages"}},"3.4.3-beta.15":{"name":"@crawlee/linkedom","version":"3.4.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"04fd773a47d3bb82b868a95417e62defb5efee77","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.15.tgz","fileCount":13,"integrity":"sha512-AmGQ/LoMygOUySlImKc+4i/v7OKPkiwaN4/eUuYMC7Y4mj/eGD7vQDtwwq00s/sckGprMiwfuHYUGW55N8P/GA==","signatures":[{"sig":"MEQCIG0n/h4/YvbD6Xx7tNBi8uJomILk+SMGRKgcYa/WkZhMAiAUnAIJxd0HXj45GVcXQPDKygW93UwCy9D9ikqGcYshhQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184755},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"147f6405fd213079c9225f97568b2496f6e7d914","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.15_1690473119509_0.138909377135654","host":"s3://npm-registry-packages"}},"3.4.3-beta.16":{"name":"@crawlee/linkedom","version":"3.4.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d910251098a421c21039237621a6d07e3dc54e9e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.16.tgz","fileCount":13,"integrity":"sha512-A9zGmJ13hDciKzYXTSuUmi6/163Fp5Vx4ovMwLNTf8RGpPjszshGq66oclQnvNrdfoJvgZ7a9i1pR2blhmEBwg==","signatures":[{"sig":"MEYCIQC6w1lOojQTMMyjS95OrqhZvvfBWtaNJhbMlJnDcHLDAAIhAI6S/rjBcpcBJgD+5ZZfAEP3k2sIcai/M8fDJ2zGKy/L","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184579},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6edc134053908e1535492babd1be090183e84bd6","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.16_1690549254776_0.5654198522488934","host":"s3://npm-registry-packages"}},"3.4.3-beta.17":{"name":"@crawlee/linkedom","version":"3.4.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.4.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c57453559ed225ae7dae06ed4d0b48eaa40d0290","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.4.3-beta.17.tgz","fileCount":13,"integrity":"sha512-S9Wl9LjIZESjuOktlHP+IRSa/CQO0lsZ/ivtJTP6neT/9Tz+wvqB1zrwQgoWq+cFEutrXuKva5handON2hW3Ow==","signatures":[{"sig":"MEQCIHeAUK8vFQPJe4kSdfFPcO586kjtv+aUKpYQivjg1oOGAiAzjJDVjlBio+UGAGdPV30hwFhiTL71wnYCvtAeA8vOyg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184579},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ce454f640d6a32065e53a0d67c9f01e5ab7a060f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.4.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"^3.4.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.4.3-beta.17_1690785355917_0.423984723575483","host":"s3://npm-registry-packages"}},"3.5.0":{"name":"@crawlee/linkedom","version":"3.5.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7acfe33031403847168380e2ed701393ee12b665","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.0.tgz","fileCount":13,"integrity":"sha512-qcrseTwB7mrIygephCFRHbedbc9eNzjIq0v/kZBnpR2VWXXugD7yhzz3zZnY2whETDiCju9Yhj+jHFtPMDYpmA==","signatures":[{"sig":"MEUCIQCVuSxc0ccthYyYtdouP8tgQwGG85G4o+UekflBhmCp0AIgecFkZ419QSrxJlJbqr2ljz6DC5TzduHmWyn/ZaL5foo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184555},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"58cc3d4a74ee8a5e62672c38e88d722bdac90ecb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.0_1690786506783_0.874776935667569","host":"s3://npm-registry-packages"}},"3.5.1-beta.0":{"name":"@crawlee/linkedom","version":"3.5.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72e564e715d73c454aa7de81b1e32a3fab5b1e68","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.0.tgz","fileCount":13,"integrity":"sha512-w91u7OKJrfw0z6DPacureF0+1BA7vgCBeYjsO63FvhiESldoPgbWh0hUzA7AfnM5Z7hhsg/bwfnM9LUez2Cw+Q==","signatures":[{"sig":"MEUCIQDs1ac15PnPsVcBm6niRiJJMXBVES887sKQsJ+zKVGDPwIga5mI8bUXbS8FCaKVUMluRfYEnFLpDppn/8Kz1FkEU4U=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184576},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3628d02dbeed7c3ece4c823e6b34929d70a529f9","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.0_1690787544702_0.411306311846112","host":"s3://npm-registry-packages"}},"3.5.1-beta.1":{"name":"@crawlee/linkedom","version":"3.5.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b3828c2eda5858d13aed84dc4efa66fd4275328d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.1.tgz","fileCount":13,"integrity":"sha512-LC2BxH4BqvylCYvNzpw8hz/qt3QUOK7ufNcgGKYI2FivqSfGd/xWV2i400VV8spsq81wsi8sUqnsG24EsRo5tg==","signatures":[{"sig":"MEUCIFy3BOZAYF8OaNC51XF4eZHBRKZG0qDARYjWOWTdT2GKAiEAlWs0Um3wq2OkKVM/q3W4OomqzsLk2n7cgDU/x3QasYQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b31f0bc27ed9655e8b06ec34913e5eb5d48e4226","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.1_1690847266868_0.21177740267296197","host":"s3://npm-registry-packages"}},"3.5.1-beta.2":{"name":"@crawlee/linkedom","version":"3.5.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"06d0b5d1917aecafbf44c75a42e6bc44244635f6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.2.tgz","fileCount":13,"integrity":"sha512-BP7ewTHOPppRE4i6N+F3b9MuALVkT2HmykbgZ05RLi7ICCEUmlG1FJlpdtQrg+r66r+lYgFkeOflScgTzJZ5MA==","signatures":[{"sig":"MEYCIQD95UUE4xZQfn2KhXs5s0vj+EjXSEhmyD5J+/9IiKkdcQIhAKOUCmtwyAlbd6FyMYRpqM37rUeg9OPe/x077z9h0KmB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"48326bb85437ff8d3b91d8fb2778b279f5ed88d0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.2_1690991842474_0.2558029011399465","host":"s3://npm-registry-packages"}},"3.5.1-beta.3":{"name":"@crawlee/linkedom","version":"3.5.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fc9e82a9c735d838ef75e6ea51f1e7798159ca31","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.3.tgz","fileCount":13,"integrity":"sha512-Wdf+ja7d87g5CAWedoomRDY0N1E28E6+ceQm2YiACHhUE8G25KgarvHqqGfvszjmyfsIpr7OuDDZ5XM0dVdWyw==","signatures":[{"sig":"MEYCIQCfG3VY53XBfM1ygJnkUDGyjqUIe9yugCkDuTA7Yzx1RwIhAPepwh+9FvFFavajUq/e/IuAt+uUbqCcQLL2rMoECD2T","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0d7e5f9ab898c65159571d24bc7e8a8e779af890","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.3_1691083476183_0.5798576324212046","host":"s3://npm-registry-packages"}},"3.5.1-beta.4":{"name":"@crawlee/linkedom","version":"3.5.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ba0e72e262507bb77c7ab35100482dc528590c0f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.4.tgz","fileCount":13,"integrity":"sha512-1YoSbNQFDrYwcdnC75t4U0JKFFnjYJZechRUrBuwYzuTCvofjrmYzInbJYR9LMZoARw0MUzUmosHNwjoH2TuzQ==","signatures":[{"sig":"MEQCIBjwvQK+mg3MTsFLaKlHXjyD5uujB5v7jHifXvhwOkDuAiAFQdA+9qcEuR1kkqcvJaxN+l80iW0s1erWM7WJxThg1g==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ba6f6f914ebcd2fe35d53a75cf3881e65fa89a53","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.4_1691153226050_0.3655556346277449","host":"s3://npm-registry-packages"}},"3.5.1-beta.5":{"name":"@crawlee/linkedom","version":"3.5.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"097d94b430b7cc3ed04feb195e92ae05e97bccf0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.5.tgz","fileCount":13,"integrity":"sha512-38z5Pdi+3zutpU3SJlZi+OW6et9wtvQp8cuQKpf4ydZbSH7Km8zUfLEOPqRMJlPuxnxDxgIYMcbuB/RucT0I0g==","signatures":[{"sig":"MEUCIAtXxlg3FrjatEnWdBgqQ3ffgheK7JINAoApFlX0k7FzAiEAwdbsxN1NKF4P/RtGzqce6pWuEn9lr/DR2N4AAthf+mU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"da0fb85fa9dc32be7054a5dd52f3e3949debd347","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.5_1691450621149_0.07266867830047286","host":"s3://npm-registry-packages"}},"3.5.1-beta.6":{"name":"@crawlee/linkedom","version":"3.5.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6ee9374e1e3974e23639d5fee4950164dc75dd97","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.6.tgz","fileCount":13,"integrity":"sha512-JEPy5hXbpTwRX2+rxBX4jC+jz0kmXvOo1+sG3jdZdTinL9Ypy4/MceEGeWk5QdzvCJYIESoj6uAjTYo3t4Vc6w==","signatures":[{"sig":"MEYCIQD5FRxXhaehASU97aIphFimj1azT19cIZumwJLE4TngigIhAIZvGVX9bZejaJWhm0Vy6QbcQAjs1VNPTLxOgUq0SASE","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0a8c0f0e379d93ad2ee7bc90cf4286a5745d11a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.6_1691525065868_0.5515402861689975","host":"s3://npm-registry-packages"}},"3.5.1-beta.7":{"name":"@crawlee/linkedom","version":"3.5.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"773e7c2fef14ae780b331112b4186810f63646e2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.7.tgz","fileCount":13,"integrity":"sha512-0HI+q9TGnWmbLfldqQiCOrgS5qUsxA9ubfvLdBdjq3faDSmHvGgJulRh/2Wk4Ka/WRS7bLX1SVMe9Q6bpkCV6Q==","signatures":[{"sig":"MEUCIQCG561ojhPOwLps8VYJ3KAn17TgbpvCJWB8uN4KwKuPEQIgM45QU1krpNVAeD0Ot2ONonsaETTGp/rZxbibukINP9I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9f6630d2a29f7c770b150e365ee50c6da7ee7c42","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.7_1691595161593_0.7432089338572501","host":"s3://npm-registry-packages"}},"3.5.1-beta.8":{"name":"@crawlee/linkedom","version":"3.5.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5f5a0625d72654cc697e316e65d6df06c5ce14e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.8.tgz","fileCount":13,"integrity":"sha512-XrQ1ZoYZnlIzuFtgQJqxKu4zWt9PzCX4W3VH/c5IgKdjloC2TBK+ixKAqyTdSnrEMQ11Df5ZXIt50Oo0ptVU+g==","signatures":[{"sig":"MEYCIQCK2rBYKmPoUex95RYeEQNWY2OnPP3aZza9ROb19rbq0wIhAO5u60HzUYIiNAzBKxNAjbUxqJQzanw2ssvbMknxDbCg","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2cf45997620dc92537542f8bd6c5969c28be9e12","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.8_1691620053531_0.06377742860346203","host":"s3://npm-registry-packages"}},"3.5.1-beta.9":{"name":"@crawlee/linkedom","version":"3.5.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e412062e75fc1dd1e079b4c27d13740cb4cde9f3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.9.tgz","fileCount":13,"integrity":"sha512-Gy0gl3ic+InvDkuQDoyr1oltO/HMDbwzqiGF5wj4TYVOfva0ODLoH4SzaxiFD69kbBD2vkpn8T17x6JQt+dqww==","signatures":[{"sig":"MEYCIQDmVP4UOQ1lH8C3h5MJKXy6jUIUZjGrae+BPUC39A+/iQIhAIfk+FG04pq4OrZ+1ZQ0kaqA/T3GJpdmCMF4hzc7GEkd","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"345e98095fe1c48cda41b88b28658c36bce5a13b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.9_1691728642449_0.9194624761361814","host":"s3://npm-registry-packages"}},"3.5.1-beta.10":{"name":"@crawlee/linkedom","version":"3.5.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a9403ddbf9e312aaa8398e1201922ac5e95d7074","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.10.tgz","fileCount":13,"integrity":"sha512-L6c9u30pCYhM1tkd54oduNGGky7Sheop5zXdR4CSV3DVsvXNoimZ330iU9ueDs92R47GcmOY2FyALinFIvSMAA==","signatures":[{"sig":"MEUCIQDWmkUYR9T2J+68IC5hm7uUe4eIZkQ1PARv1t0rqSHonQIgHFbZ4l/RaVmqJ4fdbKQZ4e7DL/SXzfA1AwhEzyo8OrQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184193},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ea38689ab2c8209235caa2e54645ef6f62a83ff","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.10_1691752435266_0.7684689413872938","host":"s3://npm-registry-packages"}},"3.5.1-beta.11":{"name":"@crawlee/linkedom","version":"3.5.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"472702628d7ae29a6a8fd7db5fee6398c209c8d5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1-beta.11.tgz","fileCount":13,"integrity":"sha512-RluYzIgtKmpNQYtebRnLTP1aRtz9r220ew8B5sdo77eekEwSNKtWxWx6w/ZlPBSbmemtyFyhfC30TsKgGS7k6w==","signatures":[{"sig":"MEUCIQDQlESWsW6VPv9nl7ZOfWdaeg6d67dH84BMsf6CBWtO8gIgFCS2lFo5nx0+gTCQM6A2zz0jGKwPzWkpJa3qe7zhMv0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184193},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aff4107be4ddeb462e061a8b83d68b36cedaece0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1-beta.11_1692051065427_0.4152878754291436","host":"s3://npm-registry-packages"}},"3.5.1":{"name":"@crawlee/linkedom","version":"3.5.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1a0a67a39d885ea79cc7e3e6b59520de09d05d39","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.1.tgz","fileCount":13,"integrity":"sha512-WB7zxGbQ7NoMkjgVbgufcjVdogeKx9N/ys0VCNMXsYkVAwPcSlkHiKAi1dCGYoI6r/ePrWHLmTmgtxD7CbXtVQ==","signatures":[{"sig":"MEQCIEcXSlHh3G/kUFnjhvLx4HxeLKhS1w0GzR9+Yefi4QeCAiBypcS21DD9E7aMDgkxhTGzesjvkGKiYpVJ6nQlfVYBAA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184169},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b389ccdca3117f8466ce8a3892096a429817781f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.1_1692175782952_0.40188823681896246","host":"s3://npm-registry-packages"}},"3.5.2-beta.0":{"name":"@crawlee/linkedom","version":"3.5.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"284264768f19b6098515e2f47c6a132adb7c2ebb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.0.tgz","fileCount":13,"integrity":"sha512-UWDXZJpfQ9eXv29ZGLah9tTZC0lTsj3jZZgged2w2T775jbC5TR29CpUUGUyywkd0Cy8GZijD+azrxQKQVf4lA==","signatures":[{"sig":"MEUCIQDbhIMOd7K0rcfNMDPjm9Wv3MKiJNht/bXxRJJO+7mmlAIgOZG3AXcXIaaeybCwafm9j5SDKlEf9/eOrIMmv74IQVY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a3be5ab3111ef0812d728de8e39e5210be501caa","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.0_1692176939433_0.9723765541582516","host":"s3://npm-registry-packages"}},"3.5.2-beta.1":{"name":"@crawlee/linkedom","version":"3.5.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"911ab8798cee4f0ed86e7b63750d2966a965e675","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.1.tgz","fileCount":13,"integrity":"sha512-gnOXauh7z5n7bY5HAx2KZhujElq89MF0HWSn8gKyh3SlGQMzPB+KgbcNiMyhFvFvNHH852N72bd6gJKa1kuHWQ==","signatures":[{"sig":"MEYCIQCubULNx/r0rRgIEsAl8P2wwAbA7MG4CzWFu/Y+6c+V3gIhAJsP8YK886RbUUjVEKQfWjnosCWzq+y5uS1C21CuwgEw","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c9f1ee6fea5b05a6aa3bdf7c3d9d4f9e66e24c58","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.1_1692319744089_0.22663849765225286","host":"s3://npm-registry-packages"}},"3.5.2-beta.2":{"name":"@crawlee/linkedom","version":"3.5.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e4bdc938ba7dbc33c6e48be8f6241c176ad0454f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.2.tgz","fileCount":13,"integrity":"sha512-qgbEJE8X6eKlJ3VXeA5dc2hRUr8Cibe4uxuWvT31OXqU2pipYoudLkkovQNPLTW4l5Qj0MPBbsD2OkzYoSo8GA==","signatures":[{"sig":"MEQCIDeUXmnVMM2THWWjbB2Jedudw4zZCDP96DbP7aPpokD6AiBJi1mjy2kQ5E9msLvqv4KXup0RHKipgiJ3BU6ANXUyKw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3a1499fd30edff9ccb032496cfac8abc9730e2b0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.2_1692358201096_0.08439035592794464","host":"s3://npm-registry-packages"}},"3.5.2-beta.3":{"name":"@crawlee/linkedom","version":"3.5.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8315395406a298d2aef3903af61b177556af772d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.3.tgz","fileCount":13,"integrity":"sha512-+OmpzFD/34d7o1lEAJE1AkIK5hS+yd60QtRp+2p1V6pZKspSkT5gpy8wmX2Bqbz3Dbd5TPCRHGlUtd+fYJJO+Q==","signatures":[{"sig":"MEYCIQCIT9atvhLtcci1rr+fStIn5MfYvzODyUhoWiaLMv2T9wIhAO3CVThYElDqiC+0c/HOu/HiSw/UAQKAa6Q9TyGm2Qnm","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0eec22f6c98eae77fb998f702a61cb764be9405","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.3_1692368343954_0.3858465347313522","host":"s3://npm-registry-packages"}},"3.5.2-beta.4":{"name":"@crawlee/linkedom","version":"3.5.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e6b27649e8e552f14b7d2129d4a2f9827520092b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.4.tgz","fileCount":13,"integrity":"sha512-E3LzRvD5SgAPdaya0NvnpEb0zctgs8+oPw2KVzZ1Ez7EtTXwy/GJabhBhXU1aQwUS1IfgU4/cKaDvWB+UKtxOA==","signatures":[{"sig":"MEUCIBavdT3r5Wx12jhuuU/JNTApAggY6hLs20JJp3WxTqZlAiEAiw1TfCugRja+6SVxz+3KYKnefYGd1d3XSuIbaqNQcGM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184190},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b1cc799517c38a7da1e60a3e5ee0d3faed79bf5a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.4/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.4_1692614336201_0.7207257659816018","host":"s3://npm-registry-packages"}},"3.5.2-beta.5":{"name":"@crawlee/linkedom","version":"3.5.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"89f62d8fe7e0ecb813275d4d1e0f09d2a1c4525c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.5.tgz","fileCount":13,"integrity":"sha512-MpCYqJvCaZCQ4MaOX1QEa9y3/OzOtmUNR0n0Sjcz1ubZe5y89MZfbzCuj4TNDS1bsycxDmGU9mNU+J6mtOG4JA==","signatures":[{"sig":"MEUCIB206m9WFg5fXBW1HvtZhNGIXcO9ybe3+bHaMlvZDN6ZAiEAmUS6LYAR/WSnjYisnund40fWpbFzhxeY2S6WVKI4yMU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184698},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b2a89d3731d501b914cc4c14ba9d7c1d76866749","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.5_1692616283767_0.3157689148078284","host":"s3://npm-registry-packages"}},"3.5.2-beta.6":{"name":"@crawlee/linkedom","version":"3.5.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27c5dfbcc062d79b5359b97bf1c8e34beb46ccdf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.6.tgz","fileCount":13,"integrity":"sha512-p9sFI9r6SG5PVTKONsVgN6QxiK2+M1nkwWPL8TDv0n+Thr7b0+4kEU2hN+nXh4LvNrO8+za/qq9Ep+vYaPuPjA==","signatures":[{"sig":"MEUCIQDj09eM491o0ziNUGg0CMS4wJUKhNgKqss3GIpCHguYBwIgTIj7Zsm2z+9MwtrXGY/0S2451QKuPhyktAeIZdWxsUA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184698},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eadad1e4cbce810aefd4cf30c7541fc4c0b335e2","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.6_1692617740915_0.16200959674874227","host":"s3://npm-registry-packages"}},"3.5.2-beta.7":{"name":"@crawlee/linkedom","version":"3.5.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b98743d4e2b3994df017a1284e3867c1de4b4f60","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2-beta.7.tgz","fileCount":13,"integrity":"sha512-X2ZVkqaheEZDCADHCyuT5M/AXlT8lt2LTDsvFXqy+HLTI/3Sl2iLCVmKTHfLe3mXE2GHKIh0nLsfwugTeHrReA==","signatures":[{"sig":"MEUCIH58w17vrhOo5Dl9HMHUVqixHB5kMgY6PvbzoYSGscpRAiEAuPQZv0qZpJPYhGjHY76kx5HHA0VN3hz9HvABmGjHMgI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184698},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5faa8971b41fd92291a6784c5bc03816d880d4bb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2-beta.7_1692620863817_0.9017145685631676","host":"s3://npm-registry-packages"}},"3.5.2":{"name":"@crawlee/linkedom","version":"3.5.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"69ca72a0e68822bea3e67ed3184f0f20afc69fe6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.2.tgz","fileCount":13,"integrity":"sha512-2RTLshgdQK/IawM8OfWZ/1PgS0FfTg4I05NyDdZnKmu0+d+EZ+erV+c5wK3ylMMJa0/2kwW/VWqKoaD3AEQ/8A==","signatures":[{"sig":"MEUCIDYqjI5Y3xxCrusXh9iP7Bf97U37D+Sb4WxvDSLTwgayAiEA5txv6bHE9IC5CuZ81yP+fNfWGhJhyMkNh9cvTcjwcbQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184677},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"37415788f3a019b1e1217016918ad0186a006394","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.2","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.2_1692621720973_0.26209218252524225","host":"s3://npm-registry-packages"}},"3.5.3-beta.0":{"name":"@crawlee/linkedom","version":"3.5.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5837355046db7c721b686e4148ac991d4b192427","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.0.tgz","fileCount":13,"integrity":"sha512-YMHs36y/wJv5QjR9l1ryvPpD0LHMU8psyXMnYlAYQchdGwJ/vNZfE8p7+2dJYIZZFKyAJwARKc1g3PkbogAelQ==","signatures":[{"sig":"MEYCIQCOrQGv74s1RfBnfsYV9DzmA1Rh/5HqX+alppWLouNGzAIhAIAdxlcsuUOImtV1GvytbhLYT5W8Hvbb3oDoUXaAmB5n","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184698},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5a85495addb5b2d73b7c2c11c78a56b8adffbe0e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.0_1692623561348_0.20177306581717458","host":"s3://npm-registry-packages"}},"3.5.3-beta.1":{"name":"@crawlee/linkedom","version":"3.5.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"818ffe0dc0e523edbefc9c7115e2c1ade422cb98","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.1.tgz","fileCount":13,"integrity":"sha512-kk5FCFz4fmfaB1SGWrHp+AfSPZYlL+yhFqYGmJv0Euw9376hB31bJKHGcljS+tfR4nTI4xEab+o55PRCEqdDLA==","signatures":[{"sig":"MEYCIQDq4viCc8qhqu5La/MJTci5dZPBOlj1/J6gBO5Rgo2DsgIhAMhYfDXsJO1y+eoYRH59U1esZPkR+IovGoBD7dwopgME","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184696},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"deef2d53395753cdf6e7c5f817da301a07a5c39a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.1_1692638592158_0.22556179462743242","host":"s3://npm-registry-packages"}},"3.5.3-beta.2":{"name":"@crawlee/linkedom","version":"3.5.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4c67404fe2e0c78b3b9df81ea43600d162b65722","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.2.tgz","fileCount":13,"integrity":"sha512-Pim6gKDWUERTRYhaDDXcI2gP99glTo5UJDFuGS3gZ1MAtxD5jcQl+dpK4gxbMEWINEmc8vVpSBKpVrkQtwW8OA==","signatures":[{"sig":"MEUCIQDiXcdrxea4UqaTsZe6bsNqF8XEZqGbIsuoFcZPIZ6sFAIgEVkV6aGSp82jbFL1faH95oxU+oe4ydSXikoxVh/Yzqo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184696},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cc2a6fbb743eecb9c4f7f7a371079b433c025efb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.2_1692653397933_0.6289886576221397","host":"s3://npm-registry-packages"}},"3.5.3-beta.3":{"name":"@crawlee/linkedom","version":"3.5.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7a3f73f6751b0305ecd128bc5d826964dc00cfc9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.3.tgz","fileCount":13,"integrity":"sha512-79ug9tQU/4OkMS0JlYAIlGYBf2QIAtuq5e739rS+PAH1pWidLvOJixEjpV9tt1sas/yKyDAWkbQR0uDptX3q7g==","signatures":[{"sig":"MEYCIQCkbFML8U3U6S6PhmJw8vDqosyyu+my1IZxN45hT5R1BQIhALTM/cezmvZ3GhWUXZ5URYlTGcCoxOiB9++rSmob34Gn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"70bc910c4cb3b7f72874011a255ecbcfc1258562","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.3_1692676789550_0.316757172709325","host":"s3://npm-registry-packages"}},"3.5.3-beta.4":{"name":"@crawlee/linkedom","version":"3.5.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ab8de564ad66bf1438ae08ee491a3c1f0d470ddb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.4.tgz","fileCount":13,"integrity":"sha512-8/w2Qsz2LVew/yquKohSkt7kT236X8djkRBtn7jO+6tTwJapJqmQ7vmQ5voxudqm7jSGLaSbpjEQbBCk9A28yA==","signatures":[{"sig":"MEQCIEHIu+o15ktfpkqRMFTKa1vXEWEmDj9+YUx/XP91tWx+AiAsOtZWfNK1Drh4TZA2p3nF7aQm2higIQAF7dU7ipY+QQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1be04e1008b88fd2576d219a942ba296d971c557","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.4_1692765033845_0.5255765197725122","host":"s3://npm-registry-packages"}},"3.5.3-beta.5":{"name":"@crawlee/linkedom","version":"3.5.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad3675e0625f9cd3a523385f08173fd6b2e663f9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.5.tgz","fileCount":13,"integrity":"sha512-TrtnKLX16ggqFD83mrnfNP9Gm7S+nGq+B4Q0vkwIv4LHj+2D4PzlxR22LBrVax3mtCRATD89XWjzAVDiSr04pA==","signatures":[{"sig":"MEQCIDFigmq3WtmVMSmUhh64Pxume9jqEcvmI3HXQbZVzgAoAiAWAqTO9YTZtHAAvtwTPOlolUVLZ0IWozse9Fs/x33SLg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"36ac6b3a8131eab21174479efebb0d2ccdb272f1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.5_1692806087754_0.5910552518735441","host":"s3://npm-registry-packages"}},"3.5.3-beta.6":{"name":"@crawlee/linkedom","version":"3.5.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad22e9dd03c578b52815ce37779aa9eb39d16a34","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.6.tgz","fileCount":13,"integrity":"sha512-ZVJilBgvYrOYTEzIVpL3Q650fkjRNOS1Ci26auovKKQFwGO8lw0cP1lrb6Ra+wXfpW1EJrM/BPN1+TP++CGCQA==","signatures":[{"sig":"MEYCIQDVXsDGiGn+pueNErn5RIibjEvWJnN61VvaYpK9GtKlrQIhAPaOTMb9ScBiaqUTQuzfvOh8hS/ZXk47PC43ir13jeNB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"711b82e52d2e23f8a7bb97d3100400cb2e79174d","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.6_1692845261178_0.2652836090960684","host":"s3://npm-registry-packages"}},"3.5.3-beta.7":{"name":"@crawlee/linkedom","version":"3.5.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"54eb28e7aba77ad68b72ecf6c506679f90a74905","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.7.tgz","fileCount":13,"integrity":"sha512-9T42Zg5SB+0be2nUnYXKPddte8K46w7w7IKKuPyTqE3Qn8URunK2+X3QG/PGwekDck7/aCHEnOWJeYVWrYvuYA==","signatures":[{"sig":"MEUCIQDt+U/PuoNn0XRmt0+wetSCFAikCq82x0AqiwZGVJA/wwIgfuoxaPKPGybvamWREwpyrrDv7erJ3qp9g4FoX7uC5m0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c7db737dc18b82e7307db198669765261b44d17c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.7_1692890369330_0.38305506376559495","host":"s3://npm-registry-packages"}},"3.5.3-beta.8":{"name":"@crawlee/linkedom","version":"3.5.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8309b8acd2b85f1f763213d0eb88219cf7bb3e2b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.8.tgz","fileCount":13,"integrity":"sha512-aWXLd/SU+dYEJAx6bviagx2m4FUGVtoR18dUiI+6Y0XzEGnqLIbS9F14j1U0sHegPevbtPs9PRrsPmua8l0LQw==","signatures":[{"sig":"MEUCIQC9JhgUX9eX6pae13GyMrAs2k+2Gif5cWwqHexaB4hXMwIgCxXLTHCMF1KlPy/kKwq/Ub9j4hDSjvBNM8GTCjaEJ0E=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f93cc7467e77381222d547badc2253f99d599b47","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.8_1692968553339_0.7017295891420425","host":"s3://npm-registry-packages"}},"3.5.3-beta.9":{"name":"@crawlee/linkedom","version":"3.5.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cc63b44f97849b984ae331f8f70d65b355cb1474","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.9.tgz","fileCount":13,"integrity":"sha512-3DI4liTm5BZF7RyhMgInKq4jzt5Z+H3T8E4K2spDPISKvu7ZKYeXWsr8SmEK/T1LjhZAypnPyJ1rMN+7PJAUcQ==","signatures":[{"sig":"MEYCIQC2ivSCB7kHfEmGum93cJwXVfRhNGmpwO1QiVqioO4KvgIhAKUlRlAGik/hLXg5Or9cXlLkeo30Cp3IGbP/ujC4g0Gx","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184693},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ff264695ca7e5afa0fcf36d2b7960a01f7dda07b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.9_1693264608384_0.485882089234944","host":"s3://npm-registry-packages"}},"3.5.3-beta.10":{"name":"@crawlee/linkedom","version":"3.5.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"284b160e0f8d9e5bc5b989d3a6644cb2b2151679","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.10.tgz","fileCount":13,"integrity":"sha512-kWv1sPljvcd6QDUFMVWuaM5Dx5PHYx7x6Rm8L7AiCkoNY5ekHiFat9re+rH9aBrMGqzuUgJgewqgTUOGTz2oaQ==","signatures":[{"sig":"MEYCIQDtASMD6p+GjjQgnQgqKfY6AX1ZDz49qZ2c5/zKx+VJBAIhAL2HQKkoQPulaiNAb+KyK3eSzUJFytUz62OtkmYqRe3h","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184704},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aba8718cad13a84b64dd197ad3e704824b217d44","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.10_1693313754399_0.004392693865064912","host":"s3://npm-registry-packages"}},"3.5.3-beta.11":{"name":"@crawlee/linkedom","version":"3.5.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"13cd9d0c4cd0bd0b35245705dcc5f940ba36c1b8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.11.tgz","fileCount":13,"integrity":"sha512-x9cm4Gw/gnATFpD3EgMIlXH7vJ71+EnxGDiTFAidaziINbtejl3w8X/ciGilZn/w5Z2OIzveGswTLxiYxm8lDg==","signatures":[{"sig":"MEUCIDaOKbzLstjK5AJxu6QrVW6RoY7c/xBv/1hNp0y7Ha3XAiEA/Uacl+EuRX1V+A9MUzuP4p9SPo+WPBqrg89uE70l5+c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184708},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"27ce91a16106a99285b96f6e9a29b27b5abd95e7","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.11_1693407288114_0.9182981329086095","host":"s3://npm-registry-packages"}},"3.5.3-beta.12":{"name":"@crawlee/linkedom","version":"3.5.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"885524026530e4e8fcf474100397b7662cdaee60","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3-beta.12.tgz","fileCount":13,"integrity":"sha512-z/EllA4NTEPXpKOb9qBIJRL2qRo4ZKFxZD+dQKOs0fxvqCmW3NbSLVOd3sMxbCYsM7LOE+3sU09MO7lfZ92v0w==","signatures":[{"sig":"MEUCIQDN6MnhjSmlScYZgJGiIFa0fuc62HutWjfhGXnQ53gXLwIgV7sII9EEigryYOed+q/GEtyiyKWEFEDtuY7ty7t3Dj8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184708},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"50fca923d23b885a4cfa3d6a19c3578f726a06cf","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3-beta.12_1693410874996_0.14781194854425084","host":"s3://npm-registry-packages"}},"3.5.3":{"name":"@crawlee/linkedom","version":"3.5.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c058033fd28c0e36733013214a02f0bb82143ced","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.3.tgz","fileCount":13,"integrity":"sha512-xAhvRT3iiKesrAYQ5mzRtzKqQI/2oq4MFOyU1E1IqyXaSYgWKAiO+ezcBye1ePM3dzbeJQHiQohc7xN3KpxQbg==","signatures":[{"sig":"MEYCIQCG2s9cBAQnjFcNsDcHdDMcL2aP1Eua2VBhwyXABuskzgIhAK23CWhgG3EUx2gNHVl8XAgT5vqQ+1IfGRQQeSPLgX0A","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"742f32efb9d3e40845c4e445274b1f99290f0f7f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"b4nan","email":"martinadamek59@gmail.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.16.1+arm64 (darwin)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.16.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.3_1693468407296_0.8852935450530381","host":"s3://npm-registry-packages"}},"3.5.4-beta.0":{"name":"@crawlee/linkedom","version":"3.5.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f11f7f5e94ac3a1996d6ef67f2f94810c703baf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.0.tgz","fileCount":13,"integrity":"sha512-0LyK6OGVO3lf1bWXRxr8sEfLrdc6kraG31i+wNUha+uYnWudWqhBBtbPfyeiYzw8HeLJoFXPdwHBNBBTPD5r1A==","signatures":[{"sig":"MEQCIEITStzIOOQ30RkpYBpUtI6lB/yenx5ugbSzAekHpwZCAiBy1ia5gLGoy3ufF6q53ZGoSI83OAHpRfS3N0TGJY6NUw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184707},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dc69121ccc706dae05b3d24c139f528a1aad3705","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.0_1693469054248_0.2818395410983081","host":"s3://npm-registry-packages"}},"3.5.4-beta.1":{"name":"@crawlee/linkedom","version":"3.5.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c42f499aa0a0c276d40e4c305eadf4f732948737","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.1.tgz","fileCount":13,"integrity":"sha512-++jNQt5MNa4rP2h5/2lZMq0SGOWQmE9CMfVNyIN1bAHNK+Qol6z9YCUPN57HC0b2TuHRSxDyVzlh7LXycILg6Q==","signatures":[{"sig":"MEUCIQDHFsXA6n4oJCCpDt00DnXArOuEIo1vGMF3p2poYQ/XpgIgKlVCVS1QbB+EQP4vfczFpcxm3d5rvqfEvC0PlQOrgO8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"898a13b97f2ac730b8eb7cd10f28aa7f78cfd5be","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.1_1693484671773_0.16255701413975165","host":"s3://npm-registry-packages"}},"3.5.4-beta.2":{"name":"@crawlee/linkedom","version":"3.5.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"008d7d6bd82ffe25dd1277c370d238f2a05c775d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.2.tgz","fileCount":13,"integrity":"sha512-LXxvymOqsu+7LL3fpMIsrn3eOrbbHtI2Aep4WN9xoJax268J87mKN9bR88WnakP3ggv1bZqpTCCEb/07GHne/A==","signatures":[{"sig":"MEUCIGddOid5xXVo0zJ4jd/OSf63nuA3xo5Qj+S3cCU0ZT4HAiEA/5Dm59KOcM8VDzFZhhvO6mBvjqnm9MGkNpCipsHNz0g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"18b3d608d9b4bd95b7c41ed742200e80386ce1da","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.1.5/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.2_1694005058563_0.6090000592992615","host":"s3://npm-registry-packages"}},"3.5.4-beta.3":{"name":"@crawlee/linkedom","version":"3.5.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"664f1702baf3da6b8e4ad5b707431593b2da9e41","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.3.tgz","fileCount":13,"integrity":"sha512-xy5aMfn+lKd2yjsICGHtco4gjOFfCFzbbEGgSJ+TNsvnXoVsO5aIyJQFczdrbknNkEO/KIXpFoI/sn73m+oZYQ==","signatures":[{"sig":"MEQCIGgPvNgRx/P6OCrxP2/nmyRbihVkYla4pMAuJdPnuInaAiBRfBNMiL+lWEgqvKYpvi3JZoL9rrM16x6MBI/X7nomhw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"613c04c5ffe277499aca796306a24e876a93d341","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.3_1694006726244_0.07016597775235911","host":"s3://npm-registry-packages"}},"3.5.4-beta.4":{"name":"@crawlee/linkedom","version":"3.5.4-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cf5ba25eeb8357e44807ff69a79817d8c50bbd07","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.4.tgz","fileCount":13,"integrity":"sha512-W75S7uGZhxLhNN2ycsXkIsMfcftOPolxAZAMW20E+JL4l6lg2mFtuolQ7cwLqqbHlsfqRavMG/2gCBBmptfdOw==","signatures":[{"sig":"MEUCIQDBA/o7XM870X2KHEtIPl4bpuNeK7TRUOZp+WK9Swgp+gIgPBCp4Bduj0GKIaVFLtS8rFFwdPTSE23qj+XZ6JWfaTM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f3fe3eb183ea78ecd4ecbfb6548172c107d8aab5","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.4_1694175262363_0.06678225824710382","host":"s3://npm-registry-packages"}},"3.5.4-beta.5":{"name":"@crawlee/linkedom","version":"3.5.4-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f2608b5b502834a6848dcc17329fbdc1736d6040","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4-beta.5.tgz","fileCount":13,"integrity":"sha512-8Dt3Nk2E1G3Km4zwWA/+pBkUZbK0bFYHI33M/csjeRzwmw1Y6K52k0wpGhYkSu4Io/6/8TQdiFDP2gl7qhmDuQ==","signatures":[{"sig":"MEUCIQC1tj5puu965ooRQG3ym4R3AvSEn0mEDqHmBXZJaHBhcAIgDAfsqCBup0woHs882sPMtZJ4znD6OkHZ0T1l6zCWpOY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c022207037394de6d6002f04921cbb240ea4d555","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4-beta.5_1694430530875_0.27803976636607053","host":"s3://npm-registry-packages"}},"3.5.4":{"name":"@crawlee/linkedom","version":"3.5.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"73213f13fdeab03ae9de5a6eeaf88818759de635","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.4.tgz","fileCount":13,"integrity":"sha512-6uWo0xsOo/t7iCJHF6uFcyYGH4Plli4qUdIg4tLprG2YGTGCxPY9TuPGeUKJpEbhb1I14iP/D0Bteel+r4BGOw==","signatures":[{"sig":"MEUCIQCrG7a7Fs2ghdcAaDn+hwNVltw1Sg5Q9/IJOgGGSaazgQIgH5MlyWpimgGwh2TVuHVYgybER1FG0Z2jRB92w0wJh7Y=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185647},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ea7e9797ab1741a4b8d6d1046353d54ba841c726","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.4_1694438711482_0.1328527646214146","host":"s3://npm-registry-packages"}},"3.5.5-beta.0":{"name":"@crawlee/linkedom","version":"3.5.5-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c06301caf7efffa0c888aa70507fc6bab8978bf2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.0.tgz","fileCount":13,"integrity":"sha512-d4rdS48O4xWvpZ8V4hdbsTg0H86bzVzKStpq5z1QL1re4BCuFEdRVh3wvxCwDbp7SbLQRl62sUS2z0voNI37qQ==","signatures":[{"sig":"MEUCIBME1H6UBji99Rt7vVqOaZ62OzzqEAZ9567ZwgPu3Pv8AiEA6KSJDgvt3ByNRRMDIzsWvNPZ+iv6Uw7A/PJLrbwP0rs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185670},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fa37fdbd03fc1f47508482b4f7f5941b6990c54a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.5-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.5-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.0_1694439819138_0.026494136898015164","host":"s3://npm-registry-packages"}},"3.5.5-beta.1":{"name":"@crawlee/linkedom","version":"3.5.5-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"02cd4dccf82d7229f2eb825f4483bd3694fd2058","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.1.tgz","fileCount":13,"integrity":"sha512-bGH2gg7Rd0KvW2/yam7ouD9CQLsBKXtWRlIgZoY7eTZtPbfjMYxAqyBqoOgLKx7UcnxwefruYw+ZTNTimAnT2g==","signatures":[{"sig":"MEYCIQDgY7w/PAPmFd5cGyEab4dIc8dYGO83qa9mSzWZOp3dWwIhAJqwA39ncz/KM6Fi1Xn1Q2/M7QtM2V2JObcMs4gxY6bA","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ab7b6bfb4f8123ab3718ca337b0bbc3db59f25b4","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.1_1694469958502_0.6522827466700858","host":"s3://npm-registry-packages"}},"3.5.5-beta.2":{"name":"@crawlee/linkedom","version":"3.5.5-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"51b42c4e08a4e828958cbb835c369e3859b01b64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.2.tgz","fileCount":13,"integrity":"sha512-aNxeNrPzoImE9sHGeJlyQofJGkJLfYaZ6xlOf0s7tu5qXbzYWgQRbwdJOQGCeR1i1Mrb3//A0ujttfz7aQZS+A==","signatures":[{"sig":"MEYCIQD0KR5pS1VzkpmG3YeWzAsehxF/Q4eQZc64/toAA4BxUAIhAKSmjwshfxw53mm/FYHwwy8KoBRj3vpOv8n4o3uyDjAi","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3b35e52684de8f44d0d76fb5ac23d3a8c7bba657","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.2_1694566684068_0.44074503037154744","host":"s3://npm-registry-packages"}},"3.5.5-beta.3":{"name":"@crawlee/linkedom","version":"3.5.5-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fec0eca5a9ddf424a287ad2e544c2eb774f2111c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.3.tgz","fileCount":13,"integrity":"sha512-odxlRROIEk6fM+wu83kzkO8Pgtw51Wa+p/gV/gbx8EPpDSLD2vTO6T5W+sguftEKeHufy9YkZcK1JdRG4/mO8g==","signatures":[{"sig":"MEYCIQDlhIQR5WLX27dE8gSidP0C6bRkqwJ+lN069GRwTxxXMwIhAOzLesNbMVOzoO+JRQjbE1oadCQ1wlIc+Apmte7xdxg4","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5cbfc277dc842c6a752260c969cea1a1fd138990","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.2.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.3_1694610486084_0.9217189114019484","host":"s3://npm-registry-packages"}},"3.5.5-beta.4":{"name":"@crawlee/linkedom","version":"3.5.5-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f8e0c209d51f410e2c028e6bba786262d848da8a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.4.tgz","fileCount":13,"integrity":"sha512-pOs6L9t7pDKd1IMjllBl7FuJsVsp3q/qWo4ME88N77slqHfxwg0YQB0i8w032HKuMc7qQ8Gb1J5/U/9wTA2dIw==","signatures":[{"sig":"MEUCIDue3ssm1G2PseIat5dUJ80wycolQJLyOXv0mgSiRuydAiEA0sN2odkxkDh8a/Y+UcIK9VFd6iCOt9j/azVjRwtyQIE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"85e27f2b1668949e07b0c849ee8299e648c0f716","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.4_1694688891014_0.351490792839003","host":"s3://npm-registry-packages"}},"3.5.5-beta.5":{"name":"@crawlee/linkedom","version":"3.5.5-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad8dc9fb75cd6dbb1f63698aad6e8f6d45cd850a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.5.tgz","fileCount":13,"integrity":"sha512-/wHIg7vTbVogrWRy9tQClaIrd4QcbD/N/fJAx9CCw84DuketcX4nUWZfJMr4sn07wwS4MnlwC3rdBDycJJdWpg==","signatures":[{"sig":"MEUCIGGIgwQCHvzvZFvuBIJjRwO/g9sdZmTXywY27rIfu8TYAiEAmeOGdXqrynb19oTBMMB4CyvlLVkyc29JqSEmU4/K8uk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f0d6703fbab5bda8acf889b4ebaf20c374a3e1c5","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.5_1695211615573_0.505553713478953","host":"s3://npm-registry-packages"}},"3.5.5-beta.6":{"name":"@crawlee/linkedom","version":"3.5.5-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"abe8841937210854292fb2a28b70c8b0e941f098","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.6.tgz","fileCount":13,"integrity":"sha512-sLiH1dS4M6YdwG4EEMMRSNfjuALgSfTjbFEsL8Yi52wLMkjew92Oe3PEgySl6pubNRaYDpFF3E1SDfPAV+rinw==","signatures":[{"sig":"MEUCICUCyEQnpRKjBtJVjwO0ER0mw4vHt2IbWFIyC6X7J3ujAiEAiHPDczkAvshNBzcGZD/HtJuVWgV4JyM7BWLV/zkvy2k=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"833263442cce377e41124e4042a16da826da8cad","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.6_1695213129614_0.9438931183055981","host":"s3://npm-registry-packages"}},"3.5.5-beta.7":{"name":"@crawlee/linkedom","version":"3.5.5-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"de8fe835a95e07734f34a8a6efd0a0fb56b78c91","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.7.tgz","fileCount":13,"integrity":"sha512-3Buh7bNFSUkROHS69J58mJOoW3bUQLiX3StI3aMvqqv8/V9nb7ltDXS6KDF5X6Q5LSJ43hbQzXua371b4Xlmjg==","signatures":[{"sig":"MEQCIHvqKbpO/HEP4DbmkpUd6jf4EOVsjqnqNJpqMOKmVAdEAiAkSWx2FHF8fZLlMkZlnpHc2Cu7Pf/OYbLn1dSSN2RggA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"335a01bb95cdd6e9c05696cfd64c4a007393e3ba","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.7_1695217715668_0.15050659126767973","host":"s3://npm-registry-packages"}},"3.5.5-beta.8":{"name":"@crawlee/linkedom","version":"3.5.5-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ca1120c83e909c15ddda5626a8e9d2982e9d041b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.8.tgz","fileCount":13,"integrity":"sha512-gswggNftpv9GQYo6yGy54HRrVBCxJ3QHOTcykmsM1he1REt7pTAcV3LJhln/24yJO6dFga69GBwyu8AlU+NIoQ==","signatures":[{"sig":"MEQCIHatvnN+QF6lwG/guJPjMjpI2bByjfSlvThwiXrG6aFaAiBAlA4ZI6YsD7EW23eQmiIXWd21SPwQ1OtdJaRsYEhTYA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":185668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ec2d124de2d4cab9b4672616cc342644b849bec2","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.8_1695272975098_0.5152437080011005","host":"s3://npm-registry-packages"}},"3.5.5-beta.9":{"name":"@crawlee/linkedom","version":"3.5.5-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"aefe3c85ea3a6a3e5a56f64ae5aef6a23aebd706","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.9.tgz","fileCount":13,"integrity":"sha512-SCt097igMNyetNja2UzVawdemBE7enfZz5mKagkXY6bDNhOX9MM7QFi1T6OyORhL1Ewtc/guGSJk6iJvfRostQ==","signatures":[{"sig":"MEUCIDlyqOtRxON0A2PscLt9KxUHuwo8nuYjlIJCsjF0SSW5AiEAuhvRRMkVAqkWBYavjE63DB1nlpN+WIZjo4Am7JAA41M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"75e00d23f481181a10b947e020eecbc319d46341","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.9_1695291648629_0.7178230064675333","host":"s3://npm-registry-packages"}},"3.5.5-beta.10":{"name":"@crawlee/linkedom","version":"3.5.5-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"947ad5ba0030662978cf20eaace2e5188f0f5f25","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.10.tgz","fileCount":13,"integrity":"sha512-5EzK7+ccCDO4OtPfcdfT3HsEunRrKgl77stwHxcrbMZw1JFGcSZVXu/AM81wANaZKPnlS/JFpkEpc2cvvPO2SA==","signatures":[{"sig":"MEUCIQCEtsvxHpcu6m17ZtFNITKJyUIMxkySgL0ju1+X9o2NhgIgci0GWpZ0so9gxQiurOn0pZVH1jDxFnT0jUUzRQKwHSo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"429a04948397bd1128e205b48e803775ee21c344","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.10_1695296200928_0.5754234409480747","host":"s3://npm-registry-packages"}},"3.5.5-beta.11":{"name":"@crawlee/linkedom","version":"3.5.5-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"95e0ee8802c42ffa3d6e190b913e356af1697dd6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.11.tgz","fileCount":13,"integrity":"sha512-D3sEuQulzZNBL9RVq5ljErgeaHqoFbp8LQA+Vz82llXIykO/ezUqctAU7s9X0SD9IPoRRt/gp4F7ZyiK5B3VGg==","signatures":[{"sig":"MEUCIQCKiKxk+HmqBowuLgBAGl/0919BKCnJq9VjZUFqb68qgAIgK1ZFy4BWgRZXII3OBLJPzgFjwSB6/Z8IorU4Zfe100o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"20d2a37d8774223e2c41e7b593bc547aedbfad70","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.11_1695354377125_0.3157580297552225","host":"s3://npm-registry-packages"}},"3.5.5-beta.12":{"name":"@crawlee/linkedom","version":"3.5.5-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"967d81e6c16ae9a3e7c84b8bc15ab1c488cd7f46","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.12.tgz","fileCount":13,"integrity":"sha512-WKa3fIp9zop8f871XQh3msSegzViJeky6YmUq4YnDNc/FECCKOVm7QM0SbW570IH5hW3bnNe2DjqBOnOs4fmcQ==","signatures":[{"sig":"MEUCIDLvZkCNVxYGUJL+Phyid61rh8LzEb82+H+kV+PVWrYnAiEAq4zY9AcFKKqO/KvEgwEaAZa7Wx4/SZxP6okl5AWyARI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0afe60ceb007dba5b00ee7e54418eb6d310b5b97","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.12_1695528852610_0.47601459392046563","host":"s3://npm-registry-packages"}},"3.5.5-beta.13":{"name":"@crawlee/linkedom","version":"3.5.5-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9cf50358e0336e657a0f8c7e47f8aa3bf2653a44","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.13.tgz","fileCount":13,"integrity":"sha512-vKW8dPOv0XujtWgES3qeimXbV1j/X7x9Bpa+i3c9LhRVyCsbKj5dumNL6eZdCS+db+rODyel6AUb9Imr5Lw4WQ==","signatures":[{"sig":"MEQCIBBnU1H4zSEI6rxPn7QL4oIawDwUlGF5VgpiXE8whjKyAiBTiILpV9qlIXk5Mgl2lq6J6MwgAMemoNWQYCP6iGyU8Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"94abfdcb305a023d9a7a1e38f8534e126dbcd9b1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.13_1695618495124_0.628952305757748","host":"s3://npm-registry-packages"}},"3.5.5-beta.15":{"name":"@crawlee/linkedom","version":"3.5.5-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dce20f7b7e3b73117f2ee2b17b8346df92b1f9ae","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.15.tgz","fileCount":13,"integrity":"sha512-1+3DHWsZtugDJ0tSQAYkhMxg999OHjlGjAWzaxol26ty/hK3V1AGX2hHiYUcJ3lKEppyYASek1L4QLETwd1xUQ==","signatures":[{"sig":"MEQCIBoNDZxb90M2CBQ+EzW+9n0Z4bY0KmDEl2Y7xJSbaD20AiA+lQc8c34RALCY4Csmgm4Ci05i6I1BDmKeTH20NOszUw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1fdc25917f100e0a8f38c1682ea5ed9b494dcd60","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.15_1695649910855_0.350820548953084","host":"s3://npm-registry-packages"}},"3.5.5-beta.16":{"name":"@crawlee/linkedom","version":"3.5.5-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a131a3f7442ed9b0c757724a9574995235676a7b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.16.tgz","fileCount":13,"integrity":"sha512-IfktMCqzyOO3GMZyvgNYQBL4Hke5yNk5gcmiE+TGRdxDR0rifNxsHpfaLLiQfi1mYV49fq8MZhAV/LckL4JRhQ==","signatures":[{"sig":"MEQCIChu7TnV6nxFd87PEmS9CqQcui9szqyQBhZCm7hRzO0aAiBQ9oHMU9kChwkE/Io2f5vOb5KmpGkoX034epDy5Dlvzg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ea04b7e65c84dffe470d7a397f47cf81d9f0f7a8","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.17.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.17.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.16_1695877205968_0.33911706692353105","host":"s3://npm-registry-packages"}},"3.5.5-beta.17":{"name":"@crawlee/linkedom","version":"3.5.5-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"71bde0eb90e580483a40c93c84ac2452dcfc7a3c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.17.tgz","fileCount":13,"integrity":"sha512-v5mqdry1nZ5fpko4ibF3zBtKumPY8h4U+whaYVmFSdHDjEmcp6B/TaalpNHw02Hi+d12H4m/MK603jQDERGpUA==","signatures":[{"sig":"MEYCIQD0p0oOBMmJGUUyAKIOUmXwvy5XzPI5iUZjkdWJLttsnQIhAL2x9M3CN7aPuY2GjW/g0kEnWeWeUFjDoVkOwnt5p5GA","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"545eabc8e9dbc9edbec608f6e048d148ff1f1c97","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.17_1696236853889_0.7753987312240573","host":"s3://npm-registry-packages"}},"3.5.5-beta.18":{"name":"@crawlee/linkedom","version":"3.5.5-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ca5292bea74d5edde94ddee986e1369e600c58df","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5-beta.18.tgz","fileCount":13,"integrity":"sha512-J5urJIN8W6Wo7k8fiMNhi0mzO2L5q8RtxWBQ8/AT2SgR603MaGUEZ/RRP6QAJ2Ah3b9RYIn5nQQ57kSVxRW1Gw==","signatures":[{"sig":"MEYCIQCHVfqa15qF7k+wQymQayesWwm4VdrEImCb+u4OrtWbRwIhAL7T5n1QqCqs7w1mpwRZviLaxnqgc6dPO1y7QMvbc43n","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186090},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3c35a6725e2c0e95d23af854fd59204499f25db8","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5-beta.18_1696251571826_0.7239356519048181","host":"s3://npm-registry-packages"}},"3.5.5":{"name":"@crawlee/linkedom","version":"3.5.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"193824b5bd05314c2dcd2d46d6f92b26cd208bcc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.5.tgz","fileCount":13,"integrity":"sha512-83THPZhx63zraXG94Bl5ix18w6UuZdqfg5ysbaTMX4QV0eqydVG/7hI56CwoRxYFIwSKJQO1HFK0f0vm9aF83g==","signatures":[{"sig":"MEUCICTwQOK5Yd3DcWA98GFHL/OFG4kukxPAmj2kCrIBQnBWAiEAtEWSxwVpJFGjiyZj326TDu/N8NmO721WpOOwO9THIe4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186066},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6b681a475b1b3542a29e2edd26d7106fd96fecc0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.5_1696251812386_0.5985381946467985","host":"s3://npm-registry-packages"}},"3.5.6-beta.0":{"name":"@crawlee/linkedom","version":"3.5.6-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"76adfb91f3b0e2f7dce0a0008df857adb1dd7743","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.0.tgz","fileCount":13,"integrity":"sha512-62CetHqHVqlMoUf1AgsNAO9f1PD6EP4lAkHEYPwQdtoYvK6306enZjc/+tADbnNvIvayZ/bcdZqAxSlvNszsqw==","signatures":[{"sig":"MEUCIElmF5PhB2NZV93Jp4Ko05bljjtVcELy2pdJd50at4y8AiEAt0M0A/7wqu8IDzfybhZ9UEuYmQz0Ufv63oPxlwBguoA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"238c5b62aae04376b1d5e8d5e8ef98dc37042c00","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.6-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.6-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.0_1696252891047_0.674550469979154","host":"s3://npm-registry-packages"}},"3.5.6-beta.1":{"name":"@crawlee/linkedom","version":"3.5.6-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"480d05d83d228951e4e3cc266eaab6aa13993172","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.1.tgz","fileCount":13,"integrity":"sha512-E+y4ynHi+2NIftC6IcaGpjs4pOE1UiIHtni3kBUcKQODhRB7D2SQFsUuftxC3N0Rl7sC6Woc/ZtXpNQixx8PEQ==","signatures":[{"sig":"MEUCIB1rLPc7gmO7hS2b/4BBuluhaXxUj2E1JGP20BtVnUTsAiEAuk1AK9ckzQE1fkFVBMoKFD5hjzbTYhN5hZ5yPrub1SU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"82d3631a546b48099e4e523d730c3d5ba723a796","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.1_1696256484146_0.5797185081515568","host":"s3://npm-registry-packages"}},"3.5.6-beta.2":{"name":"@crawlee/linkedom","version":"3.5.6-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"059df59ff0296310aa0f6537f1e870120eb68ba5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.2.tgz","fileCount":13,"integrity":"sha512-ynRsdRvCVIC02YP/d7Nx0XKbFInPwzYP75B/wENY5XFmOaqPosBXNt/S0w0FVqmrkjQ4nvVVpjG1VJe5JVVL3A==","signatures":[{"sig":"MEUCIC19lz6McBAcSQ/wQpiyUl/j83k9xiQO1ItdG2nI81BWAiEA06vjot3+vJlhRjAz8QVVneEDIK4tQFBOoT0DjwjgsFU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b33183746a323362b934155e03d300239805e561","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.2_1696275319653_0.43515688784875173","host":"s3://npm-registry-packages"}},"3.5.6-beta.3":{"name":"@crawlee/linkedom","version":"3.5.6-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8a66ad4c6737e0a634520a31605bdb0bc0cc1bbf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.3.tgz","fileCount":13,"integrity":"sha512-aGaWhekxBQri3LMfuQknsSqBXTsF3AFwbfPu1FC6R0xZgTPjG5bC/mWdN6dYJmzu7UdN34tuVVC7xm8b/PiFjw==","signatures":[{"sig":"MEUCIDvW2cuQEmvlh0LSTA3BH4f21PpR1gfJliYq/yUc3nwgAiEA0vlSIts2TkkE6WYzZg82CiJg43vBB3fgvsdT/2qO0DI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"141fc3a3e81e5e89238b446b9bcca737d069143b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.3_1696287259004_0.44874298971628135","host":"s3://npm-registry-packages"}},"3.5.6-beta.4":{"name":"@crawlee/linkedom","version":"3.5.6-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8300e099aca79c5f389efd8f9314c28f76687e4e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.4.tgz","fileCount":13,"integrity":"sha512-o+zDu8mWVvBCb9crgwx4AoN7O6PAweszF8rbAZzXRDgk2OH20az4Aw4uNlzbEV83aHyRLKByuGWI+i6svxHFlw==","signatures":[{"sig":"MEUCIQDo682B8rfmxg/fgQiDkbUa0skI+mqbsZCO9xPEcERXkQIgCJtLfx4CzccrJluziYIFD4A0NzdZMy6SiO1/dNNEj5c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a0c32bceb47714affba7f76c2f68fda5fc2c2741","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.4_1696336946279_0.4302854216866874","host":"s3://npm-registry-packages"}},"3.5.6-beta.5":{"name":"@crawlee/linkedom","version":"3.5.6-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9eca57644f36d8c11c2c79a2b9c889c7875e8209","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.5.tgz","fileCount":13,"integrity":"sha512-SBMQvjijV4fN6Jtcbv/ZAPsB3XlX5PSWfliEU2C2JqXctG1+Z0O/iHjMOWUBepxJIrtj8Bwugg2iALq759zL2g==","signatures":[{"sig":"MEYCIQCAJyztQEkqVm5VF9u+HMRCFem7QScn0CYJdenY0RkmLAIhAO7uKMsI4O9HCbnkQcxDjiqMnqdqGXHzIE1oTA/UbVu0","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96d0ce168a88803a89d995779c2539c9739c1342","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.5_1696383083592_0.4347074036117726","host":"s3://npm-registry-packages"}},"3.5.6-beta.6":{"name":"@crawlee/linkedom","version":"3.5.6-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"74d30045cd4225e52b92322edaaecd72c8111a09","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6-beta.6.tgz","fileCount":13,"integrity":"sha512-pnzAwHDjEDgo30WswQvSkL5OPVU8qCmOmQJ/aCp8KLV7xLW5FkmvlLMcZsSd1HrkzSM04SFMUxokAy6IFRTdTg==","signatures":[{"sig":"MEUCIQCbZsa6Gnf3jRGvXhrhb9rIJOki/5WLS/ZSPBEwQIPhpwIgAVYHz5wzr9HcThGd10D9u77oW1RX+HmSn8t/iodfaLM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b4d32f53b9c99a8c1e1af3694bccb2140fbe8d7b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6-beta.6_1696408584152_0.9340561109259398","host":"s3://npm-registry-packages"}},"3.5.6":{"name":"@crawlee/linkedom","version":"3.5.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d4af52951d199272c31a2d533d65fd31aee36d2b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.6.tgz","fileCount":13,"integrity":"sha512-/1SOxoK7X0gOJgsNOVco0uzqfX2EJ6HZ9Mxkr8e5MwDWpWMSM8X3CmT3LARe4nUmmWMUGPp258NOZgVcutVo1Q==","signatures":[{"sig":"MEUCIGDVxI33YfaxGkUBb7cFQEkld3P2ZumU8WaxASlpRqt5AiEA9QjZL/9mZ6Nf5h5uerpz6g1TGpjSQYca8LUt2ioJPbI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186066},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"77600c7d01cecc2538f02261f4decb32a08d76c4","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.6_1696415522476_0.4848519816924963","host":"s3://npm-registry-packages"}},"3.5.7-beta.0":{"name":"@crawlee/linkedom","version":"3.5.7-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a70c6bc8bbbe9f6a8d71c97f8dd42a0d2c391434","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7-beta.0.tgz","fileCount":13,"integrity":"sha512-JubyXPbVFuNHXILJ+XG9DVNGd2y06ZaI6XeNzb3jM6vjBhZi5Tpd8a2Z+0/vpK14A94ezRGADdtVSlElEtULQA==","signatures":[{"sig":"MEYCIQCZQTAnXcGLWbFnEawPAtFsG7CsjQhBH7hFZyl9aqyztwIhAOJDYq55RTxVvEg9ya9mywAeIdPcThdtb/97pjuy0Krd","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9cccd373a67548188cffe0507ed1575c50e273db","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.7-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.7-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7-beta.0_1696416476081_0.2486011410118647","host":"s3://npm-registry-packages"}},"3.5.7-beta.1":{"name":"@crawlee/linkedom","version":"3.5.7-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"08c7d684a5c93ea8cc2ffb991cbaef7ee688dc07","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7-beta.1.tgz","fileCount":13,"integrity":"sha512-Flrm1jjPToc4czdLx4ABcWiD+TgsYguuzIOI9StVbXoFL1S4jvXctP2/UGI3bzcn5ZW8JF4lCwMeGfuGxXmpTA==","signatures":[{"sig":"MEUCIHn90WsLOh77w1WdCbIPfTGDJ22plPCDQpyD97Bpr99JAiEAguGJ9UAqQGzYeROMRkgs/CVCQVPFNl0vYzU7Q9B0ubE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f4ed00e1d79af0f6dd212d2a1910fe64c1b27dc3","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.7-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.7-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7-beta.1_1696419338059_0.5782088747975103","host":"s3://npm-registry-packages"}},"3.5.7-beta.2":{"name":"@crawlee/linkedom","version":"3.5.7-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"473fb918a7ef7ebd69ee0174609de05ccf9217d0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7-beta.2.tgz","fileCount":13,"integrity":"sha512-DLUTv8eIROupJXu0N+1n9NrX6V/IdcDP4zwOnHfJadd1bAaKEBqsi49u2yK7ed8Vn/o2nXgL/yr85M33XTpZjg==","signatures":[{"sig":"MEQCIE4PMeJIL04nKAbddurgZfCR/vubnCBDL3dMUbroj2bCAiBtNEymftConFDdzIA2srvin+3RZcEZ69ag4Ym/J3uysA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df5f9579a9e858ec518ee9ab32fb6c71d3a01466","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.7-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.7-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7-beta.2_1696424214994_0.5567659029288787","host":"s3://npm-registry-packages"}},"3.5.7-beta.3":{"name":"@crawlee/linkedom","version":"3.5.7-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"db410a26858be497696555a6fb49c6bfa2bb7780","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7-beta.3.tgz","fileCount":13,"integrity":"sha512-AKzTHHd0LYPCE4wzaDPFTa0zb6cjVGmP9Ao+XIA8+eTWhWsWSRFEGxhQzeLgnwn57bGZzRmbSgRrOm9H5Hupcw==","signatures":[{"sig":"MEUCIGiUWEEmTM0U0ozSjDmTS7YkCOwJEADej3MeKH4/F7p8AiEA2K+sgRImzpC0T9puAvvelmnme4Er2qWt7eCATwBsY0g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"97898070e6b9a0bd4d233e139455432f7d21d83a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.7-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.7-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7-beta.3_1696425389006_0.2526884422807545","host":"s3://npm-registry-packages"}},"3.5.7-beta.4":{"name":"@crawlee/linkedom","version":"3.5.7-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"938413ba307e2636a5a6b2fa487f12e2808f2e34","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7-beta.4.tgz","fileCount":13,"integrity":"sha512-BI/Uv4Hz88l1zpkGDfDGU0dGuZhDShQ0OTJ8H6moGBzi/NvnEm5BigYyctn61FHZ6ztJnWh0Nsk8f5OFr/klGw==","signatures":[{"sig":"MEQCIEGETDtit7yXnr8UlYQWZ2KREU331hUkBNXBDUiNTNtcAiAUIjBnt08cRSzvD9/+H3z1M8nuQGLMMYykH4l2zkhCZg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df29c8e812ba5e4d819f82604c8b233e3fc88008","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.7-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.7-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7-beta.4_1696495803681_0.31948453383727093","host":"s3://npm-registry-packages"}},"3.5.7":{"name":"@crawlee/linkedom","version":"3.5.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"80af22346fcae93c4418671aa2daf07fc1c28f42","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.7.tgz","fileCount":13,"integrity":"sha512-YlbI9GiUxc8yI74MKgKGt3nVJSq95+/otXmngvFXuVBZ4cdWA03JaF3WX1rtl8xo3dU3yr0RtCa3JUA5RkCjjg==","signatures":[{"sig":"MEUCIB/R/2zZ0zMp4au81wQvrYSC1qeZD8ANSKd7oA1uVs7tAiEAlPK1gS0JsmK0NNjed/hoz5qss9nvTupfhFsUUULjoHc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186066},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"da74c2073d1ae23c2a5b0be550c685253c0f257e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.7_1696496691974_0.24084288410755006","host":"s3://npm-registry-packages"}},"3.5.8-beta.0":{"name":"@crawlee/linkedom","version":"3.5.8-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2054f08c95ee444fde30149d1fe1158c12ceb8c9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.0.tgz","fileCount":13,"integrity":"sha512-XKj4lKSqTEtfBs/mNWpXJZILNykxjXOe/E3d9r/6vFpfUg53JZOnyqnVndctmtLa4vRFytOU/vtmODr1BQ3tFg==","signatures":[{"sig":"MEQCIFhHZXxh1Pzj/5hQfNJkrFeF3e1GAA2OvII0yHx+DQoeAiA+cLoOA6zU6ceO1gr1P2NzVJtKdsXyKn9nGB8MHBCyuw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"175c542d34df8368b1f10f518e459b7e98073efb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.8-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.8-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.0_1696497509478_0.6973286021894769","host":"s3://npm-registry-packages"}},"3.5.8-beta.1":{"name":"@crawlee/linkedom","version":"3.5.8-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"464d041eede75cad8689608c4a8119bf12ff4b85","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.1.tgz","fileCount":13,"integrity":"sha512-etmavvqPWbw9y3LlNggXBc3MIrSPjt6P5HE1tx8epEl7dlNB2jr501VEvn85ijmR++wT0fbQnWwGzOlqGIZkyg==","signatures":[{"sig":"MEUCIBRTjTd3bz5HZuCWAd3E5bInt26lbjLy0MKcERupw/7EAiEAmz4YZYmcuEe6cATCoqUIykgYn2h6Y33aUfCK+eOH/bw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7dd3126fd1efb351c79ecee35f982b2668cacee9","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.1_1696541077720_0.35362018195156675","host":"s3://npm-registry-packages"}},"3.5.8-beta.2":{"name":"@crawlee/linkedom","version":"3.5.8-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fd2d592ed4f775ca4589be0d08dac1e231c3b254","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.2.tgz","fileCount":13,"integrity":"sha512-9Mu+5q4Fd14N4KVtl/El2BuDfNkPMNA0N9FJkNpsrcloRxXeBJsXrU5LDPpr8Y3bY0naYPzrTIGqD6tMwprdFQ==","signatures":[{"sig":"MEUCIHp1v/hnBHjm/SZn+KxU/SV9YsYBjAiGf7PvapH/zExsAiEAo8r5W7TGJMQFCPnys52rmHG9zIcyfaFG6XKIKvnPR8I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186087},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4a3a535c13f7c672180c2d6d3f65baa26925f4c4","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.2_1696609657586_0.47452693818511094","host":"s3://npm-registry-packages"}},"3.5.8-beta.3":{"name":"@crawlee/linkedom","version":"3.5.8-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a1d48184ac8b8c8587a479a6a45f701862c88447","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.3.tgz","fileCount":13,"integrity":"sha512-+ooszR8+Vd49mgqLZaRK9tceLyboZcJdJj1ew7uVpIYYsVfZblKXzKtjaJXsOulgNtQ9HjCYPkvcTrDStTJkOg==","signatures":[{"sig":"MEQCIDynneM1x35fWwI0gjjlx6uwq+U1lc7yTtvp6qd//n4BAiBbpZpOblyRW0kT+yzByHfoV7tss51LSRMm9KrFExyGgg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186109},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fe853e7c8575719830c8230eb7195a509a658ce8","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.3_1696913399867_0.6989364407402934","host":"s3://npm-registry-packages"}},"3.5.8-beta.4":{"name":"@crawlee/linkedom","version":"3.5.8-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f610bd1a3128cc180d276778111c0398c92a230c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.4.tgz","fileCount":13,"integrity":"sha512-AY7cpTmvtHUI2OAJJWhDW6euq0MVJoAMbuQELi+nkA2DXdOtmhScUYDs/R3fDM3X0L6kc28MUxu3Tczj5dXK8w==","signatures":[{"sig":"MEUCIQCjUpcszoScRq5eIdN2R/Q9X9qlWUDxL+jaBWZQ6Qza9AIgKkln4bS8VlSyD2EWPKa+N99BAotnUK++e3NmUrLd/Ng=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186109},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"15bee46d2cd0562a947bb37fec9b6ddac9875a23","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.4_1696919011035_0.24638262494779717","host":"s3://npm-registry-packages"}},"3.5.8-beta.5":{"name":"@crawlee/linkedom","version":"3.5.8-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6a60f9f98592f5dfb1aa92cac78ae5931ec438b1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.5.tgz","fileCount":13,"integrity":"sha512-HwgFEhrFE116646LveOPvdMxrV1BJWmXVAVjDoIJNitgL874pC/gRQt4d0z6W4FjAMkB/ToiFtx6TjFdEq2fxg==","signatures":[{"sig":"MEYCIQCVYs0SlMCoRq19DCHIQ8Jpd16bAJ4EBlp+OvJGZTMM8gIhAINdkITBlcZQrvUr7kN9Kpi+fShS8Q09fF775CrIpyL0","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186109},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b78a4087e685bca0e347e163624a831286cb99ef","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.5_1696937374218_0.14125984707236205","host":"s3://npm-registry-packages"}},"3.5.8-beta.6":{"name":"@crawlee/linkedom","version":"3.5.8-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"22f12340eda020c2a7af8bc243f472290bbbaade","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.6.tgz","fileCount":13,"integrity":"sha512-veoolhyrg2N6VD4c2XZHSrveqQpAW7XRySCj3kBW7OBTZuKQdvZ5bzuRvoe4nBWo35hhJ5sYLPxHn/og5DsiYA==","signatures":[{"sig":"MEQCIBPNoYjplXroJ1iIsuLeZkD3/GxNSyXV6YjV7tdfAmM9AiBU9+pr4Q784hk6Ahd19NN1yMWEwMYcLVSe17Tl5Z4hKQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186109},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2930606e89f4791d8fa69c8a6b4541ea42c2cf5b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.6_1696978174943_0.7236787681799004","host":"s3://npm-registry-packages"}},"3.5.8-beta.7":{"name":"@crawlee/linkedom","version":"3.5.8-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1b6b934653042c52fdc70fcd18281cf94b2ab0fc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.7.tgz","fileCount":13,"integrity":"sha512-77dMnFQmo2KSm4zuECag2Zcslbz4cCpv1RkIYkCmo6riqP/xybRBjecrF3iNKj8e20H8770oLFDE370aGhrDSQ==","signatures":[{"sig":"MEUCIDkudBS3e62d+7VpAlRFZpirtRrCEccxxgtx26PQlYy1AiEA5gBneDZvjr19Mx1uky+LQ1uv/k+Ym93yjzZl8x3FBvc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":186109},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9780a3659d049d0feab4d11c52f32f6d3d991dc7","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.7_1696995625659_0.4063938784651897","host":"s3://npm-registry-packages"}},"3.5.8-beta.8":{"name":"@crawlee/linkedom","version":"3.5.8-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3ae16ff83dfde1f9323b0468dad9a2782bb7553e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.8.tgz","fileCount":13,"integrity":"sha512-sLmm804y6jkvxN4cZLAyiqgNViv8FfCqam1nKE6sQojMtH6gbae2SiZdt4risaTY9tEkNqWFdDjbXhQko9K3Rg==","signatures":[{"sig":"MEUCIBpvclqHiN72JRt47ScOJRjAMzUrwEQLGI1XemMdyX+OAiEA0Dze5gHzqJG58X9aiYhx0yYqyRHPEqlanMSYk95h/uM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183809},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f836b9d06912af4299f23d90e8d073ca4cd446af","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.8_1697182039932_0.49890942430804963","host":"s3://npm-registry-packages"}},"3.5.8-beta.9":{"name":"@crawlee/linkedom","version":"3.5.8-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"081be22abeacc4148d529de8f6a05192fec28558","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.9.tgz","fileCount":13,"integrity":"sha512-mT4pRqX9w7Y1QBAJOIZJA1pUIbYfUpZ6nR+WswF4z9XfqBPdmUeA27ESN4+rQKfKAoUjJ2KpCmfSjEtzl9VWBQ==","signatures":[{"sig":"MEUCIAyUg3/B3Wfb6bswObtOWv98GgLFTdC2CNxhKziI84sPAiEAlWHufu7UtK9v2pd+RVl505KBgQjfHe2vNy8kvRvXfro=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183809},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1b9b857ecd3d11e134fb90251b1386dbcb99641a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.9_1697196520865_0.34640063409131416","host":"s3://npm-registry-packages"}},"3.5.8-beta.10":{"name":"@crawlee/linkedom","version":"3.5.8-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"98ddb385f1359518524cf5b12f505697b2150811","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.10.tgz","fileCount":13,"integrity":"sha512-vSJj4JiMcJzCugxoEnZZYjklNajh/pDyUO3GrA6ohffSDNqgRhWDBywAqhruZ0+zWj7Wdz4HxwmBIR7Ed6ULbg==","signatures":[{"sig":"MEYCIQD05Xm7uz4NAHmQLdSe+1lrSbCTzMJgwWcroK3QuyS8tQIhAImqXTD5O0/q0xgSU0VNvvR4jafDwXp/fuYufQr+gvb/","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183812},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1c6766c13ab294ce56a15797041e3732d3065615","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.10_1697211239940_0.07276638790130807","host":"s3://npm-registry-packages"}},"3.5.8-beta.11":{"name":"@crawlee/linkedom","version":"3.5.8-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dffd739ec4da3d4971e3a7b06f660a77da30ae89","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.11.tgz","fileCount":13,"integrity":"sha512-Ng3q22vwDq1NnjW17ffUqyIVizyJi44Ewp7i3EPJh/MSUtLQ41nwMAGNfnxZ9e+X+czrtZRinJNH9EKTXBB8hg==","signatures":[{"sig":"MEYCIQD3xjAb0lyJ6EcsWzULCbZwpFeFytU35sLMMbFSfXKskAIhANXMhnUKe8QL7yjjGP8d9qWP9UWinsfi328ZMhVut8zT","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183812},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"801cd27e3f90dded329ebc93187335241dfec54c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.11_1697479048621_0.6817776928663271","host":"s3://npm-registry-packages"}},"3.5.8-beta.12":{"name":"@crawlee/linkedom","version":"3.5.8-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e00412dc0c62483d9c24f04827dfce7231a0a05","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.12.tgz","fileCount":13,"integrity":"sha512-osjYhaDIweYSYey/rGSTJoD0ogbcbBp9xOxmYkxe0WWWa93H0RX7soLoDEHA97kUwP6Do4d+ea5mHHKmK4XShw==","signatures":[{"sig":"MEUCIQCx3ev1UpPj3ggwvEgEJ0eYlc2+R94+6esyMb6PzmrAEQIgAkc0qEBHXrBcKlK/OCcNvbDCrE2MolY2+rYCkiDXrj0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183812},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"04bf4cd3fb12a0dfa102816993ffd2411476e3a7","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.12_1697514770366_0.1589519399393553","host":"s3://npm-registry-packages"}},"3.5.8-beta.13":{"name":"@crawlee/linkedom","version":"3.5.8-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"07af0bd8105b5149a9073d723798da858cf873d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8-beta.13.tgz","fileCount":13,"integrity":"sha512-+v8oW5skcJxYHxZG1/HwYkIXCzIK9dIO9zBUu5ZaK+brq6a73TkCprG5pbNZqbU8WZK2UN4Vidk+EoQXTljHeg==","signatures":[{"sig":"MEYCIQCDsXoLXbLH7jwDZwo/sKLT9J5WAbEX146FsPA1HKV1iAIhAPwS8OGyaGzxGGQx0TJNgNSUhyTgIlNFWKuHtVGjYdjr","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183812},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f79b974eac642b7de1bdf547f832aa816f987677","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8-beta.13_1697537297653_0.6234689539153833","host":"s3://npm-registry-packages"}},"3.5.8":{"name":"@crawlee/linkedom","version":"3.5.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"950e12a0327371b2555c1e95bf93053b9315b937","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.8.tgz","fileCount":13,"integrity":"sha512-J0WrlYP0oMAabXR01cfQhsA6vFzQeXnL5l3FVj2t4HLBRolyAjqfAlF7jq0EJGFYlHWjpVg5/M2kJM6hTWv6Kw==","signatures":[{"sig":"MEQCIBQrhnbY+NqTpcVyzVmO2EA0uiOb7MpS/8ctF73G+FYoAiBC1UZtgD5VLrGdXA1xe1wtfFkMjKYUPcw0zdtxR4DZJA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183788},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"43786925843b4dbdcff851cb391e949e2414bf05","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.8_1697538082526_0.7922102572308436","host":"s3://npm-registry-packages"}},"3.5.9-beta.0":{"name":"@crawlee/linkedom","version":"3.5.9-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c8c106b80a83ea195f44bf2865b9c10b41eb5572","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.0.tgz","fileCount":13,"integrity":"sha512-U1LEP5kyqcNl4UrhRB5eh++ya6DlTV1hmYiUj6NLH3nYM55s6+0B5un68gdWGNzPfvrfA3gNmegZzZbV0EPq7A==","signatures":[{"sig":"MEYCIQDWQxO0H+lpSlWBCHjPr/6FKx+Yl8RXSx3+DMgeUtRu6QIhAKvi5ydWc/GFC9i9ypSvuaA0e6CgB2mablJeqfSa/SBA","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183811},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4258518061da5f8fef74d00ef431a27fffe92fd2","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.3.1/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"^3.5.9-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.5.9-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.0_1697539112031_0.16242098629582657","host":"s3://npm-registry-packages"}},"3.5.9-beta.1":{"name":"@crawlee/linkedom","version":"3.5.9-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2a87f303b6c2b3faf39622abfa8642d29c15ca39","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.1.tgz","fileCount":13,"integrity":"sha512-+g26/gUeSLXhEtVyv1nKhUAjFnB+dAEAWG1z+oW+fGJDYwrpqMEaWWNgid2+MGLqmQJ+VKD4gwnp6mw9ibYotg==","signatures":[{"sig":"MEUCIQCIVUPXm/SOtebgPAmGGCbwzgFDvcFZKl9CbR3fP6vN9AIgUr1jUaCylgb+yylxp7t0HrdSTgS3yIBK4+PlIpog27o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":183809},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b2deae8142d7f367a81c895a433c58d68d7e56cb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.0/node@v18.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.1_1697601746788_0.1474314348779504","host":"s3://npm-registry-packages"}},"3.5.9-beta.2":{"name":"@crawlee/linkedom","version":"3.5.9-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b6c1dffe7a27b7032e0b81430341b9dd31804cf5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.2.tgz","fileCount":13,"integrity":"sha512-3YGj2xl2lp7OxNS7agoy/zYMsMo1zMV/dSnAdda2jK1rZgaCmEYyrGeckmz8zm7DWKMwLwxTdTinePHArRJRbg==","signatures":[{"sig":"MEQCIG+TE+RQcqMiWDoPGyrVO4b7RCwyg4GyU9JxMEqHKQEMAiB+r4Sng1cBX0WS1bGk7XcZr9iCi8SEEi9CVVRzM69l4g==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9549f24c6c3e8eaa2a207553fadf5e4a1c430a1f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.2_1697689578308_0.03931656545215678","host":"s3://npm-registry-packages"}},"3.5.9-beta.3":{"name":"@crawlee/linkedom","version":"3.5.9-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a7aa66c2da4704d4176ee7501a431a8b333b57d5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.3.tgz","fileCount":13,"integrity":"sha512-UUwL6FhXIPYU0cyvYsW3Pn9MszZaFi/N5ObG4wRHOiOPR03R8szpkz1j/ogmZWu0Bk4fJCfsm62Bx6swS9+dCQ==","signatures":[{"sig":"MEYCIQDDsWp93ayS7RWBIYR4OYmf43mSprDrVvnIdvG9PRrwmQIhAPsLcigqopPBpK+MSIR2ZVYXk/TSHdDRw7XjLE+L2C5/","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0752cd7c524570d67132e5a2dd79c5583168e93c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.3_1697778206685_0.8284861531381009","host":"s3://npm-registry-packages"}},"3.5.9-beta.4":{"name":"@crawlee/linkedom","version":"3.5.9-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9534d72f721445ec506cdc173ab3d6b6d7f777f2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.4.tgz","fileCount":13,"integrity":"sha512-iy+Z2AI8JXVtjW5uygJ56WPr71UdNqgqVTGzVSl0mInad3uFpoAAUQ+hdaB3c183o/3uvTaEYhCc6eFILoVX+w==","signatures":[{"sig":"MEYCIQCdY3yBQJeMFdU0xELBaZBqG2RKbPy20v+pxnFJ39ucnAIhAI6VWasJIXnTecBaCtSQij9eDVt9h0Xaw13EL1RR2knn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ef8a63357ce26d39a5a11e6464b42863a65bf4b3","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.4_1697860733012_0.7567537081440909","host":"s3://npm-registry-packages"}},"3.5.9-beta.5":{"name":"@crawlee/linkedom","version":"3.5.9-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"18fe8d84ee98be4eb724780aad44bd1471f98233","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.5.tgz","fileCount":13,"integrity":"sha512-5GxKYF8wXDXWpN0sh125aibgkpnjonRkUU9nXrbMEz4YThM7L8RK1Atov7hfVQu0oI7oKB4Y8c1blv07qnNGfg==","signatures":[{"sig":"MEUCIDU1MItjGF5TkWeFOOGyFvHE9DKeIvXvmgZm/5GwTgTgAiEA5ELzolq7nVf9Iy3KhH4QnIt5V9lqyiS2xtj+2A8qk9g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bfc7e416d6d4559e912b4ff5557c803d0651d50e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.5_1697890263704_0.042193060558722184","host":"s3://npm-registry-packages"}},"3.5.9-beta.6":{"name":"@crawlee/linkedom","version":"3.5.9-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"60b681270d12fe4dbdd99d451019297d5f96ad3f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.6.tgz","fileCount":13,"integrity":"sha512-6F2A64JeiDjIq4J2CKM6iiR/QSkTMbvsG77MP1LmNIi+mdl0fMvvJYUyHwjOj5VuwKWEMviZwA15Vkuu7exbEA==","signatures":[{"sig":"MEUCIQD0IUgWuWzPBbqM980WNhcZjjl5fgbT0R4Jdaw6O7ZujgIgNcE97LvC9ZVr439fzjGyMx1NMcQi67/MbZTKg//OnwY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f56e58521001885b8bc18d7f53328e1087732fb0","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.6_1697946852692_0.444918638734483","host":"s3://npm-registry-packages"}},"3.5.9-beta.7":{"name":"@crawlee/linkedom","version":"3.5.9-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a2f1cf3283fe2e41e0e4961d384f3b1fdad4d45b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.7.tgz","fileCount":13,"integrity":"sha512-TCczdJtUT16qDfNSywOJQBhFvF7dRj0nZHw0ag3OXjqaId0F0ik4NitsEXPuZ6RoVXilqCyFZerEI7hOpv4XUw==","signatures":[{"sig":"MEQCIC5SJaT7xMUbxapvgV+AW+IskOztbrDPGjS03sYjp5jNAiAtzmikNlKCRnIPuJFxRogyZ/jidwDRAXyT20wfRwZlJA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c5f8e96293c69bf023c7a310394fc981d7655a97","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.7_1698085010990_0.39014254818076655","host":"s3://npm-registry-packages"}},"3.5.9-beta.8":{"name":"@crawlee/linkedom","version":"3.5.9-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"281504bc958fe8f0f59ae0929b40490b2c3e1410","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.8.tgz","fileCount":13,"integrity":"sha512-IkATkHO3DJX6max1eGh/NEst9odEkkA6qhBkQ1dnOmpS6XzuUqFwXI71+DWo4czSR0bwoo9bqconNZx14MdAuQ==","signatures":[{"sig":"MEYCIQC0Tk5PHIz4/brYNVOhw9EEznDH7GZN/oyjJV38c5bUYAIhANv3z0Z3pwHNiS9KQtAB5pl2DDYpTIqbEqVMYwlFECHn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"475fbd2513c00df1df7ec64b668cdb0e9ca86057","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.8_1698120045378_0.7566819065000197","host":"s3://npm-registry-packages"}},"3.5.9-beta.9":{"name":"@crawlee/linkedom","version":"3.5.9-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6563da78cc509dc2e254fedf1c160ff086b48cac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.9.tgz","fileCount":13,"integrity":"sha512-JSca1yjOZQUJO1XkIFprpC6uGk+1SeEd/aWdDC6HekPnK6MQCCwnEUZuvbHZu7mTD+FYudTO2xHC6H6EFYXcpg==","signatures":[{"sig":"MEUCICgOZ+YOQhoNRkNSjc30HGExhAWZSo2DBnCi1qhkarp5AiEA5RfNAY3SBpJasVsbab73cm/cE/T81mA+516QoEpuDNs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184282},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"217bfd488076db89d852499b3d6a7c05262ace61","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.9_1698210798147_0.92197205928501","host":"s3://npm-registry-packages"}},"3.5.9-beta.10":{"name":"@crawlee/linkedom","version":"3.5.9-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0f481160eafeb7cf2ad0b129bf01d55abaea6a2e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.10.tgz","fileCount":13,"integrity":"sha512-BbtwI8FV51dlF7/2b/Bc6A8LWD3A1SQvWlou+s2CjvXxTykoQ9NX0UQOH8W4ZBJ1nT2Iu3msdslkmxyfiTFbbw==","signatures":[{"sig":"MEQCICgKQBNeXPq9w2nFVlTUG7MCRJYdtdxXV//a/fmPOe/3AiBbR3sIonfD2JoviOv6sEFUT2q9DMcETOz4VbAiLIw3/Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184285},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e9f930d74c231f5cc40fdc6c6c676939d4b6f8fd","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.10_1698658297368_0.8371778926641991","host":"s3://npm-registry-packages"}},"3.5.9-beta.11":{"name":"@crawlee/linkedom","version":"3.5.9-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"75db6ffe0849a7d5012dceff1f2cac85ea0a1c90","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.11.tgz","fileCount":13,"integrity":"sha512-978bwCr20WyLCkdNy3STLQwNroagt8BdfFuKrRNU2r7iE0+OkZ8a1F52PQBKluQE5aX7A3NFyRO4QBNVg3Rj5A==","signatures":[{"sig":"MEUCICQ41UWASbhsgn8FK+K1kmFYZv46ajCKxHMeATrhAyPvAiEA4LyWfUCl9vvWuu0yvohDvjjdvsUURUzVnr26BW8lSVI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":184285},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"158f44736cc916999aca4cb1ad70d6b42dfd8ec4","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.11_1698659929745_0.819236756639683","host":"s3://npm-registry-packages"}},"3.5.9-beta.12":{"name":"@crawlee/linkedom","version":"3.5.9-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8a6529c960f2637f0af684b809de49765c4ffb4d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.12.tgz","fileCount":13,"integrity":"sha512-3YbTcmBblKlbNZTPMkR2lnTSsGNjg+OOVTIrARL9J09+gSRVwlwWyxrDFNh6Tl9UbjUhFYE+VnHJO/0hmGNYzw==","signatures":[{"sig":"MEYCIQDNd/YQ/XDF5aCRfA/suyEBBOe03tTPgRXuZ3iTZQZZMQIhAL1amHYCVzlP7ouV64K6EAaF1aUzlQSko/sfEsOqRhIl","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":189501},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0390b5f20be44136f46f61828a3a896b2a57c9da","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.15.0","@crawlee/http":"3.5.9-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.12_1698922943409_0.950787619060476","host":"s3://npm-registry-packages"}},"3.5.9-beta.13":{"name":"@crawlee/linkedom","version":"3.5.9-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6e67bd74f165f197a23d895ef536e067c4fdc047","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.13.tgz","fileCount":13,"integrity":"sha512-yTxeMxOsqnpZwOO1bohUcon5o2uSBMBAdaLboknKnUI2BdbxPCnaeqNqOnahDDs+hZq5Wb6RbSIAphPr/TuwEw==","signatures":[{"sig":"MEUCIQDaUl9sGthBUmZyHHuOnxnnZb/4+T4qOPQJz7hvcWH2egIgUDp9UMUbtM+9ustya0YvMM0VHQAyXciZFEvMVPoCqhM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":189668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cef47b0fc99b6af2ac722d3f2d610993b23622a1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.13_1698927639765_0.8197719800727898","host":"s3://npm-registry-packages"}},"3.5.9-beta.14":{"name":"@crawlee/linkedom","version":"3.5.9-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fda4e49cdb3dcb3198f383ad290f43d2727a85ca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.14.tgz","fileCount":13,"integrity":"sha512-EWQ5e9iE0Ne/O1IMNx9tA4gc9FZ8NAEGOSf1nFmvuSI8Rrbk7j+5ksErfw0zBn5VtobaWLsBv21TYCzrsdWN+A==","signatures":[{"sig":"MEQCIH/v/x63U9g76gU8L6+u8ITxHW/pmR0hKiidTLnew1zGAiBeRQyQKGmykV2cZ7Uf1LeYm9pDQ35uALfD46Hg8sQ3pw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":189668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9792d2103fbab1f08e46ce8953d7a61e48366a14","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.14_1698929713357_0.4485863440986524","host":"s3://npm-registry-packages"}},"3.5.9-beta.15":{"name":"@crawlee/linkedom","version":"3.5.9-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f35bb9ab20a6e71a6e120d7f3a317899099896b9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.15.tgz","fileCount":13,"integrity":"sha512-vfWHvPizC/bKEvLF4UTOlJXaETBQT76BlojTwIhFju7KXT0iDd30UhVvyRcNsySknI+EkPdxu6d2wKfYzNYvZg==","signatures":[{"sig":"MEUCIHRWR1Y2hHTq7wUxLauOtyCDYx0Pzh/J6Pr0kf9iIl9XAiEA0MqW3iGWYIu4DI2uVThQv8hJSIRQPKR9U7pX4DyNvTE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":189668},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"26e355046ea2e2c5339f943b16a9a6f939074535","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.1/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.15_1698939346518_0.6874195150163651","host":"s3://npm-registry-packages"}},"3.5.9-beta.16":{"name":"@crawlee/linkedom","version":"3.5.9-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d7d609d7b7da7d008b94cae883f3cc54f038cf8f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.16.tgz","fileCount":13,"integrity":"sha512-qKHbgMp4vAUjYE6882JErLhdRmxHYIlHRNgL7w8h2QZt2GXq1oEHEqyeze+nLLJLp4kgA0dWYAyNd0qY58XYpw==","signatures":[{"sig":"MEQCIG+MmEEqtUaToBib6/mfi5UXYm1Vqzj1yLce8rIhxEW2AiAENOzJ7lNMsi98FiG/lv4h2xLd3Xjo3Df32QGNxWQkmQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"904530e1d232f4225fcf395aa0ca1664e34c2f55","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.16_1698981843894_0.7298781451429526","host":"s3://npm-registry-packages"}},"3.5.9-beta.17":{"name":"@crawlee/linkedom","version":"3.5.9-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27a2d77647cfdacafdf54bb5d3b16288a2e812f7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.17.tgz","fileCount":13,"integrity":"sha512-yVuUdfNioadFbLr+pivK1V8vXmKpfIP2vP4ZSNsX5Y13HMYXSqVTYZLDlaA8q9xal52ntsrcY9lVFEQtqzb/qA==","signatures":[{"sig":"MEUCIFpb3smYva0BKCVziI5Py+w4HaNxuQw0OqoR1A1PwxmHAiEAraGnADa8qoT8I3fAUWyj8i7jJmdmcO/jkBIgUuJ97Nk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b282a6cf19864bb1b84b47ba425f1d8d0147ecee","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.17_1698997900148_0.5519210611594341","host":"s3://npm-registry-packages"}},"3.5.9-beta.18":{"name":"@crawlee/linkedom","version":"3.5.9-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5120f5032fb4472cedb63b6449e826d21d9e2769","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.18.tgz","fileCount":13,"integrity":"sha512-hnGd1F3+4PIGUm3+9oLh/68RGAPObyOdx2jiJyn236NS8tsWaqY2ybIjQB4YqTevxoEZF1D8MNhTaU4+8aCmhQ==","signatures":[{"sig":"MEUCIQCMvYMfwCbtgC7MA9ZLzPAEi5leH8DaLyg+bORhhgQEvwIgeMpSYRvziUcF1hI8crjSnBjHYFKd+D2/dqjd9F/Q7B0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"435d926b333dc7ead47b45997c157f79b23a52d6","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.18_1699032508223_0.42902481220499","host":"s3://npm-registry-packages"}},"3.5.9-beta.19":{"name":"@crawlee/linkedom","version":"3.5.9-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e5b52d34fb3301ff3bb1e08279a29a2c492c9c2f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.19.tgz","fileCount":13,"integrity":"sha512-g5OVW7YF6w6ABDzOP2RwhXcN+J0gt6juYZRMVByeNYG2sPcNC/csOoIyaz47NZDuHF8Xg0cV42JfCm+UNzF3Gw==","signatures":[{"sig":"MEYCIQCNuQy7kuIAcj+JBkmlIFhSYqXAZwYOb5uTmSkIy6G7dgIhAPr66tVeOE9DJ7rXJXm+TXYMScAHVjFZ8Yk44OUUKJII","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"384271fdac5ba3581a6726af2b151b456afeee95","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.19_1699070233904_0.27996141825269505","host":"s3://npm-registry-packages"}},"3.5.9-beta.20":{"name":"@crawlee/linkedom","version":"3.5.9-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1939a96fcb3b4c8cf34ffad2968125fe7db0eb96","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.20.tgz","fileCount":13,"integrity":"sha512-dJahJ6lZyDbiKEJiOa9yYfytURiwQ5WaJieLS5z8Y79zHrVrz/lgA5zb3Emj/2JDB/bt1palXEpaj3x1V94s5Q==","signatures":[{"sig":"MEYCIQDT4h2x14iSdKa3VbsCDcJXVQFlEwd1fKaGT8WKLGF4VwIhAO4zmWAg0X50bzcD3LtwrwBdmxqNSvLCylUau6Ci44Sn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d11b52e6fb01589b5f6ef7a0d12fbe7b2918f1a1","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.20_1699158588314_0.4678417018608507","host":"s3://npm-registry-packages"}},"3.5.9-beta.21":{"name":"@crawlee/linkedom","version":"3.5.9-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b9259ee3a9f74f6c195db9f3ed6742177c59396","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.21.tgz","fileCount":13,"integrity":"sha512-YR1ISunIwInFV9Unk8zqDDQqbGutfGV76lctsh/82hhpT2WLG1sEyhDrOJ/8YipTLxQbvhLd+17sAFG4XGEouQ==","signatures":[{"sig":"MEYCIQDklQSxpyeA/Dj6cMgCIFEDJaWajqQm0WOSNCKdmJNk0QIhAK9+4Wh1gXoxyEAAufEPk8QUy7q411/6kzsTgcKHWzdU","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f8b8c13d993112aa21ebecc76b47292d77053d14","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.21_1699244034304_0.37687710268247265","host":"s3://npm-registry-packages"}},"3.5.9-beta.22":{"name":"@crawlee/linkedom","version":"3.5.9-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b8c568d55f2a2ba3d13cec5aa00058a320d9c96","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.22.tgz","fileCount":13,"integrity":"sha512-stMb5pVxt30B0MT6ZUOmhL6lmOo2H7h9yUNaDflBClDIDzDY6haoZlRAJn/NA2YhfwUJ+224pWpLcKv+bjcc9A==","signatures":[{"sig":"MEYCIQDIO99Avs8WlwHudX9AuD/Emj16KjVoIHpB+FNOyCBpKgIhAPTF69/yswIDVz1ddvF1Nw7FW/XdqskLCUtAzpwBIfWd","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bfc7fc396fbbc2b9804c63b398e7165ac3404245","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.22_1699276099939_0.5662416124040204","host":"s3://npm-registry-packages"}},"3.5.9-beta.23":{"name":"@crawlee/linkedom","version":"3.5.9-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5f937025d95dd13b6eb40483fa9f9562b7487566","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.23.tgz","fileCount":13,"integrity":"sha512-O1aqr8PznOxC3xwDklhS9wt9ZKR2K45jo3gChIsTiTeb2+f/1q4lo82JXaqZNpxZXIaFuoBhWd3a7qolteygbw==","signatures":[{"sig":"MEQCIFbcAqoHgurzPopaHz+8QplMbqNg6Z10Fxs0/QAL6vZCAiB/wIO1p5GlxTnlobJ6/I8si2Qn9pkyLU1mtlOZRT5JJw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"505f25407a126c88601eaa97abd5d44f7abe66dd","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.23_1699417862975_0.8210884046819538","host":"s3://npm-registry-packages"}},"3.5.9-beta.24":{"name":"@crawlee/linkedom","version":"3.5.9-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b2cf8cdb44e2696d1df0019d21e48757de153c4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.24.tgz","fileCount":13,"integrity":"sha512-fWp/m4cZiHd4hP93RbpIgA2vs+hkfObs+1657/9qo5ZSSPVwU8l6u8iwfL3W+jWpRfjPhsig8gK6aMfvKXJcCg==","signatures":[{"sig":"MEQCICm8fA0IkLOD7sN604FA2xdk559UaeVtsf0MDGfHFLFeAiA2t8hmPjhdvUjeGzNP14s2LV1LbPir7cAjtadKekUrlQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"128deea8723011ec8701b69f1b2c932bc1948fc5","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.24_1699426591726_0.7064664374808141","host":"s3://npm-registry-packages"}},"3.5.9-beta.25":{"name":"@crawlee/linkedom","version":"3.5.9-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b9c22cb6ff04f5ca5c8172aa3e53a2bb8b876b1a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.25.tgz","fileCount":13,"integrity":"sha512-Y1vSmzEtLkvmcCd2M7v/Z4D0SJ/8qnMd0/RQFa2Jg5Dw+lYn0u6s0KZbhPVHlxjSAMs89p3+UNAVxX4XAtMw0g==","signatures":[{"sig":"MEQCIG3F616W+Mwvz+HlPl2+1MicmGBwI68UjJ2MPPKdztnFAiAE3mpfTMWKivYQSS10We5boJ0/Fbeqm5vmkXMiuu9M7A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"94f6f8715b99ae833fefb251e389d0112f9e6701","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.25_1699436342780_0.08014446914287832","host":"s3://npm-registry-packages"}},"3.5.9-beta.26":{"name":"@crawlee/linkedom","version":"3.5.9-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d486b7a7d31a5c86f2da61a236872bf49f852715","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.26.tgz","fileCount":13,"integrity":"sha512-ykdeO5mxkvnNsU0yJqQM/EFCNx07cQACp7fqrLnIQr53CvOqeQ84P840ILNv9k/9Z/ARHDEeIB7HExG9eH3Tzg==","signatures":[{"sig":"MEYCIQDZTYxMzO9lKdxjk3/QmE/To5OCOA7V91QA/EIhriledgIhAINNvR8vq08wiwP08ksJqAqPIUyQAfczjlNc9UmCbe5y","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"af148014d1728f6ebe50d6a1aea57fdfe22ac264","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.26_1699505358519_0.9299976663757599","host":"s3://npm-registry-packages"}},"3.5.9-beta.27":{"name":"@crawlee/linkedom","version":"3.5.9-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0eab1abe1955f7f896f7b0f4ee4f8f0af8ddee75","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.27.tgz","fileCount":13,"integrity":"sha512-Xi14dBhNdOYlUTfK6G9T+URIIz5+GfPNxLN4o/e32e67UwGjD8c1D+jXPW33JgKP+J1qrCAxjfC+EaZM2PMNqA==","signatures":[{"sig":"MEYCIQCT53uzVxCzgQHVFJx3mZjLGRy/0VKrD35/1UgSJtALHAIhAJCAvfD5ITK0Ph5BjTgb4Mv1zwXcWBMAzJ/4Gz5iI1z7","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8b172a69204b317ed3989f2ff56b4a6571ca184e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.27_1699547615106_0.122137604703489","host":"s3://npm-registry-packages"}},"3.5.9-beta.28":{"name":"@crawlee/linkedom","version":"3.5.9-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ee1121310aaa9876a43cc343b4d9eb571c5e983e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.28.tgz","fileCount":13,"integrity":"sha512-CBUmQa+LCYydUErrvLl09MsPKQZwVWepELA8231odB53fddwdHMU3qArFNO7DNIfLULu07NPg+QmZs6fXngSVw==","signatures":[{"sig":"MEUCIQDB+XWCf6manu6SACmZ8nyvaFzOGyxuUjph7e05i1+ziQIgQm02PLIQWOLRBcJ1Tmefa4brZ/9Xmj51eoeT+TtJR9g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6782b963237e499b21b79f8530f7d97cc3d30c0e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.28_1699587971079_0.641303455346379","host":"s3://npm-registry-packages"}},"3.5.9-beta.29":{"name":"@crawlee/linkedom","version":"3.5.9-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c71f27a881236e71486947b0bdcc1d396851f29e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.29.tgz","fileCount":13,"integrity":"sha512-ysieWO3ni1XAzpHy1VjQHgQR6Ick12B43PTnjjz6Zr9XGj5syd/xQTjVIPOj7E+58afzFji6lqIEFhotRMnl2Q==","signatures":[{"sig":"MEUCIQC9NX6+5v4y5kSHv4kLoEVztHbxaTTxlzi9UyyMdB1ZjgIgSOu4xnzPgqvZ0Ze9Lxz3SiZaM/DAlSebYgxLqKZILEM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"42a3ba4ab3c966282b463ad9fb23e65e1c462a90","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.29_1699677129501_0.6157472735421929","host":"s3://npm-registry-packages"}},"3.5.9-beta.30":{"name":"@crawlee/linkedom","version":"3.5.9-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"30768bf1ac2a79c52922e2bcb0dc2ceb6d805954","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.30.tgz","fileCount":13,"integrity":"sha512-+G7b/C2Vjt/XYsBmDPKcV5c7Z91qRYoe+jVMb+SB6wDyeKLhq88Z795+CzVJ2zcFTJvy0XuvprYgcNe45okN8Q==","signatures":[{"sig":"MEUCIBVkLkhPR1EdF9+S448K9a2vFf7Zs9YseW/9v6dtFD2sAiEA4eyqTvzT675dyHarSMecOm+H2DA9xVhd1HyZVfz40LM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"11f41f5673db3466253adc0bdb755b7a6996ad3b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.30_1699766071663_0.182526095089379","host":"s3://npm-registry-packages"}},"3.5.9-beta.31":{"name":"@crawlee/linkedom","version":"3.5.9-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8697f974c74c9bb4984f0f48e640f123162ba4a0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.31.tgz","fileCount":13,"integrity":"sha512-JjoN8bVQ03dsnP5dMNNbD+8cC6c7rtNvG3IkyVkPaczY5HznC8pnmndmrySDShKOH8O5/PKqopGjKSRxxiaszA==","signatures":[{"sig":"MEYCIQDc7Vm3Ej22WhioxCTniqBU9YkhNutGLhDFSi3f7MrfOgIhAN0mdHN29/FaDCzokL7iCjKX3gvrt1L2H537JPmpNATP","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"801c4b2e2b9315cdf7ba7b4a798eaac9b1c1a16e","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.31_1699872397221_0.1404007673512293","host":"s3://npm-registry-packages"}},"3.5.9-beta.32":{"name":"@crawlee/linkedom","version":"3.5.9-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3205a0762ae034df507827100995cc0fa1517436","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.32.tgz","fileCount":13,"integrity":"sha512-Vie4lhfLcKXeC//9KKzabc8KI+eRNNoCstOfjQnVkm6/IL5E4rSAZQqqCUyxrAW5zmrEnoGhGPk2vqMpA4GRQg==","signatures":[{"sig":"MEQCIGyWC2mt7g8H3UhCsZxHyqYk03TlyE94fKkJuDRv9hFAAiBiIJgMzXEXvFLQPMXlwh3D848jp+GlFMgwM61iR+ZAkw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6477e6ba49c9d256a0d2f339462021e256c4f175","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.32_1699873614719_0.4442140192263344","host":"s3://npm-registry-packages"}},"3.5.9-beta.33":{"name":"@crawlee/linkedom","version":"3.5.9-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c9e3a4eb7693539cb12ae278a932db6d65946a6c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.33.tgz","fileCount":13,"integrity":"sha512-jb23kSW4coK6e0CzcluU5q0fD1pd1FYRA4k8ZGiLS5vddr/la85nFoaIsSxbBgrMBHjbe2iSYoPQCSpdT9lujQ==","signatures":[{"sig":"MEYCIQCS0St4umz0pBu97ISlwyEq1j5pOSc0NeWR9jDvGku/RgIhAJ4Hs+/tmhL5frV4OTU/HD6nY0iWpQZqcjzf07zXMNfY","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"714944756de1a8f633a11b697554837311f7a07b","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.33_1699938738644_0.5245700024015814","host":"s3://npm-registry-packages"}},"3.5.9-beta.34":{"name":"@crawlee/linkedom","version":"3.5.9-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d499b224256c1c11aa6258a894d923b71c3e564a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.34.tgz","fileCount":13,"integrity":"sha512-9DeoZA0COB7v6tXBC00Q0u34RHjgy9c87du8g6KZDOpa80H8liqc2L1UgCKahB6aM6o4dUc/FN7JjplAbXGK6w==","signatures":[{"sig":"MEQCIA7GaLvK4mD8x+AWiEBraFLOfhy4x3Pd88a9z/GugzSCAiBtHuEhvxYFawZLp2osXce8JipZsWgPVixY9dJ+hgrdog==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":192689},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"978f198b1ad6bc9950c1ebfcc071cc6c5cca3164","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.34_1699943030190_0.15345901010080798","host":"s3://npm-registry-packages"}},"3.5.9-beta.35":{"name":"@crawlee/linkedom","version":"3.5.9-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"89c47534d4f3a33a1f6e15a05dbc8c2d55f418b9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.35.tgz","fileCount":13,"integrity":"sha512-ou4jfUn6rp+62Vb1TEd/59bbfNVAxDar4exMN/zPeFLfG4RUvKcRoPAL/j9ps+TJrEtBGIcEc6bNuaG7rFspOQ==","signatures":[{"sig":"MEUCIDI5IdLo4U4hMfmxy2hiY8Uzgz0B3yd0kM0vYonAM+xmAiEAm6fPq0w0YD3MvUUM2WnO0lZ5r3H9cd614lxxYwDksTQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3c09da258c70d271045e1767b43b049bd82c0d71","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.35_1699948107956_0.6002968678358813","host":"s3://npm-registry-packages"}},"3.5.9-beta.36":{"name":"@crawlee/linkedom","version":"3.5.9-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"444868ea0b545aecdeb3b1dfda49be8ebdcc761a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.36.tgz","fileCount":13,"integrity":"sha512-puSnT+rX4PhlcTQY4fUhGbrKGyooxrDXPElbGsBG4OU65dYj29tFtikh79V5ha5fwnKIobbkXfTeEBvdfL5L2Q==","signatures":[{"sig":"MEUCIQDEo1vXSzQVFsnkYxoq9Qd4RRa3QdxudkB/XoGi0nrphAIgOW9A6ESY5z1fF1ifYyW/nn4NkgyMCBIs+ZwcH9tWdcA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e69780be8bbd4979bb5a5fc6b4505345168c65ba","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.36_1699963503359_0.1595983578324056","host":"s3://npm-registry-packages"}},"3.5.9-beta.37":{"name":"@crawlee/linkedom","version":"3.5.9-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9dcf5f5b97c1732b053b23553eb89a5726a79137","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.37.tgz","fileCount":13,"integrity":"sha512-qIZ5KGrwVHstOhAc8/Cf9wKlN/aHogvnq+FRWnLtHLFPdGaeRhQrmhoz2MfpewTOHUlkTvvWf+y8hADyUHPTwA==","signatures":[{"sig":"MEUCIQCr0TyWBKsCjAwtNT5CfclBJJIQ2ikX+kP8T+WKrW69UgIgUE/5F7so+l/U0R5zuE2k8bXUepmJYt56TyrkPVIan7A=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c8b88be24908d2c24885dcb63ca30cd9c001f001","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.37_1699971558452_0.8500745728159991","host":"s3://npm-registry-packages"}},"3.5.9-beta.38":{"name":"@crawlee/linkedom","version":"3.5.9-beta.38","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.38","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7bb17abf62dfec80609554c9f6a7bf749d76973c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.38.tgz","fileCount":13,"integrity":"sha512-Vd3FBNbPzAU9W6EE+K/QgTFM8VNFhawtHPxsYJgz28dDilVCJpMEAoHNkgMeGyTwVA2m8vo4sRj3ctq45xN/jg==","signatures":[{"sig":"MEQCIAdOesRLowTXuaID0bMTcPlBIQnbRM6JCaAE0ybfl9TQAiAhLcuvN6MdVmUwB2WYqzMjHdaMDkIK1Bk7GUoXGEbwnA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9afa8951c564632e9c4f65abb5d93793d6b35fa5","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.38","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.38","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.38_1700022545584_0.9913814565803492","host":"s3://npm-registry-packages"}},"3.5.9-beta.39":{"name":"@crawlee/linkedom","version":"3.5.9-beta.39","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.5.9-beta.39","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"328c969ae0f4277cfbcdc121d230e9e369588712","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.5.9-beta.39.tgz","fileCount":13,"integrity":"sha512-BlPexEFhEJnf/VCFCdIzZH1hnXFHWS2zVzFxXaM0ta0deyitc/MN3UuoiZcrckJ7NqEOuZED3LewOlZPNf8QmQ==","signatures":[{"sig":"MEYCIQCVrxX/JMqjjCfuwlpVoWYAdw+Zbht2S9nERtXbKSAWaAIhAK0LoHHb/xDYyPcHw4kFuwYJk1AQxobshHjq0RB9qT5o","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b2d87c1e5f0fdd649a18903a12d07aee08f39416","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.5.9-beta.39","@apify/timeout":"^0.3.0","@crawlee/types":"3.5.9-beta.39","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.5.9-beta.39_1700057181933_0.27616797661524384","host":"s3://npm-registry-packages"}},"3.6.0":{"name":"@crawlee/linkedom","version":"3.6.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"67964c6df6f7125a680320dcbe0881ee7904ff3a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.0.tgz","fileCount":13,"integrity":"sha512-ywvm5pHmicsg/SsL6Bba34Hv2zjL5kN9PDqsAgjV06aa2Ge1sOhdamfIWVU94OqXExvItnMGPGreWyhg+7TG4A==","signatures":[{"sig":"MEUCIBbz1jBbSZNt6eoB+bSfRZtDARYRQJkOKpgTe9sOf83nAiEAmGgKAGMgOgTUZ77FOHI5F3AdUnaZ/AfWAWHoA4+nFig=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4370b9554de4df5f1857dba325da9a1479b5d732","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.0_1700061695616_0.29771438669399775","host":"s3://npm-registry-packages"}},"3.6.1-beta.0":{"name":"@crawlee/linkedom","version":"3.6.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4cc0be56b80ea6d50b06500e3c347b8ad7c3ee21","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.1-beta.0.tgz","fileCount":13,"integrity":"sha512-AYKhozOygGJsxGvtLYd4FfV11U1XH96eEtfX64xQwJLY36OxVg8p6v+iAAhA1Oxo7e1672irRUrIxvMBysjOjw==","signatures":[{"sig":"MEQCIC3aqi9KDLWzcUWk3kI2WDTAAzb8wetHcnMBmzmLpfXqAiBqDr6wNQi8/5hjfxZIg+J0nob7OyaRDmxyTXKz1yUjeQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221204},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fef0ec65b3f5b1608dc59a018c4b78e3b0185869","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.6.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.6.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.1-beta.0_1700062432474_0.7315767529312565","host":"s3://npm-registry-packages"}},"3.6.1-beta.1":{"name":"@crawlee/linkedom","version":"3.6.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0d150ce34ecc2095097b73dc1e8490051755a900","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.1-beta.1.tgz","fileCount":13,"integrity":"sha512-jjC+WjEylyiax6oy4rWE44Jettt6/h6VcMTVjDfnRZGcZ245xNAkg/c4Wf102UAzmEiDG81OBT6jwRqIsOUYGg==","signatures":[{"sig":"MEQCIEHBmw8A1em5k9AXGtJFHTZXtT/CaxOROzbDDF5aClRYAiBXlgkcCwNvDkuCH/ezFpjdkHK28h4Ax/OI6OTgjnqpcA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221202},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"82df1e2475caa45b8ea14be5104f80c2dafc0b8c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.1-beta.1_1700065952464_0.8603066641746364","host":"s3://npm-registry-packages"}},"3.6.1-beta.2":{"name":"@crawlee/linkedom","version":"3.6.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dcb8afed5d42a33914de7a2576376340df90f3e1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.1-beta.2.tgz","fileCount":13,"integrity":"sha512-0TVofpgZwlGJVd0Z/Pq6964PrHlrUfHY0ojUi+wFsfSK6mBNNVElo/J4s8kGlTQ77LqZStvUp9VoDrfX2FJEPQ==","signatures":[{"sig":"MEUCIHW/XdelceXXhpJPQp1q97ruyu3HJ5McQvbOm5zMJLQbAiEAyvI3dXZ8SQg1Qi1qthD+nlfkZgzQknBJn24CvsSyL7k=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221202},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e8f8b5591e83319dbfecef3a5b84e0e241321454","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.1-beta.2_1700072554491_0.5821133021510574","host":"s3://npm-registry-packages"}},"3.6.1-beta.3":{"name":"@crawlee/linkedom","version":"3.6.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e7870cb58afd105d11f5785269a19c43e72b9b05","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.1-beta.3.tgz","fileCount":13,"integrity":"sha512-ETtx5CR53xdfUy8PiR2J3ShSvu49yOn4Wfg9xG/QKxqd+J5WRlE2f4w8UxwhBcZ4MWYI5CMuNEzSo++AnWQw2w==","signatures":[{"sig":"MEUCIQCQSms0UHI3wHvdyhUJVTYpwIvoriqyLDeWztomd+7UvAIgGTqvgzbWmmdun5PAdlOlEa3EtAohuSS6ogZW18QRTpw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221202},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bb3e2b05683d01923fbaea9166e7bc4a1bc56015","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.1-beta.3_1700073507725_0.5383925183263458","host":"s3://npm-registry-packages"}},"3.6.1":{"name":"@crawlee/linkedom","version":"3.6.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8ff5c9c4dce6bdc246d08e0b98294fdfb4860fe0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.1.tgz","fileCount":13,"integrity":"sha512-NBK/j9JFamHtr7Mnpx+xTQiBblJ2FJOaYU0I3wXkcFMJfWEvzgM+kQHcTULuiQ0+POOakb2Az5+M49XRpGmY6w==","signatures":[{"sig":"MEUCIA/1L5fzInvxdnAQN9hf5O7upXOF4SUTpIpo6lX+eNXnAiEA5i3zWhLAXqdjxtttsAgMa/FlwHaCJyxvBi9uSQemtDc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bca9eabfcdbddcb7a304728da73791c0eb4e0e54","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.1_1700074618625_0.9350195818922433","host":"s3://npm-registry-packages"}},"3.6.2-beta.0":{"name":"@crawlee/linkedom","version":"3.6.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"908589baa3d04fb7ca89119c997024d35a98dce2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.0.tgz","fileCount":13,"integrity":"sha512-ke9SQQ/pFaYxMsUAnkWgivTnA8OFcAYSRfqNNhmJXB7bzH5Vj2Eb5c687fYQUwvHO72lUrKdEa2XlhdrysviCg==","signatures":[{"sig":"MEUCIHGInoVBc2t7XD6SvjFvZIUOwah2Oa0KB06B+V150lTkAiEA2ZBGjgn4CYy/DFxMf8JxfGeq1aQ0RVe8QTxps9nJs+A=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221204},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"98fd2d6ffc528689b04acc844e5bb29323e8fd7a","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.6.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.6.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.0_1700075345162_0.7511621003339588","host":"s3://npm-registry-packages"}},"3.6.2-beta.1":{"name":"@crawlee/linkedom","version":"3.6.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dacae66e04f95211e38c393114efe482a5c204f9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.1.tgz","fileCount":13,"integrity":"sha512-vbOPoxS93fpV6vhuMO0zDHHRJAdcRO/GZK+Y6iuLgeO9KJ1lZEWx7MvnwyZCQzmcN76L6qmb5aR2NrNkWjCOvg==","signatures":[{"sig":"MEYCIQCZ3Ld3xVAOTD5O3GxDYywb2ZAB3jPHo5H06e3pZBM+7AIhANzA8mHrBX0G2K0xBWlFciBuN5Ljx3yhWgofgwsH6ngy","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221202},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96b0214289f8f4905c1d35ff2dc08ab8ba5149ad","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.1_1700082956443_0.46493698999237143","host":"s3://npm-registry-packages"}},"3.6.2-beta.2":{"name":"@crawlee/linkedom","version":"3.6.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"255cc4c0240ef8bd78cf6fd5d00dfb7d5fc8af72","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.2.tgz","fileCount":13,"integrity":"sha512-OV2xIwiGOy414Aj3PKSP9SLTAx0ERXWjCHaVokHscgDJJDBON5IUZ8TT72acLeZmdo1GbXuvT0fNSdG21aCx+w==","signatures":[{"sig":"MEUCIQCizLC6w5mPhOkTxrcx39dW5O6+l1eG4mVCjK0D8uURsQIgST5SOT6tOhyx6Pj4dm9seZB3MaS29IDbvea2PtpNU5w=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":221621},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ec8cadc2a01adad8242d0f22c8bfb74cdf3114eb","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.2_1700105516541_0.12478075720975479","host":"s3://npm-registry-packages"}},"3.6.2-beta.3":{"name":"@crawlee/linkedom","version":"3.6.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2ce7c6cc53fb264014b90802e7191a376d03e948","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.3.tgz","fileCount":13,"integrity":"sha512-LgAXrtuJh2cDJfbEl9Rcw/Of6G++ZUNpIoG6vG/srYMLj1hyap0Jz4grE9RRVYCh0r2EhpaoHvPxlQsTWXe9nA==","signatures":[{"sig":"MEQCIAR62JsFvX4+xxHAdnCznaJaxM63rvY4j/dDua7ieL1aAiA7U0HXh+rt15q5hWixoDCbmKVI40WE5WMn2QzEH2CGHA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"635265b5752ada89e825ad36d0e6d078a23d167c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v18.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"18.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.3_1700194617815_0.9616545827486775","host":"s3://npm-registry-packages"}},"3.6.2-beta.4":{"name":"@crawlee/linkedom","version":"3.6.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5a7de4bd59199b9e2c8195220bb6673e9da16208","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.4.tgz","fileCount":13,"integrity":"sha512-PfZ7ZUFk7sHF8XPQHvzUpu/87bfIlD8x9iOwg9LKZS6cTEECmCJg+kpcbQ7veQbeylmsppiSZvYmRUXjqp+/fw==","signatures":[{"sig":"MEUCIFj4LNA9XJqeN2rMX0JqQTiRaivnyzNG8llvKUYfmDR/AiEAzrCOArjqHVdUHTVuJphpTVzJMsqO/+1nklFxVlU3ajg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"46ca46daeed6b7496dbe72847849f40c16c88cda","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.4_1700517037287_0.9662993245235703","host":"s3://npm-registry-packages"}},"3.6.2-beta.5":{"name":"@crawlee/linkedom","version":"3.6.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"acd76079fce1989f4cd29e039c89568d5342186f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.5.tgz","fileCount":13,"integrity":"sha512-jkY5cKomUlngmBDCulJbPWeHu0CQFOVyuz3nn5Oi/H3UqMQsEcmjWxMA5v7S1FA6gRUocuEzfAKt5D/Am5FeDA==","signatures":[{"sig":"MEUCIQD+4Nk8GIkm0Ao20jI6C3d4ZA/Zkz+nK51hSd3NJMAvUgIgRgrFFcEsyGQ/wNCJQLXpLrnhuSf2VPvimG2e6Pqk9DE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96eea476e5e06236a5e3846512dab33c1e5a5f3f","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.5_1700518426817_0.06579832526244767","host":"s3://npm-registry-packages"}},"3.6.2-beta.6":{"name":"@crawlee/linkedom","version":"3.6.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1632dcc7fe8d3f8d9a76ab38023eee00deaf9342","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.6.tgz","fileCount":13,"integrity":"sha512-GauzYV9tapdNoDYzPmHlJs47WsPpj9aIT8Gw4NKH0/a4CHIg/1u+gE/jmTQdW7vuLaPTMvJI9FE9TPHSfidocQ==","signatures":[{"sig":"MEYCIQC1BLQ/8imJPydqUBGftsJZd+9VIzbhZyEeny3YEuQsnwIhAOrLjKo/qyQJlrSAYYacWtLo/zus6ZQr1FNNT9paBIWu","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"899ddcee761103162e7fe41679f78aca13ef5e87","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.6_1700520606106_0.2454437105417464","host":"s3://npm-registry-packages"}},"3.6.2-beta.7":{"name":"@crawlee/linkedom","version":"3.6.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"74ebc5adaf0f7af10d7a82fd467d545ec996a7d6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.7.tgz","fileCount":13,"integrity":"sha512-NJoQZ5v1IKOBErX309lbn0SACXOyMuc8tg3DFdB9RtduWTwL4J+dlHhF/vJcOD1pQjdL0AS4y/5xL97EO7px3g==","signatures":[{"sig":"MEQCIEWUqwaB5aMUb/mRkmoZ7a9kzke2tZ+qiNsVtTD+xGvrAiBV6mvIbsWZxFMzajMQ/QIODwJfnstI+5UxZNUZJVGO3A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d0ef876fba146a7dc4ccd6071528ed2cb5c06b13","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.7_1700654950090_0.3371507051883109","host":"s3://npm-registry-packages"}},"3.6.2-beta.8":{"name":"@crawlee/linkedom","version":"3.6.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"646d2b0d8601130baf42303207fcf1e954c5ade1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.8.tgz","fileCount":13,"integrity":"sha512-evT/qMNRoaPyMGTC/3zFh9ppotppaVzYnwdGkJ7x2NmvT5XYitNNFHwUmNrUN/PqHzzIzQUNLaVujchnBFRVqw==","signatures":[{"sig":"MEQCIElCfGNnqJjzHEve5OTNq/S/Jb6ofvRjmxz92orSWRmmAiA3Uhs2Sbe2kDwplnW1GBUmhOdzgTr2LMBJkBRF2D0ckw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"92b0359798af88faf2fa188b7c85d2e21f29e52c","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.8_1700678142315_0.9895393476904886","host":"s3://npm-registry-packages"}},"3.6.2-beta.9":{"name":"@crawlee/linkedom","version":"3.6.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fa0d9c5b0b31d85290f555bec129930ce3ec2ecd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.9.tgz","fileCount":13,"integrity":"sha512-zR9tmilWMB3A8HzyXD2gRK5WsgZVS7ia5bQOlJ8OhCEdQPr/n3B/Eu2wPuV6TAamhHVPLJ9jtmY4QVuUyUkiVQ==","signatures":[{"sig":"MEQCIDZfAKgIrYwuAUOEwZnnBJANZG9N+fmvfPJyhkt0i8heAiATW0m1FTV89RCSwJ5sxj6KbI4yvL1x+7Zqjb+h0wlSYw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219482},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0bd5cccce9f3df2040bb6eeabc8585c763b36915","scripts":{"copy":"ts-node -T ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.9_1700822595446_0.29148609062168784","host":"s3://npm-registry-packages"}},"3.6.2-beta.10":{"name":"@crawlee/linkedom","version":"3.6.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e45f9f1972b9c2cd1ed8bab555e8d51d7acada1c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.10.tgz","fileCount":13,"integrity":"sha512-rg0D/qsZV28jzn6J6/QWqrm0gFvqMVAmPuicQllD0meweQy2/V4bEvpzSufZX8s74DnACBqCRmaCMk+RlyiaRQ==","signatures":[{"sig":"MEUCIGuZtVkBXuyEpfM5DJwm16PUCC1fMVIXP932SVMMzcQsAiEAkQmvlhlVJIKJC+nOAj2XN+m8iHAbRm2G2CyEMjYXJ5o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219478},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7422c7cd22169e037bbf1f8de2cf0ff2fa824bc8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.10_1700914745518_0.4483588376746961","host":"s3://npm-registry-packages"}},"3.6.2-beta.11":{"name":"@crawlee/linkedom","version":"3.6.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"067d187bb41191de3f569b5c23fade0ccbf6eaad","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2-beta.11.tgz","fileCount":13,"integrity":"sha512-DY+E3e02TnCt6zesGd+xUpM2PDDjwABS4FIN+hrwuYclKdMEKAsXkZa2Ta/7nqwSvunH0xeEHMjEEvJASWYjzg==","signatures":[{"sig":"MEUCIGSaczpybcyT6xPzCwNe3CNfV0/2NPiVoJ0fddsigOzWAiEAv7JQvHfCjo94GrY3sGxrkRyARtndOoRmxzpWh+AWDC8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219478},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aa27ffd51024ad0720d014a736483526bb36a3e1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2-beta.11_1701002158570_0.8877210697569493","host":"s3://npm-registry-packages"}},"3.6.2":{"name":"@crawlee/linkedom","version":"3.6.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"16ed671f83c9a68ed0595ec6229b94eb18ea8cad","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.2.tgz","fileCount":13,"integrity":"sha512-ISATzA5PzQJZfcshfWJMxq5GUq9Yi4arDMUShRBbp2pSAuWrdibCTpPOblC0FVnZbYVl4nNUZobQyXNfus7YmQ==","signatures":[{"sig":"MEQCID43zLiYFdfXdg1P66WJsOgIbHqV4oZ4koSK0Ki9jBF7AiAXo6gSz8Uzw6ElQmsKYzEVZHPAl+3aE4V5gkTvjSD1/Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219454},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9cdc34c5247d70d7ee816bbe98971d55a108c3c2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.2_1701002210339_0.8771934658358367","host":"s3://npm-registry-packages"}},"3.6.3-beta.0":{"name":"@crawlee/linkedom","version":"3.6.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a26cd3593b85aa42081a3df5d1237159d677a9a7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.0.tgz","fileCount":13,"integrity":"sha512-nm90fj/3xSymr7Npbso2/N0CPYazGcWx8u0U8gz/vqyS6RGxjKI53xhnmdn61SFK+CPMw7v6g6vLFrJmGtwcMg==","signatures":[{"sig":"MEUCIDAZq1tIVY8PWQZXfVwME7q7qH2gpWdhSMj02Oi5AhdHAiEAtU1muKitSVpOVQsuuyt52QHsQKeIGxh5F1Hptyheszc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219477},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b05084083a693e53b70c52c69b17f728a15e3598","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.6.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.6.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.0_1701002961648_0.47497812009615714","host":"s3://npm-registry-packages"}},"3.6.3-beta.1":{"name":"@crawlee/linkedom","version":"3.6.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2e466fb63c54a2983cc871aa7df3db914f9e0091","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.1.tgz","fileCount":13,"integrity":"sha512-SyGv57yhBgGLGsHAZPiOpyraTse8cni2PJ5TLrTD/orioBhRCkIHfBhH64lchsL1bIjxNA5e9GyBqXQgBmglNA==","signatures":[{"sig":"MEUCIQCMChDRSxF2NJnXtNoN9eXyCv+TEujd3CBs7E9cZbdPVwIgMgfUCernmkrT+qUu073jh1ywI0D+ZpqydLRByfGt5DE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":219646},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"78e01c8f7510a8f03833c6e8fbfa4023bb867dd4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/7.4.2/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.1_1701016722449_0.4724511583965474","host":"s3://npm-registry-packages"}},"3.6.3-beta.2":{"name":"@crawlee/linkedom","version":"3.6.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2d9496c2847d1203ce23ac43a993d8854f3b4c02","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.2.tgz","fileCount":13,"integrity":"sha512-g6t8w5WmxyUgr/iCg70sUZTtxdrKjGjIJb2D/fWJgKD9NRVLShpv0a3BHincNmHJkv+xWbjnHDpCsOsUQNn27A==","signatures":[{"sig":"MEYCIQDcVhgKRmTI//oyulBSLZNxP3Nb5D1EHdDFrzzx9kA3KAIhAL9O2YUqSGJk2B0slblrUN/tM6Lo/TwXemZHcXjtQh8b","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"288834a68ed2416bdd75c6f20bc1f81991bfccfa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.2_1701020054293_0.910201937747652","host":"s3://npm-registry-packages"}},"3.6.3-beta.3":{"name":"@crawlee/linkedom","version":"3.6.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9506c7057ad3bdcbbfac674965b76e55074780a5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.3.tgz","fileCount":13,"integrity":"sha512-JR+/AJKUEwzuGrr+a/38ZN01fuq0pE1ZS76z0UVBOVdqkwuimVy7d2xZ81ds+P9jCbTc8zbjC1GEN9BNigmTwA==","signatures":[{"sig":"MEUCICUcow6NtlUWOjTZJcG0NUEu2KdgfjO4s8zMTLvrYW+IAiEA6N75zoUzsAK/tp/K5Miuglob7vESjITXEpOMErENUe8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a8e412631ca56bdd48e03317a543529f1fa157c2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.3_1701058169103_0.015535068989629197","host":"s3://npm-registry-packages"}},"3.6.3-beta.4":{"name":"@crawlee/linkedom","version":"3.6.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"68eca266cbd71527fe733dda5f885ab696748ed5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.4.tgz","fileCount":13,"integrity":"sha512-3QR3QlgzcHx39bWo81qbX6svR2IyIodw5kY5PrgJvrSIjZbgJzufTc5L4A7KqalRA2/+RmBybC2O1BGf2c2Ohg==","signatures":[{"sig":"MEUCIQDjw74gDUfa2KfGoA1g0j/+hVH9FZCV6p/Z4vzkpMpg4wIgBB23tWNg1FLl3M4q4LL64Pu2y9PY+znr8LsKLsq3Aas=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eee1269806e4dbe1da640be276d5341c41263ebd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.4_1701086141160_0.9385451288953297","host":"s3://npm-registry-packages"}},"3.6.3-beta.5":{"name":"@crawlee/linkedom","version":"3.6.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a642e6d307cabada7264431b2c9651e136e1266e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.5.tgz","fileCount":13,"integrity":"sha512-XNJMmVMqDqGwfD8jxwKevf1VseXoOOYdNW7Bfa9F5ArmZbuyDjT8ir8jUk+vM4U2WNcSzzPnxfRwX9IkIDu2Iw==","signatures":[{"sig":"MEQCIGNAdNcjcYxkkd86FmrG2gYutMjPJuC1KySIIciN9RbSAiAMe1LXeTZIHM28srkR+llWyvZIaLOBRXW1GDLi99lo3w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f664e8cd1f103add8b4cb0b64db2c4f0325f020f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.5_1701086878746_0.18159482667710725","host":"s3://npm-registry-packages"}},"3.6.3-beta.6":{"name":"@crawlee/linkedom","version":"3.6.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fe16ced4142beeed340bad9a1d263f2ae5e7460b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.6.tgz","fileCount":13,"integrity":"sha512-fgThre5RErViUkXvksm9SnaM5SDAYSJ6vQGb4ZOGPFHKGjHrBf46iVLNgouRFWSA8N7p2oTXVEsdl7GBO86FdA==","signatures":[{"sig":"MEUCIHzi92Ix2uyjzYxT+sNU2XC2uhrOmBI1DfN94U/6C4YvAiEA35fvc2S/banxWmmlKxt6p0AnAtOuygK0GgM0VeDG/UM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"54f169dca62cad023c9ddeb03ded83eb9a040710","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.6_1701121081095_0.6534275499734383","host":"s3://npm-registry-packages"}},"3.6.3-beta.7":{"name":"@crawlee/linkedom","version":"3.6.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"717ddaade819522707784fcf0c6c7383bc3bc8ec","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.7.tgz","fileCount":13,"integrity":"sha512-quE7SoMOqmy1BlFDFrPlC8Dfges4op/QtlJCutN6Qz1acSGMT6UB/8JPwxU0KcJPRPmdBx/o8TGXaLy8Z4Be5w==","signatures":[{"sig":"MEUCIFecwWCYBrjlXWTazD9wIjtvPpWUzCs2c0FCC6J6XgjAAiEA3jgai+AYIP81VVJai3vvnlDMeVejvzpmBZbx9bhUz0M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217415},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f525b3d4f5cd7f601c28141d6c63220340f7a73b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.7_1701177831373_0.25650752218316053","host":"s3://npm-registry-packages"}},"3.6.3-beta.8":{"name":"@crawlee/linkedom","version":"3.6.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc1d8868fecb205967eb1e8d40d8433e9fd1eb33","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.8.tgz","fileCount":13,"integrity":"sha512-6f1zy8jJQrzN/+hh4pLoX23waZTOVVVPnt7TiUbgaxO2sD7j/BPw0jxK874iQ0pU0wPtQbSkkYDQbBQOjqYoAw==","signatures":[{"sig":"MEUCIHvZVUr8ishD4o9sleWVW3cSbYJyZPXlBOX5Pi7ZaeCcAiEAz+S65JrwhMGOtJhi2IO1Fz6f9GD4EUpuwcShmryiebc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216996},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bed656d2272b84011328897d8c7af14c13943466","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.8_1701205306360_0.6669540033989521","host":"s3://npm-registry-packages"}},"3.6.3-beta.9":{"name":"@crawlee/linkedom","version":"3.6.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9b6b9e36af3fd783453126a1c768a64d732045cb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.9.tgz","fileCount":13,"integrity":"sha512-vsC74pOtgjqRBQoEBwIaAhJrt9DY9VwoBe5Mtr7qM+6BdQ3oEgkwTl0gxg9w90FRQuDWs6FnqZ5kXh9wkPs1yw==","signatures":[{"sig":"MEQCID4Ayyzvwff+O5NNPgKOgeuWPjbyIYkjvxqoSI5y/Lx+AiAe0mgOab2YBg4plblLiHE+AiEXNskYswSOZJWE6i1ZEQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216996},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3ac6f73da1abab5fb904c8098669becbccc3f6be","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.9_1701252684541_0.820996212808285","host":"s3://npm-registry-packages"}},"3.6.3-beta.10":{"name":"@crawlee/linkedom","version":"3.6.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"86e4241a9f0d1ed6a1a5af1baca36c0a17e126b0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.10.tgz","fileCount":13,"integrity":"sha512-/8HFiNFScw74mOVU/nB9v2qD9vhPRo8ii3XfTbtHWT3pFeZM9E6bD/hTpiDOtBqD591yH6ER2HgfjHZU/cjZeQ==","signatures":[{"sig":"MEUCIEtL66NlAx0RKU6rVQnklhOvef9MAwSUR8HOn6p1Ni29AiEArKeJBJl+azvtEEx+i7MfUhdg2EwNpaGorrgq8ybceEY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216999},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4974b3cc5a41c42342f1acc170dc16377001066c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.10_1701255178517_0.17080745841778588","host":"s3://npm-registry-packages"}},"3.6.3-beta.11":{"name":"@crawlee/linkedom","version":"3.6.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2d751dfc1ea5db8818be4949281a06c1d9e10eac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.11.tgz","fileCount":13,"integrity":"sha512-CUuij5O2JL9JSlIof8rwOXXjXdkCuNirRxaU2e6Mp+3LAQ0tBrCWh/Rerz471AtcQTasrKIx0rpxCk7G33k6bQ==","signatures":[{"sig":"MEUCIFqlfPimOltrC6Hq7Bak0QA8VtdVkF7ASL2IaXC/P1V7AiEA3z5THoDZHzO56k1vlxMUV7I6PzWNdp2mMcvmTKe/e34=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216999},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"79f6e1dda83024763d59da225c301edd996926d3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.11_1701255997122_0.17497317706405346","host":"s3://npm-registry-packages"}},"3.6.3-beta.12":{"name":"@crawlee/linkedom","version":"3.6.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"acbac11f2a9af73bda87272c6f8d6ef44deb4430","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.12.tgz","fileCount":13,"integrity":"sha512-k6piYwPKEzKPBLuRDX3I11GKqMji9PklOqhEIsOdffrkCkofjCub9DE6F9TKUT6MnTEPteUvMCZ/bvznOCgyvg==","signatures":[{"sig":"MEQCIBOxA1MVoxjgqfFM5qiri8XjeER5he625cqTFax//Bo5AiA4ELfnIZoSi4zbMU82We1vKvtqnQuAMcvDFB/mtKla9w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216999},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b4cf676632192ac4c793d58c439b3b07782564f5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.9.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.9.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.12_1701318158067_0.7980230714978347","host":"s3://npm-registry-packages"}},"3.6.3-beta.13":{"name":"@crawlee/linkedom","version":"3.6.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eb52a79c1ca471d84f14f41266fc4414f8ae0662","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.13.tgz","fileCount":13,"integrity":"sha512-R8m/dk8sgXpe3QhWZ953BHoCTuKxp/tykXS++sKi386iRSjGBaJk5h109X6HiHJeeaw2NcuocktxfglcNYiurg==","signatures":[{"sig":"MEUCIE4z5pqBmzZm7T9//KsK5EUspSS/4TmOspStLDEWYOaHAiEA2MUonNbkf3Ctfo+HK+EUiPcVgbif+0opEPmguTP4pf0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216999},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2d34709ed8ed9a346701b73d111b35391528b8ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.13_1701396476713_0.3982300111546091","host":"s3://npm-registry-packages"}},"3.6.3-beta.14":{"name":"@crawlee/linkedom","version":"3.6.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5dc7535c1b673c861b15c0a1cdc9ea1b677d9a72","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.14.tgz","fileCount":13,"integrity":"sha512-FhLuEK8ER5fR69edAejEXH/HT8Pn741qjmAkgkDqIWf35cQSyOeLW4zRvEHw+8ah4ZmQJ1lR5gDQUEJPVpJj2A==","signatures":[{"sig":"MEQCIF/5tUPc7vBulR0EuVXlzvGaCv6Htu0unOID0ZIPbgNlAiBos9Kfg0wFoWl/fQIzbcnfv9LAko4OT2qmJigtSopFnA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216999},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"78037f7e19cce1637c1e301d18e2ef429b730bb8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.14_1701400859372_0.4968712059803939","host":"s3://npm-registry-packages"}},"3.6.3-beta.15":{"name":"@crawlee/linkedom","version":"3.6.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3fc45e1c95e37c2be8ffb37466db8c2cc463df10","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.15.tgz","fileCount":13,"integrity":"sha512-gHqAMME8qAzreaM2Az7+WRpNYLcG7sS2QXSUfLaHriPyXUgHVNkiSW5RDEXQY3oLamsBZImQeZn3AXfqoizijw==","signatures":[{"sig":"MEQCIA/kc6salAdgHGcd6jQdIhx+7tY7X4ekg/c3qPf+IkrOAiA9wYoKMwnrFXivlY5QjVUGZwR+fIA3Dx4TKSG5dSpdpA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"337dec6b2e3d8fd1586c9ae5f95c40be34a49ae6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.15_1701488671970_0.5254974004654913","host":"s3://npm-registry-packages"}},"3.6.3-beta.16":{"name":"@crawlee/linkedom","version":"3.6.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81ee4b451a7b7568acddf6f1d9b46550275ff809","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.16.tgz","fileCount":13,"integrity":"sha512-qnvHuOyfrvAQl2hpkjIowVmigmgb6mHfjrG62kmYjmdJowiRdVMdNzUbiLOPe7sD+vat0V/A0OHcj/zJjqHenw==","signatures":[{"sig":"MEUCIFBPVrB/NloxYTtWeD0XN9z9KOcNyzpjvciesqUlp51uAiEA+8ZGpCj/RAmtSk6sKEBt8PsIYBGHzytZOGF+sE57kJI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6c17bf8db1de9b7c40f29daf18c56b204839f8a6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.16_1701663553031_0.5446763932178798","host":"s3://npm-registry-packages"}},"3.6.3-beta.17":{"name":"@crawlee/linkedom","version":"3.6.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"897e3c18018740c2631815aec3ff096209fdec3e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.17.tgz","fileCount":13,"integrity":"sha512-k3YrY0M31CBZ+D8ocG8AE36TQtajhLjOCetqumnl153Q+x7aZiYozMM4/Am3ZAGrbjzRhB7zdtfFzVe5nT6r2Q==","signatures":[{"sig":"MEQCIHEqmkxss+3au9NAuqXmtXAdUo5vbFlY4hOorI4YiVGKAiBQ3rQcYkrhoAqxY/e6JaLBRVoAidrIQuiXhjQv95x2Mw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"28fdfd937f2d41eae6d552f31ab478e6f384d717","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.17_1701720445604_0.36286620402612946","host":"s3://npm-registry-packages"}},"3.6.3-beta.18":{"name":"@crawlee/linkedom","version":"3.6.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6c2087454a9dda6cc8e988a2b86faddee7f3e9c0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.18.tgz","fileCount":13,"integrity":"sha512-6xP7ntjRMRcnLrpIoXVWAYDYMrwpoWhj04pfGCnRBzIpkLAOVcjLyC4rsJPwmznBGHgLKz6pXa3T/PQHAE/4Mg==","signatures":[{"sig":"MEQCIBRC/lCeJrprf0GZiKi7xytBqNkGb4uGjJtB+BSi60CLAiADEKtzqdPJ4Hvw7BZaKoX+FM4TdGYR8VU+ldWyjNhtBg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"023f0ef16084ba66be77dc5bb30ee66429501930","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.18_1701732721763_0.3630265684270937","host":"s3://npm-registry-packages"}},"3.6.3-beta.19":{"name":"@crawlee/linkedom","version":"3.6.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"963f9450688132a3db03a59d34db4a2e1cd0955b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.19.tgz","fileCount":13,"integrity":"sha512-AselrOgV436ZlcGHq/qeaTg9H/MPlFcjqiK57GIfR+WdGqMtYlxhV1Uza6v9dxcusXgNxq7XWau6wVBF8bMOBw==","signatures":[{"sig":"MEYCIQDCMsiYLGzxpU8hrt85KRAR9IT2HFrrPAyzOrkZz+t85gIhANntvRmhaXMjO5hF2She7uO/JIkc5a1VQCrmsAUkBGlA","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fb34faec1a5640ff2fe6b73ff7b91bde84a7497a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.19_1701753458741_0.5254001934078432","host":"s3://npm-registry-packages"}},"3.6.3-beta.20":{"name":"@crawlee/linkedom","version":"3.6.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1bfa86f8adbdcde7f12595ee740258e824081a99","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.20.tgz","fileCount":13,"integrity":"sha512-Q+SkteMTzIu8w3U+MGpqptJL35d4kAOimvzPMnpErKVYjf9rkyOyw/np8WKf6vgWI5oFn59XTYOyMU/rQxxs2w==","signatures":[{"sig":"MEUCIEzGpCVJRTzczVVG/2qp/4CyfU/dKLnOwVDSQ486JkLUAiEAjpbuh5Eq4Yjr9gtZBmjPTYdcE+cO5IJrv/CVSngX2Ko=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ff121bb29791a4042b949b68e09c6e42267a5988","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.20_1701822128820_0.2855145192678239","host":"s3://npm-registry-packages"}},"3.6.3-beta.21":{"name":"@crawlee/linkedom","version":"3.6.3-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6b2c43cca1fa39999cb266215ea07d643cda2392","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.21.tgz","fileCount":13,"integrity":"sha512-x91K09ow5Jz3DuM6AWQB30x9Sq4X7pr0l2qpsuPcAInZY3V7QlzMGyTDyTAVZ0vSwa8KzhUIGc1M1dKdinr9Fg==","signatures":[{"sig":"MEQCIHf+s/Lw9rscteHBVhSKfg03dsQl3clDTlxNf3cXq+nOAiBg5uort6aHORgequLCD0dMvlklnm4haHJcGrvqbbA8qQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"925bfe51bddcf2c68dff8c786ed2bd55bb2f9081","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.21_1701838943579_0.01012877840883819","host":"s3://npm-registry-packages"}},"3.6.3-beta.22":{"name":"@crawlee/linkedom","version":"3.6.3-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b7034171e4f3348b9ccff4b1f055562c7ffc9910","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.22.tgz","fileCount":13,"integrity":"sha512-2gDp1IeeZjWfE9SelicQnD59s02y+bN8dMDt/875HzJzUyEckbtGq5K3ZaGlruc8Bh50dKowU1P5oWmc0O4Oqw==","signatures":[{"sig":"MEUCIGPb8LzWj/mQEHDxCyGx8mzD4arHCC/SQLIpBVG8x0WyAiEA7soJTArFoE1EfjxTJNMipzFA3HVfLDfqJr6/Db+hMhs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d41f69bb6b297bd740f427d4d7d193a021a2625d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.22_1701878889278_0.5729845735885499","host":"s3://npm-registry-packages"}},"3.6.3-beta.23":{"name":"@crawlee/linkedom","version":"3.6.3-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8aceb8986b626d9c95e7c71e3f7e15784c734b24","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.23.tgz","fileCount":13,"integrity":"sha512-iL+LJDcqADemDTNgolYNIkXOp6PZlcm8B/b3Gq1ds6eJ/PWh1WLYdpJthaFDFOTwx0pYnkq9rq3q2PFaSNAavg==","signatures":[{"sig":"MEUCIQCM3EH28XKbg7CR3ozfhGq9ta2IKzfi4Ip/a2mh6nH3ggIgFNWw8NthVg3sFZq9ctkoFgfKUj5a7isceSfXpqDuH5I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c571b33df1bb6b47778d9fd2b04402e5015a080b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.23_1701905895286_0.44348510167902","host":"s3://npm-registry-packages"}},"3.6.3-beta.24":{"name":"@crawlee/linkedom","version":"3.6.3-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"33ab53cb45fa1777ca68de415129a6366005b1b3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.24.tgz","fileCount":13,"integrity":"sha512-OjRlYHEYfBUB0SZ9xQi941E12MgO3TSCrP+RwTvBUpSfKwlJl6CnFhUnew2cKidz8bN7FFYs0xkQseOabtOcwQ==","signatures":[{"sig":"MEQCIB3bQnHbbTR5dSP9AFilhEzlTR+PMBXDtQqAUlobONKxAiBl2K2D/391dz5MCVy693alIt5mzmAsVSbM4D8Idav9FQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212597},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b87a1675bd46bf4c4892b1b8a7f56fc7124975b3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.24_1701923088410_0.2596681667521634","host":"s3://npm-registry-packages"}},"3.6.3-beta.25":{"name":"@crawlee/linkedom","version":"3.6.3-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e6a561b9fb765b92048893b54dd914338604e2bc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.25.tgz","fileCount":13,"integrity":"sha512-DnwmUc5e8NkBNEMetlNsHd0WW2pDRz8Sg0NOrxIySUpALMYAjE+Slyz8jmm64VAea1XroMyc33q+eadqyDeAyA==","signatures":[{"sig":"MEYCIQDkmB834cdcxWMxyAlvpwOeqSO07S8VLNJ3ACurHFmCNAIhAJq+q39AxJG4rLDHvP8CTb3hYbkajExuC48cw/eRAn58","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5bb8749c1fbeac78980e6b2cfa861e87428a881b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.25_1701948035170_0.6391396201230715","host":"s3://npm-registry-packages"}},"3.6.3-beta.26":{"name":"@crawlee/linkedom","version":"3.6.3-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"510bba40fa0c6b9f65fea02a41d9b285703748eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.26.tgz","fileCount":13,"integrity":"sha512-FTY1IcnzRzyypPOlh5cpdRFVlnlMRgzrgXy7mdqg6rQODlqQudCD6QFhI3Y0wQF2KJK1EBFNo+eOmQGOoUTEUA==","signatures":[{"sig":"MEUCIB63m/xtIW8Q1wcV/Bso1A8KNrc8YgoLPjeVh/8arnwcAiEA7PcmSM1xboJe9+08+r0AfqU74hAvkfsHcPffK+85sPQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b536d4e00df4104a82239fc3738c16f3b38fa53d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.26_1702007639573_0.11234668536373804","host":"s3://npm-registry-packages"}},"3.6.3-beta.27":{"name":"@crawlee/linkedom","version":"3.6.3-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2346015f83ce8336dd2256b461ddb11678021380","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.27.tgz","fileCount":13,"integrity":"sha512-SnC10zx1CH9qDIOmfFvNtPLT9s5JDTl8xjHTOe+LAsrRHAvOaBfZ0nmsuJVYo9TP7MJnm3jhSWekoJhiC23gJg==","signatures":[{"sig":"MEUCIGM8k5eDSqhBt5e0dWXhkO9y+v+zVi9xrsWGqYcOmOZ6AiEAyKNSmoSXSMiriOzOOFoJBNnO9o6pF9ET9CBth+Orgo8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57ec0bfb2ba509125fc6f0c73df021ae75e78eeb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.27_1702016029817_0.28982591370710953","host":"s3://npm-registry-packages"}},"3.6.3-beta.28":{"name":"@crawlee/linkedom","version":"3.6.3-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2ecddd9417de75170e57f9a5fb6f8b3424cd349b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.28.tgz","fileCount":13,"integrity":"sha512-QSoWPLTkzHgWP+q0Kcz5rZq+l5TNtPADbKSjkGUYjiTFl+jje88zWAh9Z5Ud7QthZ2bSjJNpwWuu5GrLGJyeyA==","signatures":[{"sig":"MEUCICy5o4L9J6pMRnlwPUdOqpHKbiqiyfCxMgwFkI9ib4gUAiEAuDJqjVVG4lNA+bNcBB8XliURiAzFic3vRnuliYaGlyU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df42f48d5ca44ae1b93c37d9e148cce333c3c31f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.28_1702095558224_0.19782590561532754","host":"s3://npm-registry-packages"}},"3.6.3-beta.29":{"name":"@crawlee/linkedom","version":"3.6.3-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9509a311eb97ad5ac7495f347ea8081df69e89b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.29.tgz","fileCount":13,"integrity":"sha512-LfjnTZsOmFmPdH6sNSLIY+A91nIKX/wgGRTo8UigYx5WrhxwrIyO0P4niaKuHYvLfb8t3Uor6KuQWoovuZ3+zA==","signatures":[{"sig":"MEUCIGkiObsADjo4jHSeW6A/NLWjMVQPOjjCdWt4PnLeZsWUAiEArFmgBNaE+qeDqM09nTskYX6Nr5k84DkOxtK3jFIJDRc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5add5192579c0c8fea9f5a1badabf7f7f1c44a44","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.29_1702184546334_0.8110252710436974","host":"s3://npm-registry-packages"}},"3.6.3-beta.30":{"name":"@crawlee/linkedom","version":"3.6.3-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f9043b28f4f26490cf566bf7d8af0cb7cc4d6da","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.30.tgz","fileCount":13,"integrity":"sha512-Bnsnc2ZE0FQ+B2G0K04PFQkqbNsPhPJlSDCE8mZZLgdXJo4whG26GCm+U9G4cBy1VfBljH5S4OYw+Ffm6KjWaw==","signatures":[{"sig":"MEUCICuHS/aSAvFVYgUdSAY102zesJQxcmA3EZ5yyiWXMZJoAiEAkNs7Qm2WoZD45GPBYDq+P0vrodKwvOt6Duayyk8NGuY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"674355625fc80fc3465c8925feb54a9fa6812d05","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.30_1702269679060_0.6844311030188515","host":"s3://npm-registry-packages"}},"3.6.3-beta.31":{"name":"@crawlee/linkedom","version":"3.6.3-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"beb8f83d96567c2a8091565812bdc3c498b7fe91","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.31.tgz","fileCount":13,"integrity":"sha512-BveAKjaBaSE/w70vssN4KAhE9g1z66HkUUM0wVbGA2ozLD8VJoqXhkSjtFdyYaBGK/g0Y/RDVhotOezEgcz1Gw==","signatures":[{"sig":"MEUCIQCsCicMChcZ0Jn4HbI7gwxxRel28lOQ0RGAVVX/mrLBIgIgQLXn2gfvqmCJXeOiPdP5aHK06jFYl+/OPMHW1K0jwIU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212216},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"749ab55bcedd23339516145e5eb67feb16a980e2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.31_1702333208780_0.8276301830982773","host":"s3://npm-registry-packages"}},"3.6.3-beta.32":{"name":"@crawlee/linkedom","version":"3.6.3-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"154e48dfcd6812998acc58fd2307876cbdfb0552","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.32.tgz","fileCount":13,"integrity":"sha512-FYT6x9y71CwZvuM6EmxTHNqebSeFTZhBOiAoiRTI0B6HkaqE2qqi1YP62E6KiRu44DMZHb3kH3LoYWAgSwdP+Q==","signatures":[{"sig":"MEQCIE/LSdiP3gcooag7LqS2jIsGBFFWOAm6OsjhCTpYnNkHAiB6dugg3PDV20aGXNXGztMA+1LeFu7ySntZT3rjOtpEBw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212236},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f0186eb5af8e13a927bd3ba5292c797c07a6644a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.32_1702352155393_0.3843802439219757","host":"s3://npm-registry-packages"}},"3.6.3-beta.33":{"name":"@crawlee/linkedom","version":"3.6.3-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f01f6a6215cbfd58ed527b102129bf81617059b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.33.tgz","fileCount":13,"integrity":"sha512-RErTuJeHlTVah/VQH8gpfxVXvoYqqQhbmVP4CCw8KSi+DBYubPLrgS3ieGqu3OdsW+66t/Z+LOn1yfFg0VZXTA==","signatures":[{"sig":"MEUCIQDruu06IcYnX9QNa+47ocaHbn84NK/xOIIjre8PdcfEmwIgI84WA43ffyHr++eXTSMrM9hMLtqCBkIPnOAR1Kh62YA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212236},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4d66c3a6ab55686c9369f314a0fae83d29425894","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.33_1702428801930_0.608117570270384","host":"s3://npm-registry-packages"}},"3.6.3-beta.34":{"name":"@crawlee/linkedom","version":"3.6.3-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e1eb383f6ee58751a3e15b78a365d557bdf6afed","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.34.tgz","fileCount":13,"integrity":"sha512-oaMwGJ6lDOEphb0VuPQvaWb0v1lpeIsbO8cL9P/ISGKYANygPX0gUPtEWigySKYRmtSSGxLmvSqe5mFmwfhyqg==","signatures":[{"sig":"MEUCIFnk1x9VFpqirYjfv5IYF/BNp+0skVop5DnqTvtBORYYAiEAh0MpWb6pN/Ecp2s13hADOh7TNHDfuOgSrXEaFVfmiSU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212236},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"514aa8774a736422433599df2d185e0085c20704","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.34_1702440618584_0.5772705123903143","host":"s3://npm-registry-packages"}},"3.6.3-beta.35":{"name":"@crawlee/linkedom","version":"3.6.3-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bb97a4abba615d8c31cac5060a61911ae03baae1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.35.tgz","fileCount":13,"integrity":"sha512-HnyFLD5r1jJqbqbVyw4oVgfxFclpYinSv3j265vzYo7yIURUl5loinS3S/Uf8J2ajf6qQhr41lVOQBzRkgmy/Q==","signatures":[{"sig":"MEYCIQCsvInN2PxVpeNILDqAdwoY2Kc/olhKrwVJ6/b/OEJSrgIhAKqdep2tvf3GBJuihNEbzeTOVufdiVKtgfG6u2Ndo3o1","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212236},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"464a7ae80cc7fda791702be8ee1c83e158a95ba0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.35_1702493753916_0.026046911916872917","host":"s3://npm-registry-packages"}},"3.6.3-beta.36":{"name":"@crawlee/linkedom","version":"3.6.3-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c46c72aedb02515ebf9decb5527687cc9693f3f2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.36.tgz","fileCount":13,"integrity":"sha512-h/QR6nYQ895dlD8eV9LrZcPCfUXIR31EB8hKAJNAgMm9Qt75z9jXbCxGq+SCziUpf5F1T8Pz8Bs5y2FjVG2ICg==","signatures":[{"sig":"MEUCIE4rFIeu0LCY7Rty1eRl9hFzddcvhmCelL7PiP5aPRc7AiEAr3cud5orAMAQOOYaAr8RIqTsy+LQy55vYywZZ2mpi50=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212050},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0cdb30b3de9d6bc4f7aaf35ccc7250f52b020fc5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.0/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.36_1702612104480_0.9933790020098738","host":"s3://npm-registry-packages"}},"3.6.3-beta.37":{"name":"@crawlee/linkedom","version":"3.6.3-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b09d4dfe31253155278a490ef213dbd41ac451b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.37.tgz","fileCount":13,"integrity":"sha512-CcDDaDhacyMyePGbYu5DKwf3QeaJKDxeEtAUo2PKyiuh5WtzP4Y6Aaodorkt0p3llgNLCAwHwacKszjtBmE9IQ==","signatures":[{"sig":"MEYCIQDUb9iWXXik2apasgY4QJ/InWUKFMAoNTi35kr8+2dKRQIhAJxhuFzbdTorphZq+hASdEJg6Xvi2wuz5kUxOOZiWGIC","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0dc44d09ac3be1bb8478c9bf98328bbff911e2a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.37_1702697772443_0.6781961728933912","host":"s3://npm-registry-packages"}},"3.6.3-beta.38":{"name":"@crawlee/linkedom","version":"3.6.3-beta.38","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.38","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b7a37cba714d060606777737830523bb96163fee","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.38.tgz","fileCount":13,"integrity":"sha512-SC4b/hlD4MiOeikPg9psba33JoKSMJZGeDI34/zTQlwRcXuBQiDfJNcrV3sJmTQe+8tuxiN9veXUYm8RvbAJdA==","signatures":[{"sig":"MEUCIQCQkSz8YtiyaO+q8zJgYnxGwRfrKzfKmJa1uhu9mf9sOAIgJs7Zf5h5eLOJubRgVtJjR7JEBoRBMUVL2U924V8ttUU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eac66ad1453f78930602b83d0441ba22b690d3bf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.38","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.38","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.38_1702870223540_0.1229962924680903","host":"s3://npm-registry-packages"}},"3.6.3-beta.39":{"name":"@crawlee/linkedom","version":"3.6.3-beta.39","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.39","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"399a40c4e0835851592249a46fdc0cf3320786d8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.39.tgz","fileCount":13,"integrity":"sha512-YlA+EihWTrvUlXfUGv+XOwa9rcxyTak2NSbdGOBgGpvQ21QI19YokRuyiWXVDZpHXQOuQXMio6EaiJ7ouOJpvQ==","signatures":[{"sig":"MEYCIQDOQmtFeJEBLohLALxxpuZmI7jJBgmfWOZS489Y3ltDQgIhALQNKfgNoISqA/yHkA6E3PK24I7VUMCZ+/Mc6PN357nV","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2cfcac90a8fbd7758e2eaffe4efbb266b6f2c3d0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.39","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.39","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.39_1702901799441_0.2062096223791221","host":"s3://npm-registry-packages"}},"3.6.3-beta.40":{"name":"@crawlee/linkedom","version":"3.6.3-beta.40","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.40","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"197f79f106bb4fc6492a137e4f3035c90c8ebf50","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.40.tgz","fileCount":13,"integrity":"sha512-ihmRQxmsHFaT3fxniePOW991eUT32px6p01WgF3Glm8GfsOrRzKwMC4vbSXidukzg6gpo2SpNxWoGlNTsCr8zQ==","signatures":[{"sig":"MEUCICy4Y9A1PljRu/6frzvxrilum3vJjbxBrK1Za0W0toarAiEA+Tu1moSflHyODdMuaMY4EtKENsV/ZwZSd6hfNXCXiUs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"47a4632e8f5b8579923054106690baef67fa5bdd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.40","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.40","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.40_1702940918245_0.08866558260716206","host":"s3://npm-registry-packages"}},"3.6.3-beta.41":{"name":"@crawlee/linkedom","version":"3.6.3-beta.41","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.41","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"75102b1bd5929d54f26feda49679dac90c22158a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.41.tgz","fileCount":13,"integrity":"sha512-8v+tjl2lcAoSMuOxuUc4v77iElNI/MPoJyAttT73ZPoXhwYvtzUz5znIcEockBbAND+tT/ziYK6LBbnQc8Nqtw==","signatures":[{"sig":"MEUCIQCq59jtQRpIiA1d2u7gbdGvqCdUL+BpyKI7p8Eumo4ZZwIgB8j5R1PnxOw7IojJ7UCrekgg28Lb+0Aj7Xja2ejQAh0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"205f62eee730360bc8ae78755760b998218b76ad","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.41","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.41","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.41_1702957586860_0.42426811137140974","host":"s3://npm-registry-packages"}},"3.6.3-beta.42":{"name":"@crawlee/linkedom","version":"3.6.3-beta.42","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.42","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5554da13e8dbe0f99f19200078266e0bba6245a2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.42.tgz","fileCount":13,"integrity":"sha512-XgPmUTP7CHhwm0gw8bdlwEQom07jLzOXCuwzqh6V+PqsuwxlSaRcfur3Ryfqy85V83RqAOXrt5lyG9b78TWzzA==","signatures":[{"sig":"MEUCIQDuvQnMIpSNpHUGBp2muwv8ZfnNric8Cu9f+jmFxgd18AIgfUMM+ETIez8eGVLxNSOJb8fWTuMEBRYkpV/sNqezWzo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214478},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"563ac352bd82c635eba0c6500706023c89447447","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.42","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.42","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.42_1702991951951_0.014169500704688032","host":"s3://npm-registry-packages"}},"3.6.3-beta.43":{"name":"@crawlee/linkedom","version":"3.6.3-beta.43","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.43","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8aba9e8f448e3ef7d1cee575c172fddd3582cdac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.43.tgz","fileCount":13,"integrity":"sha512-T1QvrkRo/fochfE8s0mBDLM6vffVW3t786Zy9nTZIKkhOFmr7hAjO8E3FhuuJyG8JB6geOM6S0ZQpXTtBLG7bg==","signatures":[{"sig":"MEUCIQCne7SDCfRJ/rFIWMF8ZOb20AvZQzD1Aszru/0kgZ8SJgIgdOcRB9Wo6dxgr6eDK6KWMse9o9T72gA4V5dXn9ewtns=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214478},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1b37a9cd6b1c771c1ac9d548529dbbae89c1473a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.43","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.43","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.43_1703048287000_0.7843449477704367","host":"s3://npm-registry-packages"}},"3.6.3-beta.44":{"name":"@crawlee/linkedom","version":"3.6.3-beta.44","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.44","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e591b53f87e8e0aa1a72af02ad9fbc162932a329","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.44.tgz","fileCount":13,"integrity":"sha512-eSBleG0caOCCOLjAv16dnfmqS4tBK5+dJ4gflRUZbUPX5wDJt94TX1Q+tcybOQ5cQbaHGpLq/jwzhKw44sTNkQ==","signatures":[{"sig":"MEQCIGc3GpVNIV315w+wEUPeyEpI/BdFZUwAiaIm/zMS6yFZAiARjUZtDKAy2g/VzOYUvMGktNkHwnm6ndLzVimQJrhipQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214478},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b6023bb92d2cf0c7e3ea8267d20cc4b477905e4b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.44","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.44","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.44_1703066963214_0.9249753573491737","host":"s3://npm-registry-packages"}},"3.6.3-beta.45":{"name":"@crawlee/linkedom","version":"3.6.3-beta.45","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.45","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"53bdb5a50afb265ee92260b9ee25290d76e90f44","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.45.tgz","fileCount":13,"integrity":"sha512-AyiVAJZveB89TrvPH3PBpCJr57caol9mz2ALOiwrzx49n3M7wUOsxwDdq5jahjHSkt/Xt1gDsx95cAhsZA2ULw==","signatures":[{"sig":"MEQCIQD0ueqGan1/H1si4Fa3/ujVjHpKHaaCW/cSgFwdfn4VHQIfL114EqVhrjKu+C7WfOCogCT+Hwi2yrUbUiopD7SSKQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214792},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"895aeddecb56fc68563c9ff8f84a53fa5b212f78","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.45","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.45","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.45_1703075610923_0.7887529488461693","host":"s3://npm-registry-packages"}},"3.6.3-beta.46":{"name":"@crawlee/linkedom","version":"3.6.3-beta.46","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.46","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cae1cae62c2898fa5ed8bcdaa0ca462d40eca51d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.46.tgz","fileCount":13,"integrity":"sha512-oru11p/TD7jjbmdgMDKgEAnffB8P4TfvMtCBRPBYVxCVR6iHXp0eb/sEHBG4VVViLLFa+5HPYS9S1qaIh6bo9w==","signatures":[{"sig":"MEUCIEPGTMkX5Nd4867LlI3mTkvqZ9zxM1eB9QiRlEZ9BKBZAiEA5cUhbnAU1IIVz09sEzHIDGKYg2TxcKAwzh3ma/OA/Mw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214796},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5a6eea59284673c403e5c5e3658e3001559fb944","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.46","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.46","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.46_1703082799535_0.4728982505057655","host":"s3://npm-registry-packages"}},"3.6.3-beta.47":{"name":"@crawlee/linkedom","version":"3.6.3-beta.47","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.47","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f5016d1c8308f10d26f59c01d8b8faba4d148e3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.47.tgz","fileCount":13,"integrity":"sha512-CwECVrwsG+i9dGzw8dSGUBr24tvhBFNsumfeQ3PbxYf+yCNeYSnTOP931hfg9nmJyowgHgfI/GL2PVrkLRWebA==","signatures":[{"sig":"MEYCIQDJefOH2N87bF76M2ROcSKQL87wqZ8aZXM0CCpoznf3cAIhAIupMBYB3x7VfCn8yJVohE9MC80Uk44/An1OMHf2x3YO","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214800},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a59ff7d42ce2cc2d29cb51f0c5a6162c2a81922e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.47","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.47","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.47_1703154147785_0.9263296761926012","host":"s3://npm-registry-packages"}},"3.6.3-beta.48":{"name":"@crawlee/linkedom","version":"3.6.3-beta.48","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.6.3-beta.48","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e2cdd31b49852490910cb98e3637f99f568d2aa5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.6.3-beta.48.tgz","fileCount":13,"integrity":"sha512-KEhjxlc1JIoFfvR0nT3GKUGf+QLORGxCqVIgp4PxXwpgme3jFPYz5eIBIn1L06P3a7xsuSRmdD2LCfEcHu+Kfw==","signatures":[{"sig":"MEUCIGpnT+cQUkRA74sbM6uhgYYkEce7YSbH7xUhzrYD1/TzAiEAox7myPTnzh+PpZYVxr0/wSkDI2+xYpEDlXHxgXN5plQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214800},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5f8e34641bbcfb5fca79c4be946a06707873d457","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.6.3-beta.48","@apify/timeout":"^0.3.0","@crawlee/types":"3.6.3-beta.48","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.6.3-beta.48_1703169728782_0.15513603978364765","host":"s3://npm-registry-packages"}},"3.7.0":{"name":"@crawlee/linkedom","version":"3.7.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c00425a2624e857ca8324db5e01f573a48ce1fe","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.0.tgz","fileCount":13,"integrity":"sha512-X7VXaY3R2N+ogk25zyTXJAjuhA9ojCezRWaKklJidEvyNZbJLCgYkxsl3LNdl/yHo1VMOh+5iv2tFgeNY8aWYg==","signatures":[{"sig":"MEUCIFETAozDxKGpgMprW+4e5lg7k6fSJ3EGo7Y/Swu9oe09AiEAgDeP4niwVae5MeF3nRm5DSRx2X0skOU6Ip8ql3cOM0I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214776},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"22fb0537b3a9b09b66a3a5da3899e97f26b9df6e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.0_1703175137471_0.759330322063505","host":"s3://npm-registry-packages"}},"3.7.1-beta.0":{"name":"@crawlee/linkedom","version":"3.7.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d912b7375ea4f7ac41bf46ddf4c2c056c429b57c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.0.tgz","fileCount":13,"integrity":"sha512-i76kZ5YPIM/KdSxylUtklI+OUk7m3X30z8mrYDF4cPwu2OeboqGHoJsa7l2M28/mZXU233lAxknpZilDDnrfaQ==","signatures":[{"sig":"MEUCIQC6vBNDseBdmGoUOpVRgLWdnRsUH65AatXr0dMwzxkWGwIgRony0W9HEXOnu10Y7T+PEZSyz/gVIH1g5iFJN8r4BqA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214799},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e8ee23c7c9ad210070cfb38f670310c39a035612","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.7.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.7.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.0_1703175647163_0.0767845227392121","host":"s3://npm-registry-packages"}},"3.7.1-beta.1":{"name":"@crawlee/linkedom","version":"3.7.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8219a76d449bb175070dedf45f77e656b8aa5d00","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.1.tgz","fileCount":13,"integrity":"sha512-45XHchFxHbPHybjKaDquHZ5gH5cuQnS9kSKJ/FV0Iw3Ja4aRQZ2l81ty2hLlm10ZzMm8qvMibp4cgEhyD1ZpNA==","signatures":[{"sig":"MEYCIQCuRyiEu+iQ/mTr8nNV3Rh2nH08qvzKLo3jVyeJ+XRsPwIhAMGEeTSy0dvST0TK+nfSAv+5QIEm0xAmin154gz43Tiw","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214797},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3c5dc416f5eb073fa274435e6204ab3d389bde61","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.1_1703216322977_0.897951725580495","host":"s3://npm-registry-packages"}},"3.7.1-beta.2":{"name":"@crawlee/linkedom","version":"3.7.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e3c92ae9c8d4d6ae6b8741194cbfac760e44413c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.2.tgz","fileCount":13,"integrity":"sha512-ut5qUf6vxieLuuSChp61qkxHOO1+HyA0lIItn/nhrrL3QN3bQol7xsBSlKiv0F6Vp+hmjnyx9oQQ5KrYdlSUmQ==","signatures":[{"sig":"MEUCIAguD1c0fAV8HCYMzL6vW/y+XwZOIPDu0uTKiWrIjHSMAiEA6HqFUFHgNnrroJcUUSIqtZdEqIPerDWDQFcFKuQyNU4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214797},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"24e2adf7a9d7c02544080852f8d85cd48b7b681d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.2_1703405500890_0.01702579240919766","host":"s3://npm-registry-packages"}},"3.7.1-beta.3":{"name":"@crawlee/linkedom","version":"3.7.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d16bd0ce69f1f8ba1e275eadcfff200905776c4d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.3.tgz","fileCount":13,"integrity":"sha512-l2I3n9tTWsXZ3lfLhzjNn+FHartWvQ5Y3hUZ27GAAludiqs4EiNhTO4RhEBnat3HJ4oVTUSMnTcROQ/C/5eHYg==","signatures":[{"sig":"MEUCIF8h2CputueicNlS/3kHTbICChRKrOi5jinJTR3XFYQZAiEA97PHLmiXcskvYqucWIKJdN0SmLLCFF6XdLX5ALs+Vf8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214797},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"668d03a00cb5f9fe56d4fcd275568df0351c253b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.3_1703544350446_0.010831194167097768","host":"s3://npm-registry-packages"}},"3.7.1-beta.4":{"name":"@crawlee/linkedom","version":"3.7.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"70fc164a108e31a26113de59547eceeebc8ae5a8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.4.tgz","fileCount":13,"integrity":"sha512-8Fdd6tC/M45PLTxaofGiJAbkFiIxGXnlUZ17wTNdZJdj6hlgz+6fxNE1gUlwc80HOx9HEq/+Q2mJfPgQRZoUCQ==","signatures":[{"sig":"MEQCIBNGuoyhX9M89VlDZ1vQtSh1NFa/8wHsOBdEUKVkmDnVAiBJLQJBgY4tleuN61Gi560Dlx2WdHfSnwIrmxT+QcwnSA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214797},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9957e0ac9336718d611936819914cc71e49c2d6c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.4_1703563866190_0.6659574696464585","host":"s3://npm-registry-packages"}},"3.7.1-beta.5":{"name":"@crawlee/linkedom","version":"3.7.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ab94c5ff48d8cb4ff9a5c30b5b4b5c1a32429f53","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.5.tgz","fileCount":13,"integrity":"sha512-f4ZUd867bO8fLpPXrfpBUHFjNd18UeAXeqKaK7RkqblAQs2zjpwdz8S293m/LGeHJKMlPrmv9RcTFmb3oQWNsQ==","signatures":[{"sig":"MEQCIFRuo2pGB0KpPCrH4PmS1CSYHaALXH/JxNwxVkBvMgADAiAoLxo9AlhD9uovYQ84gdWzMx4IAaTVxPFXFXnuf8qpSA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214797},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d47e70518d8e9dea23647587537ae0b081c54ac","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.5_1703649932230_0.18561978049864702","host":"s3://npm-registry-packages"}},"3.7.1-beta.6":{"name":"@crawlee/linkedom","version":"3.7.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6ad5f59e9e6255bfef8be87fa3233bd1b1dfdecd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.6.tgz","fileCount":13,"integrity":"sha512-aY5jscekYgFL8hmZrarRf0RufnPCiienePdni3a6qKN6I7HlM/T4i3vQhH3c7+JRXMNYcK5KwmOzY94xYHdNgQ==","signatures":[{"sig":"MEYCIQCqQ+wwD4S/0xRYZPupVxoqaz35mI+vJrde8Ceq03LlIAIhAI76XFlqKoS77AW6/0FkWUNlEhK7RjGD7xrYn7TB8R59","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215205},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"01664e58799374a6acc2aa9db397566c1acc69d4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.6_1703697672256_0.6817780065033194","host":"s3://npm-registry-packages"}},"3.7.1-beta.7":{"name":"@crawlee/linkedom","version":"3.7.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5ebfb46adf080318c39e86853c8820a853495188","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.7.tgz","fileCount":13,"integrity":"sha512-Hmc9PaerhG0jHlHOUnZ9ijr5yCvkiLYUGeH7dCjlM6xHSRSQ8sls1DvAEPi88GyooCSt+8X0Ctd/RoQNulaUhQ==","signatures":[{"sig":"MEUCIB1qXU+Yk7edP/Z/paZHNhVXc/ckNjrhzHM+13VIBAyKAiEAnO5lgN6mCJJ7B7/wSePAZbucYMbPoHrEUUFZHzMpMNk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215427},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b663febfe61dc8d7f6084c439ba898680a819381","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.7_1703734881640_0.9589637748007265","host":"s3://npm-registry-packages"}},"3.7.1-beta.8":{"name":"@crawlee/linkedom","version":"3.7.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c8c52434a91c7a2bcde3275d94735059b30663a2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.8.tgz","fileCount":13,"integrity":"sha512-PoO2tIcsKdkAe5j+TrSqrFR4VNe8J9thtw3lYca+F+/109XiNuPyFEE6f3H5sWAtOFVicaoIwlrcaOzYLaJ5CQ==","signatures":[{"sig":"MEUCIESKzfK4fTYo0yBXkwpmFN4+1GqOM9LMzl6/O85wydjQAiEA7oTGaril0L62KEhqwpVqAa2ju20oeOC62JmlZ9IZqd0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215427},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c2fa07e16080dd4fdf0ebdfdb51878edddcdb437","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.8_1703824533511_0.19822337944921653","host":"s3://npm-registry-packages"}},"3.7.1-beta.9":{"name":"@crawlee/linkedom","version":"3.7.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8c184604dac9365b0e25d65589847a89ea187b05","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.9.tgz","fileCount":13,"integrity":"sha512-wQRUJjWPLJ8DCD31piT5VgSbcGzAgb8Wiup8XDcjo4+hY3Uwgxgqla0UUOgfiM5cWuKggXjKRyXLjbK6wWdVkw==","signatures":[{"sig":"MEQCICMz3/X0LVtyzYl5l8DO87+F+ekIZWkx7yc/wfpsmaOAAiB2x+avcLYxupcdOf8BKj0yAZEzriei4Y/0rjUrUqjARw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215427},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7b9894816eb8ccb39e6d41e56b8729438e74fca5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.9_1703906946706_0.6345462892362863","host":"s3://npm-registry-packages"}},"3.7.1-beta.10":{"name":"@crawlee/linkedom","version":"3.7.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6af27d98c2cd05867185044d1c615d2fc86be75b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.10.tgz","fileCount":13,"integrity":"sha512-2vczoeYzXQ1O6g12YbZgadKeW3YCQrgVNvybjGwks9SQ6xuF4pnbs0iCSgKae/FPVNKleCKuzfJ667i9DkoAgw==","signatures":[{"sig":"MEUCIBu6LjJ5tNtSsfpCjM81mkmgFfxxJ1jnlMl2G+8HWFROAiEAlko7PYTKjTVKw43gL2nSlp31ZrzDzIubv0y5NCjyzuI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215430},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4660566073a815b613870e691b5eee096db7a71d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.10_1703995302223_0.5327317476322755","host":"s3://npm-registry-packages"}},"3.7.1-beta.11":{"name":"@crawlee/linkedom","version":"3.7.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6b7aa10196d67b1ab770dd2afbf3bc179b04dd41","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.11.tgz","fileCount":13,"integrity":"sha512-rdNoR6rJvvyS0GPr/rEGPi9CCEXqp7QvhlwBWMTKcY/w5ddAs2pkkiee9ESHR7JOUFjv+RpCVUd2JlCpI7K+Wg==","signatures":[{"sig":"MEUCIH/CV8+IS1aIPBCzAWm6uhL08BTGlOVCoy6616DSerLMAiEAsnPVu2pUQ9zu+NVMG8Zo84v5HU7tK3Co4sl34QKvuLI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215430},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0e34694ea99e36b118776422698c4df0cee8791a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.11_1704079317014_0.200473466707902","host":"s3://npm-registry-packages"}},"3.7.1-beta.12":{"name":"@crawlee/linkedom","version":"3.7.1-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bd4e20cc9c8ef4443430cdafe2985fc13f4481a0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.12.tgz","fileCount":13,"integrity":"sha512-wnIZJqA4zMDuzjL7p/cXsHhD8NtJ2q51fPqKl5WqZUn9KCM8XgmhS0kB8KOSIyDPMjqkvb53UheuGJw7BKkhWQ==","signatures":[{"sig":"MEYCIQCIg4piEbdGCxKjHs7hMtbQnBdgR5aUMaJtm7/Ss9sKGgIhANsyA7g9QcD+JvpsAVgW1FmKOy82pbId5z5fYfuzvnMn","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215430},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"af6986c47171ed03eb97fce9e8b2586c480f748c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.12_1704150081572_0.8739540530229444","host":"s3://npm-registry-packages"}},"3.7.1-beta.13":{"name":"@crawlee/linkedom","version":"3.7.1-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"37dfff0cb0a0f1732360f33a0c85a695b3b4bc6a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1-beta.13.tgz","fileCount":13,"integrity":"sha512-E42byZKzfe5OSFic5DxJudEDfa7ct+Z5XUatNaJSBlCHPbI0VOm4BGKyJGmZ87b+C8fmt1aBBmNHAx9htIGFsA==","signatures":[{"sig":"MEUCIQDfKeUIcrlvoSAKREesPDuTc0R9jSWFvt6dAFRj2K7uPwIgBwOSxmXwVAk2cArqQgixwhF8s1iAb6/qzWmXviBgLkc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215430},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4b7cd3d54dc539b809e9d02caa3df641ece1fb87","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1-beta.13_1704169449737_0.9116683181237348","host":"s3://npm-registry-packages"}},"3.7.1":{"name":"@crawlee/linkedom","version":"3.7.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c0fc128b39a4ffec990ab1cb4d0588b33e85f4e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.1.tgz","fileCount":13,"integrity":"sha512-6OQoTjjL2vJ7TroOnXFGMsO8rKTRY7awd+POx1Ci7TIYeYt2Ty7DDica8BcChNwCGfjWwUa1wUNswL1ZAe///w==","signatures":[{"sig":"MEUCIQDzSOKTKCAUGtkDHxpDp2mk4SdIUplsD7nap4exkysjKAIgOqtNgnBnveApzTXaAvGydKza6O12hVZ/I/xqIkfPHJk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215406},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a93da6cf3e9e26aa9442228c129e783cf9280080","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.1_1704184185958_0.865667314729418","host":"s3://npm-registry-packages"}},"3.7.2-beta.0":{"name":"@crawlee/linkedom","version":"3.7.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f3a218978821323ee8b17a56835f1d045c43590f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.0.tgz","fileCount":13,"integrity":"sha512-hPdrcLd9Vz4/ykrUB0LrNaQ5PotbeDvAtSOnj/VKa65IAPyssd7T/aFxaaZ23NlX1rtKcqE5QQ0Kc3V0ln3XTQ==","signatures":[{"sig":"MEUCIQCUVKTFxEOjNrdEUA9uxZD3MfwTRTr7l5VCfmFc5Cv8PQIgdu+UdKY2LjKqYeqHsvZdkmlByYjfOKbBuKckXPUPETg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215429},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"28112f573d9aff0202a9d369516fab79e2b0687b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.7.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.7.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.0_1704184699134_0.1792607769087342","host":"s3://npm-registry-packages"}},"3.7.2-beta.1":{"name":"@crawlee/linkedom","version":"3.7.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5a152da885f157ec28b15b637fe82aa6a04d5ab1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.1.tgz","fileCount":13,"integrity":"sha512-gsLHjBbdixVKScmf7y75UVFMQndwap5wVGQJiIESxtrXxhmZmJpdiaWVAcKg6kHEht0zkjH599kr1rz2VKIdow==","signatures":[{"sig":"MEQCIFKbXr/4C1bNX2xTWmNQs01SxOPwecceWmcgFHKYoSTVAiBgrD+BFn8jU4L8Z03MEH9g09t/9T/8m4UlYukWCLHvdQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215427},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"98e9880c77b827ebf76b39af4f8565c96d10216e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.1_1704257540109_0.8146800855100318","host":"s3://npm-registry-packages"}},"3.7.2-beta.2":{"name":"@crawlee/linkedom","version":"3.7.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e24f06bdc74a799cb4978a71385a5dbae5626724","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.2.tgz","fileCount":13,"integrity":"sha512-5QmcWT6/0CO7Uk59fuXfOfNLlHWlGRXl4Ng3N6j7WDDPE4fu0tSp1tmX1exaHKfsUYu/g6Vxt5fO2Qij82Dw3w==","signatures":[{"sig":"MEQCIGN9iVfUxj+6jgVn8DzbF4+ZmcOR6SDw1qKmUyDVYl42AiATpfxKXd55PSwCiEGtlGoIXnsPd8oNI8goC1wbPBGpgQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"216a608edd71f9c870b92692ef5f1891547f560c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.2_1704287128345_0.2612993988606598","host":"s3://npm-registry-packages"}},"3.7.2-beta.3":{"name":"@crawlee/linkedom","version":"3.7.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"308dad7a81847d8221a61c6ba06d32699d5d252d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.3.tgz","fileCount":13,"integrity":"sha512-s7rQwRYARAbghM2hqZWVpjh5km0//5VtHb+iRcDSzVKqy5bFC0rucGmWna61+on9yuyivjVsG5plscIdDkJ3mg==","signatures":[{"sig":"MEYCIQCE2ChysY0IeRrPTKd/lPJ/yhLIaJUv1E9tMv/D/H7T7wIhAOAy13qNYrHfBAovme8nmcdCTtEG2AtdDzGfGWhY+uWq","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f61478b73da2049fc4ba331948291c171d9bed2d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.3_1704340171809_0.9251769417490667","host":"s3://npm-registry-packages"}},"3.7.2-beta.4":{"name":"@crawlee/linkedom","version":"3.7.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"535f47c8d59f1231300fd2c55d384f833204c7a9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.4.tgz","fileCount":13,"integrity":"sha512-wv7Obb3d0Y5qDZ1wKr8O/cWfJNeY4dgnVn78/qf0quZUXDnBlWq7UWiNUVaJT3SAn8omvp6h2dSSlDuYiwqQNg==","signatures":[{"sig":"MEUCICkTBtA/H9YyZT1yr4mlIs4H0p6LT0YV4MUremAKKacxAiEA25ZpQHU3CHVHxu6O9+uNlaXcT5SLt3XGIjxhDwxGOtE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"231b077d301bc6a2405e878b9bb1659c1b88373a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.4_1704360423450_0.8827404642350283","host":"s3://npm-registry-packages"}},"3.7.2-beta.5":{"name":"@crawlee/linkedom","version":"3.7.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3ed351cb0592b93126d25c55eb3227029b2f5782","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.5.tgz","fileCount":13,"integrity":"sha512-xdT4chJJ7j6I9jGcKTrLuVBoHaRm3WKcX5lM6V8uio0jv8TLA7JdTrCPDY8ZsV2+K41Y1OvFqT8z3UvzXNbZqA==","signatures":[{"sig":"MEQCIDIdY5TcHjapk/5BtTSpw9HXwUIbIAQAhdst7CSfKupHAiBOswotBSv/fFZpPp8LYKCu1i00Y9OC/NzARyigQV7wTg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2b78fda5bc603b339d8837aa375461cc7b126731","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.5_1704362105886_0.08251080108399522","host":"s3://npm-registry-packages"}},"3.7.2-beta.6":{"name":"@crawlee/linkedom","version":"3.7.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0d2629a8d9d2c372e12a8ed8a627019c8d2b5ec5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.6.tgz","fileCount":13,"integrity":"sha512-c0KjAP7PBvQqYfl9SJydg4qyeXNufqZ05TKj6pCkHjhqlQhlMwpaSzShK8dhlaSj6VTv7pOHbiZSBWgCPld77w==","signatures":[{"sig":"MEQCIBAMICXaLJn510rEKWEpW73BpzcsfLKjjegxT5kqgXoTAiA0LPdV627ihpY56YojFGXY6kvrEK5+kB1vKC+Dnz4O+A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8e957455573ec47788de8a841df6dcbc4f87ed07","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.6_1704393056720_0.897798339947818","host":"s3://npm-registry-packages"}},"3.7.2-beta.7":{"name":"@crawlee/linkedom","version":"3.7.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fc1747f3e90430acfc1ed5c6769c9da77bcbc797","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.7.tgz","fileCount":13,"integrity":"sha512-lEK5Z56VS5Az2yRWUS9Xnv5sup8N3rHNxhBWvapC5VJ5JvtFb9+rfH4ChwPUOL9rlxlXX4gqXw7pl+L+xQx8fg==","signatures":[{"sig":"MEUCIQDiEerVa6YDGtmuWYZx1h4vJaQOJUA1kMD7k2DgZ9WcbQIgXBCoW2RNW1oPv75x7FHZwh/ofbfn2si9mQgBUEN5S9s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"073f8aeed65fab945e5c6f5e1c5440a1a052ffe7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.7_1704428522864_0.4249347261646892","host":"s3://npm-registry-packages"}},"3.7.2-beta.8":{"name":"@crawlee/linkedom","version":"3.7.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"30dfb101e06d78430a87fe48d2fc5297b86577a6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.8.tgz","fileCount":13,"integrity":"sha512-axMPggYOTP5+O5X+k2o910xUwBxjUKvIiD+fD1A39CGS2zJ2fyKraVVe/99xrMG0I63qNxc53iguYVxLPNjmBg==","signatures":[{"sig":"MEQCIBSmBpGabuH7RMcaFOohnN1dns3GdFbMMd+2PTaUj+fOAiBKMYzQIf/MifuQxD79po28KubEJbYng8cpMG1PyhSjZg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215431},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"35899c507536d558f2e57c7db481e25420e492a5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.1/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.8_1704495123313_0.20900543835700658","host":"s3://npm-registry-packages"}},"3.7.2-beta.9":{"name":"@crawlee/linkedom","version":"3.7.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6082fa88afe08954af8d1338429fa157b38a2f02","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.9.tgz","fileCount":13,"integrity":"sha512-B+nwct6TSaubqpqWpUl3cR0SkGwv5PrkOqtPQEFEByXr3tROweCYP5DQ6E7PwlSMXBrCCuUOIqi+afu4V8BudA==","signatures":[{"sig":"MEUCIAQRTFvAMTQS+lJpa1dL6uiFUxbm6qlklZ63vuq4FFd8AiEAjnxyXeNGN2gQPvD6J9jy4fhAh19rF73uNzC1c1cLo5Q=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215581},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c4c8bd92e666450ae82a7c4c569427bb2381bd00","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.9_1704512647686_0.31140113664599434","host":"s3://npm-registry-packages"}},"3.7.2-beta.10":{"name":"@crawlee/linkedom","version":"3.7.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d23f8952ad281e0d0c51a6b4d50078aed501293d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.10.tgz","fileCount":13,"integrity":"sha512-wS8hXiNOQD4a38qSwZRsF8vCKwPs6UNaqN2vzaYpCO71U6h3KuBFvpYrJzRVEKySyj0FkMAP/f/eusKuqIxMzg==","signatures":[{"sig":"MEUCIQCfTFBCNI/YX4/wUJhp5Z7Tfn/lJ3RKmjtxhMouP87BygIgbt1RaFvmrAtFCaeT8TNzbD9njfIgCk/Ylc5DfMuePfA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215584},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3dc465ed3d7c019abc68c3a49f784c2074edd784","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.10_1704771664004_0.22206275614098003","host":"s3://npm-registry-packages"}},"3.7.2-beta.11":{"name":"@crawlee/linkedom","version":"3.7.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0e42160bdef71308ab9b11f755bbbb640a0d8f79","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2-beta.11.tgz","fileCount":13,"integrity":"sha512-UAZJCmkxa+913UAfPSEuFIEQgBj6vWT2IcwMwFc944GjwBU3J9bzMUvN3cMPhQAh24aiRuJVimBDeiz9LYtTCw==","signatures":[{"sig":"MEUCIBaWHrkj2QV/WiXcHWmar/ICxepiG0419vzKM9b3rmYXAiEA3ZyWrMjVPA8sVTyvS2c7JwL3l8WLBRv3axzix6pJvTs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215584},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"324399e9d799bf9121f55fda1a162b4d182cf371","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2-beta.11_1704782488982_0.9589961108190515","host":"s3://npm-registry-packages"}},"3.7.2":{"name":"@crawlee/linkedom","version":"3.7.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"87ce1ef8fe52747c9a54e4d64df708fb416cd478","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.2.tgz","fileCount":13,"integrity":"sha512-I9ar9zd+DeRiNgYMkqcG1HsTq1++Nbt/5xvte5oQUDeE0OqNOlSyOOxYLkS6PyI8QCtKsLJ52kgryHuQJ6xBkQ==","signatures":[{"sig":"MEYCIQCoKobhHqr3OBYFZSD1rjLvCbc5h9PH2eLcuy2pfxZrxAIhALB5/euWzQkZL39DbK5iroseQKh8gANYxb/bT7weqSd1","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215560},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"602aab661b29b223ee2ed51a91f8eb2b29f1bad1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.2_1704826276756_0.7166023658911207","host":"s3://npm-registry-packages"}},"3.7.3-beta.0":{"name":"@crawlee/linkedom","version":"3.7.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"19a4ee0acc5a88ee0032868e46add8ea4a7ed196","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.0.tgz","fileCount":13,"integrity":"sha512-1EsrGL8Vkm1Uv7GLOpshHw061fq0Yvc0yGeaVokQpNG4AcL0wG1R5/FTYBdA2XMRX9KHR/G74WYR05Aj0TMsWQ==","signatures":[{"sig":"MEQCIDrp2+Bgd0zCQ//mF2TjAIi1N5Znvfm+xg5srnXrRUmYAiAXKzgqmXLHXpIgvBW1/QnlPYMBcV20GnFKxcpl3GvqUA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215583},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d9b2b707f190bfadcb9be25ebf5f99fe6b0ddd5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.7.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.7.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.0_1704826765595_0.27398075714054926","host":"s3://npm-registry-packages"}},"3.7.3-beta.1":{"name":"@crawlee/linkedom","version":"3.7.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2770c738bfbbbcf98c537196ec8c41879fbd9082","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.1.tgz","fileCount":13,"integrity":"sha512-45c5C/AqSqGigMVzhmcLiXnszR+47T4/1ip7q50OZ91ZSpHB4/NXvqiOqPZcD/j0kAgW492w0NSvXEgT+F1fwA==","signatures":[{"sig":"MEQCIHCRxVc4ISuqtjEFFA75tlPal67gT0cxi5Q0EBr+yr+QAiAFgMpPq9VxLVktzfXFCY9q8OSS1SaIPZTEYBxp2yQKng==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215581},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"814faf6ff3b38955123bd2f91eb498ff15394f31","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.1_1704922092224_0.8670738683021351","host":"s3://npm-registry-packages"}},"3.7.3-beta.2":{"name":"@crawlee/linkedom","version":"3.7.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d3bc1a381cfa89b9c1afdd4af67826cc2d330810","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.2.tgz","fileCount":13,"integrity":"sha512-mRAEL+anhk76mkBOH78mZp23YZrmzUEOJPK9Fq8sBwKvXWq+Iw4YjWxgrGqT9ZG+slwFCiKy9sSIR1SmqF6xZA==","signatures":[{"sig":"MEYCIQCG2HtYWRWex8wt6iDXft0Sj3GXYa+OZS0vnEOOAjje/QIhAPD4Vz3J6LsOxmnYFUKpy0QaksQSdePabgaG7lKyIINz","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215581},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9d6b626f7c1c205e435cffb762fc91b22a4a8217","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.2_1704976517747_0.9499120941746497","host":"s3://npm-registry-packages"}},"3.7.3-beta.3":{"name":"@crawlee/linkedom","version":"3.7.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d502beb8be75b14577837c2e3887e7d7cb455db6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.3.tgz","fileCount":13,"integrity":"sha512-VDsem/EdShnkamLP9QllNAaFMjx2pUcsos27YIARS+z1Ghix/5wjO3sKizoqwDMv7QoVsPKvxSvUnwczfim0xA==","signatures":[{"sig":"MEUCIH6Lm3pgXIbGjLI/BDKkmbwIWMJV3h3U/zxpO3sckSq4AiEA2SqC2oGX028UhPLmUVb1v/eQoYDw9MxD4n+7wRh4rb0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5f4719095652a98810cc69ac06dc032cfead4016","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.3_1705030698796_0.12846078136265326","host":"s3://npm-registry-packages"}},"3.7.3-beta.4":{"name":"@crawlee/linkedom","version":"3.7.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"aa031e93544faad836415abb55b90e3d3109c2e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.4.tgz","fileCount":13,"integrity":"sha512-L8k4bfIi44LkIClMyE2hk8QussZYoHic2gOmBMXlNFSJKA8MSFFB58PNwC2TpWMqtzyFfXwKLc2ggiLT9l+ejw==","signatures":[{"sig":"MEQCIA5Zijow5cnn1ptlHo5JTt8M/5TSQVbrLYaKTxwz77upAiAv074zYb4Ox9hipMfEfd7hWDr7krFJXPxaLl+bAmUrkQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"105ac24c89d6d30fe5cc437ae20c94802b346160","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.4_1705116385341_0.873425283802796","host":"s3://npm-registry-packages"}},"3.7.3-beta.5":{"name":"@crawlee/linkedom","version":"3.7.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d40a7db4354a01a1760b41ba840de68f96bfc74a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.5.tgz","fileCount":13,"integrity":"sha512-hWs40HmM18b3wLeOzkMXBC5OWwYFEn3/bW1hYiotOHU6JUUonbZW8RzBfQzCnnkm5UrpL5a4t4aWWuZ5NgAADw==","signatures":[{"sig":"MEQCIFQyLOz9b3XeXJIvSTUae2Fw5O/KuF31T8XNxGevsq8zAiBj+0yWMI8Zcq4JePDhJ5CQ0VP5oouUpR616t56Fc+PRg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"47f69e5fb65f5156f5dbcee1a2a6f8406bff78d8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.5_1705296750173_0.14667063997084195","host":"s3://npm-registry-packages"}},"3.7.3-beta.6":{"name":"@crawlee/linkedom","version":"3.7.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bedbf6af6837aaf919a7e710d7983257a2b52c02","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.6.tgz","fileCount":13,"integrity":"sha512-CcA6c10LnuE/davc5zDFS33/MAsUiXaGiYY+MIVwNh3LhuCJsvEbSpvMlYVzbBP1ixwzVbwskqNzQ1h7Ah+KVQ==","signatures":[{"sig":"MEUCIQD5d0Fcw2NulXBLWSyd6FlsP6QmK1rdWf89t+I8gXUL4wIgFfSeZIW6CkfsLDzTKomJXkLxNMDShbZs/ay3U+Y9p2c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32f929708af3068e72fdcbd7fd5f1d40e3652237","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.6_1705353846714_0.13471186146580716","host":"s3://npm-registry-packages"}},"3.7.3-beta.7":{"name":"@crawlee/linkedom","version":"3.7.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"61d19e8824f8e52b167a4328ed1dcf5186c7043e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.7.tgz","fileCount":13,"integrity":"sha512-IHcIXWCSIk4CFfvh5gEj3wpqLSLH+jmItoF8xXQ1wRRwiPadghSeZD0Hv5EPb/Qt+F0qkNWrV3wTXR9xl9zwYw==","signatures":[{"sig":"MEQCIGMOtGAwPE54DxIlfSg9LdNgOYU+mHeHcEmyk62/88F8AiAndfz75ysJxAndKflexDaMD2YmOIbCGt3f+SJvYJzy2Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211867},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"53ebd8a7d9202cf5546312f79edfb52d6bb078d9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.7_1705441414465_0.06836243956125077","host":"s3://npm-registry-packages"}},"3.7.3-beta.8":{"name":"@crawlee/linkedom","version":"3.7.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fdd01f0516bda05d2acca74d58ac35ac6e636be5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.8.tgz","fileCount":13,"integrity":"sha512-mypziA2AhG6L/MW/gentbyChurx1J2c2SmukQF9j43cVOCsgSmkO8Zp2fPYUN/1FW9i+aCh0gNQNV9qK/WYWew==","signatures":[{"sig":"MEYCIQDSjI5SUloLnqIjb2xjav6cVgwH+MpcWH9aa3vRZMuEswIhALJFztLyE60QxpJlrzol9pZ9vp7VJ0za/MmR2HWuI2Tv","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211867},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d916356218190bf6833297d90eef3636c916bf5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.8_1705467246137_0.1606411754986563","host":"s3://npm-registry-packages"}},"3.7.3-beta.9":{"name":"@crawlee/linkedom","version":"3.7.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fea77cc7f0a8c81464dc1794593cd1e77826c495","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.9.tgz","fileCount":13,"integrity":"sha512-rD8FDpGFBJhY+0GTgYmBPwZCicEa8re8bjI63XPlJMJxP59vGEFIlbWCtQCwiCTQvSVj4yvOebhcU1f/ccwkTg==","signatures":[{"sig":"MEYCIQC/JU2XFbPnxmvsjFF25RRT5BQdtgPd4zRm5hQisYNdWQIhAL2nYsmjxx6mJy4XK7UjjmqYulfZJg/rhIQS3+EODCSu","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211867},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"019083b584b5866ffe6a85b180723d1f4ea3b174","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.9_1705484507758_0.0013206704421562243","host":"s3://npm-registry-packages"}},"3.7.3-beta.10":{"name":"@crawlee/linkedom","version":"3.7.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2af5a1f197744270be645d5763044bb0bbf680eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.10.tgz","fileCount":13,"integrity":"sha512-t8yAB5mW26XfQl2i6kNUstRcNGXVDSaBawS2tDgaHzcXLlD+6Hw6TxoGo2qQR9EiNdcoUsh7ViQxySDBWmti+g==","signatures":[{"sig":"MEQCIAjRjfd6sI9epfsXRdWITQwEzz7hO2QG7fmXAvYKkk9TAiAKL+2gMfQ1X6WZtKS+m8W5Dz6MHp3PQ7xIkOCrhfOKpg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c7304d0f273a2075485666b7a45d1a367b0631a0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.10_1705555557824_0.9337442595515952","host":"s3://npm-registry-packages"}},"3.7.3-beta.11":{"name":"@crawlee/linkedom","version":"3.7.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"116cdd92731a12ac7c952d191b93ccb011986f5d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.11.tgz","fileCount":13,"integrity":"sha512-bQkyX+rag6eByIRla5BvfAmnjo+yU5pVbqLywdUIsLw1pu3LVYMb764jSmDCjE527PivLyfL42X9r37s+wPviQ==","signatures":[{"sig":"MEQCIFTQahwtGTlrtQNHVOFPDLhYR5JkOTTNJNa0Wx7Dhd1lAiA4SYgvFWtPIM/mt9IdjGFWw39OK55dUU0UmOSrMVp6UQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cd966df7d908d02a10504909322a3156b279b868","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.11_1705586483765_0.9913168237119776","host":"s3://npm-registry-packages"}},"3.7.3-beta.12":{"name":"@crawlee/linkedom","version":"3.7.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7247c8cd521785eda0a15d9d1dad053aa110a916","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.12.tgz","fileCount":13,"integrity":"sha512-zwd0nDC0270CE/sceTCYcpQqKjo7G/O/q0YTb3hZbJfUoKKrs3PjkBcUXlnpNoHNZ/1Mfm9RWRhegcCSFTDwZA==","signatures":[{"sig":"MEUCIQDuWN79opi7W7YJ5GG+cV7SuS3K2e/fBshZdpjua2P33gIgZlrzWMqXstZBjo2qwHJjzcsBl5v2H+wUsCER7iMz8eo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7f633fb63b11b7c388f8fd2c9d487dfa6c3bd588","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.12_1705636886941_0.7762282598216881","host":"s3://npm-registry-packages"}},"3.7.3-beta.13":{"name":"@crawlee/linkedom","version":"3.7.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"05493571b589d68c5d40030e4fb11aecdcd24f2a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.13.tgz","fileCount":13,"integrity":"sha512-SO7WzgcXassBTDux/2j0gbZCf+VGa5Oo5bLFkS5Fo7tW/zsI76/7CAMmWxQ/psVUZpCo4NhfXyQJE8Tnna7UfA==","signatures":[{"sig":"MEUCIFKie8OWltazWsxoptoLmRmUjBjKnVCIHMQ4/E0BLg9wAiEAyfpgI+J1oela54/5ebWB723f3MuTknkEv/HI9In7klw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d526c1a2548076e4b10e6c8a1b863d16f86ec410","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.13_1705684133376_0.8334448609933722","host":"s3://npm-registry-packages"}},"3.7.3-beta.14":{"name":"@crawlee/linkedom","version":"3.7.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc89e1d8803a1c3fa1cec6663058b3887c286655","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.14.tgz","fileCount":13,"integrity":"sha512-zxXuyY8INIdvs7aiarq3U8HsJAkd5aDIAYcyHfGuT9eJ6vBWM9U+UWsjqM6h5GPPJaj4LTgEfwew2YZfBvs3qg==","signatures":[{"sig":"MEUCICpC6BRiuw4Kvvj0VhApd19lOBkeZIXbezrPqVNTGU2PAiEAgYpR4XJ8mV/MYNO73vd7iPe+Rvo8lQvxMpx/8phipBU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7fba9dc3c958814068cc1bbb351bab9f0ae3e6b5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.14_1705684970140_0.8494650053548152","host":"s3://npm-registry-packages"}},"3.7.3-beta.15":{"name":"@crawlee/linkedom","version":"3.7.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7da83170609bf1998dccfd7b1fe328db43365490","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.15.tgz","fileCount":13,"integrity":"sha512-mjMylcW7pa2Rm+VlUBdC9apArcM1ZhFKmylZ9rEptYclRshBrFcV6jniDllCwuS9MuERyO5t/A/3I2L/y1zhHw==","signatures":[{"sig":"MEUCIQDLU58N+2ffzLhCtoyk33mNCAeHQimJSO0v5bZQFtUmxAIgSyJxNBDAFCO3PPeTfNqhUUH4B9FtYkbgbTlzsuHc6Hc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1502ad5da780cc7efc31d0930be35b23269d1b04","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.15_1705720487922_0.6106344024240615","host":"s3://npm-registry-packages"}},"3.7.3-beta.16":{"name":"@crawlee/linkedom","version":"3.7.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"667f5345b8a953eea4211eec47e6c2939f6d811e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.16.tgz","fileCount":13,"integrity":"sha512-mkecrUu0Jo+BjcN0xE4xwgHY6us0TNy3EMWaELDDIiK25ClyEYwjiiP5cSuPOADfbxDSTkMZEn/YtjBptDokUw==","signatures":[{"sig":"MEUCID2rq4WqJXtMVxdNhoJoCNHF82VzBJmrnuq3etyVvaz5AiEAwqZkW3VxFwoDDFS4D+w947LTnSwGW3+FxwYk1NyH9jU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"650e2a7b1aae2e4cad11a1323676f6a4bdd0e1cb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.16_1705810697025_0.10762929234468066","host":"s3://npm-registry-packages"}},"3.7.3-beta.17":{"name":"@crawlee/linkedom","version":"3.7.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e15458a219919b6361fbca13a6af411b0bb10292","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.17.tgz","fileCount":13,"integrity":"sha512-KWDKEV1B7/mRjKT68Qo6YXQzMlArPeSHKg8t5N9SMGJSRZF01dYvSOxHOZ8nMOfI8ntl1Tj6/A4JPhvaJqDXWg==","signatures":[{"sig":"MEYCIQDeHXxA7M9EDL1L9KtWfiglmhdV4krHtrs2IqMXRHFn/QIhAM688bZoh2uUY9CcmhDAM7xiZ4ZKvu02vpHcaR1DZ8EB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"753e726ee67b7b4cbc19bf0e097dd7aececf6e2b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.17_1705896003501_0.8404786645794105","host":"s3://npm-registry-packages"}},"3.7.3-beta.18":{"name":"@crawlee/linkedom","version":"3.7.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6269954b2c79eb7e458dfd6c72a5836f7b54c7c1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.18.tgz","fileCount":13,"integrity":"sha512-AVP8rWlAMEJHQd5qeLDyzYzUSUnPnGtAL3+a5I+ChS8PVEO/6NnmkKQIQ+i+xVGJl+HsOUVTaDCRYb3fZoGT1w==","signatures":[{"sig":"MEYCIQD6xhyFLW7T4iVD+UH1FKrRe2JXojV2flgSE0Ne7MTiiQIhAPF8AT67dEuo30BLscIj1MzZhpRVUV6z399t/9Kh8HUx","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211870},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d0ba46f7c4a80efcec8d098b21e6d711754a518b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.18_1705960917025_0.003587963903020075","host":"s3://npm-registry-packages"}},"3.7.3-beta.19":{"name":"@crawlee/linkedom","version":"3.7.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4e53415348521ff58e864e64e64a2439fea6d3e0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.19.tgz","fileCount":13,"integrity":"sha512-o4h2EbPlBbTzb3ZqYakbQYr0BXyEnW49IOtzB5BEyWiMnU/355eaHiKsUDbeZ4HbgAYYPcL2RnhDF/LntY77Fg==","signatures":[{"sig":"MEUCIFZJdMR9BsSSao+kxnbEP+8fhBZWQCawK2yDFwvlP0cXAiEA1xw/OTQ5pPDvwPoyhx+HTrMzqa3JZPD2A5HB+63M2GQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9d58a9f143d9517494bb1387998d6b6fb6730645","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.19_1705980603907_0.5899000003549357","host":"s3://npm-registry-packages"}},"3.7.3-beta.20":{"name":"@crawlee/linkedom","version":"3.7.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3a14b2659b3cc4daab6561f4294d9552dcce8103","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.20.tgz","fileCount":13,"integrity":"sha512-5Ow97gShLozOYAWHTVPbPnyVUgpACAJzY3r7s223eKS6S+npi5tj5zxEIiX3O1drJtEi1CD2BmzKLp0w3Qq5jw==","signatures":[{"sig":"MEUCIQCgS8AVgO8NxbIeuXaWdivVbKoLRIfCxIKKE85UcDdzjgIgWqoxkCM5Ju9U5G8PeE5dzFflxBFDSbu+VbMA0puJVx4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"901ce28cb805b36564234ab018614ef2872e6cbe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.20_1706069528621_0.39693920105971503","host":"s3://npm-registry-packages"}},"3.7.3-beta.21":{"name":"@crawlee/linkedom","version":"3.7.3-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"80d0d02e04a8efb9437406889ad595aa491535d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.21.tgz","fileCount":13,"integrity":"sha512-VLnmreHsamOsHPCdWvjCccGMY5vW8x+7c4FGhCZ2D+xYBZOpi1IUJOcA4I0Ch5ev0T4l/cSdiWQXJKLi/pWBxw==","signatures":[{"sig":"MEYCIQDZsu3tbbOmV8IBgmYt124l1+0Ya373wEaZ/u6267GdxgIhAIpcqllQkDRSPedHHxBy1Gx9nprepVibnxqqYlKc7n3H","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211684},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9799e864acd4cf262a850c0549b7ca5e853d69ce","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.21_1706115218360_0.061193300582597754","host":"s3://npm-registry-packages"}},"3.7.3-beta.22":{"name":"@crawlee/linkedom","version":"3.7.3-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"da663539e86381f97dd915724c05845a6e3aeed2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.22.tgz","fileCount":13,"integrity":"sha512-qabrEfZPPVkQMIF2b8HLjQZyzfrpqFX7PwjrPpUrHM4h4uRsq59kLl/TQFC7gokV7Fyho1xfe3JniAdVFFWOCg==","signatures":[{"sig":"MEUCIQCxZO5DCXse2qlIgd49wDG/xCHIdblDUHhz5yf8+w1VOgIgFnvubgjIttvwwFtitzP8kzTGQu7OQVt1IEYrltMRvls=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211878},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"021ff165a870b37cf6e94ddd44cf4badbfa77f30","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.22_1706165751355_0.755676456190155","host":"s3://npm-registry-packages"}},"3.7.3-beta.23":{"name":"@crawlee/linkedom","version":"3.7.3-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0377aa60fffccfe2b18dccdaf24bdd9227467730","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.23.tgz","fileCount":13,"integrity":"sha512-pvX7CA+QrLs3/EURicFVEvdCe5iOZytgEfnWrDCDk4gWUfA2r/JyCHklmlhRJWr7YJHgl4e4H90kwBT39H9AFw==","signatures":[{"sig":"MEQCIGJkuY3A8gr9MmuKYeNIpueCkuBmS046O0cbggmoDj6gAiBWWR2PktVHG9zeMuuHjr5WkjohVSSWnScgdgFfuryiEA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211878},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"93cfab60ab7f5daf751eaf3ab6f1c2fd5a28ed33","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.23_1706216739131_0.9260354653291711","host":"s3://npm-registry-packages"}},"3.7.3-beta.24":{"name":"@crawlee/linkedom","version":"3.7.3-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f14277b191c0f1f29ae6d3a031772b5c738643a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.24.tgz","fileCount":13,"integrity":"sha512-mSzq1uMap+4qI9QGZ897gEDKDeYxsnbSj2XW/Z7YvmXkSqoDj+Z7reztLXkW9acsPtrteMh1YeTenQmdM1QS5A==","signatures":[{"sig":"MEUCICoPuKwgt58zlMz8qAJ+VUXDHM3yua3+N1E8D2M7E4RsAiEA69y8jBYgMMiWxpcfCtHCaCqGAHmKwN10T+bDl1xibOY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211878},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"078174ced6ce54690d619d7e1f526c5cc513c766","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.24_1706246320534_0.4155436112266917","host":"s3://npm-registry-packages"}},"3.7.3-beta.25":{"name":"@crawlee/linkedom","version":"3.7.3-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0eb958eff4d6d8f79361d8ba3e5d010220680600","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.25.tgz","fileCount":13,"integrity":"sha512-fsNSBJwC9lRNmZ9JV3ZLlxPfu1VjFjQa7noOPo2kZtgTjKoOFQkf9Yu0BjcGvjT6jjli4T6fioRwYm+cFsvsqA==","signatures":[{"sig":"MEYCIQDQf6+0jUlA3h5DE9W4WeeTDH9rY3V8KYM4Fc/tqtvMLgIhALukhkmaShdtoSb+X5VMpJvDS8Y9CLHps0oWG+mX8g58","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211878},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d73a66e9de0c09d6c8a001b1ac0d618feb2319f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.25_1706294254267_0.3989444394961339","host":"s3://npm-registry-packages"}},"3.7.3-beta.26":{"name":"@crawlee/linkedom","version":"3.7.3-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d22fa97e6159202e88231ae1891494b54cffef52","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.26.tgz","fileCount":13,"integrity":"sha512-Oa9OoOME3LuG1rvWA+R8vQ5ENyMIJhXBz5r2/FmsiySaqulh+y6JYgEDzQd3PvmL2KkTzaUOb4N7s4r/lXLP6A==","signatures":[{"sig":"MEYCIQCN6LE+SD4CuHpRiFy0oCmhZ8R9M3PVEmCmS+bvRzTIjgIhAPbwRgSF9FbFgqrmp5WRV9tcFZaqt450+IZ2bDjN3bNT","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca019da2ab084882ae8ed5dfaed179f244511b58","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.26_1706421090494_0.5493938358582444","host":"s3://npm-registry-packages"}},"3.7.3-beta.27":{"name":"@crawlee/linkedom","version":"3.7.3-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e519e7508519dcaacdd9aec3b68b52edd43214e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.27.tgz","fileCount":13,"integrity":"sha512-1c21L4MQgA7cIWj5cHpDS69kUUfHOiSFRzs6Uc+9fY/aYtxCiCimDoEfcpq9ehwhZp0YHoLQkWHuUd8UgN4LNg==","signatures":[{"sig":"MEUCIQDRO7CPhGJE+BblBexcQE8E9pGIBquotBIeXLh5PKmFugIgWe4+ibvT5cNxcwAN2T9yq3ykYMaeOKTUA130KFOJ3A8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3f268fe5dabd2a46ed102c9aff013d31a0b0a997","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.27_1706565766524_0.3904136868364121","host":"s3://npm-registry-packages"}},"3.7.3-beta.28":{"name":"@crawlee/linkedom","version":"3.7.3-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d23c2dc85a801bcf5f4a7103809a46a02aae1eb7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.28.tgz","fileCount":13,"integrity":"sha512-oYaQc9FZjyYLYrFbB4Aqwbd/+pi7VKWiuLDysrqbL4wtpOTK0gLt9QlR20thBacghU/Dbtkz+pjKTPiDF1QTuA==","signatures":[{"sig":"MEUCIQDExCbmqaYZvebKpfQ45EY9vmo9BNkKC1w+baqJLeLxMwIgMt2u3MYNVsAhWO7Bt+eqw9vfHJhsQNenv2tDvAfd8zM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"13d7f61cdb018a4ec0618765144b672d5695e7ab","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.28_1706592799136_0.13685570432701888","host":"s3://npm-registry-packages"}},"3.7.3-beta.29":{"name":"@crawlee/linkedom","version":"3.7.3-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5c6a9e0b61926fd4551ba5b46f97201e2d7c1da4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3-beta.29.tgz","fileCount":13,"integrity":"sha512-Ar6AcCKXspWirEpG4N6RF+Q1/4lOnucaG2mFjmbzIQLO7ohZO8MkvfzI9d4LGV5C3zKij8y+/oxJu2yqF5ABBw==","signatures":[{"sig":"MEYCIQCqQaGom3wGKKFVE2GwH7Ugj9BV4aa+0T0Atid2QOhWQgIhAKquVtE2Mwe1nD+m4QjOfnxrcSduwvAZlJgoWnkmglS5","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"50e8c51e24b660045aed79be9667dd01ab3cc235","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3-beta.29_1706616261078_0.18906520753859546","host":"s3://npm-registry-packages"}},"3.7.3":{"name":"@crawlee/linkedom","version":"3.7.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b5be7e68749c372e1eac762a3416ff685f66ff0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.3.tgz","fileCount":13,"integrity":"sha512-dpH1ndxPB88Ip10kLzq7hizDj5br0l69jxrjcBBgVPE85ncZOuhdqgFkMW6VbOGlSj0enCppQgJPikguMaS4hw==","signatures":[{"sig":"MEQCIBxosrioRovvj4xNUTG1+tm7lUCA3Ja9WnD6fP03WvwPAiBri+8fl+sql06+OkOa7blfaM89dQoa0hO1XBUngpVm6A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211880},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57e706386f06f39ce1dae93ea4541426f1f9b611","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.3_1706626403972_0.3923824398022655","host":"s3://npm-registry-packages"}},"3.7.4-beta.0":{"name":"@crawlee/linkedom","version":"3.7.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c40991bc2d63b1322f1dac0d1a5bfd25b284e7d9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.0.tgz","fileCount":13,"integrity":"sha512-5djZulFAU2x9yxy2wEqs1J7cwFP3/1pFooGymmqNZwApl7GbSgr+yYiZO5ScsYTRmazsj7FlDsEMCYEC+nP6AA==","signatures":[{"sig":"MEYCIQDHjHNy3kY2xO7WQCkMh3vdCq6nBQ/rNDBf0xvv//ECowIhAKLUtsMEpzmQ2BWzuNawM72sns7Zdvw7p4ekSATfAOy7","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6c25a2757f102f03bf2e9170bddc05ad4f8abf49","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.7.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.7.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.0_1706626919097_0.4258713285958393","host":"s3://npm-registry-packages"}},"3.7.4-beta.1":{"name":"@crawlee/linkedom","version":"3.7.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d68e14439ebfa862f8b7b561610ff9c230784fbf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.1.tgz","fileCount":13,"integrity":"sha512-+phLlkQt6JJy/NMN4NG/HSLBVsTAz/FWZd2xOJ6g9enJK+R1be7kWCdaWO5relgHWkmkXdmgb4hN37kCvnrFlQ==","signatures":[{"sig":"MEYCIQDu5k/ZSrt51YKbA+xBvZkedNdniUvOVe7wbg1CPtVYfgIhAKngNo9zSgaNaNEg82Fq669Yg/NK7DcsOa7HUJHdu2UQ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"69c0b0bbd3dec25f594fa22202d5716e9abf7b42","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.1_1706674974862_0.31725363874033463","host":"s3://npm-registry-packages"}},"3.7.4-beta.2":{"name":"@crawlee/linkedom","version":"3.7.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f62e3e60060ea96b64b341f067cbda07318211b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.2.tgz","fileCount":13,"integrity":"sha512-03/kCHiqnXss2MWL7jDD21CttcqOeMuQ80UQX8Y/ljebq0D8FnKmYlA5pLm+sUsfjxEzZv5Alukf3T9FKvwS/Q==","signatures":[{"sig":"MEYCIQCgqO8/bT2Rzx5jroX2AIBxtzmodlhhSqf07M6IHovQuwIhAL9p6kMvMhlr63RFzMNkmtIce2L6BzuKYwAMbTbXNFQh","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f25a323c5965c804ae851e6a6de0dd9940b7bc75","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.2_1706710736066_0.4309573107016331","host":"s3://npm-registry-packages"}},"3.7.4-beta.3":{"name":"@crawlee/linkedom","version":"3.7.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fc113a689d7cb114a3dc1471d0d78fd97681f4af","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.3.tgz","fileCount":13,"integrity":"sha512-f7SDaSLguNKSVjtlNKCLewPj8BQQwPi0OkpXyMMHP78NJntge6KEnfHXtIXf5ymVVpIZASkA2IndsDUuBBTjeA==","signatures":[{"sig":"MEYCIQCQX6kBLAVMpa7ZmFO8QHeryaZYZd1LbnkLl36mYqF3jgIhAJGRrhgKJkhmIo2Y/xOE02g8NWTS0nL77GDchAsxq1Pt","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0d0292aa84e9a60bce50a270d441646d1bebf8d7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.3_1706731305494_0.42319851741405157","host":"s3://npm-registry-packages"}},"3.7.4-beta.4":{"name":"@crawlee/linkedom","version":"3.7.4-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72ace637955ee68221db091fada8ee9590c76606","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.4.tgz","fileCount":13,"integrity":"sha512-C2A1HyyiXqrVJ3KnB/MZogcPsgCg6qlOWqYTF7omm8KwUKHI67sTZl9qCWNqwAqwlfKWMq7TnLziaM0PIqCIMQ==","signatures":[{"sig":"MEYCIQD8TkQ3E/kiwlVcjnsMuZs2clIqUSvMJ6SoyIM7eF7/ywIhAJdmruMze6gIbbzWZcHW1dpyRqXhEuhrmKXCvXlNE426","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"211c1c2155ccb4d2a3df9eeda28e0e9017df1a76","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.4_1706762009853_0.5947282186118199","host":"s3://npm-registry-packages"}},"3.7.4-beta.5":{"name":"@crawlee/linkedom","version":"3.7.4-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4573314dddf083485f86bc4c6bb30acedc1c0daf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.5.tgz","fileCount":13,"integrity":"sha512-95MxgAeL/bYC3H0lZ8PbEUmWBr2bY3VqF0pM5k7vv4PobDHQuBStEzw7RmKlUPI0hNEnE+w3lbCzzh6gIBYBzg==","signatures":[{"sig":"MEUCIDDEsdDGDccteVkr/2br1gPdsZBIbO7FX1XzNuoQONlNAiEA3fLIH3ihai8sAXSl1bzFvn3ywvyr2cKyyG8U/ZesfU4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ae200ec612e65739c7f57da6515a4ffa499c044c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.5_1706857638589_0.23927031973247037","host":"s3://npm-registry-packages"}},"3.7.4-beta.6":{"name":"@crawlee/linkedom","version":"3.7.4-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bf354b37df7a1f760815c24fc9d42754cc6e0d36","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.6.tgz","fileCount":13,"integrity":"sha512-i9Jn6Yepv+QZTcPwlutwPeOc4wDTqhexQ6/0ap0Pes4OtQ+WdEeIZDu78legnzSn597p+UHNAaI8+EUxCHMLsA==","signatures":[{"sig":"MEQCIGnJ95EylBwey5f3+ZzaBY4+51Z9EBSTrWbd2fsIXoTDAiBGz1WIpUkm8cXvavmEXFCdx6KU1c4HdzOuTVwADfrHpA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8026381f02cdd711b609fea0ebb5073e0af4b645","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.6_1707023331802_0.33820945815459846","host":"s3://npm-registry-packages"}},"3.7.4-beta.7":{"name":"@crawlee/linkedom","version":"3.7.4-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d4e80edbe33e2bf6eb084012df0ce75e6f9b3d1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.7.tgz","fileCount":13,"integrity":"sha512-qP34iT5IusXMivJYs2eYVSoZfg4FKVKfpLg3j7MMKU7AF+OLYmB4SvO6sAPcinYUoTOOD/RO6wgR/dNgrEYeJw==","signatures":[{"sig":"MEYCIQCMn9lqsqb7DNHWDjpNbPZJDzKK4Mx/Zercu8uznCu+xgIhAIcW5ilkDmQcayokJiVK8d3xZjdJNG7CMlphxS0e0owX","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a8bb0a0892fc0ed1a689f4e7f990e3879cf5e806","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.0.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.7_1707103901929_0.30575609650110347","host":"s3://npm-registry-packages"}},"3.7.4-beta.8":{"name":"@crawlee/linkedom","version":"3.7.4-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2b67b489d98d1d973ad739b1efef3b3751f390e7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.8.tgz","fileCount":13,"integrity":"sha512-3mXbEv8bpWuWgpIHjHXp2XUCOYcFHxWvpuZjDJtd8A5jtFn6bX9y+SdiYcmu9N0NDy5u6QvrUfGIgy4paqaJoA==","signatures":[{"sig":"MEUCIQDjdMUFIm3xYUYPq0JwCKLig/yym6WvorNo4P/uvzr01gIgSRxp5SLFKOCDxiXZc/gy804FOAc+PPg8am1DI3lrEHE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"83abc8f1527c11bac121512097b50c6124ebf4fa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.8_1707191244122_0.4680391660655485","host":"s3://npm-registry-packages"}},"3.7.4-beta.9":{"name":"@crawlee/linkedom","version":"3.7.4-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8ee2eda7051675cc3177fdd7891626c8afdadd40","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.9.tgz","fileCount":13,"integrity":"sha512-DFPQuy4/YgjRtO1pfhY02ZX5pyWnjSz020WpQnT+kVHxBivlwjpxjC2mh3Khs62cLUZ7otWLweDKGHd/6hKPQA==","signatures":[{"sig":"MEUCIHeWhxMDqMRVZE51qsKhq/coBOOt45e1m467xl+LQizRAiEAv3l7vdqOaN7HDf+pIbNX7CduXnJf5G8H+4vVGOckDWE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211901},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"76a5fd34ea087a080e7aee1441053f6b51b76b6e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.9_1707226838291_0.7065503945054645","host":"s3://npm-registry-packages"}},"3.7.4-beta.10":{"name":"@crawlee/linkedom","version":"3.7.4-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"773bff74b0a2e06864a07b77c39e32e7900edba7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.10.tgz","fileCount":13,"integrity":"sha512-isT6t54QFe5mpQo9xxgsHl78psAC61lM9/CbS4/zE0CJlKo7gsbmYoPlmTr30+bbMDUruUt3e/wKCCjKOA6GUw==","signatures":[{"sig":"MEYCIQDD52H9NuSCkA9L9A54BMfQ+Yy6NsLBw9hb9iUF6MI31gIhAJrCpJIobz4uJzKkpfY1oMLylNExxKBZXcyZy/MaCqe+","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9c796ce8ab5a3558a0fb0759f1ff9ba1dc8ba8f9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.10_1707278559508_0.9684523109032952","host":"s3://npm-registry-packages"}},"3.7.4-beta.11":{"name":"@crawlee/linkedom","version":"3.7.4-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f0c2a019ae79942a4678884d95ba1588e3cedb66","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.11.tgz","fileCount":13,"integrity":"sha512-DEvN/te+WOxxIlUd6SyeI7bKxQcpe98ZkaHtSwzH/0eYUE0IgHINU8UxbNbAyDE6agVlc4iG/PEmdQOLIwGJzg==","signatures":[{"sig":"MEUCIQC7MTWneegK+XWQLdiogRL/QdG8cp+Uaj/rdku8NmXyEQIgLX/mnszfnO+d9fpkkhdpVj4SWXA/qmX9vYKykbBcGks=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"36ec80314570e2943ad8fe4a6629e6752cee8abc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.11_1707492766061_0.9704508273608596","host":"s3://npm-registry-packages"}},"3.7.4-beta.12":{"name":"@crawlee/linkedom","version":"3.7.4-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0d141b7b695735ef899d41609dbabc9de0c195d6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.12.tgz","fileCount":13,"integrity":"sha512-uy4+9oB/lvshHuZFHGIAByAYhdC4IC/Cstjc7ZT0WCX2lCfeJPmjBLP+g/9QwkykWz8pwVheUh981go6z182Kg==","signatures":[{"sig":"MEUCIAj1YMBhdbtpAeX11X0+tNE8rDKZZveG9Mx/QoL7b7NeAiEAvsOTvIG5T2ub4bHvAc9UGm/qcCc0qvIuegsUvMs1qR8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8d871884df7c688d3c579612d87288f517487a8d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.12_1707502545468_0.2438844985881483","host":"s3://npm-registry-packages"}},"3.7.4-beta.13":{"name":"@crawlee/linkedom","version":"3.7.4-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b5375cc9fbade4336912a5a280b098ffd3b8c6ea","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.13.tgz","fileCount":13,"integrity":"sha512-WqGGPak1sT8rJyCu2khnGSa4H0vICuVElpRkAcBQjqH9t+NFrYg/JcCiuuPJ7iJTvhAvi5OW1OkvUER1MNVgqg==","signatures":[{"sig":"MEQCIDqVYqkcu/on3Gl07QI2EBCbOHI3J658zZ9CI980/F6NAiBPX+HnKR3ErvAotir7NJcB49i1YkKWXAluT0YfWARH5w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"11915fc67d435ff96d6159f6983f32dd3279ec2f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.13_1707539406038_0.4419250198271347","host":"s3://npm-registry-packages"}},"3.7.4-beta.14":{"name":"@crawlee/linkedom","version":"3.7.4-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"73f96969b834161c9f2db90327e999c6986bcbf3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.14.tgz","fileCount":13,"integrity":"sha512-G+xX59jFs5o1rXSROxB5eVuLZr/wFnAVnugD6THP8hP6GzD/uE7l4uwcXLlExJuOLJ2xfZSVz4t0kGQblc+cNA==","signatures":[{"sig":"MEQCICF8QgH2L4seoPvH2Pt+iDEFptcbN7Ac1cvZBHjn0MKSAiAPvRqhHfuk/hM9S7Lgl2QClXUrN/9wPX11bWYfz9KUZw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c43d194bfdb2b6c8c34145aab9d1f43c26d88436","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.14_1707638832972_0.4048326653505354","host":"s3://npm-registry-packages"}},"3.7.4-beta.15":{"name":"@crawlee/linkedom","version":"3.7.4-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad2985e237eaf8ede5856337f368038bb510c09d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.15.tgz","fileCount":13,"integrity":"sha512-Rx4ypVaRbBJIpesLqKoG9gFViBWD+xirY4GU6e3TAgADVXuyy7iihGP5zzfkCO26xe1BxyJuvEH9Sjq/5UhRqg==","signatures":[{"sig":"MEUCICf64iz5jyoevpizdatPtPXnGtinAKVrarC624rseZTnAiEA2VXjkFpLGJhWTXYVxsJx9bfzVeDRmVITb5iM+EueOSo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"423a644b4166c9b2e0ce9b42380c684bcddf702d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.15_1707639408495_0.45850317292404097","host":"s3://npm-registry-packages"}},"3.7.4-beta.16":{"name":"@crawlee/linkedom","version":"3.7.4-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"161b53da882e7adfc9111fecf69eeb0357056b7f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.16.tgz","fileCount":13,"integrity":"sha512-hXkJmuCNixspj4TeaGJ4Q5p9TF+J5WQMPoOOSwEzKR9p7QRDRXv6cJFvzWkvDCz2N5zjlNlTWh8+lxeF4leBbA==","signatures":[{"sig":"MEUCIEqmuj/pu8sZS1v7JNGAksyujMkd8kAbR86cswy9gyVnAiEAw7wuv4J1sfpy/eZXP/XKulYSxZvOyGWLCLxU/Ig8mB4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211904},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a717745498140627608d990b741cbd715804bd9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.16_1707708652051_0.5369974103737178","host":"s3://npm-registry-packages"}},"3.7.4-beta.17":{"name":"@crawlee/linkedom","version":"3.7.4-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5d02a980c78ea8fe7cfc06df99b8bda71f8adef6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.17.tgz","fileCount":13,"integrity":"sha512-67FvwNLbAOEHNvmpAIZDe8oRSMXvCM3Wap1TIIeyDwqrgMYeS0xp0xTCHRU2wlEig/1zoKPeYJjIUMes0imyVg==","signatures":[{"sig":"MEYCIQCsBWMtVVLxle0b7wrZkFB5f1FhdYPhkrM1jkwqtnPIYAIhAMDI7+X5E6OwPUoDTmTguEdNOttnPh4PDChb5jKOZUoB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"50c206be6af8d4d33fc0679cbbb0403902d012e4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.17_1707773370470_0.9957182351028797","host":"s3://npm-registry-packages"}},"3.7.4-beta.18":{"name":"@crawlee/linkedom","version":"3.7.4-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4233ffd5268fc849d6e329cd48182b9d4fb7f5a6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.18.tgz","fileCount":13,"integrity":"sha512-QdLyqFJ9pugzWJrqAQAnK6C/7onbAOeowOqzGOChK0eE9x/hPVUdJJTnK+XsNmLI23tSvTlHPQQvsQVu/NN1YA==","signatures":[{"sig":"MEUCICYzavJzeWSiIkBUNfACc5s8LI/vbtycBXDDpWYoaW1wAiEAskJ3ZyZv6+i03JHTmBDvP8dbBLiOuJfyYvBFvynzM+I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9448fb4dec81b5cea6193216e436d5827f58f983","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.18_1708004838740_0.4853253037102949","host":"s3://npm-registry-packages"}},"3.7.4-beta.19":{"name":"@crawlee/linkedom","version":"3.7.4-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"df8e227cdd83d9f41a452459950b19037b6c88b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.19.tgz","fileCount":13,"integrity":"sha512-i0XoDlbzfeYomHI8yO0ALLq8M7b6QYTzzXNxprJXxx8sfCxhSP5+juUscNnvCiYI+vagaQcjL/1Q57EgQ3ZGBQ==","signatures":[{"sig":"MEYCIQDj3CSyzDaH3ZWdCG9Nd5ef977h828GWUwH4/XVtO+EDgIhAJZmDUUmqqp2mBPMqhLUC9MTrQDCP6xIM097bMObp6/T","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e84c731986de20a150fd378236dd75ed6171ebfb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.19_1708005772297_0.3291464482904052","host":"s3://npm-registry-packages"}},"3.7.4-beta.20":{"name":"@crawlee/linkedom","version":"3.7.4-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f509a3994ef5971c52a64fbe3523134d3d571032","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.20.tgz","fileCount":13,"integrity":"sha512-nJNDUR+BU2la4BEUJuy3sHUtA8QvdwWyPNgZMlwwT2iRW4XF6/X3MULu7Bs2qZa+VYdM0folmMd91RjryGXhLA==","signatures":[{"sig":"MEQCICQ5oupbx20jf7OtwsufmqOAoiCdSagHqfQgrcI2q+oQAiAOpftLKh4Czg6HlqTgYhZFHt2XsNxe4Qnp++VO7g9ASg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dfcc30da7311852f99bd277056483a49e5230ab9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.20_1708006519636_0.39666121745124117","host":"s3://npm-registry-packages"}},"3.7.4-beta.21":{"name":"@crawlee/linkedom","version":"3.7.4-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4d0f349a140946b9029db5a34df80e611dd4b426","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.21.tgz","fileCount":13,"integrity":"sha512-Sp63h/meVLG5T/K0f2XvMU835/p6oyLIVwGtnxDrlHrFNip5JAg1inoYzceFeVRCxIlducgmPR8n8vTpz3lKBw==","signatures":[{"sig":"MEUCIBrkkxgjBy0o9KPGByeUzj1k4ud0kuLIkJiR6JSetNqWAiEAmrVB+TzEDgLjgZJIrvekiosiOHk2sK42tJwlu3f1Jb0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d9a70d9d156ea3905fda120cb9e553de19c68dfe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.21_1708011888282_0.7292376391316611","host":"s3://npm-registry-packages"}},"3.7.4-beta.22":{"name":"@crawlee/linkedom","version":"3.7.4-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1b4ffb0dc1f2d2cfeefa5291476ff161465578b3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.22.tgz","fileCount":13,"integrity":"sha512-EX26EDyB0w8abwtdituWG+w8vYghY9+myP1wI2a7Xl/CzrfQJnLKtXw8LkDlOLdCj49jZJRUp2IwsJe36h85Hw==","signatures":[{"sig":"MEYCIQCfL07TvYfkcY2YbQ8yak1F8/2HXrADQlMMphLZWVUqTAIhAJO1YPg9xX5XiHsz39VQEfjmjfwYGtM8DcJ4W+CTddYP","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d38c6e243fa1b6df5737231a8f9a4fd210fbf5b7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.22_1708013688515_0.029656107287789446","host":"s3://npm-registry-packages"}},"3.7.4-beta.23":{"name":"@crawlee/linkedom","version":"3.7.4-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"26ab27d82d8ec1a797a4d9df06c45cef5f7a243d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.23.tgz","fileCount":13,"integrity":"sha512-mmg3i9ZH/F5c6D+VPlpqLJU4mgyHYV8B0W86SMtfljlNFFbyI6OS4rOeOWWm6Z9l4g9+jYJ9xVsueqXSbh5hbg==","signatures":[{"sig":"MEUCIHNJqe56Q5jXBGwI4ws1Mr0pJkfcbMR1IcD0rdUOeIOEAiEAuZzGuFbJqVjChNK1/2ECRycZIytRq3NJHl+CCRUFjn0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6921a700a5ac2258806c0a5bbe1bbcd619990c15","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.23_1708055400687_0.03297198532324175","host":"s3://npm-registry-packages"}},"3.7.4-beta.24":{"name":"@crawlee/linkedom","version":"3.7.4-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"307aa5a4eff2b22fce960e432d4a4e94bedb8502","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.24.tgz","fileCount":13,"integrity":"sha512-//JKI1XWCu5PJvXmmyRrUGIyoRXmuwqxd0hC/4iK8KhqUDXokvo5roIuHnfGm45KcLitiHamWN0ZkgZHiseYsQ==","signatures":[{"sig":"MEUCIGfyMYo6gJbCSwifcC6mOEyYdcFfKXP5DXsChJNNGt7pAiEAlGlLhm4goknAM3BKM9Dki8aPo1Vn5pnSsyJHxLDnBfs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f96ce54f43d6e9fd4f1c4c22c141e5dd4eef0455","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.24_1708081495930_0.4290487645014387","host":"s3://npm-registry-packages"}},"3.7.4-beta.25":{"name":"@crawlee/linkedom","version":"3.7.4-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27e95fe88ae2987e4c2dcdaf46b4913216eae69d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.25.tgz","fileCount":13,"integrity":"sha512-QZmBggKvhRYBzJxfqGtA9swpxZXJLJe5aCTnSjZvLpxgl/KWlbk0hBEkl4nKWLYM3IZ6NPbxYScCPwM7Igl7uA==","signatures":[{"sig":"MEQCIA+3czNJsOzuudneggY5N6GTPU2E898pQ1WWc2j23lBkAiBfh5vFJqzgko9B0SkFGWmH6KQvzdRWovYFg9P9jlKLLQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eea345d45682d0b2225dae8b6ce98bf75f712c05","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.25_1708145006540_0.7361894643431846","host":"s3://npm-registry-packages"}},"3.7.4-beta.26":{"name":"@crawlee/linkedom","version":"3.7.4-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"21ac26d3aaef9a87850455c161a5100a48003efd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.26.tgz","fileCount":13,"integrity":"sha512-pUQXLo+Muaiw1REt7hMXRthS6VDYUtLfLp5jF34x7FqKnzCYpgq7XMDZ7LVR3UIwy78MtXtOGkXkscsCyV89vg==","signatures":[{"sig":"MEQCIFKMQdcOmbw5V/f5Nth2MzjR/wYm1sdbM3QuFaYXMF3aAiATAubhNf8CxiOk7zCkHFve0KlTg6jiOnA0S4PiIG0HxA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"27c9768976d2e4e1a72b5c287b68907a699899b9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.26_1708318535064_0.4500421354375683","host":"s3://npm-registry-packages"}},"3.7.4-beta.27":{"name":"@crawlee/linkedom","version":"3.7.4-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"35fbab2b9defee746a5b204acd8a05818b09c0e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.27.tgz","fileCount":13,"integrity":"sha512-n3bYi4Y2DAx3IOHrWa+fuLoLWC541JnB509FgmfWZ54Sj3xcwviUgxIi+FQ/dpXSw/p/yWZdHb3cWhzyenYh/w==","signatures":[{"sig":"MEQCIBCkbe8S1mVwTSib0P2mkfuoXYjFhovVrUhsDhk7XniyAiBYu0cI9s9G7v9v4sZ2s2bd71dzkGV4QFCP3m7m22a6wg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3d3a5d4932dcb1e2ec587565f2ccbf7d9c9d8b7e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.27_1708353214929_0.23834434567468898","host":"s3://npm-registry-packages"}},"3.7.4-beta.28":{"name":"@crawlee/linkedom","version":"3.7.4-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3a3cf073953fffdc5aef857242dd045ad9ff2aa6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.28.tgz","fileCount":13,"integrity":"sha512-JRdknVsOmEoIkGU7aGDoE7f2y9r3v6kKBCBvRAh0fbTBnXPVeIlWDDpN7XXjUriMtGdoVzksPa6PWsDUJ0UXzA==","signatures":[{"sig":"MEQCICFpzXi5e0ilOvJa0JVKoTVyNPa+yaxcm5MEnW5HqoD+AiBAFfwA8CvSHeAV+mrs6OUrNkl2FtDFFMKCN1KUgGXrvA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"de03cd1b9c40e9ffffb9ce110ab8c51f7df637bf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.28_1708419728873_0.6296180175572641","host":"s3://npm-registry-packages"}},"3.7.4-beta.29":{"name":"@crawlee/linkedom","version":"3.7.4-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0f0b8250df253f5c84fff8c165353c8b2d5f682e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.29.tgz","fileCount":13,"integrity":"sha512-WE0TiblVscPTdTirFBHKlbWEQange6dUQnr5mpdFBT4QWl68epUFEg6tXS3LFbCr894r1/FtuEKZLU2tzUJNpQ==","signatures":[{"sig":"MEUCIQCZs7Nh4qgdlsovK07Rue3GtdBP+B/zjl06JrWLQrR/4gIgSUE6WFZY0W3EO6R5dyj7wGPfQTPWWEJ30em0unG+61M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32e25072a36bd2bf2da38d576b6d2cb58394e318","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.29_1708425269818_0.8175892107152865","host":"s3://npm-registry-packages"}},"3.7.4-beta.30":{"name":"@crawlee/linkedom","version":"3.7.4-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9798fe0b98ca046d8a578b91b39acca53ff58c25","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.30.tgz","fileCount":13,"integrity":"sha512-WIGXOdKGVuIh8U8jgbQ1VgRnFyRHTgD65/jrG+LlSASnGF0XtYJB+c6vJR6j21Ta/Gve+sr6G/APzUa9aQEuNw==","signatures":[{"sig":"MEYCIQCXq9UxlErQVAwY56DIfNEmXjqMiSOu//Qi8arDfe1F8gIhAOaMq+RxXyr4ynnZPoz54L0CE4A3++9i2opWm4DQq6uW","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":211886},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1c99ef0ece4f54311f9d4e2012700aaee4dc109a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.30_1708426295023_0.157785965388072","host":"s3://npm-registry-packages"}},"3.7.4-beta.31":{"name":"@crawlee/linkedom","version":"3.7.4-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.7.4-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"95fcf0efecd204922755003e3f77078a0fc0c0a0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.7.4-beta.31.tgz","fileCount":13,"integrity":"sha512-8nhSHGXGIULfod+8ULambkyThCIEvbviEU2MXLsh74CenEkNNVUF524KZ6TRbaUQizRM/Fr47hIH7XvpX+9lhg==","signatures":[{"sig":"MEYCIQDRZuY61ECn5Ue76lxO7DgflB1WGPpIA2gvaUH3VGRf9gIhAPuETag4iiqhU3ZRSQNjydLyV7bi09DNnmZAXGz9/1bv","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212132},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d745f4a79600b2c3c641187aeebb6fdad22f7788","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.7.4-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.7.4-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.7.4-beta.31_1708510878258_0.7711500947468408","host":"s3://npm-registry-packages"}},"3.8.0":{"name":"@crawlee/linkedom","version":"3.8.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f2b739cb3122f99c7f4f73e3c9170284b9d856c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.0.tgz","fileCount":13,"integrity":"sha512-8S24JDKSCy6S+UTei9IQdoRdsQiVhXJ/a3zmjTtU+niMqstHijGcsPC5CLNjaPREt9xOcz5XecyhKTRQIwkoYw==","signatures":[{"sig":"MEUCIQC3j86z8Za6C68KsRRSyYBtfXSmCW/1yqtD/ZuHLjUkUgIgHgSGeJVtWMc13Yv6j5sHeLcE+ouK30uYEpRbShXBsbU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212108},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bd430d3de22c0a9f064cb00654a6cad3bc6cd601","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.0_1708530965036_0.7118510807674832","host":"s3://npm-registry-packages"}},"3.8.1-beta.0":{"name":"@crawlee/linkedom","version":"3.8.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"98fcdf37c8623d673e7326be566dd5245c080898","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.1-beta.0.tgz","fileCount":13,"integrity":"sha512-i1Ef0KZ/AKcq4VerdesswyH2bjvTjiiTQhvp2LYxWSRyuxUHCH+uXSsJZV366RU5lS+9p22AY53lq8OgTa2dgQ==","signatures":[{"sig":"MEQCIA2BE6OJAsmL58/DO8xzqFbcDjxb0giVctDcbTE4ApRsAiB9abz9JbP3NHWhyspg5e0YIAPNEuOc/Gw3OBZVs7So8w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9bcbeb444d2658a3177b6b2c1d24e846bc0b651c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.8.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.8.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.1-beta.0_1708531491688_0.5193064174591759","host":"s3://npm-registry-packages"}},"3.8.1-beta.1":{"name":"@crawlee/linkedom","version":"3.8.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ed3bf017823a315608f9316a508d56016f1ee85e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.1-beta.1.tgz","fileCount":13,"integrity":"sha512-Gw1HtiA1MAjbass7sBqj/p/IhkSOmmLeiFZAO7GAc+g+Is0y8in+i2VQ6UiTc93IEpkvLoiuiCUQNLIogdHFNA==","signatures":[{"sig":"MEYCIQCOpJMrtoW76Z1URw57rLxd56tUblnBQIO8D394lRaFTwIhAJhwM4Iwv6bUP3MEsPR0rU6jQlcjV5tMqrwEilr3yRve","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212129},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"878a34ecaf7d7963d7b200253e91d7d2ff1cf940","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.1-beta.1_1708583337831_0.7349041179251126","host":"s3://npm-registry-packages"}},"3.8.1-beta.2":{"name":"@crawlee/linkedom","version":"3.8.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4fabc5f11c4bd2f4d7f3761d12a428bb8ac854de","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.1-beta.2.tgz","fileCount":13,"integrity":"sha512-fIGq5ckorn9EO9vNxhbawlnKkw8zFHngdbE57efK3xLaSvsylUL7wrOnYZLLVp3NnuO3DyDvQ/nCE42C3bDPIQ==","signatures":[{"sig":"MEQCIAuX/x0opTYkLgu2YQEcsXiA0t4Mk7og0wKtbKxAyDzJAiA8gh3TJqTt9a1elDQVPY+dxgO823ntcWaA+zGgl6b70Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212129},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"17fc19b74c4bb35c683c99596db67cb283ed73e4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.1-beta.2_1708608909319_0.3871892270413504","host":"s3://npm-registry-packages"}},"3.8.1-beta.3":{"name":"@crawlee/linkedom","version":"3.8.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"247f69c93077c4b86226ca3c3cc8a588c9598b1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.1-beta.3.tgz","fileCount":13,"integrity":"sha512-SDzC23mQQPxNbDzU7F02+igwKz339o8B8ltpJYmK+El4Ikw/JO/7KIlUTG2qGvpQlSqG6gZib6MYr54rkZ8Zew==","signatures":[{"sig":"MEUCIG2wR63HTAQtchGHngeKhppI54QTGtICE3jONINHD8/VAiEAmxJ42rUUoKYzKkhwQSFOYgYSnbAmtnNbvUBMrN9rICU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212129},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"acce62c16d14d90a518f4a19537a8e52b83e0344","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.1-beta.3_1708610224718_0.6166709316889873","host":"s3://npm-registry-packages"}},"3.8.1":{"name":"@crawlee/linkedom","version":"3.8.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81aa4190cf3ca338fa0b918aef569c3da19f6eb1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.1.tgz","fileCount":13,"integrity":"sha512-OgBoVCKNEDa69I3pgKnpbXVpLmGAXfB4ZEj+J8A34jSSQElutlKv5tgJybWtdzm88NTsnFA76OBtMBN1TBWOsg==","signatures":[{"sig":"MEUCIQC6cmtyEJeEst9Ekp8HaWuqpnFTqiEtYVyZS75YZY0SHQIgTw+0J7NGX9VzCj2h/nqpTHxHADbjwydlUjnt7F1pSss=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212108},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9772c1a487ca1289672f3226460cbb247c53326c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.1_1708610871042_0.3847319564993119","host":"s3://npm-registry-packages"}},"3.8.2-beta.0":{"name":"@crawlee/linkedom","version":"3.8.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"961fa7525a4f59ece4dcf6251d211576f4e34dac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.0.tgz","fileCount":13,"integrity":"sha512-NDS0gxAq2VJkhYOa5n2aooR15aieHJ2t4TFUjrXLmE5UPGTR9iP7MxCjVI1TFLYMJ3iT+UQmVIeJDeigsRsNBQ==","signatures":[{"sig":"MEUCIQCnsBe6RiyoDRXIA/n7DvU++UC/AEOZtJYPSWgomXoOVwIgbFgpdQK4aH7zEMvR7k0jYOcHgLjH11N9Pw6o1ugi/qQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"38454f368ff0379bfd1f2276b6606be100e00c76","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.8.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.8.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.0_1708611412306_0.6343410204015809","host":"s3://npm-registry-packages"}},"3.8.2-beta.1":{"name":"@crawlee/linkedom","version":"3.8.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a4cdca576bc8ea39523f6e4925a1fbc946509d53","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.1.tgz","fileCount":13,"integrity":"sha512-l2eMZ4AFHPThc7hEVB9W6VZXZYEuZ0Z3xUJjITmE7N3ad53Ndq/GmgoJa/pCpZVFewGvXdexBy3Q3XSvfUGElA==","signatures":[{"sig":"MEUCIHXU1LcYbyCDg7NOfWwlxLUAYPHeYAN19fAkBSB+s33zAiEA4jzJWf6iFAu0kOolAZSYxxbThBdkRLNu8pAmlKK6wbM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212129},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c6d8979b69fbbeb3ea74f87c501c926cbfc5e602","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.1_1708615619622_0.238949276474","host":"s3://npm-registry-packages"}},"3.8.2-beta.2":{"name":"@crawlee/linkedom","version":"3.8.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0dbb8b369f0358c2f1dbd3636fd79ccad0562852","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.2.tgz","fileCount":13,"integrity":"sha512-TmZfUuXnyteYBjZE0BU2GTPonS+49+TT5xqUcdTWm/bOzrmh4zOO3ANBCUW/9YLivcGoYXj7KYUhYJVaAif+qQ==","signatures":[{"sig":"MEUCIG4UsI5ZYoWUgC+xISQLQSJxqt0YEu4kyZsUk+gt9NwLAiEA3fn719futA5fRxaXB+1n4z18AUy105NYSHFSZNONgTI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57b8eea0b539c2de34e7c4eb6e3b1ec85e44b442","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.2_1708660903188_0.2096854402988233","host":"s3://npm-registry-packages"}},"3.8.2-beta.3":{"name":"@crawlee/linkedom","version":"3.8.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9e1d3ab71b8f53be5aedc70e5553e04e7e07b2b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.3.tgz","fileCount":13,"integrity":"sha512-hHY7e59bXKbC2WWUvhquHJjME3Dzx+Y/OgMjuyExyKhA0pFnJk0kz+nNGA6vvHdcbDimjk15GOeZKIYz7mtWTA==","signatures":[{"sig":"MEUCIB/9EDTkYRhd91lMSQwI7o+f4GvJ5ZC8roV3HlhXO+C4AiEA0xkCcceE23zS68w4aTQnGc3bJOrLbEwDrXz5IBh48Pg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5d7692764ca0de2b932d8e10f7a5c5f294261c12","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.3_1708751161126_0.29393328393699614","host":"s3://npm-registry-packages"}},"3.8.2-beta.4":{"name":"@crawlee/linkedom","version":"3.8.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6e915108606f661024da6d7cf8052d331762b5f8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.4.tgz","fileCount":13,"integrity":"sha512-8TukPt5+yODqlREqzr1SWbE6mchjf0GY6UAsIEwuncLTl442wiBJxUQQXexVs9nc0L2EtDiDvDtJ3WhSKFYh2w==","signatures":[{"sig":"MEYCIQCXvOUK2eT28rEni7ywnRWZEot8HOXO7cFwVbpR3vvfawIhAMx3zQo0rBhQAsO50M2bddZPbec2XhJHqB14ORajCvhz","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4dee5bd8a37e59dfd29357e492b0d3afcdc6a37b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.4_1708834222050_0.14825444418756284","host":"s3://npm-registry-packages"}},"3.8.2-beta.5":{"name":"@crawlee/linkedom","version":"3.8.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4adaa4aea182536e5a71edb9f2b11ee9015179da","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.5.tgz","fileCount":13,"integrity":"sha512-paOtBSmeL9oTFfvRDwoN90czLucpru/qv5r0A4A2EvEfhKaHfh1sPOvS62aabVRDCUEF3TXTQLQZSi8Ny9lQEg==","signatures":[{"sig":"MEQCIA1SKFcB+rMPcHvb5tBXB7GaZFgM5whl6Y6heIzXeLLHAiAqy8Tdf7/js2n9veCmF1rfYaZ3l+5Vnz19emw+TjGJZg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2124212f883a3b922af115240052b48f3e5ef159","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.5_1708921860570_0.6630179782074084","host":"s3://npm-registry-packages"}},"3.8.2-beta.6":{"name":"@crawlee/linkedom","version":"3.8.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cdabe173ce78e4422839c1b250c936ba98b1d1e4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.6.tgz","fileCount":13,"integrity":"sha512-LH4ki0bSPn7mY0UIqfQavZC+heBFTfbqmc6g2++H4bj+J5ySlKX3OS8+au57W8jeGHItimzJTBC5j+mb7+l4sQ==","signatures":[{"sig":"MEQCIDtjSWXES7sdpBgyuDaOtJQflX01ElJUz2cZKNPZDLODAiBndqy4HkUnEF4ygrUWOXk42tlE7LUL8h3kXSgZcrIl7A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1457661d3b6cd81bbe5ca6ad801631ce07d47c9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.6_1708939911438_0.42361186822085406","host":"s3://npm-registry-packages"}},"3.8.2-beta.7":{"name":"@crawlee/linkedom","version":"3.8.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"104a0dea94075e42f37c36cf9601e6cbfd28c159","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.7.tgz","fileCount":13,"integrity":"sha512-7pQOw2PlbnuNaCC2HQA6wc0CfsSrrWDcyk8qe31+36vkiuu90qgKdDy4z0Tm01YYFHT/Hmu+h44peHUu9R+yjw==","signatures":[{"sig":"MEUCIDd3ZYJYhbBIIyKgsxLYyNc+oedNJswBUDO9TYOnLFFcAiEA3Yf9wiGR+enUcUBzsrX0qNCYro82hoV7TqkTQ5DDfYE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b3068a7867a0fc7aaba222e3370125a697b79475","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.7_1708962894047_0.11981092997015463","host":"s3://npm-registry-packages"}},"3.8.2-beta.8":{"name":"@crawlee/linkedom","version":"3.8.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4be511ac4f292f786f8be0d4cd58f04f9d9f8a72","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.8.tgz","fileCount":13,"integrity":"sha512-VNoxe6kQRNUfm2nFnycqUX8wCGYNqrEEtVsnv9MAWvYTJTrZexbhMMyCujdl3tmL/L4F/OyVjRAFIfck+2LMVg==","signatures":[{"sig":"MEYCIQC8LoAH5SPIkl3UD2KqEyQ0YJDH0HFEUBWweFQzpi5xpgIhAMGesSDuaqL/+aFU++aRCC7u1sMSHwB9u80k7S5QQV12","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"656aef21f88a8f6050f6fb3024c03d9b0ac2c5bb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.8_1709010353017_0.008137306123295218","host":"s3://npm-registry-packages"}},"3.8.2-beta.9":{"name":"@crawlee/linkedom","version":"3.8.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a51bf92eff6603f6e63ea6df281696a37f943a1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.9.tgz","fileCount":13,"integrity":"sha512-ckenwrdruxK8u6uO9+pIqZU7m2jYQnYR7K/UcB0QSIFE0iqDjVVCFfG9sJIGQMSCbPbi9s6GJbxvAZTwAcbYvw==","signatures":[{"sig":"MEUCIQCN3nVrrXkf68XMXuSirMJhpX76tb3UslNXcwxgxSq/sQIgeNjQ7USpjgwL6C1UKshhY3f5cbU8khQWar9w2Y+nfxk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212147},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f863863dac7a1993d2ff745b9522d3e989851fcf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.9_1709095571532_0.2375976827206856","host":"s3://npm-registry-packages"}},"3.8.2-beta.10":{"name":"@crawlee/linkedom","version":"3.8.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0fb05e7dc60033e5628dfd8e94e34a3955bbd6db","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.10.tgz","fileCount":13,"integrity":"sha512-4dWOX7com4YC5sQxpM2kzbN8kASzCVYIHR1IR97ArSN1jCppuc9xNn0Xf7Iy6hXns1AG+WNuZDLuG2vfnd2nug==","signatures":[{"sig":"MEYCIQCdlZDifhr/n3fbN3jbb/gZUSpHScB7fIhxwrg0XXF6uQIhAOgrkLrf/tFJYqkHvKE1PIgUm4B3Z1No/1CUg0kbUXOv","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212150},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7369cf0a92a1c9a05bdf7338c9247e0e51a0dfc1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.10_1709111646719_0.22413565725116547","host":"s3://npm-registry-packages"}},"3.8.2-beta.11":{"name":"@crawlee/linkedom","version":"3.8.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b6808551d44edc1df42a96e9e7259701045c3653","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.11.tgz","fileCount":13,"integrity":"sha512-6ZzghcxJ97ubYWInDPPGXJ5bbC1H9094DTwfIjo3ryD44Qz941crairfnm2f2uiXlY1Uvh38Z9fxAg8ebPhMpA==","signatures":[{"sig":"MEUCIQCh5VGBfD1Mqz3qUhw9ToUK195LKJUgxUITRbZ69tOKJQIgIHQEGutZ9Oo5Aq/UZFVEQlv8cyvqY9fmlTrIK10XtmE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212150},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"acd5447435421b5946c0056ee3be5e565c8df584","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.11_1709132229024_0.9959796904546265","host":"s3://npm-registry-packages"}},"3.8.2-beta.12":{"name":"@crawlee/linkedom","version":"3.8.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9af8f1b3958b8896d80b7d99611a5b9a4d3a6dfc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.12.tgz","fileCount":13,"integrity":"sha512-l+mH8GZ0JsAnIRewlg6tXKaV/HBqGvPAw1juE8RtrcntZvzhCVvsKQ5RVV5NlGsb0iLvLBiCwKW5/rgXdR8vJw==","signatures":[{"sig":"MEUCIQDUMC9bIh/zv3xn22P2D9OUyTZh8pq5gzqRic73m5pY5QIgfHraxyaM1VvTnAIloxMf+F+jDwJ9ycbNEZ6KOfvBHp0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212150},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d97864b8d28bbc1691d96fb0379819b328a3c813","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.12_1709138829189_0.273130092103516","host":"s3://npm-registry-packages"}},"3.8.2-beta.13":{"name":"@crawlee/linkedom","version":"3.8.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8343e9f64c3a331190d74728206d136e0def9049","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.13.tgz","fileCount":13,"integrity":"sha512-5eEvGK7eSvzWkXtrylKAeTk99JsY1Zp0oeXpi/3ysOJ6kDSGVJklrn24eLMaDaCeV/WN3e747w0Ej352PUwpGg==","signatures":[{"sig":"MEQCIGJpfkTT4ZkoOT6GNq9nht4P747psngKjyn7ow8pugGIAiBuHEhGNEmp8xV5B/QB8obiN1qb7kHdK2w0Z1pPNAgKYg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212150},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e6bc4a8a778b4b03bc764cc82da87b11e636067c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.13_1709178642854_0.5198102182411657","host":"s3://npm-registry-packages"}},"3.8.2-beta.14":{"name":"@crawlee/linkedom","version":"3.8.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2a8c811f8b7f47fb66cf8bc079eeee9ec353d6d7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.14.tgz","fileCount":13,"integrity":"sha512-cLwfwljdiaFfWKD1eAGW1MFs9M+F5d34wRUXvnm3RkC+BSYGTrHI8ETqcf7ueSbkf0DH1mvakpztUZ7oAjv/Vw==","signatures":[{"sig":"MEUCIQCaRXAyiif55Jh0gJKYSu1t61aNWiBruRvRdngQqKCBCAIgWAQFUrMBQ5dwgFgF8Te9m+moOjS+h43PJJLLRvEBYQ8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212457},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"54ce5bf05955b8de91b94a7c0e384161018ea210","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.14_1709209515963_0.6909449258791998","host":"s3://npm-registry-packages"}},"3.8.2-beta.15":{"name":"@crawlee/linkedom","version":"3.8.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cad8543a355e421eeeb91c12bfe3daa9c5b59f37","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.15.tgz","fileCount":13,"integrity":"sha512-X0RWIaGb3ddpbcPUTQXNZOprg5iXXYDRuToHXiVL4yWmWg+ISugVvt9jSMDbQrjz00G7ujdG9jlcbxdrHRidGQ==","signatures":[{"sig":"MEUCIQCA1OHEOr08BvetSfCACGZsXblJWZkkSRWQKfGAFCQRcAIgFgaIIM2J2ngUZkln8xhtUEXO9Ha4Q4huDvoNGAI1jRU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212457},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b493d9b700215536b7b3eb8c792ef2f715d2d148","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.15_1709365347668_0.22196343001878094","host":"s3://npm-registry-packages"}},"3.8.2-beta.16":{"name":"@crawlee/linkedom","version":"3.8.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a4d468502f194d6b231e3c3390a13f46ff5be7ff","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.16.tgz","fileCount":13,"integrity":"sha512-Wx701VRceIe+X2uZ0h1L4fznV3odYrhhWXM2tohOwlF5D8ClCIORFa3T1+3LCoym2+Q9iqqpwPcE3BNaRN0MDw==","signatures":[{"sig":"MEUCIQCIbHCrqzLBIw8J3CnNRR/MZiFHA+ZWuVCk4zY+2+98VAIgMUYuXgllS726xRreZgbSLTcQdAqbBVmctloCqvwO+Pg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212457},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80343a2167eb06852c404e4b1726b885d748d5f5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.16_1709527795322_0.008427262893572873","host":"s3://npm-registry-packages"}},"3.8.2-beta.17":{"name":"@crawlee/linkedom","version":"3.8.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"047d0d79cbf1e6fc78b9739074812a122856ab36","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.17.tgz","fileCount":13,"integrity":"sha512-CFFWrXq/TGfZQ2OAZ1gm8RIWB4XBuWlUJIMmGFZefjlSggbbAAzxiX9vjUBUZte5xxpOV24y0GeQaRttiiWirg==","signatures":[{"sig":"MEUCIQD9TbGxAHCHYsbZ6rd2OvHF2yld3xstLsGhsgK3JxN/XwIgFTVnZb0WOHH05yIFzJU8Ssgq8i5JUZbJJOC2ER50/cM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212866},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"05b332ea26908985284a5fada1f9c218d934e51b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.17_1709614174164_0.5752647108216502","host":"s3://npm-registry-packages"}},"3.8.2-beta.18":{"name":"@crawlee/linkedom","version":"3.8.2-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dcc1a2f7e52a41b70a921f2ba4aa8b831db6e000","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.18.tgz","fileCount":13,"integrity":"sha512-dV4CILT/bxsyamaz5z9FZ+jXWao1w0SF+sCvmrwjy23TADk0AqxQdwJAAkTUqorcpmkJ1PTgFHtbYdMge3GzfA==","signatures":[{"sig":"MEUCIArXe21Rzo/Ja3hexuV7JHmbmGKlbnPoXx+opXuPf0Y6AiEAq7mS31u0wHnWeu3JqAzfDi/CFTIBJ6gHuCAh09pzfcw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213047},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"edb418d30a75b60689978994069446df1cb95213","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.18_1709659379194_0.42224054014957346","host":"s3://npm-registry-packages"}},"3.8.2-beta.19":{"name":"@crawlee/linkedom","version":"3.8.2-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f9aceae1c92366c97dd25ac9077006e891f9b6b4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.19.tgz","fileCount":13,"integrity":"sha512-4JcvrVylu10Xr1PcdncjnwBZSyz4ra1Q73qO/mvvJIaEB/QVLxzXDwfU1zSu2Ysq07dGlHfNRMBEoL0M9blmxQ==","signatures":[{"sig":"MEUCIQDufcsN2NckcTP2JNOkUCEfeB8G2dnGnyApKwRKWUKg0QIgGV0n7IOQvNT39P84DLOmVEAisSoP8WJfEyVk3A2fuoY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213819},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3d322012ba8378705c9e901d71eed94648bf9cd1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.19_1709871525290_0.7153628266710859","host":"s3://npm-registry-packages"}},"3.8.2-beta.20":{"name":"@crawlee/linkedom","version":"3.8.2-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7243c1d97a0b0b0467d47246901aa0d470d87fb8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.20.tgz","fileCount":13,"integrity":"sha512-ewo0w23rBQ5sE3ZMFE66fsPmWwT1KpXnSr7jNoaZVL046gg3/bIsN3LtAXeiNRjHr98WI05lkYOatHMItby6yw==","signatures":[{"sig":"MEUCIQDNcAYE3y1FcLVr7ql/B14gcYJC7Y5k/bAcalp9dqYgBAIgWlkfA1JVS5hTS+GvER6KltIZdpO0kRc3dEGYjpB2Vus=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"82b5dab47b9122b81866e00bab2cccbf1885b1f9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.20_1710047657643_0.2884908493334979","host":"s3://npm-registry-packages"}},"3.8.2-beta.21":{"name":"@crawlee/linkedom","version":"3.8.2-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bf34c18e1e8bd64c9173dd3f30477a6f4b10a07c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.21.tgz","fileCount":13,"integrity":"sha512-/PuoYJX8PNCVBZoSjQ1Z3E+iTm1Ud3qzIuQdikb9rGhtUeSe4BVYJb66FuA+UgcSgy8o6TMKwXI8htAr+Ew8Wg==","signatures":[{"sig":"MEYCIQDSzQCnoVGfi3ccNBW4wo7sPAMf5cR8rvlMKeQCTLcthAIhAKcDL4xsYGFwEBPW97wWQEhRV3YtcpCnknWvpCQXt/6R","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7b5aceaed889c76c6967c427bfbac47319c79a51","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.21_1710160678408_0.46459621705521137","host":"s3://npm-registry-packages"}},"3.8.2-beta.22":{"name":"@crawlee/linkedom","version":"3.8.2-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"846dc9ee2b3c00bc695bf81405d630bb809ce0c2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.22.tgz","fileCount":13,"integrity":"sha512-DGEe0c6nWL4YhbE7DvcsC5lhn/yb3tA1K6TfbEEr4Px3qJJ+orSo8y/rLTHuwb796dnSg3P34pdIeifpPlyh5Q==","signatures":[{"sig":"MEUCIQCo2eBrcx6KZT4w7Fq5Rnm4XLuZfU1LwaGQ1hVeZZ+WcAIgKpW/O9tqmiOa14sDkoSW2+2C+3FgREACrL1xvRPI3Gk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"17131afab1c5a95f0a5259bab7b46a42f98b6948","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.22_1710304480562_0.5704088108461667","host":"s3://npm-registry-packages"}},"3.8.2-beta.23":{"name":"@crawlee/linkedom","version":"3.8.2-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"afd6c20c0c0c67d6a9a2d51555eda8c30643f51a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.23.tgz","fileCount":13,"integrity":"sha512-eF2l31PPdlBVf4eFm3d1H4uhF6uRHKeuX6zV++Lh16GookwYgnXoo3U0eXcm/NA5QUTxCz/o0JcRjMrwmO7YAw==","signatures":[{"sig":"MEQCICiYrujlAxsUhGZ9Fr3qh0MkaHOYWQbwpE43CBGqdWm4AiBXc9hI7FLBpQNqckUmOQKKZsivVxbNpoQ6yi0a9Uaf1Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3be310223adf4d41667a94c254e9c40b4be06d98","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.23_1710475089694_0.35437349188461775","host":"s3://npm-registry-packages"}},"3.8.2-beta.24":{"name":"@crawlee/linkedom","version":"3.8.2-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4e61d5557511e4b6b3db730ee0045393f71278d7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.24.tgz","fileCount":13,"integrity":"sha512-pBTrRW2dvZFEPFUufUTzFxPv9cy7ghiqVaZTNJmIqEsdRcF4f+6vKceG/HTa+wSLayMhup5xWeAhPiMFMkDrlQ==","signatures":[{"sig":"MEYCIQC/yHpAIXaJkL5JLCIUl6UR23qX5qHqoGJCx8Uq9b9RVQIhAL499IfdSutXPAHtnlUTbBio4VW9uxmCx2DSfC1UVjsD","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"48ab6a06788f6152ace7d9b460e10e74d92a86ee","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.24_1710560698102_0.4619627857095261","host":"s3://npm-registry-packages"}},"3.8.2-beta.25":{"name":"@crawlee/linkedom","version":"3.8.2-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"83322178bdc8b77a47ba16deebc0bf8a68eaf627","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.25.tgz","fileCount":13,"integrity":"sha512-P5VWSNs/yLrd3bz4p0miV3PhaA9wZ1ANHqZmnlDPzl4y6FDrCF36VXQ32PasQwLq8V/o+s9Da0EWkFMvBrm+/A==","signatures":[{"sig":"MEQCIHJXi4iS1+hAKtEUXrl0yLjlDMKuI3HjQp9/LCkWF5RSAiBk9T7HwjVU6CChQgO/GDZPjo7nQjln3TLLLIqGtEoMnw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6fcea47e1ddde338190de781c0d3674126da7552","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.25_1710646477057_0.4236260877305542","host":"s3://npm-registry-packages"}},"3.8.2-beta.26":{"name":"@crawlee/linkedom","version":"3.8.2-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9d93daf9ed6465ab4cde7f0aca332f099860f37a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.26.tgz","fileCount":13,"integrity":"sha512-t+jhC8Ebqe6vOCS0lrn/pgc/npu8TcnlvcpJV+Vc3hWfNJs43UfoicE/DBMmBvRAbG05gJjucjjBpswl2CQaUw==","signatures":[{"sig":"MEQCIGSPyN7D4101/nLG+dA/SjHnvjEPn+wxtUAd40D6+HU9AiBAH5p/j9RUnYVG32S/s66eL7XnEVd0lqj/JQOBBncvXg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e5ff3b4e87b41026fdf20af36aa72d2cadbb82cf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.26_1710818573106_0.15273570085937727","host":"s3://npm-registry-packages"}},"3.8.2-beta.27":{"name":"@crawlee/linkedom","version":"3.8.2-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"32535b91d1b48444efd98ea06d14942ca4626c84","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.27.tgz","fileCount":13,"integrity":"sha512-WdwtVW+ihf4tIdkwEnAsgrFIPnE60D+JLRVQGh7RSEFBAvOtth+H/LacsP2cBXDF/QDGtyeuMjI7QzcaYGzCIg==","signatures":[{"sig":"MEQCIH/YIpTTqt1WLFrfb1PuOD9n6Qv2myLpzzTOYq1cyWNmAiA8exUiAeSXkhPQlSAbnEJWxLVPQczVh1+VeopnP7N0mw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df5fa88f44f2183b2e5347b68e219926c7e1f651","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.27_1710832008850_0.5236466639337021","host":"s3://npm-registry-packages"}},"3.8.2-beta.28":{"name":"@crawlee/linkedom","version":"3.8.2-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"979cc612258cdcc7d823f8ff0be83bf9b378745a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.28.tgz","fileCount":13,"integrity":"sha512-WlGmFwE+t9/0xPdUn6Ik3LP9arGvC9NQphGZc2Qx0lmSXX4PCeoLfa+VD9ogA2hENX3I3jMgnou/ITMiognmQA==","signatures":[{"sig":"MEYCIQC7NpoQAf8SF+9SozVIbU5FSLsrTDVj1cqv5aAlHCZlBAIhALR1wlirECz3ZNfMTsmF0lkms+3hVGde0u69fGf44AmF","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215649},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8bf2b9dbacc0f47fba8c1794663b6d12e6b1f17f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.28_1710904298527_0.4628550978950128","host":"s3://npm-registry-packages"}},"3.8.2-beta.29":{"name":"@crawlee/linkedom","version":"3.8.2-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"84502c5751a0ba52a415a474e3321d3f471f98da","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.29.tgz","fileCount":13,"integrity":"sha512-JOdG1+cy3LI/FisEOFCawsiDEL0t7vPjqmKBhj7gBfPYVXHURPNc95AvzKvqxJzdfX2ATCBwz/ef6hlJye+Sag==","signatures":[{"sig":"MEUCIQDYjRACxmjVuMpde7bhMb32EUdGzhdargjCntr7vXn+6AIgVKwzfeG/uCmWx2RDmfehztpj36oVsSWhI36h1wqHHe0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215649},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8c0556a1aa3505e1da204e135b3ea30b3ca379ed","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.29_1710995559715_0.832843086348068","host":"s3://npm-registry-packages"}},"3.8.2-beta.30":{"name":"@crawlee/linkedom","version":"3.8.2-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"88745398abce90df6be07188ee93f1e37bb39f6e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2-beta.30.tgz","fileCount":13,"integrity":"sha512-cexmdQSJDpAVJxsb0gFbRqBxT0Sikzp6sCRF7TBW7U23I8DKF7xAuU2zVJrVVmaAvSdLyJ3KFNIrt3ZqBq5P0A==","signatures":[{"sig":"MEUCIBWWr+z6KVL6vCzP4F6sh6rqWxLHhfCl9JR9CjK8uN/mAiEAzo5B91mv+XMYKbZywvXe2GhEuLHqAKlnlXgN1sRfZow=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215655},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"879ee03f7b004e2c6e746aa251cdbdf20046ff5c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2-beta.30_1711034340403_0.5064757004526781","host":"s3://npm-registry-packages"}},"3.8.2":{"name":"@crawlee/linkedom","version":"3.8.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d891d53f529b3b7a5924cb1dab81254d6a2589c4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.2.tgz","fileCount":13,"integrity":"sha512-lUw7fuz1pbATe1byjxl21JqfmHQTNCDFeHWzq2xKKoWJU9HBKjIr+5ysap+c/2zXfDgi9jq5+ekiDTAFyl2XzQ==","signatures":[{"sig":"MEUCIA6rMLxGsZRz1gjH+YdO1dADbl7sK8TJsRVmu4x39tGRAiEAnbBCGGVBFnGroTmYsnV5u2niHBSaHTxOtlW6G5WODGE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215631},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8705f7e3aa97abdd85abc5c079053dc18c0f1a94","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.2_1711038260979_0.5307146279183119","host":"s3://npm-registry-packages"}},"3.8.3-beta.0":{"name":"@crawlee/linkedom","version":"3.8.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"754aa9d88062ede19503d5f340dffc305dd9908d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.0.tgz","fileCount":13,"integrity":"sha512-rVs4wFEJt8D8PStzdYZ8rrLvSyH7Edv++O6NcuDcok6kmjYBxLLkqDckqZgbNG+Go75wPMJNooeH1ptQBmu5ZQ==","signatures":[{"sig":"MEUCICAQt+r3oX8iIONIq40gevHmEARHaYISewkAX7crZY7yAiEAy6PTAiQUFYz3B+f4eNAYzAL4xwtM6Fs6V8PsAcLwabY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215654},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"48427d669d93a7e9a4c3f4d92b309d3730da5756","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.8.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.8.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.0_1711038812503_0.477470024843609","host":"s3://npm-registry-packages"}},"3.8.3-beta.1":{"name":"@crawlee/linkedom","version":"3.8.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b969b5d2ae0225713b1ceb3d4d92b3700a3ef1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.1.tgz","fileCount":13,"integrity":"sha512-TQCreI4Bab4xL4ko+Mz8SjwvM6mH6dlrRS04tAmS+zvX4dFgkXzrGmV2nYn355MtMHI3VgQFbNxuxZj3ARINGA==","signatures":[{"sig":"MEYCIQCIj3jKMUULhdMtOS+n667eV5I3RgUPTekLS2yCg5ImxQIhAI3V3GS79yx6zxidZLsu1ThAYzfrLLOJdZ01s0hArMa7","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215652},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7c1b392f8d9d01dd811734bb393928f90a688b9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.1_1711080589806_0.35819815324312354","host":"s3://npm-registry-packages"}},"3.8.3-beta.2":{"name":"@crawlee/linkedom","version":"3.8.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"34d8c78e920bf367bcbd1157ae0699fb3155391a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.2.tgz","fileCount":13,"integrity":"sha512-eGn8YEZPu8lq7m3iR85QHN8TaeiZ1gLa65kIcV+z1T0kYMyXG0stOafLTxwr2XKU/V5bByduAj8mnrVbFLe0Ag==","signatures":[{"sig":"MEYCIQCfYoVZBXZL9TGecEHe1kAo8rLsQ1vEvBPRn6nw9dwMbgIhAJiRXk2nmqBPyaFFPA+anFW5o/+DycryQKn7+K4aEm30","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215652},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d29b478b7b265dc8ddbeaee5d1f54a953c9e2aeb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.2_1711119077649_0.5111650511604846","host":"s3://npm-registry-packages"}},"3.8.3-beta.3":{"name":"@crawlee/linkedom","version":"3.8.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7132488400c6ef10508bcf47c40795dadffe5da8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.3.tgz","fileCount":13,"integrity":"sha512-A37HlqXykQwbVY44wdNEklM4QQqN2HVTKwEESIB9dIc5pkUzg2whhVBBBUYU5bj8PBUUBB5DYK/v2Rv8dgLjrw==","signatures":[{"sig":"MEQCIHJQL0uPYP/Vc7xLrf75F1bf/NPMOE3tlI3Pmf7G/MciAiBu3uRa6TaTfQe1Ggn2A1DnvOBrCfX6mWUp06DrY5vvNQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215652},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"079c8d878a22e1e9b0338b15efe28ae3f9e0ce13","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.3_1711165431105_0.49305835196775893","host":"s3://npm-registry-packages"}},"3.8.3-beta.4":{"name":"@crawlee/linkedom","version":"3.8.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3034c6244f2ac23da5841499257dd85a08c0cc33","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.4.tgz","fileCount":13,"integrity":"sha512-tQ2ySR3qyGsPKoH6z8m4nkaai/q2QHLipqrtiRCttbXG0suy41N+ONF1c3/tfPTm/O86ODzKqSWazZSh5VYQ8A==","signatures":[{"sig":"MEQCIElUB4kH2V/MDfGtibtkDMFmO3KKTnHf/V+CJg9sSz1wAiA3fptCt3wvlhS35rNSVdpkou42ixnHJ8EgXh9xgFV8Ag==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215652},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9dbef2d00279c136341146005851f27027c74907","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.4_1711254120638_0.5812290166402112","host":"s3://npm-registry-packages"}},"3.8.3-beta.5":{"name":"@crawlee/linkedom","version":"3.8.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7ed513ff78b577a83c5def9360fdd5dc306cebee","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.5.tgz","fileCount":13,"integrity":"sha512-5CPhup1kSXHLzQZCAgi9dIKIulbUDpwF4xezF3yBqDDN988QSZU8UPcd8Uzufc/nHNspRio3RXVTZWG+bN7LFw==","signatures":[{"sig":"MEUCIB/W37RWZKflt3aXiqQynFG7P4ODueNFHkwUmWdzEm8vAiEAhKm7nT8X9Kln0DYrN0k81wnt6c/yFS1ZLKNFfx/nQxs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215840},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d872e295594be3882d51550bfc6070717e5d5699","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.5_1711339296216_0.19400851462922253","host":"s3://npm-registry-packages"}},"3.8.3-beta.6":{"name":"@crawlee/linkedom","version":"3.8.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"af30832996ff1522fc1eb5a6c9ea6453aca1f67a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.6.tgz","fileCount":13,"integrity":"sha512-9oOokIlOv6MFbQP18AbLnUoL6B9OMd+vYQWPfb11RQhRfKv2cNUGHyJ6jcFfE0HB3k2yaJg7IkzSw8yoeZXhCg==","signatures":[{"sig":"MEUCIQC01CNAK3JKPOJzvbENTuFNEkajWqxiLgEcNr02spdFKgIgcAarBdq1xnh1FGzuHOcZjcetlDXh59LNBGlTLEDoqJA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215849},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2fbf1b383ed38288483e3d8ef8c3e86bfd5dcc3d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.6_1711364270642_0.27621574442572183","host":"s3://npm-registry-packages"}},"3.8.3-beta.7":{"name":"@crawlee/linkedom","version":"3.8.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cc1157c72352cda3f0b57bc37e644e4a165199f5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.7.tgz","fileCount":13,"integrity":"sha512-wlqz4ocrwoP83ZCmYfrxEYHiDRg02Rwq5RXq1U5ANKd7JexKzbEKxeFvV525uucYhTx8M10+zRzH+asVcla21A==","signatures":[{"sig":"MEQCIGYVBqYMy283cCy72sa7gBb8eK1h5GReHAHYTaUcD2B5AiBZOE5cFmy62dEyNiFrknklMzz/nNT9aDPX4ZMiv8atIA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215849},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"541f92dfc0f8811c6d3a4ffd9733a46931c09d5a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.7_1711368704870_0.7535142189359352","host":"s3://npm-registry-packages"}},"3.8.3-beta.8":{"name":"@crawlee/linkedom","version":"3.8.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e6b3543c385fc973329199e083829c5d07414dcc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.8.tgz","fileCount":13,"integrity":"sha512-c+gEXJV0o0nv4cCupaLHOGIenpTnMtwfb9i+gxxHhWQ/Ry+CKMJs6iaukegn9Wy14JRuDhJIExUs4JKg968uAw==","signatures":[{"sig":"MEUCIGijNMpox6LS54Cd8b5zFKAWQXGMD2HacVKX4kCUlk4SAiEAnqRCvfwb/+cgBL+6bh0LZn9yAXj7sukkqycIljQQeuw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215849},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9f2a587428a88beaa58dc38523c5582a4dc5dba5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.8_1711427824315_0.006267658351320593","host":"s3://npm-registry-packages"}},"3.8.3-beta.9":{"name":"@crawlee/linkedom","version":"3.8.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"426837b316ccc432f198d8b8d776fa7b4b608612","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.9.tgz","fileCount":13,"integrity":"sha512-SulonmbGjnfrP7QRQFGiBkCjC/pEJi7g+iNCe7fIWOT+hu1CkS1+6QjnDcur2v+icz+xdqvaOXmJa8sCMw2HSg==","signatures":[{"sig":"MEQCIHgU3/J/VcvhvrEC/QHeuaS4YdJAaeFqqsi9TsI+1ukwAiBGv17kK3iMR64p0pPCMndoj2lf+Up1TPJchfMQXyYJOA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215849},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"60d409fa3ccf863be1278e2c524bf424a2389adf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.9_1711516519349_0.3719245048019535","host":"s3://npm-registry-packages"}},"3.8.3-beta.10":{"name":"@crawlee/linkedom","version":"3.8.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b36a9fc001aa47eb8b598132b4b59d5e35dd261","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.10.tgz","fileCount":13,"integrity":"sha512-7j1yD7jgvkUmNuEYOFnaqyC9IeI2+ih1fVhRkglS5cAL9Jr/h4wdVcrkw2FCVLnireWlINTS0vuEYDyC6Y5i0Q==","signatures":[{"sig":"MEQCIA0bU72B4lgkPC9XHFz/oD45tNxCAmBcaYlcNBKSDMqYAiA2zbJCaz46//f43zxLxbZ4CTsRcsuAOSMdmv/QJPkKRQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215852},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"200026a582f65c41b5ece17f24802d53a23f2224","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.10_1711541514005_0.31907851156386124","host":"s3://npm-registry-packages"}},"3.8.3-beta.11":{"name":"@crawlee/linkedom","version":"3.8.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f941194b582b5a997cbe3fb02d576cf2c3a84c4e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.11.tgz","fileCount":13,"integrity":"sha512-TOZTq7zF9V2LlvmZ3r+EirbXBjvivPNgz77I/GcfCwqY+cH3Wqo+4ogWwyDG1hsdkIoiD/WA1bnjgd8pd16Xog==","signatures":[{"sig":"MEUCIFcjJ7vLi4DGZu+zoVhCv3OecHiQcmkqKJMYsYVOf8FsAiEAr0I1CbIQsXn9fEo0Q9VH+WQ7CmCM1jK+ocefFP3kMTg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215852},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"768b7cde91a6c97110c19b908c6c4e58ace0a921","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.11_1711542613646_0.3088474358984168","host":"s3://npm-registry-packages"}},"3.8.3-beta.12":{"name":"@crawlee/linkedom","version":"3.8.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"562b1b0812152cfda1bf62d48b2ad2b49776afeb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.12.tgz","fileCount":13,"integrity":"sha512-UGoscF09+TieU89fySLkjD/4iO+XFZmhHyX6ZbPn/peIagWCaLy1pH+hhqiuzLc7zqHdsP7XAZBFUM9zSFQjuQ==","signatures":[{"sig":"MEYCIQD8FraDzIm8Wk9i2BoJZC0dG8caFGqnphOTIlfYOWz9eQIhANX9dyxjeI9xwgXdFdAprRzHuR+l6Uvc3/H3tByocEP3","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215857},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"44ed06ca0c775a7c4f22356192dd006f299faf03","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.12_1711597894665_0.9539041735161684","host":"s3://npm-registry-packages"}},"3.8.3-beta.13":{"name":"@crawlee/linkedom","version":"3.8.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5195bdeec49fb79c1b9c73c4bb00661d1170084a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.13.tgz","fileCount":13,"integrity":"sha512-7+EiwVce2zqZljd4Ol6z3WFFwTYZWLJJZMRqV1gs/EQ2cqTkELGRyrStWEsuk6ovF5H2Xr0B2S79EsH7JlvjNA==","signatures":[{"sig":"MEUCICyviPo8BqmPAtOlMSqgbCceJIy/BArYVrEZ2p5eJXJ5AiEA2xsP+AntMfVpEX5G/yhJ+RGKRvVOaVycDZ978Q63gZc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215857},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e695e9a89b4055a7efbd16a97e0c7adcd98a7ce3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.13_1711640896201_0.6681359295354166","host":"s3://npm-registry-packages"}},"3.8.3-beta.14":{"name":"@crawlee/linkedom","version":"3.8.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3d802a98e6902dd73b8d0a5daecc972d9a55e4eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.14.tgz","fileCount":13,"integrity":"sha512-HD5TNtiwAAyehy5CDcJSk2rx1bxZDHnMQhG6FRzCELOoBiJsJ6X0lRbmyEDTKl6PXEQyATW/btsHfklAlK2/Lg==","signatures":[{"sig":"MEUCIDie9XfgSHjQE8LeU74rR2VE2AXekfo/63uyv7gP/R08AiEAlS2r8K9NDk+XRxfXTrRKBGHm/JuOUE4JTEfVXLlpD6k=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"18cfa9cd1d9b5e883fb6ed3e06d089460fbb0300","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.14_1711682667052_0.06299983340154292","host":"s3://npm-registry-packages"}},"3.8.3-beta.15":{"name":"@crawlee/linkedom","version":"3.8.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b747f210cfac33082435789fc94f53cbf1bb6551","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.15.tgz","fileCount":13,"integrity":"sha512-HLnlogUI8h8u6U72G0t+x8SfEVX8dBMRXtlz90xDFH/B90Zv2TXGChyH/O/hjTDhjZXP4n90oEqysWp+mYWpHw==","signatures":[{"sig":"MEUCID51DX/0A2NgPFj41NTtcEULt6RsAnJ7+Z2afvgTqpcXAiEAvsWqO/SQnYWCKm39Lcw9ifnFmXwokRQSLz25Q0c5CfY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"16bc459721497aff6ed7be8eaba05602a135d3bc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.15_1711749465691_0.4189978092743407","host":"s3://npm-registry-packages"}},"3.8.3-beta.16":{"name":"@crawlee/linkedom","version":"3.8.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"74b26aa5785789fc85a635bb77814ec26d7d74ed","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.16.tgz","fileCount":13,"integrity":"sha512-tnP4q+4Gu6iclXNeiYGlRS7ue6BjCPMgkR6CDlHoBozDfbANsHmn3JWMTncdTPYdf50B2uQ4HJh4FHrtHYqVkg==","signatures":[{"sig":"MEUCIQCTQBlt80lYEmkM2cz/j20KN8WFmw7TL3OO/arkTJ9IOwIgLTv4eTX629IgsTH9bR111yI2dLigVQdxlJCs29Wj68M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3fda82c7229d2deec9dfcb21f1280479e833e49d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.16_1711862036209_0.6510475931172217","host":"s3://npm-registry-packages"}},"3.8.3-beta.17":{"name":"@crawlee/linkedom","version":"3.8.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"027dfa5280fcd36c9c386f76fcb5268e4bea09db","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.17.tgz","fileCount":13,"integrity":"sha512-0Pe1pdm3IqX7/OW58WJYfGqnRkpWW6VlUtFPo5j4iVbSPtkIi5jxMK/E+qW1yGK8/8vJ+jmM9impGKf4Tsh9Iw==","signatures":[{"sig":"MEQCIE2SrbE7W/kS0XcW6YjQkyny2csjaca4+bKIpusRaNcfAiAjd16pWvS8cLf+DpwSndqLC/auKbhDxxOreh7rb5rUdA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c66d0a5bc706442dc29fc5b6e237c50a79a66daa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.17_1711943813854_0.4566165446183088","host":"s3://npm-registry-packages"}},"3.8.3-beta.18":{"name":"@crawlee/linkedom","version":"3.8.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bb0885e974475a594b78d226b7fd7208a8e02420","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.18.tgz","fileCount":13,"integrity":"sha512-ZqPPyJ8042C9AUxh9zbG8bzZhYbaTbHlZdzEFNC+UvsmDDQqCcaPIo4ZTiaq590jj39KdFX5oxqh9jfGwLX42g==","signatures":[{"sig":"MEUCIQCp1sQ9lCojUuz7UeNj1o/7CKbhBcEjf2HHEM/Ato90+wIgD2tA3sTSC7QDjTsUdX8baXgV8KH2heklEItlfhtRz9Q=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2227a2ca89a655c74a7e82af970cf8efdf18aeb0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.18_1712020679235_0.04502952409294725","host":"s3://npm-registry-packages"}},"3.8.3-beta.19":{"name":"@crawlee/linkedom","version":"3.8.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1eb582c01f649e6c1aea32ed2d7202b458c620e4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.19.tgz","fileCount":13,"integrity":"sha512-T5n4RdkbIBdK3dVAjqn4OW6wiGuSjRS/nnkBBQgIy6q91wTfYxk4dMiFg4Ihfzk59wtknvKNu1QNl8W1BLKvrw==","signatures":[{"sig":"MEUCIQDxig8CVy7H+Hcn4qtQ8bZEaARd/ildaQbE0Oon/3VSDAIgNP7TdMtFczWr0/4pJDIiBV9Y33GgOKCGM5hkx8G7Sc0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"937b4d64b4f62c20b9aff1f18b5f5eb4433609b0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.19_1712032329537_0.052212865450245394","host":"s3://npm-registry-packages"}},"3.8.3-beta.20":{"name":"@crawlee/linkedom","version":"3.8.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f356d51f998a87a6c43c0959ff7a657db77e77ba","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.20.tgz","fileCount":13,"integrity":"sha512-IiSN8h8dbszbRZOFgHh0acvhMspXbP0I3+unuwxdTeBAEzmUKlbhaeRuStUBTbOvnhoR19faxo5eyhGo89nMHQ==","signatures":[{"sig":"MEUCIFRUmf5iRdOT7y2V1vHfz4r+skuCzJFHFGJqaceYPb7oAiEA7AtPaiMLwbhX/oECkrXPzPyuJOeI8PxEAkGI+NO0nAQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1f04a2e85128a11f0161e44ad4f785f437b59f16","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.20_1712055368502_0.35397676050353577","host":"s3://npm-registry-packages"}},"3.8.3-beta.21":{"name":"@crawlee/linkedom","version":"3.8.3-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"efe2289c4fd8fd6ccafabb2585cdf66215f39f1c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.21.tgz","fileCount":13,"integrity":"sha512-Nez/4h1zZeffRWAalv0LlR4c8quqwJUHjNLrvjVeYCKzF3ZTpcBUPmcLn+6VQ+cvDhdVodSx1TBdALOPTVEtuA==","signatures":[{"sig":"MEYCIQDJ1GCMwA6N6XSXEw6OI+SUCDfWRpNfMnhIWOjmSn6UYQIhALpGixSK6g/wZIywT1zdLNlOa8k4IUBNA6l93g+pXAMF","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"70d50b5543e6ca3f02461a0a1e808205a2f81731","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.21_1712061229913_0.9571355677929108","host":"s3://npm-registry-packages"}},"3.8.3-beta.22":{"name":"@crawlee/linkedom","version":"3.8.3-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f8334ce5ff2bd8cc1452901dd33046fc999cfa19","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.22.tgz","fileCount":13,"integrity":"sha512-7VfbjbKgf/dlstkaD1hpcnGdrrmPmMKGAIhuT9Rj4Ou+JQpG7buhX8q0L9YLyaQPnriHgEdehPVd1O5t9I1F7g==","signatures":[{"sig":"MEQCIF7um0lGl2N2+JGShvzlnyOndGZuFkUTSab6OfDEotC1AiAul6+SJ1lOuyGlLhkvHqv0HkmWB9Yo7d6I327Wtu9GTQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215877},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"15fa87b4a96a835c4116418611b412698811a09f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.22_1712083841591_0.19370047564114046","host":"s3://npm-registry-packages"}},"3.8.3-beta.23":{"name":"@crawlee/linkedom","version":"3.8.3-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a174b80c446d8734bcf1cb83f9624f5b50ca4e1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.23.tgz","fileCount":13,"integrity":"sha512-tueTANIKK92uC9edq46Qj5SkqnUJ1UagMHzrNUYUYdnB+Em4jrTJLgBU6rg2yTMAivjGGFsYtlNhmBTdCaDgxA==","signatures":[{"sig":"MEQCIEYTJU1lCuckEWXWUHqplovzoGySE+CPbjD8ajvi6Z4pAiA/bjmItfDxK1bLgTUHybYf+TOj1HSHHuxEmuCzJvV9Jg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215460},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"63da235e5445b34b217bc4172535639b5b845c99","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.23_1712119150413_0.11880450569799805","host":"s3://npm-registry-packages"}},"3.8.3-beta.24":{"name":"@crawlee/linkedom","version":"3.8.3-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7f8004d28e55fd1727b8bf7fc781045237774643","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.24.tgz","fileCount":13,"integrity":"sha512-pkeKMrGLD+vGEPO780rX4jDPanHs4X0poiXjTzX+80ARkpJAaccAtOXCfh0BqxayHuW1RIFEzmoN1/brrm6CYg==","signatures":[{"sig":"MEQCIH04t7CzKjQvLj9/gD6RYdN+0/NCCBY/7NIOyqOggXLTAiAefrn1aihpjrniGF0wsXpYMq+LBT8ApdwweQC2GYgevQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215460},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f62211911fb81a3de84f41ed0c0c6234f3bd0fa9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.24_1712157046643_0.5767222914182701","host":"s3://npm-registry-packages"}},"3.8.3-beta.25":{"name":"@crawlee/linkedom","version":"3.8.3-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a9eb632b8c1952c4152a4067d586cebd2522f81f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.25.tgz","fileCount":13,"integrity":"sha512-zPrqMxilvgyv6jxTZxQOxIjirf9uZ+boGP6LktyHfp3XUKW/b4h6HcOm3hOm4XAUt1KTzU2TUfV8xQtdPDGwPA==","signatures":[{"sig":"MEYCIQCIYtMrqKrsJLBZZTpfjMxaEnjwnB+KUe7N7yYiQXh43QIhAMAGHnFLtqpYVdymxsis2ENhnOuekCj9vmE2S4gJMETd","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215460},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b580a7f9cb3470a0e5d865bc986cd2c0ae49365c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.25_1712174307736_0.07405614803741889","host":"s3://npm-registry-packages"}},"3.8.3-beta.26":{"name":"@crawlee/linkedom","version":"3.8.3-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e6a7571c2c600709156848d5af452603f19abb89","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.26.tgz","fileCount":13,"integrity":"sha512-m4ztGGKqk0fd4dmdKfAeY40OOYUubUbNVaca6V4pgIvHGAz+aCXS+ysyeJkhLh4OiB1SXaYhjGBU/NopS0jJEg==","signatures":[{"sig":"MEUCIQCn/OGxAKEXF7fwiZ1ownht1w+I5WWxbTGbnQZBAd/3igIgHCfkwt5W6y0clh6epgfySR+53VzR72gKe4bNnQUnKCY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4a78a2d7e8a8a6e17758945454e4c86b5f191932","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.26_1712204197099_0.3058599412996301","host":"s3://npm-registry-packages"}},"3.8.3-beta.27":{"name":"@crawlee/linkedom","version":"3.8.3-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5786ea97cffeca8245a80745abd5e867ede70802","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.27.tgz","fileCount":13,"integrity":"sha512-0jyAhUgGYXpCxeEbzZ1AE1aKqPBZbrO+VHJXy98YB7QO+pV7muh7FAoDH9VnM02nVTn1w+zcP1i8TqLwgq0w6A==","signatures":[{"sig":"MEUCIQCKOupP6E29EKUeomS1XuInxxnTZyr/3t9bLkgO9cuTqgIgOczk5U4GDnp4IZxg5enOnTc7YEBAV8n7Z21ngdRY7Ek=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7f747b8f673470b29a55abd45b2dd6611804e852","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.27_1712223556422_0.6660704842133582","host":"s3://npm-registry-packages"}},"3.8.3-beta.28":{"name":"@crawlee/linkedom","version":"3.8.3-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dcf54fdb2e1ab371fe29ea2139ffa46d3bfc91ff","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.28.tgz","fileCount":13,"integrity":"sha512-3LGbHEzOv+PzhFfto+2K9vqrqhwf4dh71EayE15/5s6Rq6fwG+dxvoqfiK7VOgXgg3SsaMZsCWN9QTtU9a/Sfw==","signatures":[{"sig":"MEUCIQCDpkdtjBgvBHgJGVo8ZXa9+iQwqXtl2iQJ4e0CmHXTuQIgMfHpUrhXl11zXTxPje+B24s9aNbwhGH8fOgWgZOy7ZY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f542e71c914b716927987208922523647bd2c378","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.28_1712225227877_0.4064583242573703","host":"s3://npm-registry-packages"}},"3.8.3-beta.29":{"name":"@crawlee/linkedom","version":"3.8.3-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3b777d39c175a9a23f42d357ac3f5cd563352ca9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.29.tgz","fileCount":13,"integrity":"sha512-zdIyS5s2XeV9iNj5pasEcLi4Su44Hvl+gaPMMxjJFtI0+MG75dv4Bqrzoj9wzLeMaOU5VXd+pYgPcs9+XTYbyg==","signatures":[{"sig":"MEUCIDnxq1OHQpH7jc719FWN1fsL1IL5J1E7Vj6fA3oSR8Q1AiEAz6TiUqunPjf1xdLNGaaacu0lS5Gp5Auq4IXN+Y1sPmU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8960f5cec2e0f94a2b3a8fdd0cd8005bcade9965","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.29_1712278776682_0.8269060485171427","host":"s3://npm-registry-packages"}},"3.8.3-beta.30":{"name":"@crawlee/linkedom","version":"3.8.3-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f747732c94fa891fc15252b51b0d32e15029173c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.30.tgz","fileCount":13,"integrity":"sha512-687U0aorFB3MsgNWvtrCEt/cfyctYU8xAc4x4MizxSvzeBMRi1ms1E+cPcLIkGiNnoMLnM0ZQ9fJCYDoQ4EFMQ==","signatures":[{"sig":"MEUCIQCawAKesoB9k1HHgeEbqCC391f1VxSHCK+Kt9TCwvrjvwIgC9Zvx4mgQZV0HefcTGJWfTNw/dzx8/NWttLElCXSIS8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4801d804dac5c96a6b506c4533cce9fb3c3807db","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.30_1712286919074_0.059202253131605875","host":"s3://npm-registry-packages"}},"3.8.3-beta.31":{"name":"@crawlee/linkedom","version":"3.8.3-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2baf0e408ba32f592e4e918e4a772dadd78f9af1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.31.tgz","fileCount":13,"integrity":"sha512-KezUkqBLC88zAgLsWhu+tgiD1wNblm1IxKJGZL6iXun8LHDBOq2DNcWU9SS8uhY6l+c5xuKKUpoTsk3p5UBR4A==","signatures":[{"sig":"MEYCIQDKyp1xGuDgDRsOjq/6dCTIcJLNvUNyWzeexnbhDMHyaQIhAPtl0GwVFRbqRU8iWEGUjjhYyfz3Mcbs28v3lqMlk0Dc","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6551aac0efce1d76e80d9ebd2adfd102d9b2b788","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.31_1712318679583_0.40334246871423596","host":"s3://npm-registry-packages"}},"3.8.3-beta.32":{"name":"@crawlee/linkedom","version":"3.8.3-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"14b03ae2d53dc2c81ea7c21d0d9bbdc14c65a943","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.32.tgz","fileCount":13,"integrity":"sha512-YMivXCNDZgXzjSZVkKmSSRj7Sqf9LmIyd0wT0p526pLehtP32NKFY8xTn1zOxFJ9K1PduA9McJKxQeDcON4XPg==","signatures":[{"sig":"MEQCIQDN7qPzS3n49SQgjr2P9TCKCpY/oejztnMxJS5XfGA5IAIfKbGhx79Hn7Ilnpq+pVDbl8gk7Iy/pG2Ecyg7PTUUig==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2735687b557b360d1cd03ae961c411b645efbff4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.32_1712337218614_0.7189491170437143","host":"s3://npm-registry-packages"}},"3.8.3-beta.33":{"name":"@crawlee/linkedom","version":"3.8.3-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"69be4c7a597014c3091c6e9ee8371a66b36abe8f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.33.tgz","fileCount":13,"integrity":"sha512-m+REmF/gDfMSHf/gfdo5P8IShi7iYXaya4omlzNS3QRxXxLaIQG2J3ne/gsXgU8ZA4nmiHDCu90yyLHp7f8KCQ==","signatures":[{"sig":"MEUCICxJm/xzWqItUaDhC3UxKSRyWU3iGdMHLvLQdIY3wcYzAiEAgVMo5avo78/uxUvNdpdA6mxo7wcEUG/dludRzPNCjak=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1faf5dc8f110ac42704fcb513eb721021beb3af5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.33_1712374017099_0.8064115099084301","host":"s3://npm-registry-packages"}},"3.8.3-beta.34":{"name":"@crawlee/linkedom","version":"3.8.3-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d92bb972e9a7a99583f9b8218b5dd23944932cc8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.34.tgz","fileCount":13,"integrity":"sha512-qEClskvyzJuvaY9l8q91Yhypganj3h2Qs0Az50xve85vG7QnjJj5smt1INV6xZbxkvqJaMrMMCupNglJxgoAag==","signatures":[{"sig":"MEYCIQCPmjLXVd9YniOpZZHn0HaFxRICQRuz4XwfkUxfsaZvJQIhAOZ3g8wbE8+tZtwRe53ymKtLt0ZHy9Pbn56CCJI6Jo7p","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"89155786fb8bcc5682ca4ec56d8ffb4f144a9eb1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.34_1712579049019_0.9487698638786906","host":"s3://npm-registry-packages"}},"3.8.3-beta.35":{"name":"@crawlee/linkedom","version":"3.8.3-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5cc0df1066777907c4845c340391057923c13a20","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.35.tgz","fileCount":13,"integrity":"sha512-GpygWDyRKWyCkdkKu6fqwofL8Ioz3mqbfQRltaBG9uxyCx8w/Auhy8xOdh9lm3WyaVUOSdBvyAdPDqz2eAAQ4g==","signatures":[{"sig":"MEYCIQDszsdYWYDa5dKjBmBkuAw3r2MrmttpT6J9lmNpMTEQ4wIhAPb0hGSMzWSSek2I/egD/K6MD51/TzGnd5SiV/3pH1DL","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c3be8b4740f01d0d08979105241ee32e78cba04a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.35_1712640822395_0.5172749348274364","host":"s3://npm-registry-packages"}},"3.8.3-beta.36":{"name":"@crawlee/linkedom","version":"3.8.3-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"68eabe14de596e61b2a7d42467b0397a6019d890","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.36.tgz","fileCount":13,"integrity":"sha512-K/TO0qpj6cDEudLrutM894M8dqqEl3YbxrOqtVcbTM7W5LXSQI6+WBsT1ntvJdJZ769lyyxb8a5WNDeQEVY7oA==","signatures":[{"sig":"MEQCIFa37v+BvBTgRTscis9Gwdc7Id+H37uIVEHZilUXxam9AiBW3pdKjg1s99xpP9ormi52ACekVSgTXDEHAooGSsFWEQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ab8b470c3c6d6bc04e7d27829544ae45ece74a21","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.36_1712672417273_0.7089270681593893","host":"s3://npm-registry-packages"}},"3.8.3-beta.37":{"name":"@crawlee/linkedom","version":"3.8.3-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.8.3-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a9d3651f88b31e794639d833b3c936a20dce961a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.8.3-beta.37.tgz","fileCount":13,"integrity":"sha512-bmKFvTZJy7nVGin330yTqRRUfR9KCouOUHoPQ3q4SffpP8kI8zJDPah1hmHOI+GRAUlfJUINlC0mYFSdrn1XAg==","signatures":[{"sig":"MEUCIQDptb621fFyIXMrDxg+PJ3BcoIAG92GkVGg1NNPlAqizQIgRuDwgFVP+nD9aI9wz+GeYWUnoCbA1k/5p4CFw9wakj8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216006},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2981ec116b2e7cdfe7c29bafb0cc5c54fa2b931c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.8.3-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.8.3-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.8.3-beta.37_1712745340096_0.06458890397085293","host":"s3://npm-registry-packages"}},"3.9.0":{"name":"@crawlee/linkedom","version":"3.9.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ab3d63b64840e4d5926abc973c7c23a5ba7cd37c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.0.tgz","fileCount":13,"integrity":"sha512-tfERHoCdP3mjEqN2p946jqiXe8Rk9feIlXujN7EsUVl16SPjAEN2FDMndnE8XT54VuEIeN+c9finSqTctKC6Nw==","signatures":[{"sig":"MEYCIQDTRKHHpNZLtipld5CBwUWjLxfx1+yxVI4P/0HXYicIkwIhAMKKKQp7InfPLtQTgS1aCaM9JHarCviHMxY1PqmUFzK+","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a1bfb6e56c0cfded06aaa939c1da5d1688886ac9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.0_1712750150963_0.4106930847289749","host":"s3://npm-registry-packages"}},"3.9.1-beta.0":{"name":"@crawlee/linkedom","version":"3.9.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fa42fa8486af84d963103501e3412ed3737be29b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1-beta.0.tgz","fileCount":13,"integrity":"sha512-EAx9s7NIr+NqCDfBkAxdXqj6uXCC/idXux1NcwsL4sCIOb3QmOFUayOqVfRUge1Zkj7BBTDHQw3z22HfreoCmw==","signatures":[{"sig":"MEQCIGfaIWXTRJrOotI9TdlCUmghN3N1q2RVM/AT+exT+pk0AiAtXvEpRsubjhHCw1f4+qWfaAMy/jftJizo21Ut5ih/iw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216005},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"abb417450600911cb4485a079c2cc2daa54256b3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.9.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.9.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1-beta.0_1712750611822_0.21564697369306773","host":"s3://npm-registry-packages"}},"3.9.1-beta.1":{"name":"@crawlee/linkedom","version":"3.9.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3ffc73de06f7aeac9acc4c3f20cd1007f77178de","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1-beta.1.tgz","fileCount":13,"integrity":"sha512-D6PIQ2WpgRJhnTXIgUkePD10X1XbTCWAhg09gBsdCev+QiQ+ypMc/E5/PssOpNPyfIZQGr0vxBycyWeh6TfGdg==","signatures":[{"sig":"MEUCIEy2IlL2d0z9WquQUwcJkHwr+yc0wBJ35rw2f1L2681fAiEAvcARHQurdN7GuuZ9bIyO7jXIvJNE3QLhF8KhBRhxz0M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"61523f73866ba1d9d0a3232b4701059ef6e7fe02","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1-beta.1_1712773797191_0.5686498170042404","host":"s3://npm-registry-packages"}},"3.9.1-beta.2":{"name":"@crawlee/linkedom","version":"3.9.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"018d8b1b31d381e56970ee0cf2ac5bc154cf894d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1-beta.2.tgz","fileCount":13,"integrity":"sha512-a8bJXr9878zo9VO/rHYomnfNhinq1pSmdSS8EThVzZzcJpNEV+D4NtdOU2rMLPToFODyaf0eCXhYu+3F0H2iww==","signatures":[{"sig":"MEUCIQDBQ2Ppz1WSRiPkURRPY5NgZxuug/9z9LFFvsUARR9XNQIgI8vxQTYVITbB1MNJIsnrcV9pS+aYjxD7ROeq5Rc2ulE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e231a2e7cb41455ceb6e100382c7fb8f87a218c8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1-beta.2_1712786998646_0.5732655691783526","host":"s3://npm-registry-packages"}},"3.9.1-beta.3":{"name":"@crawlee/linkedom","version":"3.9.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6f671a7bff1dc0d3175d6a477dde7ff61633b2f9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1-beta.3.tgz","fileCount":13,"integrity":"sha512-T/02dvUobpYatTNFVdUS7rZhc+nBRmknCol9qXiOvLSg/RAPVf2BUOxSUUgHSwgDNMh6WxWCvCMB52EmrLEvtQ==","signatures":[{"sig":"MEQCIBd7z/43zQ4/Q4NHr0rnivq5x40TC2uASrgodYY2xLzhAiBFPnWFB9Wv0x2vD8dOFMMhWUmQ/fZJGCYUpesDaMKJQA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9753eacd73de6264b5f4e4e0f466cb8bc54ac47d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1-beta.3_1712810330514_0.5832835169807287","host":"s3://npm-registry-packages"}},"3.9.1-beta.4":{"name":"@crawlee/linkedom","version":"3.9.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ffcb1f6f6b89f3d22b1b53a0f1d2a8b83a0cda83","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1-beta.4.tgz","fileCount":13,"integrity":"sha512-kz4kOYb5egtKFnezFoYsztn1tovT0prJxGSt3ULgAq+1arc+BMe0LNHsgyhc3IPktF8ocQmmI7rNtuYHkBVKbA==","signatures":[{"sig":"MEUCIGz6RnRRPlpfTC7CIm5cSMkarpBCNJY1yhyUrH5GI0niAiEA0E6LWf/T4tidDVBiczkwOzNhjoaNOM1eRxyxOZ+5sbo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a54fd455d15bf7f126cfd987f0c8fbf6023460d6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1-beta.4_1712818794200_0.09823162195459467","host":"s3://npm-registry-packages"}},"3.9.1":{"name":"@crawlee/linkedom","version":"3.9.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"422cbbb7cee53807a4325b94d609bf037a0e3bfc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.1.tgz","fileCount":13,"integrity":"sha512-LDNTJIoL51LrXFXdbfX18LnJ5ZwJmv7P0adi4b3by6bCAeTFx9uR5hkt5/XHQLcOG07W1D5mnbBl16jEv1MhBw==","signatures":[{"sig":"MEYCIQDN4+HASILQZC3Ec5TGZVGsF1vp3cGsSRL9eZpy34ZVrAIhAIp9lkE3X2YvEakupbDzG3TkW3CNNQfEsUzNaZLc729l","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c9bd1d9ab123c851ee8a0b621cb4ab5e0a9f1c7e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.1_1712826230870_0.3946677170033037","host":"s3://npm-registry-packages"}},"3.9.2-beta.0":{"name":"@crawlee/linkedom","version":"3.9.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"38615a35856992d2ff8d90100da94f72072fabca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.0.tgz","fileCount":13,"integrity":"sha512-HZ/LkLjoD7ASRS+Lm+/x9Vn23qmagvBEGsythYcnetSxBnNr5yoPLBx3z+mycZ0eL/iCIMfkysfzy0jGwVfW0w==","signatures":[{"sig":"MEYCIQDFXQnWG03qodHX1/3GUUqHHuRmJKlpovwrMLeAY4mi/gIhAI4iEsQ5DelgqH5lkt/oukuX1mr6Xm8TrkYId38gGiUj","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216005},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d12a352a7c180ac5b5e1ca6934e277112bc5e99c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.9.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.9.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.0_1712826678162_0.2951805406409267","host":"s3://npm-registry-packages"}},"3.9.2-beta.1":{"name":"@crawlee/linkedom","version":"3.9.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ecb6eb9375327b538ce6fef3af9ae8ac7699e460","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.1.tgz","fileCount":13,"integrity":"sha512-hE2d931VSHzMmhaLrzo//cN06A+wPJzK/z4rXbHNrQgpOUoNzjOKWUekNIVDOhN0WLQK0gzjZ3WODYeLuWzNbA==","signatures":[{"sig":"MEQCIGXlawTV4clWJWCniugIuvRpGeYlHnE3idXQdBrlmHpqAiAzfXoPfgqgf674qoezb42wKxKTtkCAOOUM3ZA66JNVjw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216003},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b5c07be2e868417a50976f9b539e0cc4de01f412","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.1_1712859953047_0.26346702761563234","host":"s3://npm-registry-packages"}},"3.9.2-beta.2":{"name":"@crawlee/linkedom","version":"3.9.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4ae733028dec74ab3e23d52b467acdef6a060b3d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.2.tgz","fileCount":13,"integrity":"sha512-sNnQwg3JXV1/dgf3F66biKu6XOKOOjtQVNii4QCgbp6/zQEBXmqcgnneP/8LUDszMYYAf0KXrAccULpsAzextg==","signatures":[{"sig":"MEYCIQCZmOiUklc8e4tpymeTBzXBZyU0J8k5PLzVKvqmZ7/ZEgIhAMS6YWbupvlXpiDgkunrhDtPW5BUdcOpxoXAHh5bxNTt","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e299c5bed3c2efbee860116ceba19fc07e4bbe2a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.2_1712895876717_0.3357046557790906","host":"s3://npm-registry-packages"}},"3.9.2-beta.3":{"name":"@crawlee/linkedom","version":"3.9.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a42174c3e769c5eac5ead5ea403b677b8b1d963d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.3.tgz","fileCount":13,"integrity":"sha512-c4ig3RE57nPbCcTWm1P3/wP9LrQBE9516427HNLRQ0qwTRuH8O7XHSxM3eb3HtbmEJKyEfUgc5biZxLWzzRJrw==","signatures":[{"sig":"MEUCICH9pS/UMi7pCeXtNgXLQZKx1QeyEtM//jIVW6kZS62yAiEA+SdwLBssPZTeF1bR+jKNF+HywWeXP1nXeECOeJf7vEw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7368ff191025be069226644a899bc715f77bb237","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.3_1712957594142_0.5532587949440517","host":"s3://npm-registry-packages"}},"3.9.2-beta.4":{"name":"@crawlee/linkedom","version":"3.9.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ed8e92a7f7726c0db60ea73a1cedb2d089c3d93e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.4.tgz","fileCount":13,"integrity":"sha512-KY45TZDEKeMzssh9r2fU/4nVB2s1P9Ka0erhjFHYiEZ1Gz3vuFncbAYldDKt3BYWNJR/EHJ1jyBFThNUXx6vnQ==","signatures":[{"sig":"MEYCIQCKpvQwiE/tb/ox+iYRZcIY0H8fAjzhybTmDW02JcTfjwIhAPxovqbrQ1E5hhqa4f//HiIVlkQRiL+CuRSyLHrUCAAi","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c42a94fc900530fbcd6c7aeecaf3d9a8c078920b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.4_1712985294332_0.9000364623110841","host":"s3://npm-registry-packages"}},"3.9.2-beta.5":{"name":"@crawlee/linkedom","version":"3.9.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eb0aa803b17153303a028176f085db112f2fd11d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.5.tgz","fileCount":13,"integrity":"sha512-2esBJu81LkDJ3Y2kj7yAjH4q8Sh/F+VX2ERCB6RmVc4EHNPXd9EWlA3+O/15T7ZbBT4yyj9DfWRBHWsZwMv7Kw==","signatures":[{"sig":"MEUCIHgHIn739GrFYGlXaVMeDXhvXSG7yji6eecqocWzDoN9AiEApEzwdWZRzOYyLfYF0OBd6Tue5uxmB6iAf8j3sG80kY4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e3f0ec27f0d5a966b1957488438545bbcef7d2c6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.5_1713194758464_0.7992853199835492","host":"s3://npm-registry-packages"}},"3.9.2-beta.6":{"name":"@crawlee/linkedom","version":"3.9.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27613309f42e942d098aaa627f8f570fdbefbb5d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.6.tgz","fileCount":13,"integrity":"sha512-i7RuZYvsaU6H46J7Fe1NoEpSLm/Q5WUzyLBAsd5XKq/IagBx+LQ2DKBabLywvlzF8V4U5z7wyxzlMbEwzWdFog==","signatures":[{"sig":"MEUCIQD8au0ABuiSi44Xqk+Po8v3KZshd0Q3Wehyz2cSbV/MwQIgfIVdkQM9Stne4rhKR6OELBdSjRiHrMEVz5hY8eRdQwQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ebca33c13859776ff81e955c0ad0bec40655968b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.6_1713245900369_0.5800766540137305","host":"s3://npm-registry-packages"}},"3.9.2-beta.7":{"name":"@crawlee/linkedom","version":"3.9.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"87974323134c85197b9aa49bef404a3541e30813","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.7.tgz","fileCount":13,"integrity":"sha512-ZQi5e1zZC4jODtp2a5iH5L3pT0hld6Ni7RTpywExPeGepCNfIBXXBBFa+qBZgG9tcvg47lfOgs62MXYMi9av2g==","signatures":[{"sig":"MEUCIQCHp5EnGhE5Sq2d5MFLYPQ6oe4zkMtpEHKF0Ffjb3FIqwIgKfi++nWegtPClJNhtibckhK8T5FooTuCjgQNRX17tBw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8bef660a3f81d6fe9550cd1b66489b4872fc03b8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.7_1713265785328_0.8197259425880208","host":"s3://npm-registry-packages"}},"3.9.2-beta.8":{"name":"@crawlee/linkedom","version":"3.9.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad02372a0cf9eaf0675b079faa0dc6f6dee059e0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.8.tgz","fileCount":13,"integrity":"sha512-xAV32ArHHf7nJoiWcQuATJrIRLU7HD2dSJdhQdJoXKdGiQ4IlZOFWPWVIubUyQbC8jWlkvK7ilhsOinqtWv8CQ==","signatures":[{"sig":"MEQCIA9tfS3MfsOQtZwe5HF3tlQeQ1JWN1NrY6re4Y0Vq/0BAiBgTDcDma9VXEw9z36O6SymyVovA0uCTqHEE24R2OqV8w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c1b7aa513a0eeb4fe9046f57b565bc544c8ac9d4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.8_1713328899423_0.7404646809425122","host":"s3://npm-registry-packages"}},"3.9.2-beta.9":{"name":"@crawlee/linkedom","version":"3.9.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fefeb7a78362d529f521c526dc5149099877ff8d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2-beta.9.tgz","fileCount":13,"integrity":"sha512-07eKinsi8wOW0zgWp1qgQGJ1usqNM0BYnN1v21xbpLoZu12eR9YHyJh+/5wBWzCkj4OJGsve1ccrIY0mWnqVYQ==","signatures":[{"sig":"MEUCICzlNzjB577ttyn/tZ3OKJV+cCkOcYgugCJoqNMQnOpJAiEAm8QLdJaFmfEj23aAiTlLT07BK27i2PCc3GvinMXVSr0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1ac5b4a8332d691bcb0603d55d8d67353f5fd549","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2-beta.9_1713342377972_0.11906850216244225","host":"s3://npm-registry-packages"}},"3.9.2":{"name":"@crawlee/linkedom","version":"3.9.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"061adaf420a4de45f7ca3ed444c3430717238edd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.2.tgz","fileCount":13,"integrity":"sha512-5pPNIZ4Kk/kwSUKYrhhlTzkAKJZu8ttBSFgai3mkzNWMvWeU4hjw6IPNNHR+H31ICOGaUiaikozRebH/IJsT0w==","signatures":[{"sig":"MEQCIAgpzkP63iK7s3oSw+DYzfJjN41vZUAke3Tlkm8i/tkxAiBvKgx8cy0my/Y13HXylgjURE3WUILSJCWT/VNAFohKUg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215817},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1bb9570f9c0bc0173ba4fc266e7f4dfaa0ec1fb4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.2_1713359725156_0.8330509917473254","host":"s3://npm-registry-packages"}},"3.9.3-beta.0":{"name":"@crawlee/linkedom","version":"3.9.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cef70dbacf5310bd55350aa3d22406e639ebfb15","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.0.tgz","fileCount":13,"integrity":"sha512-y07ahHFfrUdveAWbiC+hcBXFQmBOzymfaLHubVz/meQFwTAuxA2ifAC5eJhx7i0MeIYGVOsf5B80D4coR576kg==","signatures":[{"sig":"MEUCIQCcfw4WeN5kuIFRV0qi+4E9In8SUueBrlN4Rx6dYPDK5QIgObmOHFmqU64khardXVjf7H8Vh6Ze+Q5U5aqj3Qm2Ry4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215840},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d1c79ed22d7d7feb6aa76466e0cec9e746f1dffc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"^3.9.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.9.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.0_1713360189077_0.5737784830119927","host":"s3://npm-registry-packages"}},"3.9.3-beta.1":{"name":"@crawlee/linkedom","version":"3.9.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e86acfc1d5be3b1afb92760c15315ad9b9bb9fa1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.1.tgz","fileCount":13,"integrity":"sha512-jjix/2YjHpNi9TqcG1BnQggZk7f98qysChdiKQtOziGNlm6lUTporqRoTaPmDt+KUL51em90As+h2J3GSYpG3Q==","signatures":[{"sig":"MEYCIQC8UgV4dNwkYErqajw5pL/kBPIMW4rIpWoc3wG88q6xNgIhAOs5PC6MyOHrwsQrNTpnqoXwmwHZKJv6c8cKUrk/9LLi","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ce472ef2311db70aa8f49263e56df8433d2b761a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.1_1713417635531_0.2917915594071576","host":"s3://npm-registry-packages"}},"3.9.3-beta.2":{"name":"@crawlee/linkedom","version":"3.9.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9811c9b19caa23bf5a5389c6c9eecefce8e45b8d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.2.tgz","fileCount":13,"integrity":"sha512-8i2osMyoy0JsC3eSsIrat6BptqYW+hivLYhitw+jqIEO10wE9GpuvOXHoyHjIOau+rXwcl8OrivhwgepJmO2lg==","signatures":[{"sig":"MEUCIQDy8J7g0uMCfpLEH838Ay/H9ZkI6VRsru/h4qB0buZVSgIgWWLLEvc/EzCUhYorAsvXjMhWLKdaMbh+a/R/dppgmcQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57fbce9dd8b478e7cd4b05b52928c873c3f7088e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.2_1713520409382_0.6783645305912065","host":"s3://npm-registry-packages"}},"3.9.3-beta.3":{"name":"@crawlee/linkedom","version":"3.9.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72d5581cffc0e67aba2c3a5eaaa6e3c45832b042","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.3.tgz","fileCount":13,"integrity":"sha512-PTlyuNGF4y5YkMWk21J1Z9iYI8gliCvvyNxhS+SZPt1waeNyUzRygTWjAaMsaG/kHiAjXqegljuasE+cBwDeWA==","signatures":[{"sig":"MEQCIDNd/dEyp/whWR0xLpPE6UI+8uGjTdTYAt9JPqBAdvLSAiBK1QUMz9Uvs3E6ptjuW+UY3prLAlIYboEWT3aW3b6dBg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"416a33e3b75a50b0f59fd4d7104b5c8bbf5a6397","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.3_1713590165909_0.7676223261819659","host":"s3://npm-registry-packages"}},"3.9.3-beta.4":{"name":"@crawlee/linkedom","version":"3.9.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ea1434fd4c62cd9f50e26d2b0c96d3df0471d9a4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.4.tgz","fileCount":13,"integrity":"sha512-gmJn1su9IlWVwpWow1MxrOkli6p82AUjmXkU9Xiw873iMn8GFctMxUympKXkOMhGJ7balevR873ovKyzo51ZvA==","signatures":[{"sig":"MEYCIQCJDjfiaugAn8+0tU/7pzhH1O8bM0DDPYuBefqtKL4L0QIhAIrIwqBUNm0wQrv+rCVKgUshPw/4OdFWaDqRzWzv9fBq","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"48d6412bf6f6abcda429e07ae08b016ee6f574a8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.4_1713762577492_0.7286219825707765","host":"s3://npm-registry-packages"}},"3.9.3-beta.5":{"name":"@crawlee/linkedom","version":"3.9.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b97c8b0ed954ef102b84d431f23a2e2e75fcc658","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.5.tgz","fileCount":13,"integrity":"sha512-x0KdY0oJfNQZ4USCXx28oAtuTdL9+4ftG3s2PN0w5w6wFSscAVfkP2Q/ynpgVjC3H06D2YykGUhlApPdrjacgw==","signatures":[{"sig":"MEUCICwwR+Fb3jGq9kDV54GlKlxAiPGbqNoIW3PtBMINg80HAiEA7ba4/J2+PWiuyG2A5KLXHQo5g3Vo8NMEr4PcFcYtRag=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e5671d22a9e95b4d8a8fc838526a92ce8956bac2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.5_1713773444578_0.5410997146789425","host":"s3://npm-registry-packages"}},"3.9.3-beta.6":{"name":"@crawlee/linkedom","version":"3.9.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f2f78d6e8e3efb5eb79792219b87b0d8b68edd37","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.6.tgz","fileCount":13,"integrity":"sha512-Em9im3mN54t49lEFzi7jnT4sumOAV1GgNkCoL/khg9F9KO9kBZ6ConjRZZnQAQgozwnmfXSba2kCc/d3lXf1Bw==","signatures":[{"sig":"MEUCICk/MFXrfaoKVLuOKnPPC3pVL3L58L4aQd6fIVvxknG4AiEA8VcIgIjUZJHe+kxO63W2J8gtjS8hYXX0aIiMwMjiOq0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":215838},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"594c810cfad2bfce9127e3bbc18a1c0c88351995","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.6_1713790998251_0.4109878093869048","host":"s3://npm-registry-packages"}},"3.9.3-beta.7":{"name":"@crawlee/linkedom","version":"3.9.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5051f1087eccccf15c148d7184a4384c247ba351","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.7.tgz","fileCount":13,"integrity":"sha512-64F24whKbPJs8h7ft0zXiAFPs6IaDozusyYFvMNb8VWmhUbT5vqzeBwdkCvZ4WUcaCGLYU2msnK+yrFoYLmMOA==","signatures":[{"sig":"MEUCIQC/yl72pSDy9fgSERGg5/0pBBH55CbNqx0aqW6m7bUtogIgTzuCt9uqSKCrxTqqOPQyEjjZL5AQ7jZOHWgZDMT9SME=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216250},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d421abb7c0147e6b81c2ee6b46e00467ed21782b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.7_1713848621828_0.5587302495131756","host":"s3://npm-registry-packages"}},"3.9.3-beta.8":{"name":"@crawlee/linkedom","version":"3.9.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b89461628f474f23fdc475baa63af3b57315c752","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.8.tgz","fileCount":13,"integrity":"sha512-8kHTOHCKc4i4W4MtfdPQNz5nQ8yJEKTZe61iRip4izeBHSxRlGNCnMQ0aZnea7TJ1eLYVeCLzN5gFHJL+xd+5w==","signatures":[{"sig":"MEYCIQCorHSKJTFlPOy7oBgYTZAU2ulpnLqbsFYcr/O8rROBowIhAKrbLQ/LZYkAtLRrGqaY6kNKYjOvY+bEoY704D2trEIQ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216250},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"14617f9c177fca70fabb98cf33306df2dbdc4b54","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.8_1713886846398_0.028491496001915362","host":"s3://npm-registry-packages"}},"3.9.3-beta.9":{"name":"@crawlee/linkedom","version":"3.9.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c3c53757915bfd72fbe6c1ff7b5d7b3b365cba2e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.9.tgz","fileCount":13,"integrity":"sha512-1A26pR6FQFfeZYat9N71PjrE9T3StPr7UenAEEeKACdxd16bk5ynAUzEWiHjIBtJ6ZIO6lehwAEOvPt+O189lA==","signatures":[{"sig":"MEUCIG4RMEePOQ8IX/KvL7HucPoJ0yvI5J+JffujrWh9fuYTAiEAmdYXQARLtL0kAf1w8wufblDhAszF/POl35iZvzF6WY0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216250},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e45691ea7770d6d8b9099b2c6564628d79c0b3ba","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.9_1713913662795_0.959815610686025","host":"s3://npm-registry-packages"}},"3.9.3-beta.10":{"name":"@crawlee/linkedom","version":"3.9.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4ee6778740f06febf4187df50689214a4e46c0a6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.10.tgz","fileCount":13,"integrity":"sha512-zIZvkJX1uDst0kA6f0zpXOk2Rl0T7/I4w960vkZAkHsvZF2ivjT5EI7vciRKKwm/kGk1+r4BUYNd1su6rxMrGA==","signatures":[{"sig":"MEYCIQDKaeGus6oZKLfcFu49Dy8x83u+JCtiI9/jpSiKzIelqwIhAIDHDP8yKe/CcPLjkKNguMuBuYMSQdHKek4DqzURsuVv","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216253},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4f14492750051036948ec51350d3a46cb95717ad","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.10_1713931559733_0.6277923587480538","host":"s3://npm-registry-packages"}},"3.9.3-beta.11":{"name":"@crawlee/linkedom","version":"3.9.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c77993582382361d9b2659e6be6727e35ade9782","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.11.tgz","fileCount":13,"integrity":"sha512-Iz1NAQmv132foMy8q0aPowRSbVfxXelPybW03nWqwFlNmp8DEqfkyjyhlZDfhIMuw1Fb5m4LgdnHLVRfb0NDSw==","signatures":[{"sig":"MEUCIGeV++3cOOyGAshYNI6PnihoabV67qBNK6stNXsTrMWrAiEAl1qimx2aAETL0AT7Oaz814SVaK6ZrfnhaTWy7EG0AQk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216253},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fb0dc4971acf4676c0463623475b88408bf9b46c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.11_1713984909308_0.1430723700406631","host":"s3://npm-registry-packages"}},"3.9.3-beta.12":{"name":"@crawlee/linkedom","version":"3.9.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0d4404642ffc06c6730af10cf6f116b6619ae1e3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.12.tgz","fileCount":13,"integrity":"sha512-02t2Rfg6TUfrZKsjlLot1mphPsJB+aKtpNVy0AR0fW94xUghoitf5I027cMfmNljvpdTmF1/Txr5Vsdm5QWp6g==","signatures":[{"sig":"MEQCIHMRNr67zS9ydy/mJKc6h1PdD9jJnlx+IO3KsBagu+cEAiA3Q9HbSKia0VjpBksBUjf9CZ+d/lOlXvD4wmmlmXARJw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216414},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"91b7784232f04f27cb6b4942f369e370b58efd1d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.12_1714017922518_0.5396600787470087","host":"s3://npm-registry-packages"}},"3.9.3-beta.13":{"name":"@crawlee/linkedom","version":"3.9.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"713824974a8fc5a5a709653940502dc0558ab8ca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.13.tgz","fileCount":13,"integrity":"sha512-vfbJ490CFABz/XUqZONad4uPMX5nnO+bJBr8KX6oZnAFuh6Ag2nab6fuVFEMrmSXUXL6J9y2dE2j3TuZiPBUrg==","signatures":[{"sig":"MEUCIGL9tJ27t6gLtcjOKIKDzkj5uoKMxVubfTlh/d+rPYmiAiEAjeZAghCQQbHcbHfS0v0lDvd50SsLGlSQzZVMp+eow7k=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216414},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df9cf828a65e18ade02d58cb42603c4e65d9002a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.13_1714085650944_0.45121756933236834","host":"s3://npm-registry-packages"}},"3.9.3-beta.14":{"name":"@crawlee/linkedom","version":"3.9.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d6768cbc8e045e5bdd33c7fb60c4a1034c793669","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.14.tgz","fileCount":13,"integrity":"sha512-HqRkMP//y9Msfyf6qYvVGN6d+bpnfwVZqXlOiK+nXRs2C17ciiKq3QlquHRfizQvlYCOIxVmGI6VtIAP4hRZMA==","signatures":[{"sig":"MEQCIF3k5ZZAhQ4Z3LY7E1cWcHE28UemguG9g6+oCpBp4lG2AiA7Ao3yi6gKWrOSWiav0CLbB8tg54/DO41AL1MLjixCgw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216613},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ebc6177697e798bfe89d22e26556d5c82d1b829d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.14_1714104063298_0.36647639622200234","host":"s3://npm-registry-packages"}},"3.9.3-beta.15":{"name":"@crawlee/linkedom","version":"3.9.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"579412622c79080347c2db94783372039978195e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.15.tgz","fileCount":13,"integrity":"sha512-ZltreolMlAozxgXo2SXJoQvJHJr2R0N+hdJWxD4B9llXrYmlacZg0W52aaf+Olv26UuezQhfAc6upnZD2HXF6w==","signatures":[{"sig":"MEQCIB1NXR/nugWKzGt0Yhd573B3/Mz3bpyamleaTWyNWoLPAiBWqNSUoBeddKb7bhkjZ+fscOQTXQ7YPUH1kRJapiwitg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216613},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4587d057fb18710e67d1168085ebeb4bb7e52376","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.15_1714188717297_0.840334418152902","host":"s3://npm-registry-packages"}},"3.9.3-beta.16":{"name":"@crawlee/linkedom","version":"3.9.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0c2301cece160751e5f24aeacf123ba59c989be4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.16.tgz","fileCount":13,"integrity":"sha512-1t+eF6Q1MGunmWSS7IB+ebuNPIr9jCnU4cHXbg06lkc2yJnN37is2Mdwuio+YWRtxnA2eR1w/rHWMaBV7wFEbg==","signatures":[{"sig":"MEUCIGDr5bhZs/BovErStkX7ed2nhgPRY6SvU+lPXtiWD+mhAiEA4qNPj5LZg9aYlb0fljBkCMwEDjQZdSIVwPlsfVNbTWs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216613},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0c522b14402123baecd30c4296b6ece39dd4d727","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.16_1714276535001_0.4499928956093162","host":"s3://npm-registry-packages"}},"3.9.3-beta.17":{"name":"@crawlee/linkedom","version":"3.9.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a6d96137d595205f4fc1a720793ecde4c7d9df91","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.17.tgz","fileCount":13,"integrity":"sha512-W5O5CMVXNE6dln3TZwy49ZqzgefDojE32PT1ALAiZLUj5JJKZw3ZyQgv3JZSiZ35XNXE2D+96AbdK9A76o1Yzw==","signatures":[{"sig":"MEQCIDS+GXhH+ppwMzttFNXF1wmfrdtGfhUXWevg1JmvJ5/AAiAnEPJLBLMmQ3uXOfeqaW/eB+ll0zXJj9fddieSxOUVRA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216613},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f5d76b981ca9c2df5ab57ac960cc89034d3692e5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.17_1714365017867_0.09686602962639168","host":"s3://npm-registry-packages"}},"3.9.3-beta.18":{"name":"@crawlee/linkedom","version":"3.9.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3b61730b94c04772f6b27549a75ac09430b002a1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.18.tgz","fileCount":13,"integrity":"sha512-jTbatJwKXocEnS8Dy8yeJNeZDgvUxppvtgCfd3OXlncvMrBWV/Gzxc2hfyeN+uiNFQ8mCg/r3eQcvZGfW3jZSQ==","signatures":[{"sig":"MEQCID62e95YKIpv2qRjPHGU84ok50DCKSD5SFEnwL2X+pW0AiA4biNieMp4z8NFWvnvY+QuD4KV/4r3/Ow/brll/3yDOg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8349f5ea58cf08277c6c14c2bbb02a660e2bfdb6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.18_1714454646114_0.5235981731882313","host":"s3://npm-registry-packages"}},"3.9.3-beta.19":{"name":"@crawlee/linkedom","version":"3.9.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"29823fa94175b1d4738e5a4fdd469b5e3ff0b875","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.19.tgz","fileCount":13,"integrity":"sha512-wf10d6AEKc4+i3V2ibSU+jSmiPoZ7vH+sn8epO2oQvKrwxNnr6pxZ4HxYGGkGrYND+rxh20Q2W1bR7a7zme8zQ==","signatures":[{"sig":"MEQCIG/08mG54buFz6q9sA1oRY4s3X9jD9lJ0TfHtBaKhtTLAiAZDIsc/MMdm1nq49bmUrq0Gzdych+y4F4gj69u/07xgA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ed518fbd3199bff8d4bc3c47b310a6ca207c8e3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.19_1714487984248_0.3882980622148291","host":"s3://npm-registry-packages"}},"3.9.3-beta.20":{"name":"@crawlee/linkedom","version":"3.9.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a50094dd41caef6d52b5530a6335b6fde8848654","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.20.tgz","fileCount":13,"integrity":"sha512-R7sIlWaFItMHWnwKI0dN97dZCU6DZEYivV+YGSgV1ozWc2iGBGITHxnQJcmtnB9r6Ii9BXHhAFkXsmGWKPbclg==","signatures":[{"sig":"MEQCIAJH4ioAjrPDo0P0eznxM7Til/XvnAcQ4Ylr9TgCt5i+AiBH5/MrlUOkV3DAHq45hUaiilZGejyywDskYjS274eyTQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e1f4a4835876160b5c0d689444a3927e8fafa832","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.20_1714495893621_0.034504847058626","host":"s3://npm-registry-packages"}},"3.9.3-beta.21":{"name":"@crawlee/linkedom","version":"3.9.3-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"86303237eab91da8c1fc36f131c48d265942b3d3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.21.tgz","fileCount":13,"integrity":"sha512-iQD2FRJTdjksZF4b2iZPElNMT+iAh1Bh7bvDImx72bVmRbqCcqiJ1J61QODJ0+wWn3j1b/nKui5l5Y2XPSN2Og==","signatures":[{"sig":"MEUCIQC4JqR50dkAdpEC9uZRryns2BXkRgBCLdZ4VPO50f34+gIgIpQeC+Cqu70AURWkuma+uvqyVxfWl3fY0+9WKOlK4Yw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":216982},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b637db1215aad09bd898b94202574fd69053b23d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.21_1714689076225_0.11989048240043565","host":"s3://npm-registry-packages"}},"3.9.3-beta.22":{"name":"@crawlee/linkedom","version":"3.9.3-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6fd1a23d387977cfeaa35c62f3e2e14e3e01642e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.22.tgz","fileCount":13,"integrity":"sha512-9nzGyddIB5SqfU6UQ62jlyHIxeRQD02JI04C+cMpR7e4UAgUCZoSIwyuO/D8MUjIawOSmttlOuQbQ2J0D/mG6A==","signatures":[{"sig":"MEUCIG5DJp27L7LfDLKJl8m6e2MXi78BTB2hqolyYqrl/JVmAiEA+Z8Q4jSr2aMmNpD1/U9mus+06JZqGfFuh5OHL+3ZVkU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5c457361c10ff76fbbb41070b68c09cb02133364","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.22_1714708693931_0.5624415779796299","host":"s3://npm-registry-packages"}},"3.9.3-beta.23":{"name":"@crawlee/linkedom","version":"3.9.3-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5a2040ac12fc1d838d9f83de7653cf254d5377b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.23.tgz","fileCount":13,"integrity":"sha512-Hk9h1tQx/fD1INqW8FvUszIuPncAWd5wTy25wQjurbsdT8DurKP/L3wUJXxa2hlWP+xT7oMwRgAIFTM54QjZnA==","signatures":[{"sig":"MEUCIQCML0EDuBtUpLFROIvo5nlIEldcxOJaaL4LjbfyLg5XsgIgKn1QXsxhN3zOyNVbr4q7TOP0vRGsaXWMkaxljIBGEDc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bcc9e6f160fbeb724f6f4daf33342c2ad3815859","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.23_1714721436731_0.31942140986640455","host":"s3://npm-registry-packages"}},"3.9.3-beta.24":{"name":"@crawlee/linkedom","version":"3.9.3-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"04f13d0843155f9e6442a84922e3826b3b5bc06f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.24.tgz","fileCount":13,"integrity":"sha512-2FhS1rnyLT52d8s52dF+gTLqfoFpOGFEokihep2m8qMwtVXUmiXaw3vC01aivjxWKtXcMSSfr9Ou3TQKTa3q8g==","signatures":[{"sig":"MEQCIH5VmTJHpy0wjjbLvpFbPuBbzuuVUrHogulD8UicvIKqAiB/z01JoAgFTd2GM8kjb4YdkFiK+34wwjSd7JsqUD+BVA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"152b67782b7a16884532615e57db2257c925a5fb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.24_1714741280002_0.550472222822757","host":"s3://npm-registry-packages"}},"3.9.3-beta.25":{"name":"@crawlee/linkedom","version":"3.9.3-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f7ad10a2f3ada5dc2d8e3734787be92c744c9f3c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.25.tgz","fileCount":13,"integrity":"sha512-0WWE9A0VvNs4gVx/wqz7kSEL9LxjcTO3+De/pEreUk0QzaueIfFXpgVy0481mHrBb0l+P22pYRztKt8P6aBhJw==","signatures":[{"sig":"MEUCIACPqU6wOT8nxxp15ng04emRQ6PYsSihSya5zbw+khmpAiEAv564abGHucvKA2ZLs4q4/0BLeZ3NmC5b+1LCHf5R5ww=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"12a6378a966fbfb9b8d0050508e730c1da7cbe3f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.25_1714764439768_0.8591372037583285","host":"s3://npm-registry-packages"}},"3.9.3-beta.26":{"name":"@crawlee/linkedom","version":"3.9.3-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9ca200e9005231e8f20ed57d651ee074e84a2aa2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.26.tgz","fileCount":13,"integrity":"sha512-LIH9Ak5DclHRHsdApUTbd30qFzgNOkFHGu6RKRgXkq+bi0pDebbIQiNYJAN0NFrDPrUlmc08MMF/zYs4HpHd0g==","signatures":[{"sig":"MEUCIQCRYBTdybh4s54ZF2Czfa49l2Ds7jg4lAzxy0Bj0DeW2wIgQ3VC7s1YDSFee413dgDAJibmGh/Wb379NxsCq5gg74g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ed001225e584371fa0a17da5adc432d39121afb1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.26_1714792452840_0.20130186911439707","host":"s3://npm-registry-packages"}},"3.9.3-beta.27":{"name":"@crawlee/linkedom","version":"3.9.3-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"34f6d70c04467f5390425fc87d34aa024c64a510","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.27.tgz","fileCount":13,"integrity":"sha512-FOZNxhHLuGmukFu0ZBlXWTmocrSCrkKF1VyWcfZfXQ9gTy7IoXxpvXtkX/GrVtvo7lD4EQ2r1evKVXQPqTmvbw==","signatures":[{"sig":"MEUCIDB0wzf+3YhAeAPjhODVbN/xmyf787b+pFSJVOlFlRY8AiEAnDG2E3dIpEx3chIyexmHkjq12JOcguqvehhOrvcp6tI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217181},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8112aa8c2f0f9076208af036752167fa40407176","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.27_1714882350085_0.9217179470908432","host":"s3://npm-registry-packages"}},"3.9.3-beta.28":{"name":"@crawlee/linkedom","version":"3.9.3-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2409ae336fa1772b92783b91bfd1c53d0e1aa40d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.28.tgz","fileCount":13,"integrity":"sha512-4IaCoAF3tLmlBdhGqqcOwLXvBv4pNOvDoianCXDldLm4ZRIxrloOXhqKAraevWFit2Wyljeb6lliGlx0xUiiSg==","signatures":[{"sig":"MEYCIQCNKlPaMvWEA6xR9IWyx1mY7KptMl6efmQWZK/3jAJJqgIhAPFkk1mb7pWWkTDJUP/KvcbOn9CHxx2uuLBNFcRlGvA5","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217340},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"679a933919cc450532b8a3c39049fc6e2db7407d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.28_1715002194021_0.1685474702457228","host":"s3://npm-registry-packages"}},"3.9.3-beta.29":{"name":"@crawlee/linkedom","version":"3.9.3-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"226fdb1d40d52b3a6e8ce189d9fd681e0896383e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.29.tgz","fileCount":13,"integrity":"sha512-2e/qDIjWPCb27B133K+8DVhcu2Rk23WLuOMVZvL9ff0NdK52DBUVjfao7Gf5nooJe3aIJSdxv68DpGc0xrKOPg==","signatures":[{"sig":"MEQCICD3Kiy7GKJME/aoKno72f059igRHbrrHOS38VHD2u6SAiAO0/gAb0JkZtAGLuH2UcimPUldNX4d08qnYyVn15pKug==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9bd1a5a61dfa8b14e0a3b7f991696eb2d3c4f315","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.29_1715054922877_0.20207093114160513","host":"s3://npm-registry-packages"}},"3.9.3-beta.30":{"name":"@crawlee/linkedom","version":"3.9.3-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4341acf92d6b344a22844b282fd14633d0ede839","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.30.tgz","fileCount":13,"integrity":"sha512-j/UiwgDHfIeqNnu3rnQrj9Rl0LBFBVU7UPJhz3AtbhGYB0p9622egRKFJ2XTuWOlWrZ6fz/I5j/Fq3eP/2tSRA==","signatures":[{"sig":"MEUCIQC4C5D1JBBG3IGlvBEHdxXQgFq7Qah0+Mc//OD2yr0++AIgWLEl8kBtppOAvsTZ38AbQq8TOTk9yb5bdsfTKTbx9Mc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3b8258188b369001acc91e508988d557174d2192","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.30_1715097187266_0.2799708356993844","host":"s3://npm-registry-packages"}},"3.9.3-beta.31":{"name":"@crawlee/linkedom","version":"3.9.3-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f334b5b3885aaf00dc2d99877f562eba7ce0b7a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.31.tgz","fileCount":13,"integrity":"sha512-vN7jUyK5H9i6xnrikXYZuMMT/KG1yNMHqI8j0X0iSBkC9wuvzb40hDLzXUskXvJ2kmrVQoUNBTY0QBTJcNh8jg==","signatures":[{"sig":"MEYCIQDz7ONVm9StY3RKT/+fpQIsp2ZRHKA4FhhR9301hdTerwIhAI1xO5+qtC6xmNF4x3XE/wrnhbKor5YeYkBiyDrasoK+","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dc2ef56702f15c6bc2d3203d136cfcadf175f018","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.31_1715141204336_0.5062614479914842","host":"s3://npm-registry-packages"}},"3.9.3-beta.32":{"name":"@crawlee/linkedom","version":"3.9.3-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ac4224742ed79c6462ece4c19e870a5c3ee65d1b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.32.tgz","fileCount":13,"integrity":"sha512-BOZTl5VEOqMahe9hEr0A3x7c2XxYE/+o2QsjToGTSNnvICa8OgV+bI42aeFYX9OxtFsJEZkt9P7EUJIBkfO4ug==","signatures":[{"sig":"MEYCIQC368Vqzw7zZJ5vtwspYa5si+VSDqI8EeO0MYkaF4gCgQIhAJDuxRKEee1FISu2hpQyyZOiuBHDI7bX5lTKINIWHQ5D","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f21f061ed1b06a0d0b326d2173f90a8b4c359c39","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.32_1715231330823_0.06994214274232347","host":"s3://npm-registry-packages"}},"3.9.3-beta.33":{"name":"@crawlee/linkedom","version":"3.9.3-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a1ce2de804328162462e777dbfb9011481a86090","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.33.tgz","fileCount":13,"integrity":"sha512-TKGw5YyuZ+EVMKPbWNAawLb6X591x6jqPKpOzu2zH9zZt+M6g16wcdGOMWfaLDKyiE5TDoJTpLdo7b7m1YN9vg==","signatures":[{"sig":"MEUCIBMhpWGzd1t8qKxrx20zjoiA+CkxWUlts1U0kb99W0cuAiEAhETHV/42ApEh6O+Ncac/O8lCc1379cYxv0gkFua/IoA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df885dce68b1a7889b7902e6c2fb5e7b9b547346","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.33_1715314451265_0.6596432114546293","host":"s3://npm-registry-packages"}},"3.9.3-beta.34":{"name":"@crawlee/linkedom","version":"3.9.3-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8e3d6ad2f27a590928b2314f6dd827b805b0bb33","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.34.tgz","fileCount":13,"integrity":"sha512-SjSzp5MsJFvTLBoKQsIOAilbn45W2WbSrnWrzj96kxCthkr5vjcng+pIYV9B1fN2PLQM0KitS0uHPvuMi6JxHw==","signatures":[{"sig":"MEUCIANBmGwXGrbJsJKFKa2maAb8EeIl/iNrvNrHdAciyDdyAiEA1t++41HiVuGq24Vh9eVABdQIomDNX7T3N2OETHIMgyY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3a96215e84fc60011df686019cac59f2d92bb85c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.34_1715404150728_0.8711701096100606","host":"s3://npm-registry-packages"}},"3.9.3-beta.35":{"name":"@crawlee/linkedom","version":"3.9.3-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c2a59ea52a7de826d85fd6907367aa0e9b5d2b86","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.35.tgz","fileCount":13,"integrity":"sha512-oKIuj+zV8cu8D3pNRDZ4AZ6qF8WR62gI65JUydiHjGOgr27fCiZyI+mU3QTB0Vlg2TkVqwEksL0wKwE/rkJGaw==","signatures":[{"sig":"MEUCIQCtXDsmGNCFGh8rdpdFpoYZpqBIoA1yznPEPWV3O4L65AIgDeD1J9/tnUNQv0Jjpw5ezs72VreObxoQ5GxCV3yXyZU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2f2b60756d9fc5191a135e5a0c603975f04e9308","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.35_1715487150880_0.86253760463498","host":"s3://npm-registry-packages"}},"3.9.3-beta.36":{"name":"@crawlee/linkedom","version":"3.9.3-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0170593196082d7430596ed5838dbaa12fa7052f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.36.tgz","fileCount":13,"integrity":"sha512-JAaxhtT+z96X3y0RbQ6jnhL9e6JpKCKQg3pTx0QEoxhkGMe/L+mi+9L1N4PK3yaobQeKCAYctwzDbbR85ZQtqQ==","signatures":[{"sig":"MEQCIDGMMoWj1B+Q0xn6dPGM8+g/cM+qIaSxQY13BQrDiMYtAiAjRrfeqhA4Zz5xYNklBIbpw2QJiZ39ccu1I9u2JgyGYQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c83cf444ab14161550911a5e9e9df96af4d9a932","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.16.0","@crawlee/http":"3.9.3-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.36_1715574698938_0.6519765887716926","host":"s3://npm-registry-packages"}},"3.9.3-beta.37":{"name":"@crawlee/linkedom","version":"3.9.3-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1be9e2d2764e1740a4fce3f9464d151ff5e10abb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.37.tgz","fileCount":13,"integrity":"sha512-7ZnDzBaNbHhRPHxmJgUUwPtC4pVXz0tbN7wvnHIwSS0mm7GJHHm56zq+uq9E5PfOUzhgSO2+IMgwXq7wx8S9cA==","signatures":[{"sig":"MEUCIQCKfW+EulW/fZGvTDuBavNov0sBAiOiLTtvEX0D7sm1VgIgE3UynPm0gfwL4NUKYHYlIrxZwkiVTpOvC3fDgAzIn6Q=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6e8fc1c4bacc482d4c5ccec04dcc89c527d30e46","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.37_1715585483727_0.02087183565479278","host":"s3://npm-registry-packages"}},"3.9.3-beta.38":{"name":"@crawlee/linkedom","version":"3.9.3-beta.38","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.38","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f79292bf9145eba7ca790106a4f3a9a73fe9923","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.38.tgz","fileCount":13,"integrity":"sha512-dn+EvPx4Q6M5kyHgG37M58Irr3kdMpbCxLtSYOZ8nMCcOMzl3F3m48jWWIAAgtsIxFZiPw/ajNEj6PyLNtrPrw==","signatures":[{"sig":"MEYCIQD9VKc+AnVk4dWhFpd7puetUgF101/RJA6eFnD5D+23KQIhAJ6VCA32IyyEJRY307skT7uFOpu+x6YtJIaHnUN/fWWT","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"174c7adef31f9ec6b2c9edfb9a615d52187adad8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.38","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.38","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.38_1715596646694_0.6685691894231667","host":"s3://npm-registry-packages"}},"3.9.3-beta.39":{"name":"@crawlee/linkedom","version":"3.9.3-beta.39","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.39","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f28a3c9f625c785a1aa704a6408204eb06821f3a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.39.tgz","fileCount":13,"integrity":"sha512-W64PUHglRkWSAreQUY8YeydbP+RCqEC9wDgKlFK2EuspQZABk5kW8fFPbPZPU8rpJ6AJeIC1fbMcdtIBczppnw==","signatures":[{"sig":"MEYCIQC5PR+VT6jzNft+A0RlYBuMOjRT+1GFC7XuvL1p+pLZTgIhALYCU0BAt99Sm/fUzXGQC7DOBwvJYekN3SDjj99InV+c","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217350},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4a0f7e112fd76f03bbf5d49c9b6a492cb8012374","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.39","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.39","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.39_1715609680816_0.8451662745357869","host":"s3://npm-registry-packages"}},"3.9.3-beta.40":{"name":"@crawlee/linkedom","version":"3.9.3-beta.40","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.40","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"03f3b1b4df018f2e26484d7acfd15799e6717b6e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.40.tgz","fileCount":13,"integrity":"sha512-hrGmHf6BRPgYdL8GIqhsYXS1S7OEzXjLEkNw26xQsnn13+pfUM15gYDye6t6Wd1wwGdEJ8RK11KZ6IoOAJVg0A==","signatures":[{"sig":"MEQCIQDLNfg2bfcB5uTCVppwJ5urZysgh4XFt+ORlSWt7cipBAIfJ8GDNmzoYb5n5j7SmM+d3cYFir9KgHtjfmvkmSOZyw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2e0d7afc7f19d8c1d896716fa12969921930c489","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.40","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.40","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.40_1715678926873_0.3146720485976484","host":"s3://npm-registry-packages"}},"3.9.3-beta.41":{"name":"@crawlee/linkedom","version":"3.9.3-beta.41","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.41","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1f5ce827895c27e8a8f34950d8843efc58e77fe6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.41.tgz","fileCount":13,"integrity":"sha512-xqoCMy2x75LoM8hInz4JM6pXs1EYnH+V9g+hb5NFAmwAQpg1++/xQjHye56M7tSaEnB1b8n/kclXdrDCsEfcXw==","signatures":[{"sig":"MEQCICmlagl7JdeoL8yQJtHDFcf8NnC27/sK/QogQJZNECbPAiApAs2TFLUCkv4yAwF4bupsXAbRtBrYQzu7v03r6jjmww==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"360b3b965bacbc0e734a08a2a8ff04999a661a00","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.41","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.41","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.41_1715684690780_0.25539243333654715","host":"s3://npm-registry-packages"}},"3.9.3-beta.42":{"name":"@crawlee/linkedom","version":"3.9.3-beta.42","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.42","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6a5800a232229796d8b8ee29d9f908bc843c3ea2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.42.tgz","fileCount":13,"integrity":"sha512-u2kIvDXnpg6fXpng1iAbJogBoYU2KS6CvGmjTUGIE42oEZaTh0LkTdx6menukECMaUwcP8SYywqZTvDP48VYyA==","signatures":[{"sig":"MEYCIQCjqeZkjoUeWBtFvXsxnmw92JE8R/1jFFggu9o3FyPmRgIhAJnJQok+2Mey9u4hK1xQOawY0obHiVoUFCWPCnCrIXqg","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"98087157deb5c2e910a06c5b955fdc747ae4b50d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.42","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.42","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.42_1715689284373_0.18505991238449515","host":"s3://npm-registry-packages"}},"3.9.3-beta.43":{"name":"@crawlee/linkedom","version":"3.9.3-beta.43","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.43","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f3f8c3a7f9294247e81e207182c31cb8be5e6dcf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.43.tgz","fileCount":13,"integrity":"sha512-r2qNIYxoFRl+FX6nCr6rlsLiug7y0Xclmd5iDtR4gyfyH3JL+j7CfOb6XDIIdRg7fRPlsKN1PzcClQY1zl3fBg==","signatures":[{"sig":"MEYCIQC3AMtEqMzDPLN0LkrEkVaqqVhRzNwhaf8BlBhRquAk8AIhAOTeb1R+7rH+jHe5gND7DyPlaCAW6hUTeTWE6z0rrz5P","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b8942557859fa05e401e1310bd1b498f534d739c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.43","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.43","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.43_1715782403128_0.9839455451807346","host":"s3://npm-registry-packages"}},"3.9.3-beta.44":{"name":"@crawlee/linkedom","version":"3.9.3-beta.44","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.44","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0bb605745a77013619811b33f01940e687aa9ab0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.44.tgz","fileCount":13,"integrity":"sha512-+p56dbCh5P5iqqc694qIHVPPvXAEHK9sBw/PMFLq/b8zFohwK+awr2vcmVI+BrwMAFntP2q8qJz3rVwBNvBx9A==","signatures":[{"sig":"MEQCICUQJ6PdRYfE04uRRTwpRjw5+D2Cs+kKxV3L+6lL5dGNAiAy8KhA/VEgcsyy04GFuK1QbcjNIzTIarIImyhW+2Gciw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d614499617968df528d14d3422a371eb52df059e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.44","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.44","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.44_1715794993322_0.24419560539384833","host":"s3://npm-registry-packages"}},"3.9.3-beta.45":{"name":"@crawlee/linkedom","version":"3.9.3-beta.45","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.45","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3fcf59e14652bd422368a0b1f86fe3023e1995bb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.45.tgz","fileCount":13,"integrity":"sha512-I7BRFfYpWNVt0ISFSFZqxRMe05kO4ofwBM5SnypWLBRBXGL6mksSkPxkPNHK6CNZ02p5+E/OL0wBgzg+n6wC/A==","signatures":[{"sig":"MEUCIE7JHRxvKf/MQ5VRm6o0yu1Qsd66aTmn4AcTZKVSayA1AiEAsY7zIB4sk6f1ETySWsA6JKAZhtEx/6DbrthanYBsyro=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4fec02b10a20506996005d21a0a4a1680a161aa6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.12.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.12.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.45","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.45","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.45_1715797279127_0.3848927452052968","host":"s3://npm-registry-packages"}},"3.9.3-beta.46":{"name":"@crawlee/linkedom","version":"3.9.3-beta.46","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.46","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"be77f70d2a6551f3924ec89d6e1fe6894f99e2f8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.46.tgz","fileCount":13,"integrity":"sha512-hEupCYl9OhYg12gwcqNUini1jOtdqRFk4OnTRbbv7feKjyR86qsjf/1QcjDxXhtuBxBkOD1MZXJpk4s0Tjgdjg==","signatures":[{"sig":"MEUCIE5cQxyYlsRy+HFYFG8Nz8BqFKoAazxaXQ5wuN+dlULDAiEAz+QbBbZQSnFTWTsrYjXs7ltLAJt7t8FCecvg1Ac9xGM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cadbd86a73186800f4d9a9c8e02a6abf909cf9c9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.46","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.46","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.46_1715848003876_0.6713181591571622","host":"s3://npm-registry-packages"}},"3.9.3-beta.47":{"name":"@crawlee/linkedom","version":"3.9.3-beta.47","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.47","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b6df95805b9a2e8c5f3e756c7ba7d7f2badf9595","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.47.tgz","fileCount":13,"integrity":"sha512-4Ip9XN2nBxdKArbo+DCz9Mm4rjfamjUIW+3MxO8fIaBdmYPc04M05rrGISFaYShYP7Yy+Q2TQCh/QxZqLf0pXA==","signatures":[{"sig":"MEUCIQC0SDXjRCdkRnmu1jvoITqq3wiGh5k6XEaKIh5AFuUcrQIgM/VAf6Fd4dUjqwPuqOEo8Pvvuw6k9Di7wIqDDnEib+8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217400},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"54eaa193d04e3e19da39c0f2930b550a043674ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.47","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.47","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.47_1715861044401_0.6664429576276529","host":"s3://npm-registry-packages"}},"3.9.3-beta.48":{"name":"@crawlee/linkedom","version":"3.9.3-beta.48","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.48","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b8958144472511274b339e6c9b26b42ee8c9dc51","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.48.tgz","fileCount":13,"integrity":"sha512-boszYYOvNLxHl6Cy9N5lQUHfku/TXvyM0Da+TFNY6izFgBOvbPol5xTAcwRP0WRgUdH+BM4op8LH3+S+IlUOaQ==","signatures":[{"sig":"MEQCIF+stD/1qLaqIVAOKfR2k7Lk9J32gZBWzIM5w0TyFP9JAiBGHdxDUtaWYu/GYq3V+HO4cHNWEE5hjO1zG+tJGmQ0FA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217717},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4e257b5a8e8001baa1fc17135b10032bda3b50f9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.48","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.48","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.48_1715862193987_0.4721951871220036","host":"s3://npm-registry-packages"}},"3.9.3-beta.49":{"name":"@crawlee/linkedom","version":"3.9.3-beta.49","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.49","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ceb14d421817c1456e007c02979416682b1dd3a4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.49.tgz","fileCount":13,"integrity":"sha512-+efrXKkx4+vZkKQ+2ieH9FYB0WBJrHwiNdIdeB2djCxeTZNejKfn/yaZUvLG6Yq1ycOipPydmq7gTvMyqkE/kA==","signatures":[{"sig":"MEYCIQDU2vWJMvNIR0SHYN9NdWYAX6PrDcNvUTc4W0Xo4UOe3AIhAKr6hGuvV8EHglhJzVCbMK3Wfab/QW5Tfwu87f17nb/u","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217717},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1e3035d52a6e274221be799f3d31ff1e318b791e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.49","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.49","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.49_1715865888831_0.9502478400100851","host":"s3://npm-registry-packages"}},"3.9.3-beta.50":{"name":"@crawlee/linkedom","version":"3.9.3-beta.50","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.9.3-beta.50","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"79b0ddc2a6e9c889e046af8213424d01b206fba7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.9.3-beta.50.tgz","fileCount":13,"integrity":"sha512-TKhB3w0Rtq8UVFlnyTJ32j98Jz1wgjIp53AnycuZGJIDSl/TwA0+wiw/icZG/lUO0jwmtszrCeUnsgPdugZaLg==","signatures":[{"sig":"MEQCIEufHZwdN9u7s5cSXPoc3H9eZMEzd2/0+bwvqCzqlrznAiBuDrk7NkBeaTVt2AXv4duQ5agbG2MwZN4kdUXh81FqKQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218011},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b4d36bdb7cb3de644b5c286ff634b110cf9ab580","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.9.3-beta.50","@apify/timeout":"^0.3.0","@crawlee/types":"3.9.3-beta.50","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.9.3-beta.50_1715866312720_0.48149289162498565","host":"s3://npm-registry-packages"}},"3.10.0":{"name":"@crawlee/linkedom","version":"3.10.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"52096293d7ce790d8637e0aac4ac61f99b61d110","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.0.tgz","fileCount":13,"integrity":"sha512-ZH2RbqfzK9ONUAtZlVQfRmSUf/Z28uG3rVvypsQ+WAW8vSq7jeo/KgKdLQXJzEEpbSTpNhMvGFPTTPKYsqkSuQ==","signatures":[{"sig":"MEYCIQDqbHIEygpnG6TL4xAA0kINU6VPB/WMCrLy7bQSbUFUrQIhAPIH/otZOJGo6lGMMq+ANCe/ueBuE3yhIJA3u+3pNDrX","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217990},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"805fc332d23789a5c0ff311ed4a4c33d2a961c91","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.0_1715866951846_0.7641185041905714","host":"s3://npm-registry-packages"}},"3.10.1-beta.0":{"name":"@crawlee/linkedom","version":"3.10.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7775862c740b1a9aff79ab23e20ce5a0cb154ea8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.0.tgz","fileCount":13,"integrity":"sha512-il2qsC1VJKBmiS2Rf8HUaPRiXQL4wRhnkaG3stTWVynLktxc3PQa2QFZgd/kWGLRgmvoD66Nluo8UVtz1dQaLA==","signatures":[{"sig":"MEQCIFA3/woXWwSwd6K4JfiAvm/YKTZRFGJ0K0lGeZFIjOQjAiBqfmwul9aQRxY05NwgQXxt00AIU2hQFJGGbL2pzaowxw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218013},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"22d93ae296f8ed2824beff4de9288541f28a6c1e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.2/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.10.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.10.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.0_1715867448628_0.06764710688592057","host":"s3://npm-registry-packages"}},"3.10.1-beta.1":{"name":"@crawlee/linkedom","version":"3.10.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6c4e46217d7cab18772deeaf9b114c9e1e6468a3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.1.tgz","fileCount":13,"integrity":"sha512-EqFpLD4aT+TggYugka7IdnqHqyp8KatyKJ85PwnoQPbQWyaxXTy1AaStH5jFhXdIASI57U50ndBkVenLLhZgBQ==","signatures":[{"sig":"MEUCIQCujUQsre5gDp1iehwoupf5AqhdqPv3k3UlCYtHD/Ki1gIgVHuGPF1Y66t8J9CXvL/LIFiPEfSrLIQlgIfh9keemtc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217856},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c036f36492b33fdf13861a6e18d6dcb29243d3c7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.1_1715921684875_0.06008235434816056","host":"s3://npm-registry-packages"}},"3.10.1-beta.2":{"name":"@crawlee/linkedom","version":"3.10.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a7101dffd8345fcf27ca3e422a935d7c7ec5bf68","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.2.tgz","fileCount":13,"integrity":"sha512-bovgRoSOrPwJpzejPAdXqTgW3D/EzNsEmKv/XALXxeHdeDXTwlhMF3lEYNqUpoOrDaa3OZBb8d+h9xttixPpXg==","signatures":[{"sig":"MEUCIB2+9zTDGwmgz6qu7nTl68j6QujE6d3Zh/dBNYJ3i4iqAiEAutKgcxcj6RENGL9jmRThmP59ahaHw3ribGbdRD+PWis=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217856},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5c706e360104c89cad660c44eb6fb7c1087a517c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.2_1716015570518_0.05350135162475067","host":"s3://npm-registry-packages"}},"3.10.1-beta.3":{"name":"@crawlee/linkedom","version":"3.10.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9096b696f54f1880217022f85a6f8ee57a0748d8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.3.tgz","fileCount":13,"integrity":"sha512-gL4WGZq0aICpguyoH79E9KXweXKqZcxjgGYpIVbbYrng4AQkdwVg3nUW0k9Hpk4HlqBcGMrsBC7zDaC3kOwF4Q==","signatures":[{"sig":"MEUCIHMU0jAyIQw9NN/c9NmXsGMwyeW1sFdpKRJa2WbCHZWEAiEA5mOVW9ZFGdY24y4rBtnUaVrtRieK0pgjmhFgLphakKk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217856},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7cefabfead49eb59ed29cd5eb3e1b77295469490","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.3_1716191008515_0.7468177554835147","host":"s3://npm-registry-packages"}},"3.10.1-beta.4":{"name":"@crawlee/linkedom","version":"3.10.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f51212e44cff55d4a93a9c0745b44bbc4f7cc08b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.4.tgz","fileCount":13,"integrity":"sha512-+hFemZfR3xv7eerUvXgfg63uihO/1SkxJ+p/Z7pz4NtuIBDoMWzQiX4tQhoAjlnPjKEinljiNo269aumFeAVhg==","signatures":[{"sig":"MEUCIQCNtLtZgPXVc18VYaCD+0rEnZYAUqu1gadGoHfSKBfHkQIgJOEm2mMuDgO8Et1uOV2cHkMLiS2jGfvsfRIFDOT7pD0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217856},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1e67eff930c87e3c4b656c7d209c6274dfa815e2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.4_1716299411431_0.5282056446645078","host":"s3://npm-registry-packages"}},"3.10.1-beta.5":{"name":"@crawlee/linkedom","version":"3.10.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2697e788887bd2bf02860ce2fb6de780160b5924","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.5.tgz","fileCount":13,"integrity":"sha512-hE2+F56jJ3aRWWmMIy6gFuhlaM2vW514PrymCiOk/sPU7gU1woBIbU3DCbEsp1SKaXX9oZVuhZ+UrbAObkb8eA==","signatures":[{"sig":"MEUCIB60ijVFqdDm2uZ895vnCM+V4tXB7ZTzglNxxiWDoYaVAiEA19dkZ1ZWqjPlLeRcIlC8LYaHETM5NMWaTixer4qREUU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217856},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c21cddfce9812c550e89904b010e2c554c5596ba","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.5_1716310536515_0.08509811406352252","host":"s3://npm-registry-packages"}},"3.10.1-beta.6":{"name":"@crawlee/linkedom","version":"3.10.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1a0272963b73bb2039dba45cafce93b8ccef7af6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.6.tgz","fileCount":13,"integrity":"sha512-tTNOB66j6wyjIXXZ82RGX9yxeucBnVjAiUZ7BGD5fSTn+cNlklzSDi+AWv9sYQTupNcEcMAUsN0l3+Ll97kwDQ==","signatures":[{"sig":"MEUCIQDhNrH+jg8z2Xz2DWU8xFVqG4iOKq5E0GLynHkCiSOVhAIgfmxNT2iKFXnj8zTyMqeYsj4kb8jYDx86F4dj0PPgH00=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d25d8d4f6953fcad301fda87f672da858a56c024","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.6_1716368954763_0.03814340062223209","host":"s3://npm-registry-packages"}},"3.10.1-beta.7":{"name":"@crawlee/linkedom","version":"3.10.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4350c6f15dd3ccb12832040bc6f80131a7d4ecd8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.7.tgz","fileCount":13,"integrity":"sha512-XhaofbrGSb2p/VYJrynLx3T0g8c+BX7SBelDGqhdG0Gln9nA5V9oI/U5iqidpsG42xZP9bVkjkbKW3A8TTIX9A==","signatures":[{"sig":"MEUCIB8gNa+XP5VoyfHjWxMoesf1+fDMQGKxg2M43oM+/s9yAiEA1AqLls3WUFMWbPb9oXmz/nUZRq224Z7Qh4NSQitezVY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ec0a7a7bf9a5e9fedc3a224fbd3349642f5e1c6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.7_1716387458309_0.8900674904043755","host":"s3://npm-registry-packages"}},"3.10.1-beta.8":{"name":"@crawlee/linkedom","version":"3.10.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"612fc230f8cdcdc79977662f44d35e05025a4618","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.8.tgz","fileCount":13,"integrity":"sha512-jvVowGOECpdmhJrWad/6ik9oXzJg/OshChXjiS3AnBN+SOCgI3tjKVtZ7dFWicGTURDpbORue8LHYzSDiD8mGw==","signatures":[{"sig":"MEYCIQCBBGC0vHUrPgxK7WH5pJdFEwHhktwaYbdN/BoOiSjZFgIhAOxICRX+O4Tihk6X/A11oK9OAPB6ZI0ZESmP8FpB/saB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5303d4be391e77568c96860efb043942b44b5960","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.8_1716391104081_0.44375336004430666","host":"s3://npm-registry-packages"}},"3.10.1-beta.9":{"name":"@crawlee/linkedom","version":"3.10.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bb3cb7a67c5f9cc8c8a7ecb832bc29698c3e5590","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.9.tgz","fileCount":13,"integrity":"sha512-5XYAMmo9kmeFr8gD699GAv1p+33CZugWKMLAc2cruvhy+cGUWE8jl1PG2ZDbJMUCTGd6588lXjRpVLW8jhvy8Q==","signatures":[{"sig":"MEUCIQDGK16e5jLZ4Vwfve/WChA1LEbFzAPE0Zzh1dqISLuhjAIgfYXW14XCq76mTMqYJO50ChikVML12DQYIPRpl/ZLK+w=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f2461f17ce07c0cc96c9d70f348a771e3e92320d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.9_1716394870073_0.4174976871959335","host":"s3://npm-registry-packages"}},"3.10.1-beta.10":{"name":"@crawlee/linkedom","version":"3.10.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3a2686efb3942a1ff9e4966df718a92fba21cc7a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.10.tgz","fileCount":13,"integrity":"sha512-muvrYr0quNHTn+AGayfx1Im81uAihmzT4eKADfrgDeqeRafThNuGztqcmrR56s3CA+4ZR2NbeNYw1mAYYmZVsA==","signatures":[{"sig":"MEYCIQCB6rR5uItfrCRd6qHeNTWVdYg1BWNmq2hRBC84T2OvPAIhAKSbHhfB+d6VUJx94G1WdNnniz985zDjqY9O6iLjxCBr","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218092},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0f97d67586fe28c625f488f2a2b29712ef51681e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.10_1716397886654_0.6947456564829135","host":"s3://npm-registry-packages"}},"3.10.1-beta.11":{"name":"@crawlee/linkedom","version":"3.10.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7f45fd83397550f961d2063af95907d38998f6aa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.11.tgz","fileCount":13,"integrity":"sha512-jHzTpQL6FJt7ew8PcFJd24meBH1vw2l4x+1fPLaT9syaeSSogrt/zB754LeQp83gOlsxECgkk/qiobjEPlgywg==","signatures":[{"sig":"MEYCIQDqe0pDAGTbabg7zR+sstcs52QZ26pOKD+U3iH9lydYngIhAOcJocGFY63vhotxjgmKyOkn8SXOkgSktUmQJYDfKQ5J","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218092},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d02fb2c0ce94490d79e9411732159bfc9e2122d7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.11_1716454172260_0.9551301514445387","host":"s3://npm-registry-packages"}},"3.10.1-beta.12":{"name":"@crawlee/linkedom","version":"3.10.1-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3d59489524ad65981fc92889804f37f9ca27146b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.12.tgz","fileCount":13,"integrity":"sha512-umVsftdRlnEQCVhmQGy3I0/Oc9bCO4n0V0YjEZGFGdqGFXMd6SCb8p2bm4M5jZXZhDQux2nkiMNSYCDRbs+KEQ==","signatures":[{"sig":"MEYCIQCY7jvxd3csv7xhsYwGi1axEzPsdTuESrMP9mX1CwbVLAIhAMmsIVvFTYpwkb8cImAXT0p/7ruWyO6XDDVxGAPFMOBM","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218092},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d6bc7852279461da17043685c0cf9794bdf85ccd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.12_1716455153859_0.7878592671740681","host":"s3://npm-registry-packages"}},"3.10.1-beta.13":{"name":"@crawlee/linkedom","version":"3.10.1-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3c1eb264f821d1e77fea54f4b2bb9669ee79b794","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1-beta.13.tgz","fileCount":13,"integrity":"sha512-AYzxdARcCN4S2AErEOhqNjJ8WBhfalwi46tdHESPHQ0UOCrFHWrOBoNzTp0v4rD4Sj+j8hPQV1uNjqnfXE8pLQ==","signatures":[{"sig":"MEUCIQDIfSXy08wL/JGCX3oTsJJ2yG5K+CPveQvaJKojs6vKdgIgZSQAXy0+MEau3+Jyt8K2XDRTATRsbAx5eDpNyIUwux4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217122},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cd86559fc89924284b4bd5f4d4e79b0408eb6510","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1-beta.13_1716456370235_0.7722682603402136","host":"s3://npm-registry-packages"}},"3.10.1":{"name":"@crawlee/linkedom","version":"3.10.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4aec131dd56fd1865c74a9e84352a75288924cab","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.1.tgz","fileCount":13,"integrity":"sha512-eRTt93tJIkAIGfI+zM3eVaYGe7e0xswObpdb2ZNyqhDYy9NjGJGv4alKi+4lptAm92qPPWg/bHLVvMXHXAnCEA==","signatures":[{"sig":"MEYCIQCAR7RV2UNReG1O2ttV0V7/Se9z/Ri7h2pN4XvUWqgq4gIhALg8hbi6/d6c5RzDBXATa2We1wYwipXNq148IDAA+0FB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217098},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5333e8100501bd0098d39656952d024c5b9e915d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.1_1716461233894_0.7061676828660599","host":"s3://npm-registry-packages"}},"3.10.2-beta.0":{"name":"@crawlee/linkedom","version":"3.10.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4ef420f5843b0ce605bf642b0a1b4a80f0162507","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.0.tgz","fileCount":13,"integrity":"sha512-vRQueM5aqmr7rGiI8hhwDtAiZGMw4oWswsJm7si7BUNBY+N9AYr55+M1v3L53aTK2SZBUcyvNGVRV2CahFi6gg==","signatures":[{"sig":"MEUCIA8JCP0uSAGoo/x6gM+Ry2afpYfLKJXUlzI/l71SRT+aAiEA7hEswTYSHXepWGrzj2xeUAJjLHkDwCb7zD+o1wXoir8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217119},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"668c19ce24d32ddffb0ced74d94d9eeb24deac20","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.0_1716464905652_0.2917657975352166","host":"s3://npm-registry-packages"}},"3.10.2-beta.1":{"name":"@crawlee/linkedom","version":"3.10.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"efe0afb63c7c5ac47e0b381c1ad9fda3b91e73f1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.1.tgz","fileCount":13,"integrity":"sha512-0KR7UhSR29Hco0G0Nspzqn444LpZow2mNkr11TWc8hqRDiTBDnrVnrIdBbCU9MFuFRoUDCYD8y6/kiyGaOjzfQ==","signatures":[{"sig":"MEUCIDMtdd8lJkEil4PEnPUDH/yG6wB3L0NULVwP3Oa0s5EqAiEAlvkJ3rDPj5dBEruAFGswOst8Mrp8G3TJHyhdXVAYf9A=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217119},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"088f13926762b4b8c8abc96c6f6d63563c7edd7a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.1_1716472483058_0.22857082988873567","host":"s3://npm-registry-packages"}},"3.10.2-beta.2":{"name":"@crawlee/linkedom","version":"3.10.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0e6f8f709b8abcbae74f0c04e5a8c5e7352d5f07","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.2.tgz","fileCount":13,"integrity":"sha512-UhJoef4q0q87WP3rw+sDYrJeBjHkyKlph4/CqE2JFtV2dOYHYYusK1HrEtWooSDOGdUrcXbK8znvzvfugdAQsg==","signatures":[{"sig":"MEQCIHllzPksiGNOuTVOFZcKl11gmpC+B3c/FCsYrio0WzdTAiA4t23jDIxYNUq1EPpt8boOyc2lHzlGxFJGuyFkTmKCKg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217123},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cf0c90e8cc589e85d6a4ccbd9dba199648e54945","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.2_1716525282926_0.9020710065932112","host":"s3://npm-registry-packages"}},"3.10.2-beta.3":{"name":"@crawlee/linkedom","version":"3.10.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f0b866053405ff429c80c84128e86104dce3f242","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.3.tgz","fileCount":13,"integrity":"sha512-4/5VLmaYGa8rVgyKFKsr3RcPlDmY864ThIwNIDE7rivhanLhzzzIPUSzYdCsPeB0tcxRMLlUTRMwD20gPnw7SQ==","signatures":[{"sig":"MEUCIAZcO2J+ZWzfl5Z/Zy6NT/Gp4QIAUDezA58RumIP9i9wAiEAvTb0/eqRFxj2iW5Mgy+CER5NmmjiLJambUvbAFLCupk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c2f0fbc5a59c2c79782287dcbee18d3b6d9a779a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.3_1716550990020_0.9704804436796755","host":"s3://npm-registry-packages"}},"3.10.2-beta.4":{"name":"@crawlee/linkedom","version":"3.10.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c1386061bb6b0b133025b749923bfef7997ab20","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.4.tgz","fileCount":13,"integrity":"sha512-0NI7y2vG4VZNr1C/IGnUCmFn7Ynk2xZScTkvYmb/FcLhJ5wTSVimdU3vSkPhqswV4rp1G0MPqk/3FTs/j5dduA==","signatures":[{"sig":"MEUCIBPN2vTPTixedjS3Ds4ZtT96I1k+ll9s4wXj27At1+F9AiEAgzPfZ1KFcIo6BjNH2rXZq0V8K2Fv5mXgax7fD/FFrV8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bab2a816ce62d515b0d34fea76d61c946551fdfa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.4_1716562383005_0.9003341212900573","host":"s3://npm-registry-packages"}},"3.10.2-beta.5":{"name":"@crawlee/linkedom","version":"3.10.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"18a87b423b0235a7b7b52c44265c2749aeed4ca6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.5.tgz","fileCount":13,"integrity":"sha512-VKFcdKYNES+YJLFNYIqN4rgRSErY5IBZR+6K6KY37ZyF0gn9LM/jyeNOz2qj2RmiUIBuSxbGEgkkI1+IJUZ1sA==","signatures":[{"sig":"MEUCIQCQOz96rIKtrvmjehWnwlb/s4hNkpB5dNzo/8wFw9PqfQIgFTQ6f5QtB7pjePmuf3ZZZIsUJSfZDvyE/vNKOUq6v3s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80dfccd6d8bfa5339fc5bb13459bace64adcf16c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.5_1716564161949_0.3300818574404134","host":"s3://npm-registry-packages"}},"3.10.2-beta.6":{"name":"@crawlee/linkedom","version":"3.10.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5bcfe3e51c3996841610113f444718f888d64920","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.6.tgz","fileCount":13,"integrity":"sha512-nCYK6oJDyv9In69ybeKbGQSApWeHp7JIzmAgnxPziN1qFq5sypbhuNnADSUSrjP06bVIjBGZiQCqQ5uXPVgbYQ==","signatures":[{"sig":"MEQCICAsKCzfkh4aQzHTA3GHz34TvCKXfrS/BQkK63nd91SrAiBH5k2bmZtEVOuzBVsUThC+yfNn4FJCve0U6JmWkvR4iA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217131},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"14fcec306290eb695c7e21ee823d3a12bd1774bd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.6_1716609347491_0.13490213943510243","host":"s3://npm-registry-packages"}},"3.10.2-beta.7":{"name":"@crawlee/linkedom","version":"3.10.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"de83b24633d90a3d842c3788b625e78cc3092824","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.7.tgz","fileCount":13,"integrity":"sha512-IaIXmABMB7A0KtUX5Uz+2bwqFbCR9OBluYSeuev8CN4iiKGoqaSJDCS0Zkb+A2VT/vdtyYJnbpAOkAdkXcXAKA==","signatures":[{"sig":"MEUCIFSzemO9JMJRlJddS+h+t3N/I/2dj4GkOYts9ePASoJLAiEA5mmgqofuFiDOKrcB1mZSvyahgxf/PqkrGqs9V9I9+sU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217157},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2b2eafe03921187ef1960e7a31a7aa4e81b7c2cb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.7_1716696176542_0.3972407604043471","host":"s3://npm-registry-packages"}},"3.10.2-beta.8":{"name":"@crawlee/linkedom","version":"3.10.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e94679c58f59a29c9651d878670580e527af6659","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.8.tgz","fileCount":13,"integrity":"sha512-XD/bDYXTAlujczTnKdgzeRNjttjC/UNcrCSsL7FXMy2PakB4PcG4CwhfbVPqdSRItYVY4LvgbcWXD08pPIdrXw==","signatures":[{"sig":"MEYCIQCEobOTRZ9u6ftgFqXARQ4Czp/YW7QObHs6Mw6xFAST3gIhAM8Mw4WdPwnXA6eWDtk39GWSa/pLA/V/hM+DeLgV8UVH","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217157},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ff380378eb3968dab7d4b3d9e3ed1670b23647e6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.8_1716781241673_0.5451736722548888","host":"s3://npm-registry-packages"}},"3.10.2-beta.9":{"name":"@crawlee/linkedom","version":"3.10.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c0b4d56b40695b4c3408f2bfcd2ad1cf47098742","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.9.tgz","fileCount":13,"integrity":"sha512-SY69QoSF2ZKOUA4MbqOCpRLt05MJZ79uiel/59VV5T0Fnz7Tkz2iZ23t9Zh7oIktN6xxC3wHTBN1NfjCgdc6kg==","signatures":[{"sig":"MEUCIB+i5eVCDVFtfKaIVr4ztn/PsK4vtygmZiVYfC6OE1TaAiEAhXEv/jzmfiWB8XivQ6PikqC838Br7+7oR/zXag4KYVA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217157},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9adad22bde84853357238341aa97464a3e24bb16","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.9_1716871384293_0.7392458757791978","host":"s3://npm-registry-packages"}},"3.10.2-beta.10":{"name":"@crawlee/linkedom","version":"3.10.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2d6dc4a2e9528a6750a210277f2e5460ac846df9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.10.tgz","fileCount":13,"integrity":"sha512-CAPVriZfLN155z2t70rROztdxNSL3l/hyGIJeDZRN7zRVXB0PnbKtWFi1LUs6yyt7gnnt2ghPe251GsbjtQU6A==","signatures":[{"sig":"MEUCIQD5siyIF1myDvPeD0hJfSwYGnZ2cV8H69QCOmw+DhVANQIgEqQYKr3USpjijDqE6y3NY/iY6iqHljdv4zl6LJ8Hivk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b28e9e0b73675ff2cd736da1f5ffcb3abe898f5f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.10_1716920658390_0.9131822724654235","host":"s3://npm-registry-packages"}},"3.10.2-beta.11":{"name":"@crawlee/linkedom","version":"3.10.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4378ece092ef69351e1390927a5ec6b91dc74928","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.11.tgz","fileCount":13,"integrity":"sha512-YCIVKQlrO0MvhLYdHYbv0V4Fn9aR5Yw0ufLgR5NxKLHfum68zP43WkcMH7Z7HLZlF4fXETpsWjWoiTrwafK6kQ==","signatures":[{"sig":"MEUCIEXTN93bSCccMm/XLwnRRD709eqAYBZyDOC0ju1LQmZWAiEAnbHxyt1fu3YqPUwi6E7KBD5d3XGovJ9YpzmhMjAMMwA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e44178bd2a9cbd873d03c23e4f4b104f5d70f641","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.11_1716955653877_0.495106711585257","host":"s3://npm-registry-packages"}},"3.10.2-beta.12":{"name":"@crawlee/linkedom","version":"3.10.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"73226df7aaf00cf0ba0b2289a477b93aa15f008f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.12.tgz","fileCount":13,"integrity":"sha512-C4ydlWrmOlrNPH/NWVHPX/6kPyftUKPfqXGDyp4O0KIKRCpGKFo8xwN5dL/tppoyn4h0X7//cKfA50W2KNzLqA==","signatures":[{"sig":"MEUCIQDRuYadGKpwTd6ha6FUJXHJa7YfX3mCoMwIMOjmIjvJTwIgaTmVYgBnOnDbkgcJHK68u4IRRzvpSQqgoQins837TrA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eb5823f615e353da0dfdfdb2b1d5424e1472f53a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.12_1717003672091_0.9171075892888558","host":"s3://npm-registry-packages"}},"3.10.2-beta.13":{"name":"@crawlee/linkedom","version":"3.10.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4853079af49c75bd7da2aee4c9ba4717683b89e0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.13.tgz","fileCount":13,"integrity":"sha512-u0wZFNTFL/Az2eM/yKaDN3vNM02BUhG2UVf8OTsrjw/1YLN2wuENyAogkL3AcGuWkl3ubuS/iE7F7f1K8e9ARA==","signatures":[{"sig":"MEUCIQDhc5vtqXqCkLqxtpcytxP/EA/AfQgT/3gXrzYiNQ2reAIgGUq8reAySEevjPk5H/fpdnnitT9QchqNFE3vU4+6qRA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217164},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"05add950ec3e0157e0d35a918b146648a581e32d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.13_1717045931475_0.8025735652627235","host":"s3://npm-registry-packages"}},"3.10.2-beta.14":{"name":"@crawlee/linkedom","version":"3.10.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"94c448baed7b5c4b27d1913d643c47f73c2ad446","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.14.tgz","fileCount":13,"integrity":"sha512-gKnyoSAJqQbMOCHvsyXcgLN53dappvz0u5C6fyCgWOQMb0ZgfblVkUlTGS6GX737KsiEA4xYd6Z2qVQovCKUfQ==","signatures":[{"sig":"MEQCIGkbcjnTsTtM/5PxvbxHDn/0XhD31ks0NpLqa4hUG7LZAiBrnzxcAMKVmv0mGF/7OXnXyNlMGMUx4u09w0SQY12n+Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217764},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9b0f53368d362a3d71ae09f7b209fceb59cd6971","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.14_1717130159648_0.737603280740994","host":"s3://npm-registry-packages"}},"3.10.2-beta.15":{"name":"@crawlee/linkedom","version":"3.10.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2a64ee2a916cbd27fe9cf7b53e392dc2b3851baf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.15.tgz","fileCount":13,"integrity":"sha512-NFyb9uDF+pO3Qmc/Kt2NPjWzb5NGuwQfPAdmaPzEbqS/5mmBDF18dWzc6bO7dFpD9DSMYcN7MNUxMgleXJefxA==","signatures":[{"sig":"MEUCIQCpTDjOTwAnsWIbozTEbMAe+8hTrOYs6irhj4J5ykpS7QIgbeqe/xVv/s8X+Yk+QdlCjcRjs7W0YDM0Yq5LJ1nL1wY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217764},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"93e816e059252690f47f6321fd0d70e4cf68adce","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.15_1717199372795_0.23868422334050554","host":"s3://npm-registry-packages"}},"3.10.2-beta.16":{"name":"@crawlee/linkedom","version":"3.10.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4f137e721b418a9ebf12e03aeafe412646df7572","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.16.tgz","fileCount":13,"integrity":"sha512-f0yK17nLJ0Dwns73+I5OvD7hbvGRR2MPMhba/Tka5im7/2RQjxw6L5PplIXZKVfpuzFJ+LZ2LTaXWNhGoxfBXg==","signatures":[{"sig":"MEUCIAajqZIf8+BxCmZ8aUk8r8LBMSD6LaiHTgwABJYg/UzWAiEA+xzyBWVHdSmFg+uXxHsfa9BqJpqhvFWwZoA5Rwdwv30=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217764},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f91237de921e59950a491a65ac47c612b456e16f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.16_1717298848253_0.4157028053770502","host":"s3://npm-registry-packages"}},"3.10.2-beta.17":{"name":"@crawlee/linkedom","version":"3.10.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c7753f82892e0034d36befc58adfe1d527c94570","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2-beta.17.tgz","fileCount":13,"integrity":"sha512-M9DetcN3cvYxwnjZxnJOnSTP33jtmQC3BKX4YLkuF518XOeMDSCW5c7y6wYFMbgcWvojKHCTDut+g0tTi5RilA==","signatures":[{"sig":"MEYCIQC52HtVckW4NOCG0falkG5NjjuKmp+BqevmsLFIqBmYIQIhAJRMcqiBMx6+lFE2+p4PlIbHGggcE9o+yZqk0BYBtIL2","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217764},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"230d8ea08b2a2bde7c2a6f384bdc096313b49eb5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2-beta.17_1717384534828_0.9500046493863104","host":"s3://npm-registry-packages"}},"3.10.2":{"name":"@crawlee/linkedom","version":"3.10.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c9d5f17bd62acf3ed1b9eeddec27bc7129e2e3d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.2.tgz","fileCount":13,"integrity":"sha512-vbzmZCkj/voOtWALPUh+DGhqDqEJRdvIAWhn6iZPrXkbZydlV6g8bDzjxsSbWipIzlXR7kYLHdu65MrmBwaIlQ==","signatures":[{"sig":"MEQCIFmeegBQJP0axEguSiwChCJDOEbmWL06tnqcOX0CVLhVAiArGWv2tRB96k3MdgVMfnQOK9fQ7yoQC8itI6Sm5VvMIw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217740},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1292840b97fd670f3117f32396fc22858a720af0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.2_1717405712617_0.22680379829813302","host":"s3://npm-registry-packages"}},"3.10.3-beta.0":{"name":"@crawlee/linkedom","version":"3.10.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0872a6c7b124b33307637adc87f2361d122f2e42","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.0.tgz","fileCount":13,"integrity":"sha512-kSpo3TFM7ivcbP7Ex+CywKU8dIWXqtJXcIiqq3PYoeO9sU4pGHNEpPJkzj0KrEOoO0hy8iR9D7WRBpiOgHXdfg==","signatures":[{"sig":"MEQCIEtxnq2rFc7ML8LDYnMRixGaCoyOBRYrLZvAGjFTsAHhAiA59TjG6GHpODfu+YaJ4OE1gSetPJmYuem/xEM4CJz4Hg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217761},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"727fd68366f796cce57fd74ed0f76af775718887","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.0_1717407602582_0.5663353877568351","host":"s3://npm-registry-packages"}},"3.10.3-beta.1":{"name":"@crawlee/linkedom","version":"3.10.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4ceea410ae550125a75f08a3a0c1e6bbf3e8b016","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.1.tgz","fileCount":13,"integrity":"sha512-4XzW0IMhOwpMpRiI914Kk2RhCG+GOlnUGgnAzP1WkHb/aEMYaj42JoBOKvOPjtau5vvWWDfqhIr0peZ70soxOw==","signatures":[{"sig":"MEUCIQDCBmPQHReflHzbGa/ICL0LHrJxaGAoor9oFrDSaJb4twIgNz8Yg1ml4CRZo4fEo50+pEMFGdIpH1jPgM/mg6Q+xbg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217761},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1db1ac5b6e15fcbed5e4ebf1bab2e47df0919cdd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.1_1717472452877_0.723847143799013","host":"s3://npm-registry-packages"}},"3.10.3-beta.2":{"name":"@crawlee/linkedom","version":"3.10.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2218951f90fdeedc7a24a9430023b1eb19496a8f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.2.tgz","fileCount":13,"integrity":"sha512-id3oQuWC3bAJKVcvkITA0p77DcZV1uHMc8BSpDknsEUKs5SDTTmZXzAexpsWfGsjblPNP2XY0/PidqoGqJLm+w==","signatures":[{"sig":"MEUCIEa2JystzG3y7hHThfzknnzxwyGPcCeeLsOW/1A2yUD0AiEA5EoutS0xZPzAyk1tuWj3JqTw+J4VdjqsW4Cxkvn0XYc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":234260},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6de56e7b41a79aa00990d0b2d7450c8b522a68f8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.2_1717600565791_0.5214160599289477","host":"s3://npm-registry-packages"}},"3.10.3-beta.3":{"name":"@crawlee/linkedom","version":"3.10.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6529737ba8b44845b5d5cc6637612c4f2508b807","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.3.tgz","fileCount":13,"integrity":"sha512-8DdP1NGwasW9jWnQ5iMqHXlwu1m3ZjNbIveb3ihc+sHZuPyx1cIS8IpV/A4Z2pWPPdBxBMVsqHHf2L7QLM9yhw==","signatures":[{"sig":"MEYCIQC8dPtkB+NBI5a0cXe3TP+69bIXQIwrokBIidxwQIlRugIhAL2KjKCQpwN3Ey85x8uXIHqpkRGC14JfRF1c9OY1hQb0","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":234260},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e760b8e534c941a5f82c9f37d00b41f3e109eaf3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.3_1717645881670_0.05751450842874406","host":"s3://npm-registry-packages"}},"3.10.3-beta.4":{"name":"@crawlee/linkedom","version":"3.10.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bf768cdb2e907b52e7eb48fc32179fb9a8820925","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.4.tgz","fileCount":13,"integrity":"sha512-km9XcUa2MZVMLmIE5XkG9ohmCZtCDoqn0sCg31jViP+IONAGC7M5IepJ+0hLAkGTQHwgwIAXlZm4yeGsDU3tvQ==","signatures":[{"sig":"MEUCIQDX4nP7gURLKBtZD0OvcBBhXC6RfHZTKEI9CfkpEmNMMQIgB3hqI8/54CtRBaB7dyR7JPemkk+pHopUc1q7kY4a8CM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":234260},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"450a0a96ba67e682b8c3b3e6ac7ee9d20617c91c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.4_1717666688608_0.10466221239564866","host":"s3://npm-registry-packages"}},"3.10.3-beta.5":{"name":"@crawlee/linkedom","version":"3.10.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bda0f1993e6ba1d109a2f73a2b06eec9df721ca5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.5.tgz","fileCount":13,"integrity":"sha512-G5+GZ40h5Nr/9GPomAIJU8XqBiQ1AUvlKAzwNt7tU4C8ZaXde9k5urcN3jENowyQtsjTPVXH7Q1jJxLU/vSKfA==","signatures":[{"sig":"MEUCIQCsNbn1khnzInI0O4NpHiks3OohsMxkQmJKNcJOkwo0jQIgO8N7jQzVtm75N0F+oySCyHT2RqWlC+F9nAwnJlAAE8c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237061},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f64d71e826a4d9138c12927c4580eb788b0df8d4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.5_1717678130392_0.3288700488239966","host":"s3://npm-registry-packages"}},"3.10.3-beta.6":{"name":"@crawlee/linkedom","version":"3.10.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a20c828f10944d69e85cc7f3241be68f94eb3305","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.6.tgz","fileCount":13,"integrity":"sha512-8S8ZTDFuKY3nFPvMNltrw7omUt5lmFjXVrQOkmolQJzZ6VUSnmdqIBWtHxUERA4S11ph2a2UTdPt8WOgDdPpjQ==","signatures":[{"sig":"MEUCIBbeSYjPt/z73uJ8NqfeXakSOORRrCUnK5Q7nP6CoEHrAiEA390uW1wFkKAfB1ERSRntdDHhrdHcaDfx8+1Pzyrl1QI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237041},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e7024b7af7451c76bd20b988ea9866798b202ffe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.13.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.13.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.6_1717679319037_0.37216934882344677","host":"s3://npm-registry-packages"}},"3.10.3-beta.7":{"name":"@crawlee/linkedom","version":"3.10.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"93db57dc70122c96d3782fbe086a2afdef5937eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.7.tgz","fileCount":13,"integrity":"sha512-d866eAzgbJXEVBoD82E4wLSPYWlslPgsJj6agTLd+l2i9wUDCcn1rvfVI3BO9v7L2eovPNzPjEmkFRe8K0mXNA==","signatures":[{"sig":"MEYCIQCw8Jpoi7ZOU2JDBL5WnMVp7/AWX4gg8RADufL9KlUJCQIhAInZ5etpwoVsTtBEYY3y9crQaH0BrJxoUBjiD2szZWJj","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237041},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"460b79f8e6ca9ae428d5705e4e2c689d3f69228a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.7_1717681583091_0.13115312052686812","host":"s3://npm-registry-packages"}},"3.10.3-beta.8":{"name":"@crawlee/linkedom","version":"3.10.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ac3d8cd077750267b9ac4aa36f56cd44f778286c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.8.tgz","fileCount":13,"integrity":"sha512-NFH+R0M74aagKs8MOM5BB7SP5zyuNi5umKEcbVYpszXC422jzjmI6YQFyBUNKnxf+UJf3PofZl/rf+PJJmZ4EA==","signatures":[{"sig":"MEUCIQC4ecnUpTk7GH1ctUKNme9edgbw38ArxDWzKbDy8EaGaQIgRI7NjVB7Zaw+lzNQzvSHb6kYZ2TnWIA8T/hSa8iWtuU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237041},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0d5ef28bce18fb93f6a9e7a1396159c38de4bbbf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.8_1717688875574_0.7643441901867774","host":"s3://npm-registry-packages"}},"3.10.3-beta.9":{"name":"@crawlee/linkedom","version":"3.10.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ffe3db43a91a6cef77a634693031252e110b8c7e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.9.tgz","fileCount":13,"integrity":"sha512-EHMjOObdV4iAeq27sQbCSMHMw2PrlBwYGRNcRJLQYwz1uSYnc44xmTw9QGhXZelcmbKl3r+bmnlaVZ1p5Wp94Q==","signatures":[{"sig":"MEUCIB+phjGCJfVmOvgnQL4t/xfpiGNY00RhpudG8UPdTOz6AiEAu5aQ5LHRL1KmhCXzYT296vKVTchfga47NjqbU716+XY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237041},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"44f50b164d1d4484310bae32d60a2fe3f645cfc8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.9_1717689722561_0.7286396060343163","host":"s3://npm-registry-packages"}},"3.10.3-beta.10":{"name":"@crawlee/linkedom","version":"3.10.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"86ddcbe5f0315887dac730ef7c6b50595f5d6f7d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.10.tgz","fileCount":13,"integrity":"sha512-1HyVG/2EmhQ4Kif3OPklsU1LCKmkxKvwvT+nsr1C62WubWbNLcV3m2qttEAfRLuxYowJK7sqUxyq66H4I32GIw==","signatures":[{"sig":"MEUCIQCAdwANPf8vj1gTBys2jlTmAyEClCT2vTQ2Fi456dxA2gIgVxSafQ+wphUdwOpMQkwDvUOBS0gVm+fNjgs0s6yplKs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":237044},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eb568b77771b7aad63f177354a9ed40c28c5c1ef","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.10_1717692878028_0.09419885091762992","host":"s3://npm-registry-packages"}},"3.10.3-beta.11":{"name":"@crawlee/linkedom","version":"3.10.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e3f9549964200dff85efba12a19969467c647a3e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.11.tgz","fileCount":13,"integrity":"sha512-ibiJyavkY/6/RFD7O1NfOzeyZF2djJ+xkP7fJ3By2Y4XmkTQSc5K9futJsQqjrPp6W0yoEQUIuf+KYl+nhDb8Q==","signatures":[{"sig":"MEYCIQD4HW5m+sWpdMJWd/5791l9xjyZYKm+elQPgwJjBPE64gIhALCD+Y53NRU5iSdMkDISeXWLWkcx3+N6ZzUp1cF+00AM","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"400f79c1a06cc02664a3521b2a2f25054a1c94ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.11_1717732360993_0.9449589571813326","host":"s3://npm-registry-packages"}},"3.10.3-beta.12":{"name":"@crawlee/linkedom","version":"3.10.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eb9ec9d34094dab2f68030f70f6ebce69d249590","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3-beta.12.tgz","fileCount":13,"integrity":"sha512-jMaUF3juGlFQGyQl0xJbe8+uK3q8hxt578tGHNMOk0OdVjEnc03nncbkZxvPi9Pj0DmC5zSsFdawOQ3EAZRNKA==","signatures":[{"sig":"MEUCICfKoMhKqL6qPfcl3kRq0h6ad+c4I+2J9EPdRyDzzE6fAiEA9OCfAz94mwamRPoo6HAyuq9DQ+Jt3uASfF2CCH6yK5Q=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"efccd6573de2704baaf0cb7355a411126e3fa6b3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3-beta.12_1717760688649_0.31870009884367656","host":"s3://npm-registry-packages"}},"3.10.3":{"name":"@crawlee/linkedom","version":"3.10.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"04dade575de95676007a3d290ba2867cbb780f69","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.3.tgz","fileCount":13,"integrity":"sha512-rVG7ZdTYPTezJWeidQ4xARLlVDJ/HH+1+tT10/KN+onEjNH+DdX1W5xw4LP4iNRA4zDtLfGQet4Wappw8JIVCA==","signatures":[{"sig":"MEQCIFitstJq5d7hU5YBF4wCwWKvTggTYCwGGyMPgBJk0tjVAiAsq27nZW5dWoDfiO44dyR+kaeY8oZ8bFyjTGFc4rh6hA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220720},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8a15f3bbe3b70b5a91f2e868ec23d9c4c11fb377","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.3_1717761243435_0.9447003017731521","host":"s3://npm-registry-packages"}},"3.10.4-beta.0":{"name":"@crawlee/linkedom","version":"3.10.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4001d6cdbd1d2025cce58c00b2d5d989cf789896","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.0.tgz","fileCount":13,"integrity":"sha512-F7G52PPGYrOFj2YxRLunhbhrO+YVPHT2CHpqA1g5xps/2ZKM66YwifHFMy6InLCQ6UwHnmQ+Ed0uucVyNcKdCQ==","signatures":[{"sig":"MEQCIDXtq19mgiaRjWQtwRNyYpI/J4/TdPJBUlMJ5lpUdnSyAiBHyMsSdi/IisjK9PMoJeHOY0PSr9E8t8pDefeUr+IS/g==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220743},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"81ac603c8dc4922f362dbf3ad4ff211cfffc4e6f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.10.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.10.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.0_1717761678539_0.29863586287074084","host":"s3://npm-registry-packages"}},"3.10.4-beta.1":{"name":"@crawlee/linkedom","version":"3.10.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0d163ca972fdf1928ef52cc55ef95e42f252b4cb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.1.tgz","fileCount":13,"integrity":"sha512-9D3Ojngogm6g+KT7x+srdJRP7pg9pUSLuEcp9EK7jT7iBu81Z/xydLnUa4z3DbGr3Dy4pVkz0mGQaUteZ0IkWA==","signatures":[{"sig":"MEYCIQDsE1ox8yaKKItM2UOxXW6+zf88N6YzppFcxbP/IDFbhwIhAJnmFoSp2JQfwFxXtjmGHKti6laSReIvla19DNUGhBwO","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"31ef64945385f3db3404fc2bc0f4c200bd99a15c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.1_1717820459331_0.1404549607750969","host":"s3://npm-registry-packages"}},"3.10.4-beta.2":{"name":"@crawlee/linkedom","version":"3.10.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c4cd167cd9997c49734f09f6a369bdfc13c9415b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.2.tgz","fileCount":13,"integrity":"sha512-BwBZnStPp87ODyS25Hl8oe24cmHt10WmPaafPWDsenyNchscb4XKjPoCF2axEHvp8Z1ReoZwSgbTD0v1JpiLug==","signatures":[{"sig":"MEYCIQC1b0DFXd0Vb13GTmeJZzWltQJEvXCDNj74J38zPUNddAIhALzFIdo5/ZscrjIc2hqAwqXJ2oWMUlBHvr6KyBm8LjoK","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ab052aec30e25ffc32a8dcc3233288f144fa6c33","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.3/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.2_1717908252060_0.9462869439448882","host":"s3://npm-registry-packages"}},"3.10.4-beta.3":{"name":"@crawlee/linkedom","version":"3.10.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c891e68da20b2251f0fc0214f4556a304cc1ce6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.3.tgz","fileCount":13,"integrity":"sha512-dHGywU2+pLASqVquASbNeSO826sIbghwi3f3urTCWRR7E3yMx8W6IlqwBxe2/f1mSBtEj/VOuwxWmwAz9DtzZg==","signatures":[{"sig":"MEUCID4ik4T82sI0O5/1K0hAZ4XG8Z/0fY7/Lo0m7DL4U/wSAiEA1rcPBVGJPvLZ0KZJE7GIIEIuvb5J4F69k8qTN9fw3WI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fbf5c4be884b960ef3b56537b959bfa089e9a769","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.3_1717993581397_0.014402682909723907","host":"s3://npm-registry-packages"}},"3.10.4-beta.4":{"name":"@crawlee/linkedom","version":"3.10.4-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d1947854b182598fbfc93b9c992785e0040f77bf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.4.tgz","fileCount":13,"integrity":"sha512-wuP7zbH2KJDEiuJBR9WvVt6+CYpe6GveN4ylU+vJyOuOfUO3TlLt0BJOdfpl/1jUzPgEsXEj9EIKqF5VDybcbQ==","signatures":[{"sig":"MEYCIQCAC6RUAjseueoIucbm//cuwygxN/sR1xgL3pu7gMdttwIhALJgRL6vdZsvGJ8ht4LZ0LHUj95O3OMa1d+MKqVUInR6","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"215b6d6bf37e6f9c2ced9819fce44529d0fa9b19","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.4_1718005408572_0.38433995018138756","host":"s3://npm-registry-packages"}},"3.10.4-beta.5":{"name":"@crawlee/linkedom","version":"3.10.4-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"22f4620a50000e678ef6af17699831b6201fa5f8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.5.tgz","fileCount":13,"integrity":"sha512-RoQ/7kxDudC/ZQpUqFvC22iNi7l8HuP/doeVSQysskr7oM1FOSqWpO4qRyfpoVAHFPa2F5RZbWO0l0CwyEzDYQ==","signatures":[{"sig":"MEUCIQDdUjF7aL+667LnKwPXWbOokVc8WC7K8JApPdaVnIXs0QIgDR2rIzA1TES85bUh84+UgR+z8q5OiObW6yXKH7f7DRc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80706f92c62a08b9aea4008104b56bb48c41c9f2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.5_1718006253747_0.2560821769262638","host":"s3://npm-registry-packages"}},"3.10.4-beta.6":{"name":"@crawlee/linkedom","version":"3.10.4-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"444f5f5a6e20b9661b199ec8ca5549ad06413d0a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.6.tgz","fileCount":13,"integrity":"sha512-N90/nc5Yf+WXe+hV8/nxX9EOHlwU4qUlEW7oAJp0lBiHS8uUHNv0GH2UFE+LCnv5iByXQvaoj0J1BM6IueSnOg==","signatures":[{"sig":"MEYCIQCOsbA8uYEWCM9QrBvf3EUxAm3JRcHoYhOlGwMkORFwVAIhALfIVbIa4uu2H14wh5NTwsTvruNNvgJ7r3wBZzPuCN+2","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"30939a3c09fcb532e6d6232effb74655853aeee3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.6_1718058114589_0.3842652975077834","host":"s3://npm-registry-packages"}},"3.10.4-beta.7":{"name":"@crawlee/linkedom","version":"3.10.4-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"45fac979e8ae18e803ee0a1b2ad4af8185a4687b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.7.tgz","fileCount":13,"integrity":"sha512-IQTBaEoL2YOJQ9qQ6g1WGeX1QL+7MH+N9cFiFjPwnbgN6HPHFgYQrw0n5v137T5ay6kAK58ojNYjkc3/MlSMuQ==","signatures":[{"sig":"MEYCIQDEE6BSwbXsKslVuDJJpldcvxwVz6ig/Epi98Jk/BrzQwIhANQxftu0o+6NwYqqrDB+vdpyoCKC2u1r1Bk9nRiva7m7","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"786661c3bf1b707e2d7c733c06e22d7073508e07","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.7_1718101980436_0.691619374541746","host":"s3://npm-registry-packages"}},"3.10.4-beta.8":{"name":"@crawlee/linkedom","version":"3.10.4-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6d8e04e692f6408938d8b408aea323a7c197dfdb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.8.tgz","fileCount":13,"integrity":"sha512-5O+kWMJZfc1fs4VxdBT4w1gOOjr5Te5PQUaD9ZiIEAtXuwyET8cQqNZzFVQ6oSqdO0tNLDcd1PljIouy4JR7Ng==","signatures":[{"sig":"MEYCIQCTh4Vg7EFxOd9O8Zf7qQ1xIBXLx6FhuUo5Gj3QmmzJCQIhAJJl23LJq7VlM45d6AhVSrGJUiaaOSKWJlf+AHQ24Ipp","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"20a859d6e5115ee122aca9dc48b29e1d137c6533","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.8_1718112133684_0.13129267934640065","host":"s3://npm-registry-packages"}},"3.10.4-beta.9":{"name":"@crawlee/linkedom","version":"3.10.4-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"79efb2743a5eb2976e28aaeae75e58222f6a5c6c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.9.tgz","fileCount":13,"integrity":"sha512-JB/KcICJfhhRMgaBeHP9z9eUd8gGI6PAhcrS1XD5P6lLy1AO7YycmYzlrFtQPeyMcN5mMTkuLW+JDRYVfuMTxw==","signatures":[{"sig":"MEUCIQD9gihS+zteoptKWsw6lPZ6k4lAy2QfaSVBtyvcDEfEFAIgZU23+Qj9jioRiXXnwx0kWF1P/n40DWzw2EFL3az8LrM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220749},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4a2cf544579141e829689fb8d9e933424224ec7c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.9_1718114546427_0.6543447423618647","host":"s3://npm-registry-packages"}},"3.10.4-beta.10":{"name":"@crawlee/linkedom","version":"3.10.4-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8f7c47fda9b3653c848e2103224d8ddc1f0037cf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.10.tgz","fileCount":13,"integrity":"sha512-4kE9lXoa5V7/PwE73FE0YQtbla2odSzqLxhOeDqdCrqcjh+IFwPv4StH/sLjB2Qq309sY81BLgCnjJ6HsXP9Dw==","signatures":[{"sig":"MEUCIH3q1+7+zJ9a61Sq5L5cYQLuGbwE94+N5mPaefOlgtFcAiEA2EtChny5iKOxWToX3qS2FGJgEY98GO69qA7Grpe+6oQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220755},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"18c4abb80db2dc61f2a85f334861a27732e4529f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.10_1718115168737_0.9474617251109689","host":"s3://npm-registry-packages"}},"3.10.4-beta.11":{"name":"@crawlee/linkedom","version":"3.10.4-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0aae094d74eb87602fb660f4f796c7653ae9f0ab","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4-beta.11.tgz","fileCount":13,"integrity":"sha512-bcYjrDo7vp7atOMngJ5Vbbg5TwzT5J7XrF3ZJIMTNaVmzWIfNp76s1zZn6OGkDQxysk0zDJrKSwmz6lw+45kKQ==","signatures":[{"sig":"MEYCIQDqGH/8rkDXCWdm35wnlnrty+lv9YTapDkHvw9P9s4szQIhALXO3NrGxc9b4CzMwQxx6qC+o/pdPFonyRoRqt1/Qd7N","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220755},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ef6f130e0a3975aebb4ed3bc1f985c8dfbfb82ac","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4-beta.11_1718117011558_0.7347374559999671","host":"s3://npm-registry-packages"}},"3.10.4":{"name":"@crawlee/linkedom","version":"3.10.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"240c82fdd6276cfa842496010cf32898ba340a6e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.4.tgz","fileCount":13,"integrity":"sha512-A9hXY8td9Ls5oj8q6UuEJbyrzSViE6FCW8Kky9p7nPAO50ZUreTgrEWIY9Wo6fsxhGUVEeBzgLFws9YfQSthug==","signatures":[{"sig":"MEUCIBuaNRi2+2fnzJeiTKfsXUnnxw6cgo/yrAhWlWrOVWcnAiEA261dx7AdYt+gIzECMfK19r8R2osKzZPePjD6DDOsqno=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220731},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b48e0bb05cf4a30a61204ca78492061d5c0684f3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.4_1718118420982_0.12727545784792915","host":"s3://npm-registry-packages"}},"3.10.5-beta.0":{"name":"@crawlee/linkedom","version":"3.10.5-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c3c15c8d64dc3c74b972c5ea4aba8b9571665e11","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.0.tgz","fileCount":13,"integrity":"sha512-Hw0wTBirPDu5VmFOgjunGnOTpRwDJCETA1bahFUYNtM7cajLW/3yBPBBnCCUOF9wDTOaiAUHGpXXVwDfa37mgw==","signatures":[{"sig":"MEUCIC0HNhKwWxuTDJ/LhQG7ui03kj3+XCbPyI76zJZGyUi6AiEA6NXsIo4OYvj45pMo8EwTsOhjY0Wm9K5FpxJTGrpbesg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220754},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c2c47db87da4748ff81f7fd1f790a8150a041471","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.10.5-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.10.5-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.0_1718118857621_0.4868940541796223","host":"s3://npm-registry-packages"}},"3.10.5-beta.1":{"name":"@crawlee/linkedom","version":"3.10.5-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8679053d5f7a1add84ab9c19961af82b349c308d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.1.tgz","fileCount":13,"integrity":"sha512-Nbseq2ez25Tc1xdlRXNgZGQ1d+at9UqyZIQNazK65l1o5ukhh7CHmlE+zOM5KpgbLih6/Sm9lISl+agMZipgTg==","signatures":[{"sig":"MEQCIEwlhKjSLUnh0BSUw90IJXQf6cnMVdn/Vfe0C5UereVYAiAa3thc8edkqgKjPG32CkIz13chQVvTfshw3PjOl14F+w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e677fe00e374ecffc5cda6c39e742def1473a0cf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.1_1718130896277_0.5425131145126543","host":"s3://npm-registry-packages"}},"3.10.5-beta.2":{"name":"@crawlee/linkedom","version":"3.10.5-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5cb1d16f05d5c5f5f3013dc3eb39ea4cedc17669","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.2.tgz","fileCount":13,"integrity":"sha512-W1l1eISxTXUaTY60nVxQflGA1+0LWrYfuYWpne3HYsFqN4NAbws+8O+6ednOv0pBOXOiFp16ptyc+rUnwjl7og==","signatures":[{"sig":"MEYCIQC6D9BFh9XdEIXEQ/BBSBlL14NKbp6l6t9fbZ4hS06K9QIhAPysn8bDlq+uxHNtAuYBmUrKro7WP12gsbvgcSiIgSeL","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c147b69f5f0c5c3e7102ef217994ec1ae4e635a8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.2_1718136727946_0.07161201958801588","host":"s3://npm-registry-packages"}},"3.10.5-beta.3":{"name":"@crawlee/linkedom","version":"3.10.5-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"492f464c90f11814bf0f8f7d8020fe293b7117d2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.3.tgz","fileCount":13,"integrity":"sha512-qYtETj6Zqpkq2a2nkzQmV3EOALQbSrQ6hgobEyakrMHDzjq05f7Rqhg5ZiNR3qufWreXuPtnyctDShC6BNDnmQ==","signatures":[{"sig":"MEUCIFHiSQUshqAJjiV2cCKxrcQWz5YZ5hfUzn9ycnIG7+hKAiEAxZJgHJ9jL6GVlPFhsVesu5cty0IdvBFiUgbD1ENMnhg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"559c44fe4667ec86ffd44eb3acf7b5e32b2aa09a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.3_1718142765308_0.5341423632700089","host":"s3://npm-registry-packages"}},"3.10.5-beta.4":{"name":"@crawlee/linkedom","version":"3.10.5-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c63e0615a741e03f7bfb9ec9f5c0ea54f5b9b61","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.4.tgz","fileCount":13,"integrity":"sha512-c872q9kRtNf1eaEHeHtw1D7eyDJlRwkLTnlkFjODXNs3X9ny7/e//xeStO2W7jNFHlhLTEsL37h9dqe1m3IamQ==","signatures":[{"sig":"MEYCIQDVfMc2XTMkU3xu+fKBDZStKKD9H15mLDrf7TmuuoWIdQIhAL4xBSUOcL9RajPdFPwUCNK+4g0865jndbYFV9Dd5eF1","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c4d46baf4d3c8aeb9c867ca29ce96932263220f5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.4_1718143589642_0.27218692820094237","host":"s3://npm-registry-packages"}},"3.10.5-beta.5":{"name":"@crawlee/linkedom","version":"3.10.5-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"10fade3e04ff6f5b7a43f3c27d90d7b1091b0cac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.5.tgz","fileCount":13,"integrity":"sha512-ABL4VYz801gHVpFgMeKCUsWJWGqulLabihMw7wGjCmpHKODF2PBiOCHLNqJ5vQGBsSI41xgdj6mzOakSSbr5vg==","signatures":[{"sig":"MEUCIQDzcN9tNPA+RfxXiuXLEad1n6GcuinzmIQFeelzbDGioQIgMwo9bCqjWjcvCJllctURbtp5Wdrv9npxEADKpOzErNA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"82793bd4d5314a2edf85f05eea0b4ad2b15d107d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.5_1718157168398_0.46016835553146285","host":"s3://npm-registry-packages"}},"3.10.5-beta.6":{"name":"@crawlee/linkedom","version":"3.10.5-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d252ad26959ce9e3676e3c3998e9edef3adb4fbd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5-beta.6.tgz","fileCount":13,"integrity":"sha512-AR6Umgvrg9IQJgqR1cbbSvBsYKf6+gEeAL7Ust6MfufHnz1CdfTwA9tH+bdMrlYO1ix6rDVwYo8U7L9cZScCtg==","signatures":[{"sig":"MEYCIQCDqypa7hvdoFUG/WXwKV1GkGlo2mWzH+eOQIHaGAHtPQIhAKl2HDCorvi9xbM5K9i0ozaHfQSVPZQqSfS6XRvb4McJ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6cf22b04181ce4ef22d62c880d6d2fec33028c24","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5-beta.6_1718162019424_0.09084156020391099","host":"s3://npm-registry-packages"}},"3.10.5":{"name":"@crawlee/linkedom","version":"3.10.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8606adbe9ea9484e167de7d1eb3c563be91c7a6f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.5.tgz","fileCount":13,"integrity":"sha512-/VVcaClkYjITFk9yGdkO7k2sUF2hoEuBqb96eS0dcrRSp0i374LCW5yMYSOAgjSDmWKeV6/iuhDCj1zFwKNKaw==","signatures":[{"sig":"MEYCIQDsRLmLsgbB8tN2P7P+meNG4ln38qlHNQp8BlSAV45nFgIhAILTyzRJ06mHoXMsUTl6kewz038U2/v6kmqiZj5obS1t","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220731},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"20387a52f571530741d7c8d8620c8ad02b9ae225","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.5_1718181777634_0.9171710814617899","host":"s3://npm-registry-packages"}},"3.10.6-beta.0":{"name":"@crawlee/linkedom","version":"3.10.6-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72db0e31fd2b31a2ee351ff5810c295f5f960a56","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.0.tgz","fileCount":13,"integrity":"sha512-QWr7AzOr95MSSL523aV0MZ5J+435VBdSgfJ4mE34GMtGwLg78nNSZSU9AgGiO0ofrHRhARYxFengQb61xiKgHg==","signatures":[{"sig":"MEUCIFzfDm4v8KnXsUXFVu/bHXnApmAxJD5g1pBBwLzI8+3pAiEAqx7Di1bXQthCWPIkW4MUEKc4v0gZCXHZBrS+v+1DuOI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220754},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"58f02d2600f8b6cfb188f829348f06c457b1fc00","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.10.6-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.10.6-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.0_1718182231630_0.5088130089763523","host":"s3://npm-registry-packages"}},"3.10.6-beta.1":{"name":"@crawlee/linkedom","version":"3.10.6-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"07c761fc4b774585f235fdae78f034f12df40b89","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.1.tgz","fileCount":13,"integrity":"sha512-hoae/6npG81agqLrUkmZaJYxfj1EXVZ3kjKDCw9t/ACxSgfQcsrYAX0PgqSG2GZUvxFroQW59XfIQDJvK5B9OQ==","signatures":[{"sig":"MEQCIDqqcEaaZaUCmy+dbmPL/2bsE5Vju/P7JWl9DKHl2TloAiAsrB535lWQp1ZiMXSduxCYkFMo95YTY52V1VFw6zdMgA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2fd17deaf87bcc45df5d670e9d696ca643ff51ef","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.1_1718210025337_0.7500915547429146","host":"s3://npm-registry-packages"}},"3.10.6-beta.2":{"name":"@crawlee/linkedom","version":"3.10.6-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f909863f8fc21289f91665c1c50c2db65c69787d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.2.tgz","fileCount":13,"integrity":"sha512-IIrPRi++SBRv0JHrZE8JXRG3nZ/FWud+TWuj7OynZ7y0cMpxmZ6FfRcscacdfDp8pkcpmmiS3utVdD4rbeblKQ==","signatures":[{"sig":"MEQCIAavK5yT5ebBbBqYgpWe1xYAa/FcTF6CqQavV7iVzNSQAiAiVmWX68jJJR7erAWx3lcAAyXdAi/cVJB3q7YtkIegTQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220752},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"200b0e4201fd83fbe5233e786652297356111b7c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.2_1718257080238_0.2621653755351596","host":"s3://npm-registry-packages"}},"3.10.6-beta.3":{"name":"@crawlee/linkedom","version":"3.10.6-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"227a6a7910ae16917ba511bcf1699805376a1a68","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.3.tgz","fileCount":13,"integrity":"sha512-dSn0gesTUaLDQlW1AV0Gi5tsy2KzWvjnSLndne+SfF2G6brMiGtWqYXcPSWWnxy3rwnZ6FhtNZP+xRauWuFrvA==","signatures":[{"sig":"MEYCIQCnLD4aIqkGCmSt8B0qaBLT2pSh2fI0ORzxB2sepYPosAIhAOMNPN+7eeXVO1e43bgF5jxkGY2k19umgRyB80bzA3eG","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220152},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dad92ebdb67adcc814e8d5322efe08c44a3c4ccf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.3_1718425934754_0.34848038970312767","host":"s3://npm-registry-packages"}},"3.10.6-beta.4":{"name":"@crawlee/linkedom","version":"3.10.6-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9af804b11e81c3a1ba6845508f60268a8d07940d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.4.tgz","fileCount":13,"integrity":"sha512-TJEV/aEuJAAJ/+vco1wLzDw0vQxyf7HZBkB0Jp5yspny9UsmghYv44x7u1mwKgEhCEm9XDmlkD+h9Waugv5Cjg==","signatures":[{"sig":"MEUCIGdFae1vaw5UNKg4cxG+nTDbzdsv5zewDtRJD0qk07XhAiEA4fcb9CoKP0rxglDnCnuIw1zql0GzOCkOuh2xFR//e8k=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"05de30fe00cd3f9b513f317c05fca4470ffbe1ce","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.4_1718507921848_0.6567803887660877","host":"s3://npm-registry-packages"}},"3.10.6-beta.5":{"name":"@crawlee/linkedom","version":"3.10.6-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"50a3ffd62a9cf82ff784044260b73d625f0676e0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.5.tgz","fileCount":13,"integrity":"sha512-VEhRcM2ANf6ZR76lkbDlbvyei4/IArL7uLBn0J8YxKsbNrQu4Td7M1uHvI0ccX/+IPWuw6cMS9/Bxn4heFBZCw==","signatures":[{"sig":"MEUCIQCOkCHmLORrd0s9W12DTMMEBk9UHNMyzGehHFSuntse9QIgBeIxlNspIK2iRqxF7zJlRXGo8CHMNVrJ+6LulI2oXA8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"afe4a7c0204816c16d018c57afd13cc2a4716a0c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.5_1718594347393_0.6655113729556377","host":"s3://npm-registry-packages"}},"3.10.6-beta.6":{"name":"@crawlee/linkedom","version":"3.10.6-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7736f4c1facff05955e6519df394f565d72ea490","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.6.tgz","fileCount":13,"integrity":"sha512-ZctgCpmfARCrGdYpMwrZLE8p9Cx0qO7FdGvHHVu3EoA7+UO12istwcVXRlok/9eIfMEoVu76aQECNsqrXRcoDg==","signatures":[{"sig":"MEQCIF0has8I/2SC5EObb7yTE95Waccxy94CMgpx8vZ88Th9AiBBluQ1QInvKaZZ31W9FUsCUiy7f674rqcOT36LaWvzjA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f775fe6d2cb0f45fce8d216f96f8bacb4c8d7f84","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.6_1718631368612_0.5354073324613584","host":"s3://npm-registry-packages"}},"3.10.6-beta.7":{"name":"@crawlee/linkedom","version":"3.10.6-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"406fc5f2744b9f4f78d09bd9cc49ca7c5e1021ad","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.7.tgz","fileCount":13,"integrity":"sha512-fPsCK2wWz92PDv2keYX19Z/Ug03BPK/1OYeV54TfL3r+UalDdfKpe2+XbraHmM0Ue2ikNwWkDBKrBlzwNAHRiQ==","signatures":[{"sig":"MEYCIQCMBlY3+vUHNtLKRuWyYEEYGNEaQx/j3oriRJdAD1xuYwIhAMruFnPVGp+Lxl4e9LzwiAzWqVTlej3eIHTtWGFn/D9b","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cc21c2f066d41b19f85c9ab3c7b65a1126ab77d1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.7_1718730827744_0.2612771433608425","host":"s3://npm-registry-packages"}},"3.10.6-beta.8":{"name":"@crawlee/linkedom","version":"3.10.6-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a9dc13ddeaa37e2f9b4f9f1d8ff9a0bc2dec66cf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.8.tgz","fileCount":13,"integrity":"sha512-keaPinH4Zfa4eR5T2xabzZtxLin6l0lC4mn8HyFKTl7onlwYeRJE5KdYNMSK6c8VuQdHYVP7mqj3InayfmK5Aw==","signatures":[{"sig":"MEQCIEn7I2zBs9xCJe7j431/rL3lWPWMsYVZijVrqnGkZ4SuAiBfkGzf1X7iwevwNcwA61hJP9f1Corn49Ez1Su8WtJ/xQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"425ac7df8c30ec37c65d44ad582db4b287025c54","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.8_1718772544508_0.31674307645249344","host":"s3://npm-registry-packages"}},"3.10.6-beta.9":{"name":"@crawlee/linkedom","version":"3.10.6-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81478736582be85c79f8024b53e9ea265af460dc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.9.tgz","fileCount":13,"integrity":"sha512-Q9xLW+dCi4fVSrxksrW42CT4wOhgy1ijVzqzZjdst07KwX704uqO/iK/FiFwOIW3VhbHxf/i86rv1nEY2UzKig==","signatures":[{"sig":"MEQCIB0zlqnHU5oNeXpI/3PomGHsq9j4XxCX4TXYFXO1pxwYAiAuUqNUV+/5xLybGX/04e+69LeHEzvxuP/3IBKs0KkGew==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6b5d2191e84f70bfdeefaab013c03710dad73ab6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.9_1718855197555_0.8438241559750896","host":"s3://npm-registry-packages"}},"3.10.6-beta.10":{"name":"@crawlee/linkedom","version":"3.10.6-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1230329f606a09706a84d9fecf2d2957938f0674","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.10.tgz","fileCount":13,"integrity":"sha512-Gc88vFGohbOwVu5KyeI9RnMXE/LtR6E5OFKdMcTU8BiP3x5JfVnkIFE8VHFc4uFPK8Bi8OG5U17YirNVYSDEgw==","signatures":[{"sig":"MEYCIQCatNMNzcRAO2CEezbm+08Qc4HnLaakZyG6XzBK78dY5gIhAKgz37eBCTMkc3ESAzm06E+4DWRI0CbDplmlkgdPUMvK","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ed33e71a31880b2160dec8a49909a753b6097cb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.10_1718886991043_0.006376236308278882","host":"s3://npm-registry-packages"}},"3.10.6-beta.11":{"name":"@crawlee/linkedom","version":"3.10.6-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.11","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"de40ce154b2bb04625af1ac3e85c9b49e1735095","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.11.tgz","fileCount":13,"integrity":"sha512-mBBGlS6VLD/z2/IdSdR3Av6dYJrXTr4rT7yxqS8J+NausMoDIldfnvQESbBevg6M0p0axUp5lWBQWDmO++QeCQ==","signatures":[{"sig":"MEUCIQDkZPC0EBdU6kc495niBmeqGVIvU5RTpC/7k6qAo+Md0wIgUC321REkGi7mbqg5OSdApI2tLDsDsloQGt89+0KTJbE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"087998d14373f8b1b4104ed69e0352ef64348c76","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.11_1718923127708_0.8494893407068158","host":"s3://npm-registry-packages"}},"3.10.6-beta.12":{"name":"@crawlee/linkedom","version":"3.10.6-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.12","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7644e4175d7df5b9776e2882ab59f4801aea3164","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.12.tgz","fileCount":13,"integrity":"sha512-zEH9KT4f8Ew1PblvPqb00RD/sCTS+jcBxF4llKgKNey6p+nKdrRZ/XlhKafeyc6MvbpLCUOb3jL19B3P9uIwWQ==","signatures":[{"sig":"MEYCIQD+kK75R/UA0ZNuGxEwsCbMZ2ky+kKG1lCbOtZkivHcVwIhAJeePEJBOvSXKUSXz3pS7xyaSmDBY7CHFerD8TeT7KVQ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":220163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"164ff66ceb4f8054a24d337238309fbab9f48938","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.12_1718973834273_0.1731122133115237","host":"s3://npm-registry-packages"}},"3.10.6-beta.13":{"name":"@crawlee/linkedom","version":"3.10.6-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.13","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0e601f8aa217a7e458ed0ff8381d918d974f350c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.13.tgz","fileCount":13,"integrity":"sha512-wu9TjnWR9HNy/NhsO0bX7fKWl8WqmnR7bpQ571WzEcl5/RYiGFLNpYqgODz3V7EfBXzARABm1kjik2OP31aSYw==","signatures":[{"sig":"MEYCIQCDsyv0p+7AkaNUR0AAsMq7zR7exdWicJHCwWlLWWXYGQIhAJiVyPG1/geR4isHrxwj2B6c8eZ7glv3px8P3KCULLnp","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209899},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"15fa44cc09462c67b892d854cb9a705ca4332f60","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.13_1719031658879_0.8252441496750444","host":"s3://npm-registry-packages"}},"3.10.6-beta.14":{"name":"@crawlee/linkedom","version":"3.10.6-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.14","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a2229139844f80218b73074c6eeb3fd86a861074","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.14.tgz","fileCount":13,"integrity":"sha512-aCy7ocSXmeMahI9XNESHym0xmFXESyX56ZfSDsD9FIpxTVcNkvcLYuTJYdul0s2w24Tjms3bt7eEriwRgJI9qw==","signatures":[{"sig":"MEUCIDTDnjwmTYw42ByYY9OMKWwaE6b7vZa8WjhKBfadl+9yAiEAxsVvzHZiy9ojz9dW3LHUN4wm3oSNRX9JbF8o8VdeYX4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209899},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bf560cf1d6a0cf3915e51f9ea6bcf893869967cd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.14_1719113167258_0.4371214110467867","host":"s3://npm-registry-packages"}},"3.10.6-beta.15":{"name":"@crawlee/linkedom","version":"3.10.6-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.15","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"48ab5961f1ee5fd62892470cc94f0ab13624beef","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.15.tgz","fileCount":13,"integrity":"sha512-vXK5DQm3P7pY4n7av2WsIE8kpEo/VxHIeh7fA9CednuRpiDUGyIrdDzrc9I+QPPq8FRz3f2f1S2IPahfAAduZQ==","signatures":[{"sig":"MEYCIQC6E4wT8WIU/I9SeqoxsZ4ra6WehfpazsJ9eP77GLX7cAIhANOnDYNe/FphtSbCMMtFIYXruiP4QTD+PG5wER3K8bPa","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209899},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cbe0dfb97e3418c41fc98339ccc9ed2c81d322c0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.15_1719212944601_0.39210051863199213","host":"s3://npm-registry-packages"}},"3.10.6-beta.16":{"name":"@crawlee/linkedom","version":"3.10.6-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.16","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b229990b20e3a10dc66cc122a0294ae21827e1aa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.16.tgz","fileCount":13,"integrity":"sha512-66+bjgJn7xDx6ZouCJMvhP6XW9CJjRVXVPLE5GbBlBQBJG0sIHkmmjBVPHjoFiLCTpRUHhfDO2rVIpENV0W9Fg==","signatures":[{"sig":"MEUCIQDV5r5b66GYMT+zEVJBMqtUlVS4J9YxRz/mT5Z0exjUHgIgHR9a/Yrdn1Tpsp6n2cGD3ekFIc4lkusjS0qneA5E0ro=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4e654d35f2c269b47fac2853e938d736b7710a8d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/8.1.4/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.16_1719228372468_0.6123482504430959","host":"s3://npm-registry-packages"}},"3.10.6-beta.17":{"name":"@crawlee/linkedom","version":"3.10.6-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.17","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc8aff19c32da7ee3ac45d91aa44040ba9b912e7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.17.tgz","fileCount":13,"integrity":"sha512-U54HADSPoVAyqUU3C7JvC85XNUdTJsdxPIkcWKHREmqDFCAc0F4Bg4IuPmSOIIXLF8SR/pYrG1qgTvqZ3LYrEA==","signatures":[{"sig":"MEQCICjEQZnXiY6p5l2MFGTa6D8FXtzGMh8MQEqrTi9Dk5CgAiB2OC6ms4gGxGBFxzNgDQvQ1YZ+3BBbwYHnF/QjLSuwQg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fb02d84a2c6524c321d82352a920bc54e53721ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.14.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.14.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.17_1719377492188_0.19457893712729502","host":"s3://npm-registry-packages"}},"3.10.6-beta.18":{"name":"@crawlee/linkedom","version":"3.10.6-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.18","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"44ecd42c6838efd23fab52138cd83ecd1e072ef6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.18.tgz","fileCount":13,"integrity":"sha512-InKWLdatstAnI+TTX2Sjvj0rbhJE2AcGzQ0+QURzZMv9gg36pt+Yk483nBKp41EejbfVFEhO0Q6tgEEnSZK7zw==","signatures":[{"sig":"MEYCIQCn7VSOmlcJIT7UY8RFKpBJPDKVeNBJQK+/0AuTUjbzjwIhAKEf6FunAdIDuWEQ1nHHuJxXCnNyFxicI7IOCPOylAZs","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0b12c44f0322cb991265bad3759c8fa08d61178","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.18_1719582882889_0.8740643095798244","host":"s3://npm-registry-packages"}},"3.10.6-beta.19":{"name":"@crawlee/linkedom","version":"3.10.6-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.19","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"aa79cfa61f72ff33da8d8d5c6298f7154a8d3438","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.19.tgz","fileCount":13,"integrity":"sha512-OCcgoOEeBhA7+S7KEpZzFvopGNzmIPPvnTYf4LblL6o7ZGPqhel3j03RxnMheJU42KDJXI/AVALlPgNkdJJG4w==","signatures":[{"sig":"MEUCIQDzJk6+MR1duxfuWpJ0lhKV/Ob3RLMlKOxQ+CQQ8k6JtQIgMuAEbiYXBLLX0azrObhlpPhl38kBjlriSoBsTcPArPE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"84afc08ee01db696471c5e99c182fd8bbb217b44","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.19_1719634069200_0.8808809283014163","host":"s3://npm-registry-packages"}},"3.10.6-beta.20":{"name":"@crawlee/linkedom","version":"3.10.6-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.20","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b6f354f14a2c2c62d5ea165f354348a84746d7f9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.20.tgz","fileCount":13,"integrity":"sha512-8jJ+9n+154M9wPWaROI09VSlUgNfs49VDdQhP9m8rFkgGsqbt6wqyvwGX1+Y2oQAWR9IAXQs10OxXhDRkAuIwg==","signatures":[{"sig":"MEUCIBwfhCwbf7ghtRSlAIdRmylNqaeN3nnwtomImmIEimOjAiEAq9Qn8s5X/re4gkpy3i23jJVaObP800PR7BqwTOEOFTY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"727094022a36c55e97f9444c88050e9e7c05933e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.20_1719722223996_0.008738032073403401","host":"s3://npm-registry-packages"}},"3.10.6-beta.21":{"name":"@crawlee/linkedom","version":"3.10.6-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.21","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"574fb37b2724b3652a38fdadab135002d28c55df","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.21.tgz","fileCount":13,"integrity":"sha512-qSWs4GHMqMS0GI6ZjyCqPFS5iqKjgcxdMZcTFOxxa2t0UiBdmha4rxQRvROFaFuuEOFFmK4QRqTANlDr973d7Q==","signatures":[{"sig":"MEQCIDBGGeB4ZI5ccVPn34lwpbfoRAIiyNWrxIxUwlNjzLD0AiBv5/0M2zEbwhSMkmUQJXM8KFHJ2twSBgAdgAQQeoljRQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"25496c44bbf97dd3f1986915a60fb5bbb754b79f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.21_1719909349799_0.42638760098866557","host":"s3://npm-registry-packages"}},"3.10.6-beta.22":{"name":"@crawlee/linkedom","version":"3.10.6-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.22","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"67dde77743c90809db01e605d3e7b4764be54f2b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.22.tgz","fileCount":13,"integrity":"sha512-XwNq14uy3ptR1iEqsace2QuCSYSqoPZMqlvIsAiO+AUPlHX1Ca+TlCYDLcZAf/vOYpEbaC+iKQU00UlGBNSGYQ==","signatures":[{"sig":"MEYCIQDr+zmesQ8XSojG7p1WJbfo9sq7zBbQTP6mYlcev7kzngIhAId7cXW8L69TeCzCKUdXFG/DZM/scCoXqZITcwGm7Q2F","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"adfde63fdc19983da25e9ccd5ca320243106f12e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.22_1719919268308_0.9229732163388833","host":"s3://npm-registry-packages"}},"3.10.6-beta.23":{"name":"@crawlee/linkedom","version":"3.10.6-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.23","contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"56d6667c27752405decaea664e87f98a589d56e2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.23.tgz","fileCount":13,"integrity":"sha512-UjwlBSdcUMhexvA8F5NPBIj+20+i29vXdQtdesXsjap9OHXBntoWjAQTt2TJT/qb0A4rNEd2Z70pbzFFfMMS6w==","signatures":[{"sig":"MEUCIQD0ycALTB00BpH1CrFMbbYnlBuwbHExMRtCFXe07uR6PAIgD00qp0Qp97VO6sxEH5MNnZ3wBd9sYVdNXqFgFVRVU7s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":209903},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"206463d05f260058e8dca7bfafa7a2e5757a23e9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.23_1719921344026_0.3309075751127959","host":"s3://npm-registry-packages"}},"3.10.6-beta.24":{"name":"@crawlee/linkedom","version":"3.10.6-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cbf2ff90e249d5e6cd27e7333cbd55aa6ea88627","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.24.tgz","fileCount":13,"integrity":"sha512-KMcoBO9zxa9U1AkL1z4z1TqhLYTQMcJG3qKkyHfpu/5U/gRKaKAeNAOJXXd55YkShmjjFxb2vBDKhOV8kuGmcQ==","signatures":[{"sig":"MEUCIEjVUD8XUHmSyClJzYovkmsFAD/psF+bRwBTYJbYW1vDAiEA5X5oGuc/EuJ9c4iPxP6KABKdxxOlSOEi7MW4jZf8zQo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210089},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cf47241013a1cd19d7662b5761ce1b79b9beb565","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.24_1720068486173_0.7591567675234618","host":"s3://npm-registry-packages"}},"3.10.6-beta.25":{"name":"@crawlee/linkedom","version":"3.10.6-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dd46af65e16f172c1b8c2b91d8eef061bd00df54","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.25.tgz","fileCount":13,"integrity":"sha512-7MgPG6ZwCIP3hfP2Eez/l35vx8HKpelpld3fUL5eqQ032Qkhd042bxCUES4XwXe/yEys9GfEmqMrIU62ldf1aw==","signatures":[{"sig":"MEQCIAcr7lsypFIYytrPPffPrimTWBYGX9/JUARBveIwuSRVAiA+TQLDbjOenGYUNygymoGQbfdIYkU5S+HHt5379yuXrA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210308},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e8a5d51f0fe0d8f151c570c3ac07d1df68b837bd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.25_1720091771700_0.23586218579652574","host":"s3://npm-registry-packages"}},"3.10.6-beta.26":{"name":"@crawlee/linkedom","version":"3.10.6-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"43415fdedab7a73f5d25152ea0d988c98fcafb68","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.26.tgz","fileCount":13,"integrity":"sha512-tjxpq5GTvzhtmJjq+Fw/Tw1KE/kv5CAvBl39JJXeXjxptYdMZTfPxaV0IK8dGTlFZ1SkZUljVknrbHRTCostOg==","signatures":[{"sig":"MEUCIQCvqsKblfTSR4GSlxsLKo1Xe0h7aZIv5KEwAsFKoECTagIgMr4HKC/WTTB2ZKFSiE4wVTh0UBKJy+0LIX8a8Kj65UU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210308},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f6d0b466a3bde6f8528646fe1aac7ce8a26cf45e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.5/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.26_1720156211977_0.5716426322878165","host":"s3://npm-registry-packages"}},"3.10.6-beta.27":{"name":"@crawlee/linkedom","version":"3.10.6-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.10.6-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d67b0f271cb0d502b37363c0831efeb46ad5b6ca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.10.6-beta.27.tgz","fileCount":13,"integrity":"sha512-URuSk9uPu7Itqy0liKzmpqRfCVSWdJW9AUbTlxQMcJSPuKGayDGJBqEh6BOQS6TmQh+KI/46R5X34AG0ObO16g==","signatures":[{"sig":"MEUCIQDiCo95HqJBwVp3QO4A+JK3PJAJS9mEXgzlssHb8RoufgIgWan0yslKXQqJlJrB7Ed299FW+/4IuvWPD/JyWtMbjks=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210308},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"65aa16b88ef67285357bd2dd1c30612f040a8d7c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.10.6-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.10.6-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.10.6-beta.27_1720498056689_0.3292156710898424","host":"s3://npm-registry-packages"}},"3.11.0":{"name":"@crawlee/linkedom","version":"3.11.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"59afa64e4cb00ad5f5b8fb7d0e3c0ad8727b8005","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.0.tgz","fileCount":13,"integrity":"sha512-0hfS5APu9C480umtgV3UU/ihW/SEb/GS+IKyJYBJ3m1dQxXW3f2odLv6/KVafxUgDnDiFujfE3Q1fltql8iqzw==","signatures":[{"sig":"MEUCIBRXs8kclfUHS1DzXVe+JVSmBmJNG5s8/OjTJzeSFzadAiEAq0zJPEQgEskFRVm3bF0Zw79MAMIORyeNUIUerh7qqfI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210284},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2357c6fcf10f78e59bdbdf76ebbe8f9879165e07","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.0_1720531893950_0.689772176719988","host":"s3://npm-registry-packages"}},"3.11.1-beta.0":{"name":"@crawlee/linkedom","version":"3.11.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"78b57a094328cb22b3aeb89ef8221529e7cc006e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.0.tgz","fileCount":13,"integrity":"sha512-jjv8ReaZF3jInWo6hLAVgFrtVzJtnOui8Wty/TVeygEyh5YTOVCdkcvdQU7aXlv+HEqLFwZ7rIEGEvUVpUduVA==","signatures":[{"sig":"MEUCIQDjpp7yLI71vBHAylEQGqqiQWgoZ6xTK9Do1T9jKHOEvgIgZZu7zDXWU7AxbLYYSLjMx0zIdcKQHn6fLV6exR3DbOY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ab2aa4640f351b4926ff30b86667e20eac09b6c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.0_1720711759899_0.7857496276899887","host":"s3://npm-registry-packages"}},"3.11.1-beta.1":{"name":"@crawlee/linkedom","version":"3.11.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"df7d939dd0e901592220a4aa10b7c207adbce909","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.1.tgz","fileCount":13,"integrity":"sha512-3vDsaoJe6QRRuI0hVizMxhY5s2LlUH0hBRWT5Nu4QeEoRenzsRRawrrFQOzbnZV9Jf6DxkpQ4QsA0uPUUrUAzA==","signatures":[{"sig":"MEQCICMqXCEXyc+O93nGuxGhQIGD9tlVjSsIIQmJL/+kgQ0oAiAfts2yYfK8VcDrOnCKgoEICqNQUyU0VuoEpm/n4390Lw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"273b864b42100697f2cae32c2c950b0658897654","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.1_1720730389438_0.8829511683896571","host":"s3://npm-registry-packages"}},"3.11.1-beta.2":{"name":"@crawlee/linkedom","version":"3.11.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0206e76ea4217bd40db6da9d18a751b4f9b2116b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.2.tgz","fileCount":13,"integrity":"sha512-1l3bXf0xbt+qvyu8pZYmfQm1qZpq9oiO3xdwnFPNZtQWb9DzTlDoiRb9ICAsAoWdmYQzBkYAOGLyW8I77lg4xg==","signatures":[{"sig":"MEUCICo1FhzJbCXR7gMNjJnZa9aIqoyWReK3LvkRgJ2B2NqcAiEA0d6AIYXJcsLyZ10V6qupMcESRR7kuru/fzrzZX/560U=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"526701b603075cd90277592f87f9bafe354e385c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.2_1720754234665_0.3074849797925079","host":"s3://npm-registry-packages"}},"3.11.1-beta.3":{"name":"@crawlee/linkedom","version":"3.11.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9998c0b7956b438f512d5ca8eb61defadab1fd3b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.3.tgz","fileCount":13,"integrity":"sha512-Qxd+c4cpjlnCKe/iue/b/3RHk5iicy6Ze7LS8w4aBz6CmiWQJ6Oaxi1Yo0PTvmUN4qZrgXLsw6GIGQ0ik7BZEw==","signatures":[{"sig":"MEQCIFMnkQDkjBaQoOl7srj/rF22eFAcpIyOfpqPzz7SS4oVAiBmSwT3usDd7FpcnhVZVHc20NutPUNSZXN2U7FwXWlOWg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"29d1e235bd6397b3d443c1014f0b488cf263b66b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.3_1720934085627_0.2673388387840223","host":"s3://npm-registry-packages"}},"3.11.1-beta.4":{"name":"@crawlee/linkedom","version":"3.11.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f2b26acfd3d9a784b91fc831e9511707b64eddad","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.4.tgz","fileCount":13,"integrity":"sha512-GWgSsGLg/gpxIBbo0fD+fQSfH/gRCa3xgbT48E0V4PbEnETrT46NUh4Lf9NAwXgeiKhhW327yUiaTFsXbhlq7g==","signatures":[{"sig":"MEUCIG2EasQ+mfMsNB6vTK/0OcRgrZfeX3NW4lX4RDEO/PF2AiEAxCIeBhZCGpfUDl3P6FGPJdPjqXqaz1b2DNgBaNspYb8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9e47be6850c80a644693a8e41082fc1a9edd8c72","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.4_1721016311145_0.6095321718557358","host":"s3://npm-registry-packages"}},"3.11.1-beta.5":{"name":"@crawlee/linkedom","version":"3.11.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"547b8e0cffe4f2b1576fd4de678a695f1afaa283","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.5.tgz","fileCount":13,"integrity":"sha512-Xl57e0o2BTHt8remK/0ZnDjBYG05KKj2mN9qtZT+y2CJG3P+1k49FA2ZPguNUuZB5RpuV5c0hU3hbu1rXO+KLA==","signatures":[{"sig":"MEUCIEvrFubpFwa5j9TC2c8o/DkEPdVzO+ydfv3c/yStACQ7AiEAj0D+LKgfkadrYVGzkRK9VSI96JNHqgs949Wc5983QxE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":210535},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"74d02efe20ee8ff0f80b08279e7df44c32166486","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.5_1721105293897_0.11013848784958569","host":"s3://npm-registry-packages"}},"3.11.1-beta.6":{"name":"@crawlee/linkedom","version":"3.11.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ecd33d2eff594ecc0d481a66fae43b13f7c0ff1c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.6.tgz","fileCount":13,"integrity":"sha512-QVCCCJzbCiCQafoj078F9pT86H8M5RUqeDQPl62DIrYWQUjUgGyelDZAmWKIbXENWG8rLknBzvTXXdXl2Gz+Wg==","signatures":[{"sig":"MEQCIFCy1FS+dQQz+xFGw87sA3jcZ38XlOeY44rT2mtZxi7TAiBqSGOoHOJ/TdXLw/cUVdcbIsLwF8YFMg9O5updp7YNYA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212449},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cd5771843dffabce2a12657a0052e551abd9bcf1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.6_1721187906917_0.9641553129443214","host":"s3://npm-registry-packages"}},"3.11.1-beta.7":{"name":"@crawlee/linkedom","version":"3.11.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e37e624ee40c253cf958ed41219c3d2ff4092ee4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.7.tgz","fileCount":13,"integrity":"sha512-eFgG05rYr1JpSRRkI85FCiHSOETdmxGh0DiNbPGIvb5X9ssVopVjm22vQHXD33gh+UzMaQG1/RaP5YdopUIg+Q==","signatures":[{"sig":"MEUCIQCApgSBneRVVZsTi7CvJJsjFTcnOheQD7HjyTUsn06YvwIgMry76QIRdufY3MfFjbQX3eEwdYoZaUezQn4yBiFVvNU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212449},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a1d9268bdc6d19d89e738196e976dd4fc0a0975c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.6/node@v20.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.7_1721202922628_0.09060501813644883","host":"s3://npm-registry-packages"}},"3.11.1-beta.8":{"name":"@crawlee/linkedom","version":"3.11.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"918ea4cc0bf65af9a7f0bfefd2e08e2073d201a8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.8.tgz","fileCount":13,"integrity":"sha512-qJ/2+ffP/QLku7eThjg7oSp+Zo0MVLMVS2PCVBoUH2NTeGLBJWP0FOCsC3BFsrmmE71+mXHhMd1aFW+LXlJWIw==","signatures":[{"sig":"MEUCIQCPIkrwusDLWo/bQfFLA35TmnfGdzP59pwtc48A5rjMUwIgfAKwfPFTZ2KpmKZCqXcT6PNWwVLKmWsR3GCmcJyUhs8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212449},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f539c53884276d55bd1cc0af3c4d96cc116f8a4c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.8_1721689993955_0.44571547495640096","host":"s3://npm-registry-packages"}},"3.11.1-beta.9":{"name":"@crawlee/linkedom","version":"3.11.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a114fd5f9eca57c2ecb2f8ac44301dba1a18387e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.9.tgz","fileCount":13,"integrity":"sha512-5EI1JFdRG2JJmiqrJYzJ69N+6yq2mw583cwPXo0zsDsH7aEdu9bVYqoYWzETSrBUISxOXR2IkUF/1flhNwkqOg==","signatures":[{"sig":"MEQCIDc2II7IaVeYs35H36tytJY54MEa88SNolAhqwUBVPA1AiAYeTHAoK9lBowTKPhczb+DvXcI+Gd/yTEuxTx3QaxUZA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212449},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"54d8cab889b02252a103599ff8fb4b87ca9ac358","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.9_1721794445625_0.5944911525980496","host":"s3://npm-registry-packages"}},"3.11.1-beta.10":{"name":"@crawlee/linkedom","version":"3.11.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c143c485c36a61188a729b58ed81836050bca844","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1-beta.10.tgz","fileCount":13,"integrity":"sha512-1lp1iXm0JdCJL33L7xXK+4bLjjUvmUKO5ttaTynoB6NMi5DuutqPjSHe4es6oV2kR8Zw3dW/PmqgZXnxa8wbHw==","signatures":[{"sig":"MEUCIQDsu9iJJeAUma1Ln0bev3RvQCSsFBJYnVwSjgoIPWgfKQIgDbAVJH+8/GIdaR3qwXw9YgKn2CzYc0OsahNB9YARhjw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212452},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3ec395c64170770f72da52a8a4d566c3ad40eaf1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1-beta.10_1721811293293_0.9097405687033597","host":"s3://npm-registry-packages"}},"3.11.1":{"name":"@crawlee/linkedom","version":"3.11.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"583610a5d70da5c4df4b7b9aefcefbc08e2e3b82","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.1.tgz","fileCount":13,"integrity":"sha512-Ete9ShFBhKsYOQRcUEs8GB+Tkx7lDVnr+QQs1hw+gdemuXChX9Nppo/Iz0OH8JYWh9nZUOyTvvqrrBJLFKWtow==","signatures":[{"sig":"MEUCID56Nym+0dOsNeQGqLYEqqqm6Tv26WCH2hJG2RDiqk4yAiEAwkIvdyKq1Cv/9auYDJxujq56EOk4smKl0QWA9dH+JtY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212428},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1ace5c607085efb25169f61473cc3b26d7956be7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.1_1721819222499_0.25832657355743005","host":"s3://npm-registry-packages"}},"3.11.2-beta.0":{"name":"@crawlee/linkedom","version":"3.11.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"283cff0288fc7ecb2a877b490ef9de07b772d14e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.0.tgz","fileCount":13,"integrity":"sha512-/+6PMn7AOcDomFc0oQoz6dE9I1CHeRy/9OGv5nF7kICAlcj2Nmd/8mByQmIcio/gLmwN2xeZVQ88I7J1oDSKmQ==","signatures":[{"sig":"MEQCIGDu+1Y641xLNA8Vj30eRJMe29+lyZQxq3u94UaZKYGxAiBxLupZCQhv4evbve2ZYcGLuOl2/8WXkeIF/nmduaZoIw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212451},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"accfe84e5ee2eb6d43c8fcb67a04417283810dfe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.11.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.11.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.0_1721819658320_0.4034196870394211","host":"s3://npm-registry-packages"}},"3.11.2-beta.1":{"name":"@crawlee/linkedom","version":"3.11.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1a09f321501421943b86375b611fdae23877e62c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.1.tgz","fileCount":13,"integrity":"sha512-wt0CeVB/I3BbNW955s55JLko/77Eis9juyPMs6o5EGs4FUycmL7IEWg7KnUleINKzNabPdJh38gLFMrEyg4f7g==","signatures":[{"sig":"MEQCICowHDb/NpKnzFhyS4H0KnQ3/05SiKKsuI0LtJpGzLhXAiAA3gzQu+4N19htwTq6kShOENtasUaetjMk3DWYbUzW3w==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9377ebd89b095e0bd400c15fce04309a81eed38d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.1_1721878764481_0.9098982940249978","host":"s3://npm-registry-packages"}},"3.11.2-beta.2":{"name":"@crawlee/linkedom","version":"3.11.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0530849920dedafd2ff6969858cfb2caad82ab10","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.2.tgz","fileCount":13,"integrity":"sha512-V05eUig63pQtVw/FT9j/1J7KpEVpwv1ea9gSNckFuD+vYwPBBRYM27J5cm0edqOqtd2b4vPhwW2fLt2vC+ZTTA==","signatures":[{"sig":"MEUCIB5Omn3MfF3KO/8h+TcuCmKkGtcDW9uxntUiN9UdWkQzAiEA1tmygE9n2i7+y0/lylcikyxNPn/4pfRTufJpBlaBnn8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2e3867fe7871f8fccb2c5c37dcde121ea66aabbe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.2_1721967352330_0.9686594058900326","host":"s3://npm-registry-packages"}},"3.11.2-beta.3":{"name":"@crawlee/linkedom","version":"3.11.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1ea8917e5c21f73b930536859925a1d1680ec951","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.3.tgz","fileCount":13,"integrity":"sha512-qBXOlEveWiKYQXXNYfr18wSQqAzJcydEgz+rn7rzJvq0uh0ZEBLyROdGqnZBsU/3FIOrckoHsCOXPjd8QqHunA==","signatures":[{"sig":"MEUCIQD5XN9u+J4rnsZpaHzTfKNHyB660+YAaBu914iqRDcBpAIgM1wKjhR2HMJsy3TeE6a/pug4vo9YRd9XqxiQyWAwigA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bb8b8a65d985f4be455808def2b653cea7d89dea","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.3_1722051617460_0.33358289916986794","host":"s3://npm-registry-packages"}},"3.11.2-beta.4":{"name":"@crawlee/linkedom","version":"3.11.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f18e4b832e75ee6fed8f7088ba63be0565b27299","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.4.tgz","fileCount":13,"integrity":"sha512-s6vggjD01aNzyDgI0Y8dEGMIlarQarpfYWmvWB3Z+884b19L3zKCZAw2fKzln2RUK2MLsjk5rp3GM5ux9EgSJA==","signatures":[{"sig":"MEUCIHdgK813d0G00Vy/a9/irApKaEvgPeqAJDVTM8mHr7okAiEA90CYnF+Jd0c3qZFjvjKgM9xYIIeFbW2tazD5jxg/0zU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":212425},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f96f316df4b698d431627e13030e6dc25d14b566","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.4_1722142630248_0.5680678549760445","host":"s3://npm-registry-packages"}},"3.11.2-beta.5":{"name":"@crawlee/linkedom","version":"3.11.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c60d1175b415a97624ba6a9abe690e8ba81dfe85","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.5.tgz","fileCount":13,"integrity":"sha512-9AAIvUqomNWx7OZ7x7vrtcQ+UVU5wBTbuQac8DMyiRfZpX0qDLA7ENSmBf5pwyztRQscnkvgsFzeVL/kMwmHYw==","signatures":[{"sig":"MEYCIQC8+dAndrQeYhITt9tKgHUnrsBN3HWcYEmxgeVrqCOl1AIhAINZKiaesJ4rAdX6TW/C2meo4QCirN3HphBkJW5rvZex","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213251},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a8c47fd4cf3fa32ad728983310601455c5543a98","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.5_1722230620704_0.10378175294694136","host":"s3://npm-registry-packages"}},"3.11.2-beta.6":{"name":"@crawlee/linkedom","version":"3.11.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b17288acf0cacf479df19c1410846fe3a641c95f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.6.tgz","fileCount":13,"integrity":"sha512-AD4Bg/ZB3cTogJfSQLwy5yI4m5rGRuUCWGqmLmyy+1nAvgZS8eB/JHv48fTBQWd0UlFoLshOireKOVfYrt3dJQ==","signatures":[{"sig":"MEUCIGu5mjZPditSnDE6841tKcA5ExCJ2+AD6dx3WHgegwRMAiEAwYNzzGz7zI07WbroX9hK8R+oGc31/O6PcA9BY5FeKPI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213251},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"735435caa710e41d860820f3925c38cba9cb209e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.6_1722312089981_0.9564484022582955","host":"s3://npm-registry-packages"}},"3.11.2-beta.7":{"name":"@crawlee/linkedom","version":"3.11.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e5762c22c2f9dbc679df175626ea287fdac885f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.7.tgz","fileCount":13,"integrity":"sha512-xDibnkBtNJnVv/04GRLs36yuwP6sXp2/VKJ3JxcprSw68eN9QJNZOc7JnO0GGR6wmhqQ31G35cj8NjzvCNc3Gw==","signatures":[{"sig":"MEUCIQD5CsmS+pIQmSzaC9Fm/Qzk6MaPVCk0l+nMYM1m1aD1DwIgHPQo4hdAjwudJ+Ok0C67o0aijgvdpRay1YtpSBZCx14=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213386},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"618665a0291a4f49145947f06110d6e38229f65c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.7_1722400896236_0.3455417329619377","host":"s3://npm-registry-packages"}},"3.11.2-beta.8":{"name":"@crawlee/linkedom","version":"3.11.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"362290265ab1d9261206d2a66eafc4938a2dd997","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.8.tgz","fileCount":13,"integrity":"sha512-BMMnbR/BBWgXc4mBXm2tOB7VzmahTPLHN/Mq5iinFDvdxQv8ha9ojQtGpheY/UHEXnoiORpYBZPgrHzLQAe+XA==","signatures":[{"sig":"MEUCICKc5vPmdi5YgCpeBsPHc8pfd5SGSV3MJEQO/FAV7HenAiEA/W7KbrOf1aEVIPyTHLqg+D4JhThkvqWbpSlaRQ/Muu8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213386},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9c2d468141a7f4f9fbb73a5749d444d8a1aede16","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.8_1722416263442_0.6057424984102815","host":"s3://npm-registry-packages"}},"3.11.2-beta.9":{"name":"@crawlee/linkedom","version":"3.11.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"46a5a060a28f6e5b01d8e6c8206bc1da244de9b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.9.tgz","fileCount":13,"integrity":"sha512-xs2iVUlG8E2g6Zz0Z0Ib8QWoVjH8Pt82apQHsVOeeaAfX1WHthXN6pPQkzYaOkbrwNh4EHCDsPROHxot5vsHnA==","signatures":[{"sig":"MEYCIQCI99b78TXKYBO+MU5TlVKXAmhC09NlCcUIbBWzFHwc6QIhAP0nhaR4Q3vrwgoF7L9o6a5zkBJlNUgbCxS9SQs6h2Vk","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213386},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6fbc134bd85e2490756b9ef7b52396eade5e5080","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.9_1722485438386_0.9977802162033733","host":"s3://npm-registry-packages"}},"3.11.2-beta.10":{"name":"@crawlee/linkedom","version":"3.11.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b36b1159f563a9defad6c19d47d8559c75943835","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.10.tgz","fileCount":13,"integrity":"sha512-79qPCMgpcX9A4W3FXAmbVkcBNywxFstINkJvCk8uK246PMdyQLEVPY2o2/00oUiNLBtEUCpx56vRXd4FQxm3qw==","signatures":[{"sig":"MEUCIQDNGRZWC1kMzc+5ylYkPPHWliARDnSslPJ1EutGnTx7vQIgRBZZzZdPsAgxprH9a183xiLfWl8RL+U05dentn0yfLg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213389},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"77d619e06399f96248e2a026d4943757806bf876","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.15.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.15.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.10_1722572402450_0.05025264502264237","host":"s3://npm-registry-packages"}},"3.11.2-beta.11":{"name":"@crawlee/linkedom","version":"3.11.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3b032fdfc9100bbc07c41f5af56bb567e8de5249","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.11.tgz","fileCount":13,"integrity":"sha512-J72t31L8JfPclLtQuYlOKdD9iZ11mv/Iz8peYPVlSMYOs/I/QsJ1ciOrzhJUh2N/964lUHGy8vcIPVXTnSzBaQ==","signatures":[{"sig":"MEUCIAW2uZnoV46oU+IN9yia8mmc4WBd7f8JCyhcd3DaW31hAiEA1uH6AvfZSUgwmCliZD+dYWBZKfNYQK5QBO2ZGeZuUGY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d8845dfa6dd9f121382dfd63458843998d718841","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.11_1722656445577_0.6229750684592861","host":"s3://npm-registry-packages"}},"3.11.2-beta.12":{"name":"@crawlee/linkedom","version":"3.11.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b19ff9085f7486e8d42a0b18a12b3979e614a56f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.12.tgz","fileCount":13,"integrity":"sha512-JempdLpHx7NAiWFnW6eLV/LpS3sf0y1ORUNiendD3cP6gQyyJhDGGqGTLhDFbNwdrzVzn6ScYj9idNFKYxPBkg==","signatures":[{"sig":"MEYCIQCbEwCQpzTRqHLgLWRA490fOB3ew5dZ61WN7PauBNu3swIhAK2HVxOA4flTxbt269Q0oWtd96cZci5DBMIxs4wbATz2","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"55b1052c9669883a6dc90ccb0be092aedee74678","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.12_1722743637562_0.04722323171957066","host":"s3://npm-registry-packages"}},"3.11.2-beta.13":{"name":"@crawlee/linkedom","version":"3.11.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c41ec08389514ee6abbb8eaffa55bb395097d64e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.13.tgz","fileCount":13,"integrity":"sha512-1l2gA6UTkadq/HTc21LVFWLRs7UwLjjLHvYfsZnwAeg+HOo6r5A0SXYH/CQo3BZDtNDo0vIiOeU+ELmNEgRnhw==","signatures":[{"sig":"MEUCIQCYUYhju4Hu2upt7mwyOwYWbJT4eUgp+GoP31STC2CAUQIgddHm0OifVPQSR68tTPPSVb7XZ5TRwmmSEmT5axGA+NE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"498db43ec99a47b6d539b845cfc60ec3214d8ac4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.7/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.13_1722834903120_0.4645172193397411","host":"s3://npm-registry-packages"}},"3.11.2-beta.14":{"name":"@crawlee/linkedom","version":"3.11.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8cb674454f3ebf2707085f70a01a9e0c36bc2d3b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.14.tgz","fileCount":13,"integrity":"sha512-P9W6BD7a6CJYZyX/0oKGHBfm3ZyyQR1Js1LFaOaqnlZarXTey73lbRBK+klKRGy9kMJvArJEdF0FfSTesfUeiQ==","signatures":[{"sig":"MEYCIQD1L7v10+2J+o/2wltG05YhM/dGatdhZGmD9lAQ8V9wRAIhAITIzHQwm9oawg5ZmnNijK9BEZJVKBc7imYjE/VnZvzD","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9950b69dfd88d814e36f84e24f90ac78106eb4b3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.14_1722915925814_0.9138231816492397","host":"s3://npm-registry-packages"}},"3.11.2-beta.15":{"name":"@crawlee/linkedom","version":"3.11.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5c529f1eb5a97437a28eac485b95efa7b1001db2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.15.tgz","fileCount":13,"integrity":"sha512-NUBF9Xd7LeehJk/dP9FDnU2QYMq1W5kT1NgIgOpsejeyf8t9u0EzES2TevxcUAsMo2VjZzwNdAALuhY+R52jwg==","signatures":[{"sig":"MEUCIQC9NVi3yG4+DmzXbxF3qZQOXn+EVIns+KNePmTd+HPiKgIgeghNAjXoZj1wgxvoxyTagxHwxEngW4pIh9oJVQXiJZY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"304b582238af94b0b9e98d31458e3af696caf4c2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.15_1722939601790_0.5095220852067086","host":"s3://npm-registry-packages"}},"3.11.2-beta.16":{"name":"@crawlee/linkedom","version":"3.11.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e8663cfbdbf9091e06816fe6a881d404865c81d0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.16.tgz","fileCount":13,"integrity":"sha512-LBL3GF2qUQQCc/D8ozmGq+uTjStGJUCNn97tJFrqzegEmCJc2fwnlG1R9ebNF7EZcIICvDj1FPbEjjOwBLENeA==","signatures":[{"sig":"MEQCIGb9RLcP0h2xg6kCMTVS4xingwLNofURi7/zaYL6pquQAiBLEG3ij2RzPe4EwBNZyQwTSAN+Nr9aoofGynoEOB4ZFQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"69c9baad727994e2c3cfa6ed8d1ea561089c9ada","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.16_1722944184610_0.7149045112103036","host":"s3://npm-registry-packages"}},"3.11.2-beta.17":{"name":"@crawlee/linkedom","version":"3.11.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"979961717f07bb24d05f33a407a67416cc5fdc64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.17.tgz","fileCount":13,"integrity":"sha512-gweWpVh4fYU0RzzbGVLxsMgn+BMG9KmdR7DWV03yNokJvaKcPXzO8fO+U6AJ9LsIrNkxB2CBAdUAlT4T71zcCw==","signatures":[{"sig":"MEQCIBW4BhTfjhoc5HNhjngEquDVu2CA3Sx3Qe9tD24h6dOKAiBCSUamDqlL3X59VjNzGx/xGkBhgO9fnZqRIrO/k7IXgw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213379},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"050ea4c84faadfd780cd61058e15aea6808039b0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.17_1723003245857_0.5770875566877147","host":"s3://npm-registry-packages"}},"3.11.2-beta.18":{"name":"@crawlee/linkedom","version":"3.11.2-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b9c65f836e9b779eb8a85823885b53535eaf31b6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.18.tgz","fileCount":13,"integrity":"sha512-j97eelNm8fg3woLux6KHZ2qLitK5mryoNdrLEE+1ReiOy1DimqJAynTJQdhDAA0FpuEtZmQ/TrSwo5eBzKMAhQ==","signatures":[{"sig":"MEQCIFMd05sS7PodI4tTnB9OokjzwJnWijGgmpjuUWSbm9ylAiBHNrIDHEHHDukcOQYFMi6w3VzsIqFPc6OqeHcrNIzY3Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f3b601cd219b7048bb4c0ffde5a76788666a1299","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.18_1723125494213_0.9205678296370776","host":"s3://npm-registry-packages"}},"3.11.2-beta.19":{"name":"@crawlee/linkedom","version":"3.11.2-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e76d3a007479c2a0a23df8829368d32fd49c83a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.19.tgz","fileCount":13,"integrity":"sha512-c2rQh80tCGaBLXC5uidKDyV29VlYlAn+gHjA2LJxldQHTrEAyWdLKJyPWbdLj+haGVYPwqO/hw2cvAm7v3D6XQ==","signatures":[{"sig":"MEUCIDm852L/NNLcql/yHUxUtc/kdLLItlMYhaKBg/AgcGqtAiEArsw1rX09KKLqz0BYnrp0gMHjyWvm6MDuGHSump5t+vs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"08f469cc0ab3c82981e410710caee66fcc1a4b6a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.19_1723468052211_0.010289966671357842","host":"s3://npm-registry-packages"}},"3.11.2-beta.20":{"name":"@crawlee/linkedom","version":"3.11.2-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"750243a88b23e578388cfcf43dd82bd5fea12c0f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.20.tgz","fileCount":13,"integrity":"sha512-zr0/uE1ncvgJ7GcGvpMPCjW3xUPgEq5AGMHB/ZKiR/KB375xq/exuYF/hG7Hf1atMwodcn7NE043pvdXXgd/Pg==","signatures":[{"sig":"MEUCIA5Kheizhno4/IbJIjf/bbU5sociFcRffZVgHcUwvO2RAiEA+0/CAn+6iC7i1vaqi3e9nXhVKzEAAdK7qHa4IHjeI9s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a64cb63063c22c81a786ce33a6e9fb8a17c110c9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.20_1723492462671_0.0994617916432956","host":"s3://npm-registry-packages"}},"3.11.2-beta.21":{"name":"@crawlee/linkedom","version":"3.11.2-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0527b7923bdff15189b8fedee8f6c7cb766e2e16","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.21.tgz","fileCount":13,"integrity":"sha512-lbfV7jTnKE+EeESfcJszRSClLRqfhxvYXBijSjYUKLN5+XSeXMrjdn1atBQnwCApqxlI/JzNDOzii1tKG6CwcA==","signatures":[{"sig":"MEYCIQDvIaLwvVX0FHaWcWCL9spKnJPWoNrGQPKTN/5Bc35eggIhALyAgEYjCF+W/lM8+K5Cl+PvL9QFjBcy1RPGRE2NPJnj","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3a400adeffc4149a3ef41dd1c07d51c5492d5de2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.21_1723594353437_0.20503358823008155","host":"s3://npm-registry-packages"}},"3.11.2-beta.22":{"name":"@crawlee/linkedom","version":"3.11.2-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"92d80dea5db124d8ccbd50be02a2d139fe2e3f2c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.22.tgz","fileCount":13,"integrity":"sha512-URsq9MFgw3NiCqmf//4ceMKd25mXT/HRNF9qK7ga0UxRk7W0e/LATxeRUQVGXZtWIm44ch+lYzDPYn+dpxXeIw==","signatures":[{"sig":"MEQCIC5viuKBVk1qGrWCMsFDpbnk9iN3uYswo6DsaVHfAp15AiAJqU4aZLpH+WxiuqGTq4i4sMXaE4eDPAEgDmiRr00BVA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1bab91233e0edb48659077ef21f2b7080747dce4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.22_1723610048643_0.2910393014081285","host":"s3://npm-registry-packages"}},"3.11.2-beta.23":{"name":"@crawlee/linkedom","version":"3.11.2-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"96192f6342fe02d8a45e20f3a32e4a816df9a610","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.23.tgz","fileCount":13,"integrity":"sha512-xdT5dHRAcKmqJbQ5xGnTa81EXEXNwkgB/EwcF+fmvUIGV78jLM29AHlVOh4tLbb0XFnoiSNgimsluxeXza/wNg==","signatures":[{"sig":"MEUCIQCBhX/QonV0EHJylZ70FizwxTCFMR8irgi1MgC8+VqAdAIgWfMOGvNpurPODLyhmh0FE83nWoSsHyfeSM53hyzvv+s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c95cfde5df42eee511ff6d5fdad0a9569ca3d5ae","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.23_1723694090909_0.8578014934435851","host":"s3://npm-registry-packages"}},"3.11.2-beta.24":{"name":"@crawlee/linkedom","version":"3.11.2-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"335841163a3f8efe98099218184c9bcf7e18241b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.24.tgz","fileCount":13,"integrity":"sha512-3ZbgHkE6kaJm8JIkkkbz0oVvkBu+HbaYx2Q3BJwFNAcR+mZUlSjEs318xdSfciZDoxR0YI2tTa7Uw2OmZ0ChPw==","signatures":[{"sig":"MEUCIQCcMJbbqZsCDhhKtiUEf08WBcMCLYXmdjQxOsKru8tcKgIgFn0LVZCEsBYhId6fuqSG3xyHdTdW38FNSH+py9TXM1o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e0ab1f7e9018366c77b4a957e82809578bc4f5d9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.24_1723715895861_0.1900710968918402","host":"s3://npm-registry-packages"}},"3.11.2-beta.25":{"name":"@crawlee/linkedom","version":"3.11.2-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a84dd8fe4d6c8d1812a9f71d40ab8b9614e0fe4d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.25.tgz","fileCount":13,"integrity":"sha512-cU9Poj3kpnHfzRynTNuDOT2rjoNXXfaFzjVva3g+zEyemU8FcQV8t4EhA0l9xqobR6NDgVOhwHUqVu4KlrfyUw==","signatures":[{"sig":"MEYCIQDVgFZnl3r4ZUdzQlpujD/8O7wR7mtEEncHOydYr9raSAIhAIlgKFGZUxT5rUh9JzW7BFG16S9HxCarsb6mh+27ZTJs","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213375},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3e6d190fa8346754867ddfeb7060c6539dbcd559","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.25_1723777877108_0.259420564900706","host":"s3://npm-registry-packages"}},"3.11.2-beta.26":{"name":"@crawlee/linkedom","version":"3.11.2-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"190e1df9f8896e452577e59ec1441150668a08d9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.26.tgz","fileCount":13,"integrity":"sha512-r0mcEqogyKOgr7CMxkGKnCYboTyboKGVD3VH6Pvox8NR2aJxKf1AKCjKZpR+mumzzkjw5gfmeIiHdLi/CIlBOg==","signatures":[{"sig":"MEQCIG6p/9KwnQHVV1NLXTA3SnLIky0Z99oRIIcqU0FfY3gzAiAIAVTMmoCJ0n2PJrn8dKIfiujTAWaYTBObYmHZkJUeFg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213385},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4e774e1e3f89ed0fecf996734a93c24ba0292f84","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.26_1723805676714_0.6404735511509225","host":"s3://npm-registry-packages"}},"3.11.2-beta.27":{"name":"@crawlee/linkedom","version":"3.11.2-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f40c8f7b635ea12540e250fdc0028b2c7d41ffc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.27.tgz","fileCount":13,"integrity":"sha512-Iti65B9xYxzMUKryhPkLIC7NVgVQDDOmYeKYRy53LPTQHXTKdrbAaOWplnd6bXOOEGS3sxZ4eCRv6CvpI0sBlA==","signatures":[{"sig":"MEUCIQCxNp0gkLlVFilWzd/BBqdXiCaYB8mXI/PjZLTyRzdHUQIgbzjAykJrHhNejDwmry9seNdpsePgi2EqoE+QMDUodRU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214501},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f1629cc7254530c4fa18429a1a0aadd6d7c6680d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.27_1723955168621_0.9261623850920313","host":"s3://npm-registry-packages"}},"3.11.2-beta.28":{"name":"@crawlee/linkedom","version":"3.11.2-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f9bbe414873f02af9c13030ea5bc76d00db62432","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.28.tgz","fileCount":13,"integrity":"sha512-cXclPVDCJne2kwL9cSA3l1bmFWUBVrAiJQjNdbOuyD1Lrq23XFf4hCE2EkDGt/WS9cJkABIyNJWvszkmVYflUA==","signatures":[{"sig":"MEUCIQC97h87Q6dwnLAw55banqOtzmiEqTcKtEU4PsmEN5Ha1wIgANbwp5cmyw+Fn319FvljEArcEhik/bhl9rrM/uubihU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213940},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1a9b0c18f2f49d1a778b3fd2270a03bde53da5b2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.28_1724040348217_0.04636639152187483","host":"s3://npm-registry-packages"}},"3.11.2-beta.29":{"name":"@crawlee/linkedom","version":"3.11.2-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f47c859c5c60612333706476b75a56f7663bf174","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.29.tgz","fileCount":13,"integrity":"sha512-VoO0z4xul47m5G+mbt30vd0UC8C7lG2p3dYHqdDMVDt7X9VBFEXK3MeJNUAWdUYiuYg4HHD0lAy7akDTlPY5Zg==","signatures":[{"sig":"MEYCIQDt26NZG3KFBzHDxhApqEwvDN4Jbc0P2fyc0QozG+u/9AIhAMJOZnfFzPri+JhY14EuYJxJuo/TLgiCaJZ9RF/loOSL","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213940},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca91759a8ba4808d85482a9f5b6b4bb0b09a2f37","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.29_1724129741837_0.6070192831141181","host":"s3://npm-registry-packages"}},"3.11.2-beta.30":{"name":"@crawlee/linkedom","version":"3.11.2-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cbb430cb9acdb53142c7ceebb027dd02875befcc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.30.tgz","fileCount":13,"integrity":"sha512-jitxRSWphxQCV0PODpuCllVpqXTPg7+Ro3G9fX1Sdy1wzXgcjB+Z3kbk0IeNCQsus0QNX1T/nOdWoJOpc2d7Bg==","signatures":[{"sig":"MEUCIDXNp3guXrVdU0LyCH5cEVuAJXM1SXBk6MK60thR/uH5AiEA2gZMdlVclqCbDZVqBPKTsTdBQnRfSBS/oEMl1LeFV5g=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213940},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"877bcf0bed2d94b5844264d6ce071f8b60738701","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.30_1724387849574_0.06652559904843836","host":"s3://npm-registry-packages"}},"3.11.2-beta.31":{"name":"@crawlee/linkedom","version":"3.11.2-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"13ea2b4dc7cd43ca464c6fce7e61db216b109466","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.31.tgz","fileCount":13,"integrity":"sha512-iucqXRK3IOiDuVqt+bohcntA5NieaZYRPo6cae9ODvXOrR0CHUeIB4We9r3ZCLGf4I/nYfHmF/wHrU+S6IzlkA==","signatures":[{"sig":"MEUCIQDzW6Lizhc33RCMW0fOb1BDFzD2mMDzDsbUzgklWdQTuAIgT2ATztRMoXH7KApjg2O7U+IHPWZX49p3jlrF4upcWrw=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213940},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2a25f2edc34f756691c8b51598d6ee142e5d0880","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.31_1724478258613_0.4064939789138027","host":"s3://npm-registry-packages"}},"3.11.2-beta.32":{"name":"@crawlee/linkedom","version":"3.11.2-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"df29166865ceba1489efb49063887206cbc4657a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.32.tgz","fileCount":13,"integrity":"sha512-wvY8hhhthIU3UeByl9pnrBwrMqWJLNgGJfttH7LIm4kamqjXdaJLSAApLk3BoJulkEjGHV6iZhwAhfrFOIAkMg==","signatures":[{"sig":"MEYCIQD+9HYQdI/K6BazWEfgwcftJDB+eC8miKavAAg+wkQ3/AIhANJfhWF7bHaMdDzO34vXxvpXiSzJDyFQsJtVxCAFGLkB","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213940},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32424a5c7e3a8b98582042c6e5b392b04c36ca3c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.32_1724563263888_0.45126796876745523","host":"s3://npm-registry-packages"}},"3.11.2-beta.33":{"name":"@crawlee/linkedom","version":"3.11.2-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.33","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"565fabe8c41c11340316a711730da9de4cbe720e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.33.tgz","fileCount":13,"integrity":"sha512-GPWYr2W4l4dcKkyPtysm/x48zR/LLQMebn1Gta05UzZ8/GNI/cmWgwEUryAqTQWamZLGgMGqEhIPOhSVZp4yVA==","signatures":[{"sig":"MEYCIQDjo7osYGou5QsK7IApNW939Ogun4cjNr0zOa4zp16WwAIhAJJduyR9+iJH1sXx4ofd4oMeQlo9r7F0j9L6b1hPpSLL","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2c30867c7b23b988d8a1e9db23a92767eae75fd7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.33_1724664296006_0.196999685344053","host":"s3://npm-registry-packages"}},"3.11.2-beta.34":{"name":"@crawlee/linkedom","version":"3.11.2-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.34","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a192ee24c026ac190e6991f69f3b34f306106e7e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.34.tgz","fileCount":13,"integrity":"sha512-/QbFCuLlWAuMNBz7qO1nTOBhwtELXZyL9oeim76ez3pdJvLvHgV3RT1KrFBv4piX0PUGlYCAxkbowrY2xZP9uQ==","signatures":[{"sig":"MEUCIHtILCgN9rmEJ+xP5Y8Q64Ngyji4MuIzm0wmeqr13d6sAiEAqeB8m3K6RsXhWDI0VEnvO6XEdLNIg8QHCUZIh7LTiSg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca5693aed1428961e8639d30c0041009089f7fae","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.34_1724666861658_0.36247967631959854","host":"s3://npm-registry-packages"}},"3.11.2-beta.35":{"name":"@crawlee/linkedom","version":"3.11.2-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.35","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6f629e9c9668966bbcd66c9b90b08802dac9ceb7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.35.tgz","fileCount":13,"integrity":"sha512-7Ia3ojSyzkIIdghZqicjBjwPzL3G3i2PqXXFCldKXjLBKmtLj9j0U7wzrsu7k/gRFwq+hh+YFYY1TdokkHitGA==","signatures":[{"sig":"MEYCIQDYj2JIuyKd6vDrwHYterBLkxEVND5Wyc1s1DvWfIK4YgIhAJkU7WaEtXTYNK/oM+roFzv2IXBLW5YueVsNxT53bYev","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"955d9a574af0c34209e3a9768b691413409c7a66","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.35_1724668084782_0.7551859591377974","host":"s3://npm-registry-packages"}},"3.11.2-beta.36":{"name":"@crawlee/linkedom","version":"3.11.2-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.36","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6a3f542ea21cfaad522626d04be07c1734f48bff","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.36.tgz","fileCount":13,"integrity":"sha512-WApSgJLs5SzOIQ1aGSNOI+btRCbqLQ+9+3jVn6kDOghZkynamnKZfxlHDcrum3Zq+n0q4fM7N9FwAox06JKGXA==","signatures":[{"sig":"MEUCIH8GX6TYCbx8++HsQzPH1Uv8RtBpGNNeJRLcSkqhTENgAiEA6Z7FIt2+ZQq7V4f55TuXTb71GSCussFKhaWcCZghRU8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f7654a5d64a36ee17309c081431a16db5f68efe8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.36_1724732305844_0.240091589451783","host":"s3://npm-registry-packages"}},"3.11.2-beta.37":{"name":"@crawlee/linkedom","version":"3.11.2-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.37","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ddfa7bbb64c092bed09c8bf8c771293ab2baf600","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.37.tgz","fileCount":13,"integrity":"sha512-wLS19Wz/68O/8jm3qdy0s0c6q/qUs8XLSaUm+Bxrg2Ofv3X8iwHzpA4eiL3iXRPKB6KgZIJ05LQlZSiqa8itRQ==","signatures":[{"sig":"MEQCIAyXm35kyZ427NF/aBid7mJ5YHZu/75/XKRu/kRYuBvLAiBjgKNskgebP2wg60CVuV88E7vwzSVnOZxa/Z0ByJ1wjQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"411e66194c7df571aef86aa9ccc09700961cd419","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.37_1724817245529_0.06433218670727281","host":"s3://npm-registry-packages"}},"3.11.2-beta.38":{"name":"@crawlee/linkedom","version":"3.11.2-beta.38","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.38","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4752b448b5b9bff5816b3412fbc166ae51d9d7df","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.38.tgz","fileCount":13,"integrity":"sha512-ecyYMd5xSmY+XLulsZpzaiXKL+njGO6wDQcP0PHf8lrAHYr2pdwrfzcCMEVTBRDoVDy4VX/tOrm4LG8oWSlwag==","signatures":[{"sig":"MEQCIBrmnZVnp2U9z92y95X+gXerXPWLxYEAPqugCDjNReNVAiBCkd/Z+vinea1Pqq5knxboOR9ZEHhc3sYG39bM4fr6Qw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":213944},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d90e76fcd8a8ef831db53ca14d1a8e38062ae5f1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.38","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.38","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.38_1724845517977_0.44887120871499286","host":"s3://npm-registry-packages"}},"3.11.2-beta.39":{"name":"@crawlee/linkedom","version":"3.11.2-beta.39","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2-beta.39","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ca8b087192e37166b7b232af77f566f7fa142813","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2-beta.39.tgz","fileCount":13,"integrity":"sha512-f61IEf+Avqeu9D9zH7TEkNJO+sztX1Z66Aqre7WMUsRCVK0QIP0FNGwqwMNhxnrAB7CDwEzPaMCVF3n0PJm9/Q==","signatures":[{"sig":"MEUCIBYvXp0OuLr5acyD24oRdR93Atb1cEp4QkcHq7VYWG+aAiEAn6qfYBurM1MFHSxDfYbD8F6P64u21F/dtC6+MgH6ICc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214101},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"975b9826e2ee06ebf4d87df50d245fc7c724eaf5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2-beta.39","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2-beta.39","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2-beta.39_1724846756700_0.8267609527194835","host":"s3://npm-registry-packages"}},"3.11.2":{"name":"@crawlee/linkedom","version":"3.11.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"15b409f7262129b3a0142316dc6bc33758d808ca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.2.tgz","fileCount":13,"integrity":"sha512-3kMiRAzBP3OlisclvDYykYpuOd9umW7YgnBDt6D1RepMRZqcWPVtFg6Ei9MW4UtaefVJ/zIrOL9ZfqyVIITtKw==","signatures":[{"sig":"MEUCIF7jP/gpNtu8Fo4gzPvsmHmp4xx4wFI13CAH/Oks8bBoAiEAv/rm0C/DEC/eDC+YSxpwbkxPC1y5qMZqyk1KKXyx5yk=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214077},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32d97a64e35dc765292f85d21a710c1c014808a3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.2_1724847356227_0.6277834224420706","host":"s3://npm-registry-packages"}},"3.11.3-beta.0":{"name":"@crawlee/linkedom","version":"3.11.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c7d0b8354f9cef5a0b88514f8c5c72ac538d220","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.0.tgz","fileCount":13,"integrity":"sha512-h/xdP2jINyZT53/BLzxAXCy5/5H3+7wl5vFdFovkUMwe9eOUsn2V5gPxDSAC36kGnKIBafwFvO8HzE79QgtLYg==","signatures":[{"sig":"MEQCIBHc7mePYoohXx9ciXNk9C0h+Yao2WkUbugyHOd609CeAiB5/4UQYeTimw7mnsdv+fKiU3dPz2+laheO7wFVkddWJg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214100},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d3ea3d085fe9ef15d19e0ddddb2c6d4b9ef647a0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.16.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.11.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.11.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.0_1724847801158_0.4041250531073852","host":"s3://npm-registry-packages"}},"3.11.3-beta.1":{"name":"@crawlee/linkedom","version":"3.11.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.1","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"53aeb3f46485c8a8103085553ebeb8ad5224dd65","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.1.tgz","fileCount":13,"integrity":"sha512-lfiqy+SI3Hhs9RRdOtA6+wxsNuLGk7aZ3KHvSlraVsTcf5C063+1EvK1IM7m/9ipFf2JxEACJo9QLVfHkGB4Rw==","signatures":[{"sig":"MEQCIFmmkzIIfuERWj5jMVmb0IjDSRjDugor5chlx5ISPCg3AiA2qfQoeqw4TC1b1pxTzfr4EdQ2VWcZ87DFvMuCpjswhQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4790bad18ed588258103f45f0b0b3776d0fd93ea","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.1_1724908569482_0.2798866336087036","host":"s3://npm-registry-packages"}},"3.11.3-beta.2":{"name":"@crawlee/linkedom","version":"3.11.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"09fc503dd5055ef7e72160437847509660c0b7f0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.2.tgz","fileCount":13,"integrity":"sha512-fPV0tqvHJt/wr52s+rwpMQg7a4rnSfoV6rXmiTjCGgNk/4kN1K9f09yjs2iLxssewCQSZzo7zvg1eosg+KRtCA==","signatures":[{"sig":"MEYCIQDVC789yRmJS1dzmI3FeEZYU2FjK9OhEOPHzI558pYnagIhAKqYQlDJHz/gey/JReUKWSTbMwuxvOUu38esfKbqce3N","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"753263ddf8fb78153a04e31c2077e5f6632e1f4a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.2_1724937890140_0.6240119733354201","host":"s3://npm-registry-packages"}},"3.11.3-beta.3":{"name":"@crawlee/linkedom","version":"3.11.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f508dc57017d6185f955b80c97ec80f2aecc9fbb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.3.tgz","fileCount":13,"integrity":"sha512-bMQmtQbP61SlnopCyF4dbDCXB0ZPKV1e2fEy848w6rSjHH9/XARH7Q1ZTUmYMNTKGL55E9Vbf9VgBpECHwH4HQ==","signatures":[{"sig":"MEQCIFg41LIEhmqOssk8dYrjMbND9ofCEsj3AIeHC93pIyUyAiBONFzAnlb3SuOpeKpkzNtsKao+SQw+Wd24e1djckcVdw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1e560ab127a226355077a8ec447cea7de6b9c8e7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.3_1724940881936_0.33449349048980603","host":"s3://npm-registry-packages"}},"3.11.3-beta.4":{"name":"@crawlee/linkedom","version":"3.11.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.4","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"521628cbe004928ba3e94a4b486d47279bc48d41","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.4.tgz","fileCount":13,"integrity":"sha512-CkQpiLrLCHfJPFvBqYBoygZ7dnohkOWrJbGWvQbb6om107YozsKRb+ILYeFm8vls9c8SN9o8GRFmE0C8YU8/Lw==","signatures":[{"sig":"MEUCIBFNnyLttHo+LNFqItanNSfy+68QAqEEeyo4oONd/YqfAiEA0nwF0RCGG45BVvSPXNlWk08QE8Kxh9yepFeUelH0vbc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57cdb249c7fe00cc5cb5cb6727eeac63fb45fe1e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.4_1724943245953_0.32483174733088993","host":"s3://npm-registry-packages"}},"3.11.3-beta.5":{"name":"@crawlee/linkedom","version":"3.11.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.5","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"94c8a3a672a1c4411645bb8da6234e562afd587a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.5.tgz","fileCount":13,"integrity":"sha512-lx3rmedkXpfcIYoxn8xLY5huWOj1v5WkTCCYD136kxMglkJjNDlb2K1TxbLyfihCH+fb2ehu5acTsVxL6PrdXw==","signatures":[{"sig":"MEQCIARcwYgm/bZx8X3blnNVA6w+M9vYMJnM+gyGAcX9eWi7AiBre6RLdZuKyxr8dSqcoUKwVL6mJ0pDDElxpOrNJncIeQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8742776f192d573ec28db964334dd7d60bdc6b8c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.5_1724991767841_0.5242480127439688","host":"s3://npm-registry-packages"}},"3.11.3-beta.6":{"name":"@crawlee/linkedom","version":"3.11.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.6","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"06fa7f44b349aeb5fb24547f864aacca5ecabeb6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.6.tgz","fileCount":13,"integrity":"sha512-h1NUfV79/6A/5WVkHBNOwNShm64vkFczwu/g16LXPHKkWk29e9RcbdecERXlfAHK1r7wgmE7Df5n9ku6sF38ig==","signatures":[{"sig":"MEUCIQCgcjpmG4L+8kyqXMKg0Jb2EfG3p6IxGbje4Qo2rpUliAIgL7iAw3slCpE+qcb22k74gorI1HYHEctREAiI+II26rU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"edec4f5186175c869c3d555b3b3b9b4b5c351bb5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.6_1725078445528_0.7768936889100426","host":"s3://npm-registry-packages"}},"3.11.3-beta.7":{"name":"@crawlee/linkedom","version":"3.11.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.7","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"297aa7b729be8cbe68405ec0ebfc325e5c4a9d78","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.7.tgz","fileCount":13,"integrity":"sha512-BhyN9PhNUCQ/gJfMrliGGaWNqHJBZpmlvdQfbOe7pa2IXmPUmFGTxQvrbH3rOlULSMO2MDEfNU/jnlOIdQ5QEA==","signatures":[{"sig":"MEQCIF2jULXK+CXFtg5L7d+cK+uMjYDKKLSdg6jw8kEZQSsmAiAxIw8hEz8ssqbCKc+jrd9hBmUxWVIQ8bcKfvzVZ9Wd/A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214288},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"65ddc9c46fdcdb19d033b6c6c28238027e6b351f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.7_1725162896088_0.6926102629460673","host":"s3://npm-registry-packages"}},"3.11.3-beta.8":{"name":"@crawlee/linkedom","version":"3.11.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.8","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d4fd4ee4d4155b9d106613029411860bac5328a5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.8.tgz","fileCount":13,"integrity":"sha512-gT0242k2tdVXIa+Nu4WVLFP+hnpzK51a5rsif/Vn2dT8VKe29FF+H07sLsoeQvknSM+ClnMfHHWNbkF+bY12Xg==","signatures":[{"sig":"MEUCIQDQvVe/FfsyiHqb1uqu7hOy01GOcfG7P0JSdmsNu8NMewIgG33nJkAsIIfyIPyIC8sryd8JfXU4dYLyDuYw5ePBhoE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214310},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f1bd39f970a911320ec94cce8bbe08c154a7f7a4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.8_1725252037061_0.4489506649223787","host":"s3://npm-registry-packages"}},"3.11.3-beta.9":{"name":"@crawlee/linkedom","version":"3.11.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.9","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"33146ebe588ce4bc3f0e15260cae1d1986bbf94c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.9.tgz","fileCount":13,"integrity":"sha512-Vr8nu0iTpLR1lg7FYh4apt0cZwAi6jUv52tQoMsn4iAiO8HdgTX+2+f6wMBmKuunTtbwBFtbgY53QU5ALrOc0A==","signatures":[{"sig":"MEQCIDDCtYHP6AE1rHrBl7wjw1xvx4bvRxFHrjWw0+R5XvdKAiAq7WwGRiZ13kzPrE8E6OSTkLMJKGjuJMLIh40abH/LaA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214310},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b2f3dd9a0da8eded7c647613439421e49f4a3dcc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.9_1725335825395_0.43759604869056057","host":"s3://npm-registry-packages"}},"3.11.3-beta.10":{"name":"@crawlee/linkedom","version":"3.11.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.10","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5081e6293d9ebcdb783c9017251d325b2e5433eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.10.tgz","fileCount":13,"integrity":"sha512-Kg0dYP+4bctJhIArGjE5Cu3Xo257vjyp48+yBPFwqGmE3mKegYVsRNJZbDxgnD9NyTlT01TRsJtWXyM5tV0fUg==","signatures":[{"sig":"MEUCIQDhPt49CGXIhyGe2bNyCw8lsUO1V93XcndV1jRX74mRIgIgUtmkvRqlMnoVyXbMlHpitS55WKKBGPiMMLN4+/ltvrQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214313},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f2aa40be6d6fc29db9a0ebd266cb2dca441a6d05","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.10_1725367824183_0.11397948037198846","host":"s3://npm-registry-packages"}},"3.11.3-beta.11":{"name":"@crawlee/linkedom","version":"3.11.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3-beta.11","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d57f409af651552e843e23f492b3f41bd1d0bc9d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3-beta.11.tgz","fileCount":13,"integrity":"sha512-Y2e+uSvL9mPiiVV3z1aCP3AGUl58s383bIz3w7018gIpYCIAYUyZ30Jc3Ix+38A7MxRg2BG7ok8XcAwpBdiI5w==","signatures":[{"sig":"MEUCIHesKxU2BG/BJRkjDE9JK8r/ZFmsUTrBOi4QZYPYTf20AiEAkp2GxIgUEZiNg+x9Gzc6n1s+NNveCbCu4Pn3fKjSX9s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214313},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fb6333ccec52c8abd721c363513d733745c79c77","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3-beta.11_1725368425511_0.06184509748153677","host":"s3://npm-registry-packages"}},"3.11.3":{"name":"@crawlee/linkedom","version":"3.11.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0273ff67c4ec115bfbc487319673c8388ca91953","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.3.tgz","fileCount":13,"integrity":"sha512-+87stCb3QPjOXfMAJ186PmW5t06/qL2tzOW+HFETbj6AAty8BH/KmdWaBHQkyz8n/K4H5NhUGuxtBTGXk9FVlA==","signatures":[{"sig":"MEUCIQCbpGbV3DZZ4NkERU5CiyadMgvJqa+83MfNukbSa2HaIAIgHN7PySKoczYebgpENdJFeQOtTkmTPRJmiawUNoVlotY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214289},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"02847d4a1d19cd787cedc3ba5460464d84f5d552","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.3_1725376370216_0.642994681781855","host":"s3://npm-registry-packages"}},"3.11.4-beta.0":{"name":"@crawlee/linkedom","version":"3.11.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.4-beta.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"465c17d7761d5d79bd99f1957d760de755c5d93c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.4-beta.0.tgz","fileCount":13,"integrity":"sha512-cdGjOy9GR8IFMJky5zOZyQMkhVnBf4wjY+Z5A3EkAZyqyT5LvZKsP6Ld+UZd2FwpabHKiTFKO+8znKTD0hLZfQ==","signatures":[{"sig":"MEQCIFgpmpV75ml8ducKhIaCXUaI7XpQjBnE5RkGVU+oxwA1AiBEVN1ja8ib1UgF1Ii8sTZm6VXBVZj2FM74nowB6N9D4Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214312},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"487ab2e65c0414476b82b893baf529ef5df29ba3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.11.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.11.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.4-beta.0_1725376783698_0.15616982714360828","host":"s3://npm-registry-packages"}},"3.11.4-beta.1":{"name":"@crawlee/linkedom","version":"3.11.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.4-beta.1","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f9200f77036c6dd88387818d9adf7882c7665182","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.4-beta.1.tgz","fileCount":13,"integrity":"sha512-gH/MKo2wWEmTOKrzv5K6I/1GUZThV66ssPD6n9PNVieQa34C2B8QqAV4VY4PaE/06H+Wt/+3CQsFYt5Ti6KkoQ==","signatures":[{"sig":"MEUCIQDaKO6rfkER/ciMPo68f0bZcAmK8oNoSNwNWrB3AtnOmQIgIlt8o81mK1vemGPZhaoabqPD/A33Kg9Yqz9g9skdVd4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214310},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dfa100f1363e1a7143917d2f3da9ae68324f31df","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.4-beta.1_1726836743854_0.3747593068243129","host":"s3://npm-registry-packages"}},"3.11.4-beta.2":{"name":"@crawlee/linkedom","version":"3.11.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.4-beta.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7a3a5d1f7b3a3628363c76189dcbe5999fa83dd9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.4-beta.2.tgz","fileCount":13,"integrity":"sha512-YbgS93m+cuFWYfZ4L8mSAq2qwbb3FWVYCJvzmsbEnCW4XM6ZvyU6xKAdIw/bM5qg2IGapPAnGltFu/geGBJfNg==","signatures":[{"sig":"MEUCIAdy2C8hGgU/zcbYduPaQF2yGSmoLD00xgVMAT7NiGq9AiEAnZC8IVFWofnwYVZG03U44AWEJytD337o6mxzq3MppIQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214310},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b9c114b3e61bae805256db3e625b7bd2b187854d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.4-beta.2_1726890231245_0.3517420764988082","host":"s3://npm-registry-packages"}},"3.11.4-beta.3":{"name":"@crawlee/linkedom","version":"3.11.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.4-beta.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e914350bd3df6d16ac48116a20e44b5e3ea31826","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.4-beta.3.tgz","fileCount":13,"integrity":"sha512-nwSErSAF8Az6evDMhd+6aV0UC21GuaAeybGngpuge0Jf2mYE96UsequvxOgirBfJr2xFDpjfhKTX3auLR7USFA==","signatures":[{"sig":"MEUCIQCN48yHcQFD7Vyr5GlkKNvDwndiihyNfKhl1gFX89yO/wIgaKzqkmCsW5kUj45LEajirUDr6Z5J+0djnDdahNOLvVA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214310},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"628668bd844c036a2adbb44ef4058c50b00f36a6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.4-beta.3_1726918199380_0.750832848776591","host":"s3://npm-registry-packages"}},"3.11.4":{"name":"@crawlee/linkedom","version":"3.11.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.4","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0456df1f9f41a1a30f78595f2c32dcc9d6770d7f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.4.tgz","fileCount":13,"integrity":"sha512-u57BE7gZ7HBar/o+/fkMnX8Tn/b4b8rHEjL1qH+KNOkKzzwjNyRFANjkWW35pVKhG9Zlg5Bvkc/F5xuNFZcRqA==","signatures":[{"sig":"MEYCIQC1bNPzawP2XlVtcXIZovPSt4f+ukD1qJuMHxvnMcsdmAIhAMn3pFixWOGawm4XEZhviRXdLHIay8bwCntq395xdxGZ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214289},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"11efcc252b3425056fe48aea1dc5157a5439bcf5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.4_1727079357121_0.3773024706811321","host":"s3://npm-registry-packages"}},"3.11.5-beta.0":{"name":"@crawlee/linkedom","version":"3.11.5-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d13081476d0f0d77f0326fb767694db20f7ea3b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.0.tgz","fileCount":13,"integrity":"sha512-bckX/kHfH1NWPSvNm8EEGuCF9D87nwPgcW8uaDC728oYGtuCXjL2VZIhsLWTrODojSmD7JNXsdZxZYcVkZo1ww==","signatures":[{"sig":"MEQCIBsru6Q/ihsCckaAe/fn22L91sGA8/h/MnDWmfMplfQCAiBJX+PMoLhUruefIp4PdO0nXQvL4ldwJhfK4Ld7rVQEuQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214312},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"385c188d78382fba66bc09b15847e2c0c9f1972c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.11.5-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.11.5-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.0_1727079760320_0.962333663003462","host":"s3://npm-registry-packages"}},"3.11.5-beta.1":{"name":"@crawlee/linkedom","version":"3.11.5-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.1","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5c58c35e1dd08a9fc76899d0771d1917c3912d7a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.1.tgz","fileCount":13,"integrity":"sha512-lwwFver/MfTci8OMjaXWefho7hK2ywutH8TgElyq2iiYz0i//2luxr1+Tc6H6899op//KXoDmNXRfjB1A3hZrw==","signatures":[{"sig":"MEUCIBQVdDfBbUCr2wepqwx0OBNmaREB16P0M8TrcdvkGATwAiEA/wPekR/sd11SSRKobnDDqTnheDNMzczoF4flPIidTVA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fae5d1266a04055c29eb267835490fcfdfd0c28d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.1_1727190252752_0.8355300430040749","host":"s3://npm-registry-packages"}},"3.11.5-beta.2":{"name":"@crawlee/linkedom","version":"3.11.5-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5daa0e8a5791601f86c46c4c6cf695a766a30c32","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.2.tgz","fileCount":13,"integrity":"sha512-HGUo+eCJWD+AIEOpLa/rypSXCP2IwkMDeJLke+NfGecQJvh6OAm8BOTeh/WwN1VQuHinREcQK6WALKAvCNrLJw==","signatures":[{"sig":"MEUCIGa3s9DYH57SthG9TA5KFwWAupBlXbqVd0sjVcMLxFgRAiEA3CBxyhmKuKzlsQAzsozTU7xBJo8uig2m/dudTgwqf7E=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"677591e89200f7893b74b9d36f9eff7cfa2a09c0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.2_1727191681322_0.40244744202001903","host":"s3://npm-registry-packages"}},"3.11.5-beta.3":{"name":"@crawlee/linkedom","version":"3.11.5-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ce437697325f4adbcffb5d690f4aa7d691fdc993","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.3.tgz","fileCount":13,"integrity":"sha512-gjApTY22j7fMKe4U0+un1C8mJBGvE5wpbvA9s2Jo4PR86Vp9aZ6MEunbX8Kcn8L0cH131N5tGitHkxeGvn4JcA==","signatures":[{"sig":"MEQCICtpJptyqQ90QOB1p8H1vpBgxrEyRiNwXcxs//je4QmtAiBRwbzkE/NeW0oyx3yttSpac9+3HB7V1zgW3timaKzQEw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6719d5d062ec5fef8558ebc91c9103ec12e35e53","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.3_1727266224474_0.8378469024793245","host":"s3://npm-registry-packages"}},"3.11.5-beta.4":{"name":"@crawlee/linkedom","version":"3.11.5-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.4","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e7b7d5a878689f24a13ebd8b62d0d9354efd01d5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.4.tgz","fileCount":13,"integrity":"sha512-9CQKb6YSvKTFWgLoOdMWL0aaqpj+51ibxFA3veSfVxLpZelSW15OodgAb0Ev1q7fq1rTWei0lQu6sqEzqItBAQ==","signatures":[{"sig":"MEUCIHI1EPHcIcJmXjea1WXrrU0Pl40R+zFaIVVur75ZhYVlAiEAgqmNCB60Lsx6KAWiqR65ariCSraCl3ndigWAlv0gq1A=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"15723c6804f482ea26bbf0b0affcc1ad445f7579","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.4_1727362603009_0.3571260086287651","host":"s3://npm-registry-packages"}},"3.11.5-beta.5":{"name":"@crawlee/linkedom","version":"3.11.5-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.5","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"69649c3efe590f155dd63f684e6b8bbc2359cbb7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.5.tgz","fileCount":13,"integrity":"sha512-JlDg6XgL0n1TulAxTWKtmhkJ97jlooncU17ZRQR6ldAw8IXHyEF/oWdZbrLmpU9Jq6lLM9GIyTXxpPfOLQVJAQ==","signatures":[{"sig":"MEYCIQD7jALCE9eA+hAU10Ba7+DXDO8LS2VFMlrK6+EvPlOz3wIhAMn3B4Zl8cLVU8+uc/V7v09OqTXabhUPXnJ2YzTYJasE","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ce0e7b92d00089f5e5c5caac1c0a717fd26faa8c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.5_1727427997389_0.9798355820682116","host":"s3://npm-registry-packages"}},"3.11.5-beta.6":{"name":"@crawlee/linkedom","version":"3.11.5-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.6","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6ca900efe4e5d2cd588d8154eadc7f9d969c3a3b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.6.tgz","fileCount":13,"integrity":"sha512-8h/ynxAFExpX27KAdXPFzjjdG2S8UsITMIXmqdqIWAWB/3tJ1AlBCCm5EdKqQWkSRKLlbQX0/BP8YRUGCO9D2A==","signatures":[{"sig":"MEYCIQDgtMD9/IDlrMTVDgeVtY+1EY9F0xDF/oVDkJ6MaqqhcwIhAOzoCpNx9WcrmOx6wz6awjoI5QPfCkYCSxhRLQj0wYEo","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b14415e79a39cdb3ede4446d0f053489a4d68c4f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.6_1727428849415_0.4194651471621209","host":"s3://npm-registry-packages"}},"3.11.5-beta.7":{"name":"@crawlee/linkedom","version":"3.11.5-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.7","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"229ff6d3b98c2a2b0d15bb12d9e549d069efbd6d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.7.tgz","fileCount":13,"integrity":"sha512-KAMxbUTTcdyz1hP/Dkk6MX6lqJVE7mTvQ7UIZBr7zQ1Iip8eQksbNLWjyVKelPcq//W4z9qyUrWVfIZRd+XKPw==","signatures":[{"sig":"MEUCIQCTJN3/jGRrVyPDRT+78UFpD1IMt5zomwZY4u7reLQmVwIgCD1sanzND3EZDyOh6vahtl2PGAUb6QG27Tr6XInwltE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":214487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3989ed387baa85fdb220be8dff9742eb1013efcd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.7_1727430905479_0.920741593210183","host":"s3://npm-registry-packages"}},"3.11.5-beta.8":{"name":"@crawlee/linkedom","version":"3.11.5-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.8","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"99eb4945b3b867c8f0fb1bd9b255307ee09d33a2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.8.tgz","fileCount":13,"integrity":"sha512-RYjB2crd4xArH1SvUzI0E2BETyOKxtmAofBaP69WOthbHzRW+3noeq7W7pgkpB2d92p7UKbud/dtHN9a/Abweg==","signatures":[{"sig":"MEUCIQD0HWS8KWh+CVqUmdgyjaQdvFCoBwzSikN8aX7ihAf3BgIgeZ+ej3794A2xgGSrUaJqGKLHxou7tXsXN7RuXxg1JAc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1befd52a56cc1533b9bbe32284f5f8a7b1384cca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.8_1727434848617_0.6429472443097555","host":"s3://npm-registry-packages"}},"3.11.5-beta.9":{"name":"@crawlee/linkedom","version":"3.11.5-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.9","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"61433c9dc5f62152d660383930cccad426c4f774","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.9.tgz","fileCount":13,"integrity":"sha512-h7GqZceG2/2We7oGg/MM3Pq1enSPk+NfcrWT1QhyYkl45p09h4EiaI418xoCz0fknpjWOlWpf+vRVcz0nz+ZLg==","signatures":[{"sig":"MEUCIQDKMkfvdpU804PQcM737kRvRfQGqYgEd8CCEW1iQIAatQIgM2fvf9Fghn4664qqZihoLw9XUgi16gV8ljEdwq9rYCM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"416c1c9edfdf8d4f0165a9b9f87bd4a5cb1dd0ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.9_1727690651583_0.4064965847743103","host":"s3://npm-registry-packages"}},"3.11.5-beta.10":{"name":"@crawlee/linkedom","version":"3.11.5-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.10","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a227381d1e760c3cdadc8d81ee8e75acb1b3540a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.10.tgz","fileCount":13,"integrity":"sha512-mwMlmydR0J8O5KD80gI2l0R2mwiGIAy/er+1OIMEB2K6HA4T8dIodyF/vXnjDSD2fFF0/XRpd4R8pdA6rrx7lg==","signatures":[{"sig":"MEUCIQDSkMK3ijz9UeXybIdDwioDADqI6RGCMacfYvENbhgp8QIgfuI6Ld7QjR3/UBiCwohRhQriX/XZ21zXfVgTABGzL2w=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c2cf67c52d0c62a5c235af14c327fd993d4b2def","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.10_1727771299061_0.16360257810219236","host":"s3://npm-registry-packages"}},"3.11.5-beta.11":{"name":"@crawlee/linkedom","version":"3.11.5-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.11","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e19ecab359cc2650f3601538cc8850a960c943a5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.11.tgz","fileCount":13,"integrity":"sha512-wQS0PUv/eBcQ7bROm9ywY2Cg1oIC7Y/xfdsGuf61JaejIW5fbBtXlk8NBgeqDkv4xrB9nohjxVAMWU8CYN49Bw==","signatures":[{"sig":"MEQCIBPZpfL38oNDQ61/4QZayI/G5h1C1s6ThzHLNrnzbs0FAiAOa5hHCSszkOSYidgx7zSfrGpDTyBdNCWH3l7kVHjFiw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"21b8b8600e7f7c627d7a06e1b89506da82f8164d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.11_1727869008223_0.6496521864442979","host":"s3://npm-registry-packages"}},"3.11.5-beta.12":{"name":"@crawlee/linkedom","version":"3.11.5-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.12","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"69a56a20b0b32e7b4ab42bd5d7f520299e69da98","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.12.tgz","fileCount":13,"integrity":"sha512-f7+rlWz25735VdEeegAe0AFdJbJ5/HGYB8jWQvus2m9qRyibLTeE64cgxJQiks94T8HBP+Jhqrh/zh53f1AurQ==","signatures":[{"sig":"MEUCIQCBTttbChIm4rSoyfSlq1wyn7anG2l70MPKTujElDrPQwIgE/NRRtqPAJOVRdGmkAjPb5K/htahabvKJkFkandEsig=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7020e7c96757e9c638916bd1970be2ceae3614ad","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.12_1727876160221_0.011777724745414497","host":"s3://npm-registry-packages"}},"3.11.5-beta.13":{"name":"@crawlee/linkedom","version":"3.11.5-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.13","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"53bb02adf8a61aa25be333a5da43b80e0fe54050","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.13.tgz","fileCount":13,"integrity":"sha512-sYI0A1MLv08mF9yH0XXHFptgcozUQnjSqZRrQHlfHuSgcqf7Mfa6hPRjfbmmOtcPP9bbxun6sCnnuw2m9BD79w==","signatures":[{"sig":"MEUCIQCCl+aDXM4nWRn9Oyo72yU4RDEm2CLjNuKHA6uSUch/jwIgNpHkoHG6CbMeIud+MH5djxOI0hCLuBpE39LjwCX1E3s=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8b400a4958ca17c95c9dcb42f9daba8e28277a03","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.13_1727909913401_0.2734532975317223","host":"s3://npm-registry-packages"}},"3.11.5-beta.14":{"name":"@crawlee/linkedom","version":"3.11.5-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.14","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"08c775cea76e66e5c9f762e84bf37af83d15c6ef","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.14.tgz","fileCount":13,"integrity":"sha512-Jb4b68LBadvQEDeFcDdcM9USu24u9LlYH3Vd2I1BwxTcwWN3ZI04Joys2fPtPQ4Rt1XYSAYdV++hxShfJ4Gbxg==","signatures":[{"sig":"MEYCIQCFO7USfR9jI1kcU2lNVaZJlzv0/7staOiDeiJ95FYq+AIhAIQ8D15voo1n8eQPUjoD/erhXOxAbjTqB5VhJZywUGmU","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bd1b4b94090e77278d7a71a91a05629582ce25a5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.14_1727939553140_0.22771855726264834","host":"s3://npm-registry-packages"}},"3.11.5-beta.15":{"name":"@crawlee/linkedom","version":"3.11.5-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.15","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"86e303d8ccfdd03a4229cd14631f660624977750","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.15.tgz","fileCount":13,"integrity":"sha512-2vcKiq8Fw+XV9lAcLbn13BnVjL/l64MA7ggDW/MQGskmYsG0HF6Rm70I0DBHrjACk9p+u1ikJV98cqWkXp1AZw==","signatures":[{"sig":"MEUCIQCc8KhnfNBsfxfaDx7k26j2jbYUtHVd7ifO8e/XDgzemwIgdLKbmjOq5pMsoMuUrBFf863ZT1ZjZQKHuNv27Xbk7po=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e7a2e8bd055eec66d79109b6e66ddae15dfc8544","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.15_1727950653186_0.3574162734441675","host":"s3://npm-registry-packages"}},"3.11.5-beta.16":{"name":"@crawlee/linkedom","version":"3.11.5-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.16","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d99f7c8b77583b56c577636794d7f559fd5549a6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.16.tgz","fileCount":13,"integrity":"sha512-ckG7XHtgO4B996R0EIbO6uQOQUvwFdi16Y+C5X0ovk0GA9x8tbHqjoq4n47zJcQzyB8XUu8ZQGkEUM8Qu2aOqA==","signatures":[{"sig":"MEUCIQCNemt7dmcBcKWWLYPFjLVkbe+cn9i/TPJncCi+CaIMagIgNnjSq8jB7Cayj/YW7RPkvO96g+CFsX/a7i0cNkxY/Po=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d3b55669aa0a4b7a8b77e22d1766b0638ca1c72","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.16_1727993234431_0.72459862099269","host":"s3://npm-registry-packages"}},"3.11.5-beta.17":{"name":"@crawlee/linkedom","version":"3.11.5-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.17","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0113d8dc85245d84355a0da98641b1d5a9ca7c70","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.17.tgz","fileCount":13,"integrity":"sha512-kJMOasC4K8ub7JxvSH1aB5zbhSArDGSrYn7TBssxlrQ9iYRo+hlEr6wwL02yJpiWYFdwJOsZzQZqx0CcG3JPYw==","signatures":[{"sig":"MEUCIEk959yQnuaKE3GM54R3XnD0SAtjKwfjEw5h0uHILylGAiEAg8QjEogzFwkP3trwiW5FD9Iily5ZqXlGAqZH2I9JsBA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"885ade1d88cf20affa0a8a7a6b2f78bdfb8f9e19","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.17_1728029857392_0.3249562397063612","host":"s3://npm-registry-packages"}},"3.11.5-beta.18":{"name":"@crawlee/linkedom","version":"3.11.5-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5-beta.18","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"703ffb77aa0026f3610d81b94717d52b048bc634","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5-beta.18.tgz","fileCount":13,"integrity":"sha512-5sxYjmMKsafa/BpAKqZ6YZQVWzFGtqzk2v8chZs5qpTq+a8t+cidsvt0UG65qyyITjVm2BLxHSq8zZRKqL0FcQ==","signatures":[{"sig":"MEUCIQCZp8/9d6ZfWDat/Ydp3Z4sjt7u3wLO6+te6jfKgWevXwIgXVaeoDQV2jE483oACK95l7ClYGE6aeyWqQkpNgSbw6w=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f748e462b1ae88bbc38ef1e9e1edded402075c3e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5-beta.18_1728045033384_0.21844239896662998","host":"s3://npm-registry-packages"}},"3.11.5":{"name":"@crawlee/linkedom","version":"3.11.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.5","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fae05f805ddcb17c27151da6de4eceac25f6c75a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.5.tgz","fileCount":13,"integrity":"sha512-P22M7IMFSAWMcXTZnTarWXKPOeQcgnXOUVk+bTUNof1LbuLmy3sSCrpAI0OrACA0yUNmta/wegWSAicHWU/svw==","signatures":[{"sig":"MEUCIFq2SSodguxxqIyvC7Ty4E5Tqs4GTGp1Ya6SAs17tb5hAiEApV+/AwTpaY6jBADE0tgF+hStlcglFycKPF3H0WZwqmY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217723},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6141fa58661afb415e40a4f9642360c1be3d7183","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.5_1728045442918_0.43709739039090545","host":"s3://npm-registry-packages"}},"3.11.6-beta.0":{"name":"@crawlee/linkedom","version":"3.11.6-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c0b3cfab3a0832a206307e0d6e19e6aae8de4ca8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.0.tgz","fileCount":13,"integrity":"sha512-yrXWXWwPgL+9a3APFO5Y6eP191FwiXomUVWOE9YJc6cTDX2mhZt36ycJzTeIv/AGsMjDu13CwLqJCfHN/qaZgg==","signatures":[{"sig":"MEUCIQCI8quziddX+3U42pNFchkGVb8RkGz5hZz1RCG9FCMKeAIgFItMF/64ku6q/9J3wVbZT2hIFVFypg0Ih0Dfc2BDET8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217746},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f93ddf9653dd6913dff315976b6358fba1f5ca83","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.11.6-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.11.6-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.0_1728045866215_0.4908717152739148","host":"s3://npm-registry-packages"}},"3.11.6-beta.1":{"name":"@crawlee/linkedom","version":"3.11.6-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.1","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d7f643880956c1d8168c941024b336db056cd40a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.1.tgz","fileCount":13,"integrity":"sha512-nVcf8josrqM/ce7Vf+4/C8bkqir7rkZcCTcP5hHfMVwFtppjxMNrapgzL7S3P8XG3gvRiUZ3th1tObma4L7Cdg==","signatures":[{"sig":"MEUCIGrYL2+qWBGFIusMZm8ddgmLYNvM09XS/dD6tAp1ApA3AiEA71vBm0Gp0yN28t7IDfDIePL62c0JryH55wrJ4XmDqoM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ccd8a959d84956a8552429c49fe52c81e0a172ba","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.1_1728318946256_0.0032623368805138053","host":"s3://npm-registry-packages"}},"3.11.6-beta.2":{"name":"@crawlee/linkedom","version":"3.11.6-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4c3a01b225b6c4d15e07f56e790ea5f4e5114487","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.2.tgz","fileCount":13,"integrity":"sha512-AAZO78MYFNK+1YO84EiHGvEm+FxEoAR6xh8NUFDwCMMsxPOX3bxGMI4/CWMUJU0T7/02bcBE4zw73yf+IS6nmg==","signatures":[{"sig":"MEYCIQCzq+Ls+w8vvA3wiwfm4/mmaROflTMpQRiGR6OFSyLFDQIhAKkAdYpvt8HR0P2IMtvcbYZ4BwpXZ1vPxg9gv+w8FyZM","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a94b141b0391aec8c146dfda3c29854907374b58","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.2_1728414391689_0.7259202577290229","host":"s3://npm-registry-packages"}},"3.11.6-beta.3":{"name":"@crawlee/linkedom","version":"3.11.6-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"99a9edcf8ca73e8df0cb7025c8e0daf7ed0a4b8e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.3.tgz","fileCount":13,"integrity":"sha512-WCIa5yGPzZ0a60WsX8pTAi/USkD7Zj4ypDYOI64tqybf09tYE1i7+nChs//G9Tp2luda0t+tTiw/96J3ugfdZw==","signatures":[{"sig":"MEYCIQCPL/l1Fkdv1QNTOcSPF4sVndUnG7feAQDhIsQVWhwjngIhAJxbuwEGP46vkMCopZhRcdl8zXiKWARFjvv49fVKG9Ci","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0d86e04fa2e8e4895872ef0b15e163c84406df1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.3_1728558305617_0.1207018540662923","host":"s3://npm-registry-packages"}},"3.11.6-beta.4":{"name":"@crawlee/linkedom","version":"3.11.6-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.4","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"100d2cdb0313705b9a66ebe77eac9fb1603822ea","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.4.tgz","fileCount":13,"integrity":"sha512-pGTdvpR6e5H4H/y/g9tW3FXTfrtiI4qrSeMHvasHLre9TCEVuylKj2YkbUKl6PXgj1KnyNnFofvlMw7D3i8teA==","signatures":[{"sig":"MEUCIQD6zNws4c916yCD9kjOH5tpF4r3v87wMth0BPNYVnyMNQIgZH3bB+OupZ+ReEWCL6nJAw0S4pACm0rt+Ut6h7/Cvbg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f0d83824d385df7780f98c66309ebe778c8a7ec3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.4_1728643336500_0.5367138803720153","host":"s3://npm-registry-packages"}},"3.11.6-beta.5":{"name":"@crawlee/linkedom","version":"3.11.6-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.5","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cb5469ddd086ad720f1f2d5111e93689e2fb13ee","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.5.tgz","fileCount":13,"integrity":"sha512-gyk4kOe9xsOxbtlSUypEO59ZQqk4+dRIik7HGY1p+yr/9Z/EhxuUKlCsIlVwxDnJnimOJFF/DAfLUXzv7oh2GQ==","signatures":[{"sig":"MEUCIQCLZm7ewufHSzFa0dpqqG/xIshjcIRkI+nsQ5Tc7Goc0wIgW18suI9K9hoIN5OS/OWhFqhHDLwycfwytPAZqhE4VI8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a553877bfe6dfc758a22a98b056c458f2c69bd7f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.5_1728668140532_0.35433154541961653","host":"s3://npm-registry-packages"}},"3.11.6-beta.6":{"name":"@crawlee/linkedom","version":"3.11.6-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.6","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"975fd4e13f2889a67f99c900d98cc122afe29e74","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.6.tgz","fileCount":13,"integrity":"sha512-VSeItq5bzQwQfnvl2j2Jg3q1oewXd9+5RVuy3Jdde9aRxS1RN4lyyKxt5OtFUD4dX6207lQCtyTP0waeeUsKMw==","signatures":[{"sig":"MEUCIEjVg7V/H3vZu3QipyU7LxG+SpcRUhFNGwjD76O0tRrwAiEA1kV51coUIlxwDRnxNdeVSdXN7jHyUsgw7hscHLsJKO8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6f8386f07c939951794fe847ec535652d0cbe0de","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.6_1728899315895_0.5447760582764629","host":"s3://npm-registry-packages"}},"3.11.6-beta.7":{"name":"@crawlee/linkedom","version":"3.11.6-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.7","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2abbe731fa2dde6a3b50681eeab4c55dbc4379d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.7.tgz","fileCount":13,"integrity":"sha512-X3u1cu7fJqWcrx6mDIi7D6i8N9i7lxJoqituAddRWWkXo39IfOSfASMZ3ySmZOyYmDaBeoMbjQuf9ubZLr7VGg==","signatures":[{"sig":"MEUCIQCEADVvmaTRjpT6iwJLKHnUqGQZum/yIjv6oguhsnKx7gIgeWhXbksLZ4fmXkb58hO2+MhhtnSs6KK3Nz5EO9Qa8t8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"18577389743cb5b1b82abc9042d4d4c5c87fe781","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.7_1728905424767_0.5247233816767236","host":"s3://npm-registry-packages"}},"3.11.6-beta.8":{"name":"@crawlee/linkedom","version":"3.11.6-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.8","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fd91486942cf3f091a56223b00b4626d046c4786","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.8.tgz","fileCount":13,"integrity":"sha512-6mRksRqIc6tNjsrB+6VzNNGF3b562mrj/DHYHBvdLccYM/FtUFeDyFle7FWf+w163Get2M19BA7BxECEnXG7XA==","signatures":[{"sig":"MEQCIEzwzfpAIZayL1PveQER4LP3dfDA2Pskk/noRJGPubIPAiA3CLOEB0tMCtJWK98dficyw2aieWqlO6Pplx+yrMeUkA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"925f5351d6ebf566832f89e9e28c2bfea652470a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.8_1729077070234_0.32483530950062045","host":"s3://npm-registry-packages"}},"3.11.6-beta.9":{"name":"@crawlee/linkedom","version":"3.11.6-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.9","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"13f41fed527edf13f670975ee4bf289f1759e3f6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.9.tgz","fileCount":13,"integrity":"sha512-SVQPMWTHs2EBJ7d1jDLmqHnLMoF5nUsa1ywRNhhTkJfX9y1fS0zd3E2LJJGHT0MQE0SsiyJj0cC40Pue7zEtRg==","signatures":[{"sig":"MEUCIQDCgdtuJtRNUm3z4D6V7gbf1wdOhNpLjOeXlNBkC3HqqQIgUwZn4Li1a8czeiRP8mRo8rkr/hmBO65hjBXImQsg+X4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217744},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"be6b8370a70aec931436131da94553b462349501","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.9_1729091666500_0.2583060831804127","host":"s3://npm-registry-packages"}},"3.11.6-beta.10":{"name":"@crawlee/linkedom","version":"3.11.6-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.10","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8b453134a110d3dee32a1c86b81579627f3784c3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.10.tgz","fileCount":13,"integrity":"sha512-oSSwC6wTjXq+iZH/aNmG68Z4hNlht43w/b3oeP752bJlgBY+JfKFFGEgi7DUkJ7SZrIC/WdtRAqtgpSJzCMn3Q==","signatures":[{"sig":"MEYCIQDHi9/pTUB9j3BBnIXib3M1rxng+0qneVrhpdLeZnyGYAIhAMSt6PRz6AOzSYKDL+vamcJFcD++PbmuibvSoUlZW7T3","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":217747},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5de5e99f7d606d319eb0a22e5e0abaf8efe2844f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.17.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.17.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.10_1729118614648_0.1575083634946055","host":"s3://npm-registry-packages"}},"3.11.6-beta.11":{"name":"@crawlee/linkedom","version":"3.11.6-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.11","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"01a8be419c337c51dd067214c8a3be42e4f17f80","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.11.tgz","fileCount":13,"integrity":"sha512-2mIwHMtbFSf+W50Fb4npWuz9HFLOqCX6+EVdozbEZ10vZsBrmaXHBrbste/hyen53H8dpG3nq41xUeZNs2Odvg==","signatures":[{"sig":"MEUCIEO+1MwYT9gNTRxPKQgWJh7OkwZ4DCzqCXbOi/Roy5jTAiEAqMiqXVbx+0y31W4XPoj4hS/sEdif8Yt92EV6+EdhThs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"efdb3340464b8fc53d5605c1ac95574a74927263","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.11_1729682499670_0.45388763695675993","host":"s3://npm-registry-packages"}},"3.11.6-beta.12":{"name":"@crawlee/linkedom","version":"3.11.6-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.12","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e3ec8633af2a9065aa78bee062eef9ff30e2525e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.12.tgz","fileCount":13,"integrity":"sha512-Ei6s2ORnLX6GHKkWwcQKmjLW3KcxAFTDD1DsnZgwys9Zn53zHWJJYoth4Qo0p1RsqEuvy7ntUmf0iFmyOogG+Q==","signatures":[{"sig":"MEUCIQDIahQ0Td6qlyjwFS1VLpxIFs3w6ZAfmrZ+mPOqF3Ta+AIge7vHC64kZmJTD1XVCK/U/fDriORT+fWrYqyXO4gfR+4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9b6366a75b5b6a5e237742c5dea129839679a8a2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.12_1730189166281_0.46942883511846123","host":"s3://npm-registry-packages"}},"3.11.6-beta.13":{"name":"@crawlee/linkedom","version":"3.11.6-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.13","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"14beb172bb60f3274fdf95686774de5364f74962","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.13.tgz","fileCount":13,"integrity":"sha512-spmcDLYD3FhnCzbaaxpnXcfglIdeJAjuinQYuK0/QJoYZy0hNA1GEqbzqw3USf8Ds2pvcWeMzAL5H7lx7I7GTA==","signatures":[{"sig":"MEUCIHdEsz5U2igkH31HOzkBdRSY7l7HnLk+xXEsHXivocaoAiEAimHwW8pEIf2Y7szzqpWv6v9R7xU19PsbPqV1uzpU+R4=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ebc222053f1bbe23cbbb44bdbe7173d399ed9eee","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.13_1730219668351_0.08299023336124223","host":"s3://npm-registry-packages"}},"3.11.6-beta.14":{"name":"@crawlee/linkedom","version":"3.11.6-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.11.6-beta.14","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b26034e6e9e0ca641efc23bd54b691f7b2f25c4a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.11.6-beta.14.tgz","fileCount":13,"integrity":"sha512-WvcgsopZy9kwnSBicPN43FmHZuatBIZeMcu2uBJfrmUCKu2aOFCf9U4zgHvZz0IwBOtH03OfUugnhIP6rD2tKA==","signatures":[{"sig":"MEQCIQDXNAISNOAqKs5x4uXwJ/5vDMBn9sdeQ13huTvrDtqaIgIfAqK5hoPjA+rDQInUlnaUCKUhpllEcVfTLLzj7RYVJw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"00c4f6f795b549e554ab694b9b788e1e91d0a81b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.11.6-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.11.6-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.11.6-beta.14_1730476096429_0.7622593906273571","host":"s3://npm-registry-packages"}},"3.12.0":{"name":"@crawlee/linkedom","version":"3.12.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8ecbf201d08cb561a56d11d67d091e89a9f12bdf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.0.tgz","fileCount":13,"integrity":"sha512-1Y+tDLT+802O2NGi3rhzluW7nbI5wFCvCEiYjHBt/fKM/rcaSakhNwfycG8QZn217PEw/SCy/V9Z5oymtpqoBQ==","signatures":[{"sig":"MEUCIQCOSNM2qYn5nEzX+z1grPwDk2tkQ0EcoNf4Qp/eGoXx6QIgaZPYUFwB2QxWYnoZyFQa7k1T30cm+cw9u0uoYoB7b8o=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218657},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c692fe5320bd266ac41746ec58a1ce170d09af74","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.0_1730706309011_0.5159264020017813","host":"s3://npm-registry-packages"}},"3.12.1-beta.0":{"name":"@crawlee/linkedom","version":"3.12.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.0","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81ca4e25b34a1b3ee66b8a166d9ae78ff32ce3d9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.0.tgz","fileCount":13,"integrity":"sha512-5SCISBRCe2/mHbOeST0p3esPiqsyo87fqciHcXYrF4MJufi3DtmN5nKck8dUXqR103QRo6kyiu9XgOFANyXtnA==","signatures":[{"sig":"MEQCIFX8TknmdRvsNnpWiaOttUbklUevreapx2FPk8tajvUDAiB84nu+JzG5/icLBx9qTEUWObwf9mk8IpPgTsuGcaXCHQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218680},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"54c854d33c8855bbc47ce8144e3127155c5573f6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.12.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.12.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.0_1730706729385_0.5360013888545785","host":"s3://npm-registry-packages"}},"3.12.1-beta.1":{"name":"@crawlee/linkedom","version":"3.12.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.1","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b58bdb98131eac325f78412ca7aba242c29478d8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.1.tgz","fileCount":13,"integrity":"sha512-ttly+h+Rfu/ECerFdL9rOH3D30GMNWby5/c7R3KiSs1X7sc33klRG3z1DtBsoll174/pt2cu2WbeWDRmbvVH0Q==","signatures":[{"sig":"MEUCIQCd/+XktofZYin71NlKo/AzgUkcgsFxuAMpZXqO6ZMV9gIgVN2VA1/6STcCpRPfRhKR4Aj4ATC5ctfTssPQthnkUow=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":218678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cbfdbc038e463b84aebb44993ed1e16109558aec","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.8/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.1_1730831159904_0.9199095391099779","host":"s3://npm-registry-packages"}},"3.12.1-beta.2":{"name":"@crawlee/linkedom","version":"3.12.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.2","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"041da5227672b0d024ca5070d56291dae7e7ff2d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.2.tgz","fileCount":13,"integrity":"sha512-mbzhc+WVOwBdkWlbxdEaNFvgZ/gyQS65Z7wWrLg5dRM5/MtCDNnF8E4Texbe2ItKD3d454tjQjl6RnPz2753Uw==","signatures":[{"sig":"MEYCIQCOobM2wc6+EwKwbMae7WA8ba8LO2NxuNoLVkZllQ2A7AIhAJ7fkwyRx5iN9erqeO1kE71JHrWsHYt/nYHCAYhurEQ9","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b19bbd6c474f7bf6c795bb7c2cdf15195fc4812d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.2_1730846178535_0.7673790656549353","host":"s3://npm-registry-packages"}},"3.12.1-beta.3":{"name":"@crawlee/linkedom","version":"3.12.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.3","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"61adf17b1d9c96016e976346c158fd9c43ee3e06","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.3.tgz","fileCount":13,"integrity":"sha512-Qlyi9sN9cEBozqiJNjCtjHeGCod0CmBqakqMVa2XH2AYekf7BN2IxMrxUdH0vjer/EPJcUngE7Z/+E7RNNoNZg==","signatures":[{"sig":"MEQCIBtFo03aHFmfyIF1gIh2n+yBeHDm5Qb2nzh5yr4hUYXcAiAxHXizPN2nBjv8hyda8V/kPCUo2u/6ne3ZQkvymQODow==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f856447ab0e8acfff1e323d734e93c269390c844","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.3_1730866737975_0.39093331019551614","host":"s3://npm-registry-packages"}},"3.12.1-beta.4":{"name":"@crawlee/linkedom","version":"3.12.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.4","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bee60e39b2b0f7d8413d2555c1aba675791fe4a9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.4.tgz","fileCount":13,"integrity":"sha512-QzYHf4MTKZsZ1xtdPzUzxoB4U1CD9gyd9+PwH9NgTu4+r0sk17Bdw1uqA4X8V9LyiOseImDwRPilHcyWldon3g==","signatures":[{"sig":"MEUCIQCVl3tWcD989d2U3tqeObpmKH3ZdUzglbkDYCLAaCfHEwIgNum+9tzYOCU7PRvpvwtTaUGKMZqJNuSkdZ7iCjDrZSY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8463cc609716c1648c812993ab4cc0946bd549e3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.4_1730951868959_0.9285138333949772","host":"s3://npm-registry-packages"}},"3.12.1-beta.5":{"name":"@crawlee/linkedom","version":"3.12.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.5","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"343671be3fb029625cc7a6d242c0509746954ac9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.5.tgz","fileCount":13,"integrity":"sha512-o5Nu5fxBw1RxSJH9oAjkasZIv2gzPJyxTskSvp+JHji6ypKGQflqrBoDJLyv5Q5VsX+A0EeRdG3z4O2Yr8Ldaw==","signatures":[{"sig":"MEUCID/sn+Am/N3LGhgKv01agrPBuT6i2xa2R53ukhPa5n09AiEA6F4lzZH+JT4Ja6ypVvFH2B8VrU5UiuicHfFQwFh+JpI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d6c41b57abb12503f3d33e70e3c71b65da3552f8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.5_1731008562912_0.3003546048935508","host":"s3://npm-registry-packages"}},"3.12.1-beta.6":{"name":"@crawlee/linkedom","version":"3.12.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.6","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d0511ceb9c8501e8a0881861c18b826abd4d0822","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.6.tgz","fileCount":13,"integrity":"sha512-UU7/KX4IDeb79mgi/mKW1apLFT4dGvxu3MW5a5DcJdh9GalsqXvfExShCIV/9tQSt4jYp4AxGOvw0YXEBHs2JQ==","signatures":[{"sig":"MEUCIQCXwVWz3foYdBNJYMUI39DRFP3eGP5sRpJhU9piWVH7agIgFGYMn1nRjPJ4SN2+f0Ho5fW4shZplH9ytrUUljMUgkY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f11de1488a97e2a776efc865dc004801f6014287","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.6_1731035529937_0.1395786858062842","host":"s3://npm-registry-packages"}},"3.12.1-beta.7":{"name":"@crawlee/linkedom","version":"3.12.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.7","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0297a0278a1453b606f68c28276ca58db06936ed","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.7.tgz","fileCount":13,"integrity":"sha512-eAckrhHI0eMAItCSzvTirs1LSD8Pf19QDXXpV9lK3M0+gghf4H0lt6DYlJuYLQH7S/g5OBA6BjxM28uld/GW8A==","signatures":[{"sig":"MEUCIQCcQhXALbmxXXLbJ5nQr6z0xKuWcPsY52+lJKMRHg/ZVwIgGsnR5267JvMcaxDkGhicqUJ5VwWyUbmwQxc5IO+tR0c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2c9796290743c4cf837f0443e8b3153976b54aa5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.7_1731297492639_0.784029191574104","host":"s3://npm-registry-packages"}},"3.12.1-beta.8":{"name":"@crawlee/linkedom","version":"3.12.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.8","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"21bc586d85e2e444c406d03090ceaf89ca1ae2dc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.8.tgz","fileCount":13,"integrity":"sha512-t10FdBsTlngUQJQ2xA3uGw+UPaY/DZnvKE1ecyZTQ+9XPpguTPmiIrdcGgMSBYUsm7onB0S1DMDB7ahmpi9RMw==","signatures":[{"sig":"MEUCIQDETdld0z3QNBEkewDbVbiZZDVZoz9qk5S4L3O9Apad0gIgXuAWTCW/YjVwFeW+xmpaV8EBV7iJY6mOgvEffSXWjgo=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"44429e5b28619aa37a548f2abb26c3ce20414551","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.8_1731412673792_0.8047514345730205","host":"s3://npm-registry-packages"}},"3.12.1-beta.9":{"name":"@crawlee/linkedom","version":"3.12.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.9","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7521a381d3898b3236881eb5ef7916df00f55637","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.9.tgz","fileCount":13,"integrity":"sha512-8bwR7yjmRrCDJqLLmu8vOAOEyAIXJ+Ltd21T7pNZH4sRjU1OiWO9HWfXUUNQYRL0C3UrH9WDo0naRptRf5DzSA==","signatures":[{"sig":"MEUCIQDcc6JAYVShI80AwB9XLJsphIwOWuxtf5w/Z9bWL68WGAIgQnVfejU73tv8O3cVfWEtB648wnvQN4OgO8ulSsy472U=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225185},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1177e41e70434952120575241fb830e0b3aa7f25","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.9_1731960874173_0.791148420182286","host":"s3://npm-registry-packages"}},"3.12.1-beta.10":{"name":"@crawlee/linkedom","version":"3.12.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.10","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"685e14ead724971ee6058b54af5a9c88dbd6c971","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.10.tgz","fileCount":13,"integrity":"sha512-ulkykUvn969oVDcMoa0e49OjZeRXKOyR6YjcPzxqKdgD9Dw254KT79OCcHZKFPxvt/0JBiIBxdq4STTqjr/bwQ==","signatures":[{"sig":"MEYCIQCR9j7jkbS/DbhRDm9ktzroLdjsyYjlNB6LR6dw0qiHWAIhAPNYmbh2S73MlX/Q06ZV2dhmGUEtH9XQRqm1EXl5+dET","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225188},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7dce07e1cf40c5a09f0db799e72faaa9f0b90cd2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.10_1732055110168_0.5840208081495346","host":"s3://npm-registry-packages"}},"3.12.1-beta.11":{"name":"@crawlee/linkedom","version":"3.12.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.11","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e4b18a6ff934407554d23d43b53315e5a9a8a13b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.11.tgz","fileCount":13,"integrity":"sha512-5pZT+YHVBHNXTTP4AKMYpFYkaVn7O+kPtbyXD7Hxb+pgpFaA/nb7yzuNADMobnQOzOYbmE6Y5jqtPrvhRSOUUQ==","signatures":[{"sig":"MEQCIDD9duK0uAnyuPnK7yIzj1XL+bgAuQgolz3iKcqikCl1AiB9D4hIXxH1wP9GLqIQWC37vZveqPrmRsOgzeGREZVOQQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225188},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9a6c799068eb20d72f9348669ad843a6a91cac2d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.11_1732209884389_0.6096803132041719","host":"s3://npm-registry-packages"}},"3.12.1-beta.12":{"name":"@crawlee/linkedom","version":"3.12.1-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.12","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"93c6a835939a6c8263155110197f4bb3623dd5ff","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.12.tgz","fileCount":13,"integrity":"sha512-D2AVfRGLx6D+a8Q44xRuxc2n/mGm1hM5ioRGZY0sEK2ecUFJXkWhILfgt77hxfpNQY22t7/ocon2NGml3p4moA==","signatures":[{"sig":"MEUCIFzWRTWts8srt3Sb7SNx0NXLRb2VNImVDKHawKrYxvSKAiEA8kqLX+nVrt4gV93jQbia94LFN5NC9luYqRS0lol9wFc=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225188},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0cde4d454290e4c862fdefb0d5715d9da9628f0f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.12_1732251036786_0.34105909942921797","host":"s3://npm-registry-packages"}},"3.12.1-beta.13":{"name":"@crawlee/linkedom","version":"3.12.1-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.13","maintainers":[{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2d774c97ed67809f3c5d3a20e28dfd8cf962f0ba","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.13.tgz","fileCount":13,"integrity":"sha512-4OpILNodbbn9xcUC+lCbfQM3Y/OHxMoJ7kO/60F24CRkY3/A8SfpkOPTxOZQyPpJxPGwputRns/hJlECgop72A==","signatures":[{"sig":"MEYCIQCmdhuPdrJeXl5L1lDQ2JsrtG0GtryMZHvOfEhqjalHpQIhAOlrJdPABXhD/WX1C8V8iQasMG8O3f55d5OmEHvLou6l","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225188},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"637a67fa5e2f6cee5c61aa25d428b3a6ab3e780c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.13_1732313564149_0.14104954448144502","host":"s3://npm-registry-packages"}},"3.12.1-beta.14":{"name":"@crawlee/linkedom","version":"3.12.1-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"65d224453ea6854a81ad0bb2a6acb37fb90af05a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.14.tgz","fileCount":13,"integrity":"sha512-smifChH8lLsyZZVV53WeyvdMc5bVIXvGbEDDR/zvEceKW5uZQa6whiD19HsQ3L7qJiEWMpjnGyDdWQaJVQnh8w==","signatures":[{"sig":"MEUCIFZqVGSREzcf0mlZTyerCmj4ezFsVrLQYQK2xofKVb6MAiEAy7y8Sj1T9AsKzAfk/tbQD93GMboSPO4V3nFTY4w0PUs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225587},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8ec15ff68fccbf8961fe44d70dffb02603c9c132","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.14_1732521189912_0.4338921947401668","host":"s3://npm-registry-packages"}},"3.12.1-beta.15":{"name":"@crawlee/linkedom","version":"3.12.1-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"044c58fd4ea49a5ea9f968cbb5ff9d2902816d25","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.15.tgz","fileCount":13,"integrity":"sha512-kAq4z2mS48sTn0o/Q/Voh8xEh8MbOJuu0tn8jUrNe0d6EN0TKUqDvw6g0G+4mruREoCSoxupDd1BGf44NYBFcw==","signatures":[{"sig":"MEYCIQCaFP81ywvoNNfiPM8HFBOgme18HZ7EGXnTj0ZAf76g+AIhAI3ySdEvKfh61tpTFGx5/zHVt/aUganISLJ4oUfsYXo3","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0551c00fe29d36872cb35dfbd1084e6affa963fb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.15_1732522290139_0.2575635574549777","host":"s3://npm-registry-packages"}},"3.12.1-beta.16":{"name":"@crawlee/linkedom","version":"3.12.1-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"89c297c483d3f9f74d28fa9ab0f500096662c3c3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.16.tgz","fileCount":13,"integrity":"sha512-S1DbNyIiGK6/YemFmMoSfahSV7KRLS2vJeC68F27AqDPmkrTjJxAhUPpxS0Ov1ZU4Zrbd3Q64kRgCKRsFTuqZA==","signatures":[{"sig":"MEQCIGwGQv/aR2Vfd+NC6aB+g5Q+ToteImEhMgbsobVjwqQRAiA7Xr8og6Ez1I9TVwNGwMt3R/Hfy1+53oX6nP8yrIoMLw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c9d4d1da631739fa5d87c456e0003c3cec620f61","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.16_1732548767637_0.3084538739884992","host":"s3://npm-registry-packages"}},"3.12.1-beta.17":{"name":"@crawlee/linkedom","version":"3.12.1-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f962b51a110ddf2e8976ef2d7605bfb21bb3fc7a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.17.tgz","fileCount":13,"integrity":"sha512-UU33W+gCmcaTSbSc+iw8Rw2LyB4wY0YmzOn62KkMv70MAi24+dW5/cymIH+G6zP5Xua4OHNdFmwu1Sh5tpOdVQ==","signatures":[{"sig":"MEUCIQDVy/TNAmceYkgA48wUCxUOHRtqNzHJRRkdr356w/qwVAIgX463YIA88SMBLSzxtar15U9Hf3elXA9wvH+Z5NH+LK0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225585},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6b7aeb31fee0d91e3a3514505471f340aa3690bc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.17_1733237768620_0.44429577758700844","host":"s3://npm-registry-packages"}},"3.12.1-beta.18":{"name":"@crawlee/linkedom","version":"3.12.1-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"21958ea7c4561104c480f9f0c4b4c7d690890906","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.18.tgz","fileCount":13,"integrity":"sha512-RF2XVe4gdk3bRtvbSEjwrwQVXJQZLMVJ1u1Uqds7d63eDS36IU03Y3d+lA35MJN2H81CQv/9F/cqyiB+jZ0ipQ==","signatures":[{"sig":"MEUCIBI3IwLklFLvz5myyuLLdTZe9PmU8ZomJqwSoS6L8n/0AiEA9CzRegmLt1rvdAL8zt65e+9orqmWosSPKWsM3b5xtAM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225954},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"95da79f195a73416e4cca820a66fc2001a675b17","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.18_1733249564585_0.3419153100332739","host":"s3://npm-registry-packages"}},"3.12.1-beta.19":{"name":"@crawlee/linkedom","version":"3.12.1-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c5fc2a33e61e5bb2c90d9bbf3d13f820722865e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1-beta.19.tgz","fileCount":13,"integrity":"sha512-eLOwpoRw8N0lDoIhPIcQ5Chs0J9cxY4Sc7gsZNeQvghSkPbQxgNF+9A72K0VXQn1oc68RGYm9s9HA6bW5YFtuA==","signatures":[{"sig":"MEUCIQDKiDAfy9d7sTyWbvFmnKnSp92+8B44geQZjZDpy5hU0wIgN1PzwvtRuJ7G4Us+QuonARtuyiuxHpkLKmeW5LtEVKM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225954},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"27bca9f84a0979f0a919c1374aead3d6dfa3edb8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1-beta.19_1733283912977_0.23562484831758868","host":"s3://npm-registry-packages"}},"3.12.1":{"name":"@crawlee/linkedom","version":"3.12.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3fe280726bf1967881229fb81057cc02442d1407","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.1.tgz","fileCount":13,"integrity":"sha512-2pk2XGTUkBQd4dshmpk5ji7TU8h/P9UR7BkcqIoYoRc6vtPUS0hcWVdyJjGbdZLxLh4xBx60Xw6QcE05ps5qkg==","signatures":[{"sig":"MEYCIQDKH5gk6STzb7IYJPMy68KPet8iKcC7777FSTqIj1IFZQIhANFCuZ1W+Py7cnCMBs8wQu6Qh9ePKhFSCSu7b4XbRLQp","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225930},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"29e25890462cffe368ae8cdadec3440e0eb796ee","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.1_1733304449434_0.9922311198673064","host":"s3://npm-registry-packages"}},"3.12.2-beta.0":{"name":"@crawlee/linkedom","version":"3.12.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4bce9c41d0247494aed35c070ad3ad1599c42687","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.0.tgz","fileCount":13,"integrity":"sha512-xsfijlS/Px0Ipi4rj7KvJLcMjpxKSRLzBelYyZ2K9wKI/wjtUy+4qmiiHqvZ0ExOmfjROQRHMp4YAsQkMHJeXQ==","signatures":[{"sig":"MEQCIA6kqEkMlA6+9XclNij99hmX6fdQJsMo1KOYUmCOWrU6AiBbeLBspVrsWqs8cxvGJqwlnqT6xV51YZ/UKfkmp4r03Q==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225953},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c8f1922ad298e2bf7474b4b5fc8f7239ab3f50e6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.12.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.12.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.0_1733304881146_0.013992552754710896","host":"s3://npm-registry-packages"}},"3.12.2-beta.1":{"name":"@crawlee/linkedom","version":"3.12.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3468bb972bd778c0462b283852d4d4c6e63f1e0c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.1.tgz","fileCount":13,"integrity":"sha512-tbg4m3iKMlH6FhdbJLVk7XVZetEBAorDY9tbu0p/JtQx3m6y6YIcXoZfXECGPZPXwWD6SIEmVpUNcyNh6HtLTQ==","signatures":[{"sig":"MEUCIQDlLzKvd1emiBixlo6nzJGUBzdtPzIo6nta3OmJVU38zgIgBqxReotYF0R/wZueFbgD6+QRTlhHf6GPuNlD2BHJrss=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5e166a87a34c69ba6ef33f98ddfd3b7c5920f32c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.1_1733373193894_0.342106031289348","host":"s3://npm-registry-packages"}},"3.12.2-beta.2":{"name":"@crawlee/linkedom","version":"3.12.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"25b982d9835ce802d04ce8049f2d3c7bba55b0b3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.2.tgz","fileCount":13,"integrity":"sha512-YhDRlz6jptZxnC/Y8uoHfC+KLfZZ5zWHdVXyWyIFi6ohZVoOcfqm/r90MQvD6Y1GusEJgvyOlQpFcWRL0f3qqQ==","signatures":[{"sig":"MEUCIQCIdsYZ2958HnkNKdd7YPx8Y7oDwsxleWU3Boc8H21s1QIgVNGKyQfIcZnHoRFpbYinDl0YQGDQrvOW3xpZn1MKmAA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"618516a3bfe61cd9304c64eec3fbb18d0c69e6d7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.2_1733462188368_0.2353409788955816","host":"s3://npm-registry-packages"}},"3.12.2-beta.3":{"name":"@crawlee/linkedom","version":"3.12.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3f380307d361926159a11b8cb764fab46ec04abc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.3.tgz","fileCount":13,"integrity":"sha512-JU+o8uY880GFh3ZZgOhxJqvnE712yU6BQ85qGxuiZocm3iKXsDiXc1RZxpwzchCljw5crKTZanqrAR2rFZokrg==","signatures":[{"sig":"MEQCIGXwTBQ+R8K4DXTbNyoDSf8Aojcy4zEbYYgqPr+dtMeNAiBTiY7DuYGHqMFaNjpvv5Z2R195rckUdowutEmr4rAvgQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d3e30a1b886f32c7e6a8d300ce81266507769222","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.3_1733548921472_0.15678518420838783","host":"s3://npm-registry-packages"}},"3.12.2-beta.4":{"name":"@crawlee/linkedom","version":"3.12.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8a9c33b7c5ca31d2d309c460d1c1a82bd92d5c65","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.4.tgz","fileCount":13,"integrity":"sha512-poFjgAVOfIZZE1FJNqV61M3GMX0+0xt7MJFvAC6LcRTHxKYC17h2QpRaVahxpirTKhN5uwC5zAQU2+AkKtRuOA==","signatures":[{"sig":"MEYCIQCyfeSco4o1Rnr5kxFrqAcsAzfkSkaSvGJy6acnrLHEogIhALWskBIIo84Dr24hvsbTzMt58KIf4c4KEoIJt1jLKNVc","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"11f08151b5fb977d0c82070db1f0042b0c813805","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.4_1733630634285_0.8995965456394566","host":"s3://npm-registry-packages"}},"3.12.2-beta.5":{"name":"@crawlee/linkedom","version":"3.12.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eaa8ab752ad8cdbd1bca4ab28968cb335320a03c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.5.tgz","fileCount":13,"integrity":"sha512-o86if2mQI9bkxLzye2H8mTib2MbZhTGJO++0sWA6oCFqDslAi80E3ZCniR3yLYvuJhrjZLVs+n9hj6WkLwhZOA==","signatures":[{"sig":"MEYCIQDlw/oZyD8Va9daFmw3SiJMZEA5FbKoR1Y4Anj9ArucOgIhANvv/HD7Fbp0zfGsgKioc+hr3m6xNhgGdPCLYalXlwZZ","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3c30c3bcc344e3355aa0748bc5c99e28a8a7f78c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.5_1733790417479_0.21273957892055906","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.6":{"name":"@crawlee/linkedom","version":"3.12.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7ca147340114f1aea67d62a2e61f3d94684e9a78","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.6.tgz","fileCount":13,"integrity":"sha512-g7FK76CI3URSk7tAs0EXNiC1t/qJf/jmj9Tg0n200uNxUx/Dz1rbvzihICf/Zm4d/REIwbLKIGOFkv5CQz6fDw==","signatures":[{"sig":"MEUCIEdTL7WQtzPzV72RDgyoCLbNz1a98PSUjgc1acC1ywKnAiEA310fcJaHZ+/Y1pRXjtZYszr/FDylOiTZP999ysml0GE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2b72d9bf4b21ebe7ea1f4e4457f0e040cee8f30f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.6_1733813152896_0.42217021559600254","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.7":{"name":"@crawlee/linkedom","version":"3.12.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"02e66276c6b770c7553203a023e6006c5be5bf6c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.7.tgz","fileCount":13,"integrity":"sha512-oqocOYHXNcN0yfOruzMIM+JQaLBMjkMS93OEDTkKoj6GgDZSoX9sYh5dSvAagZfjmH4QJd88AsL+nPnlXXX6FQ==","signatures":[{"sig":"MEUCIG1CFPFSaGq3tVh+P95ymW2RlN3ubwWY8Jy/mNcO6Z75AiEAm1ughKhcAzZAGz/VND2wrvvFg6k6Pv9z1OZf1p4ILcQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"198479c119e668110fc43e7661bc72e1a95f0cdc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.7_1733831366060_0.2423874174126004","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.8":{"name":"@crawlee/linkedom","version":"3.12.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"242a03661a9392ee7e71ec004b65b4cb022c1252","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.8.tgz","fileCount":13,"integrity":"sha512-nUYbRB7IjiXRjJoqZamFGodNkI2NEtfnSoasn0X0LHXvRODeW4fWbZ9zORfy0C0T/FnPHdojmrIFH/pMmGx4Jw==","signatures":[{"sig":"MEUCIQDw8PWhDV0b3ouppyAp6AUmaGlYWIwJXxNx4Z044aGwygIgacHZJki6Za94g6qlFtXQxTvpPdU0Uju61xcUUrBszXE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d2729bd1f8201bcca8fa646cf615ccab59b25236","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.8_1733880146656_0.5488713515202461","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.9":{"name":"@crawlee/linkedom","version":"3.12.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"56ff2136c53b9af282829ad119bc3654d4686198","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.9.tgz","fileCount":13,"integrity":"sha512-WrjleczcSTFpj7zrcpJDByJSsxfEO1vQMo7pLfPNskBNoRXPgAAkGprQEkn1a63kf6BpVmgtFUtRoNv2x2n1aA==","signatures":[{"sig":"MEYCIQCTILc1dLNk+8bD+DCaZmTpnZIiack9KRJj2MD0Zz2BGgIhAJefnlRpoX43aniop4uMP75E9dNFDlh1Mb5IdpNKzmI+","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225951},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7e8c7aad3f639fac7065a54e9cb61c4f949ff564","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.9_1733893705794_0.04067102126491706","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.10":{"name":"@crawlee/linkedom","version":"3.12.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c944e186caf35732c08d21751f7214901e31408e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.10.tgz","fileCount":13,"integrity":"sha512-cDueSSqrMoi6kN8vfG7xZ6GhI8knNMl7ELjfaJBtSWDTzb0TF/ambMApFguB06rjq50QIKl38FG4czDnCYoT2g==","signatures":[{"sig":"MEUCIQDzNZT7WKd2tm1l7ks1tAFTBiRdZeFNuio0MSGZ2+82TQIgRjTT6YeJtdLZWf0FjHFkBAHHqaeUK348z+8/87GGlIE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225954},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"58b3c26b260601a7c1461146036272e69fb6bc73","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.10_1733914518789_0.013080259118710247","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.11":{"name":"@crawlee/linkedom","version":"3.12.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"56079d8d3114d11de2447d2cfbad0b92414ed924","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.11.tgz","fileCount":13,"integrity":"sha512-5MLNGpQMRRukGNd0RogUUWPN/M+AjBKxEZQyhqdqeujUxALEesD5Qp0okvYt6fvicedTRP0pTb1RMMjzHNQ6ng==","signatures":[{"sig":"MEYCIQD0vIEMF1S6vPshpelYw6k3XKD1AYsxiB6+GR2/8j7DhgIhAOAmQu94JvecgC4mxaP1hJ73gr1mVD1Iu9qSbVumCttr","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225954},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b58a66bf717395f8f3e029e0a796de42be28316d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.11_1733977082658_0.518818318919612","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.12":{"name":"@crawlee/linkedom","version":"3.12.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"713cbc5ed9f53386ab9bd82fbb30d552c50661d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.12.tgz","fileCount":13,"integrity":"sha512-Cucwy/RBAJJf0zA6fvbPQbVjnbYmjR52RVzgCAjd9Z6HqSUxLEmGrS/KMu6Yd5FsoQyhFHgw4fBgCNNDMWWzhg==","signatures":[{"sig":"MEQCIEMt+SnlWiM6b5qLkbFkFYzN+0r0UvVMwV3gP5Wa2vGrAiAvROHvPTRA3rhNfd1J6BLUg/pUWl60cTEGzcrW6IzSBg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225954},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f19563ad1f3522230b348b90806b5b4538682933","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.12_1734029717179_0.18209650133733235","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.13":{"name":"@crawlee/linkedom","version":"3.12.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0df1ee5c44564b78ad97e0973b87d1b86278ae4d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.13.tgz","fileCount":13,"integrity":"sha512-7AE7qocLzgE96XkkeLAszLR+3igD0PdjfyLHkPvE4l67dKI9Fu3Jp21ThBNz19sDfqyLNbWNi/eOo5Ydy1XMUA==","signatures":[{"sig":"MEMCHy4kjCjOvYJIELYCosXWKa5UNOFI2ix/YtQKUSQzQT8CICosHtL0iqchqBYewcqfz7KygK3Qc/F8bsvQhR9r+e5F","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a8aa94e59f1c09d907961cba0aea81535cac595f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.13_1734064051247_0.15813315895603042","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.14":{"name":"@crawlee/linkedom","version":"3.12.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"06685ad8ae487e62148fe54fdc784d2c26ac9958","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.14.tgz","fileCount":13,"integrity":"sha512-pZOFwQAe9c1GPZWTswGGq9zxsVGvrXh3JXS3NMPe/WjwvWPfYtMRFJDK+ao/7AxzDYxUhuVx56V0D8rdUUx7rQ==","signatures":[{"sig":"MEYCIQDGjVYenB9+ol2ux5DdCf5eDWbaE9Qv2qSKEH8/KFB9/gIhANj03O0Fqs8UCs7OxfyjPxaMrnBLLephmMm1lERsPDBh","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2a03cd3e345f57eea174e5f088d82268630be683","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.14_1734146103234_0.667755506029682","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.15":{"name":"@crawlee/linkedom","version":"3.12.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eb39dac465661769d590c8451cb22395ba09642c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.15.tgz","fileCount":13,"integrity":"sha512-lQRqSFTgryBTjXB7gxIGcC9sjELY4O/Gb3/LAal2anNcG835eqzqqyZnOXZ06h1pX4nG96WL8QVCMhYieo28gQ==","signatures":[{"sig":"MEYCIQD7pZzEwDjqGbAeiKoNOOk5q7Y6iFP41jvKqJq5rJ+uGwIhAKSS5xTe+49BVPDb8xVysBEPGu5XA6N099Py73fddic9","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"68343e89ce5c3a3d3c43da636601d6eb94915aad","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.15_1734170370999_0.7137149185129743","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.16":{"name":"@crawlee/linkedom","version":"3.12.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cbb6553025f3c61db1ae0589d308192c052b6b10","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.16.tgz","fileCount":13,"integrity":"sha512-IC/SEmZPxkZ27TE4Od9jvR63BlqhP5fFY4/H4ryOZggpCxjtz5b6GbBYVGsMos4K+WWo43jKcYtqnY4AV9Lh1A==","signatures":[{"sig":"MEUCIQDHD8e7G9SW98Z5zGqnATcQFS6XBqgZFuYMq+2Jnd02LQIgJqluEVWl11ayk64nIEeWYCjY/wzXNZBF8UFqiNY06mQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c44958e7ad4b22522d6baa40ac7d0ae6fc633207","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.16_1734320466426_0.7581010091468818","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.17":{"name":"@crawlee/linkedom","version":"3.12.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6998bd921204201570514fbd4023e919a1189351","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.17.tgz","fileCount":13,"integrity":"sha512-Y/TI/OwllyeN2JcO8pt3nOTzwzLSdrcWt1PfDCEPd+Q+sqWfCagF+tWHCKNJUe1t7hHkRAHv8bKvBZq4CbuGXg==","signatures":[{"sig":"MEUCIA3+kOu8TNQECcdl2azs8JlncIAsuTA1OSXVjARb/DLbAiEAx13Xb1Z7FX8Hpw+BhCXSu5z7o5/EIHMtma7mer8J7fg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0fef455f6f8f25846906cef3e1381c41ea31dc1a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.17_1734495503506_0.4848190654100417","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.18":{"name":"@crawlee/linkedom","version":"3.12.2-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a9e3858c70909ec401c7df2310261c729fa4dd84","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.18.tgz","fileCount":13,"integrity":"sha512-itLtlDYsB2sg7+CRD3njmH++5i76SuWoq4wCemU5qo1GIDQd2GndHQsDU0PaqapjHcoIXL8WlKNJdxz+0PfGbA==","signatures":[{"sig":"MEUCIQDuOxhYnGpAHloE+DTZaWVuB0t0tWbCYWrHb0OzBpni4QIgBRdmP97g7VfAzJA+LqOPkTVo+lBQZw8kvlpuyh8W/p0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6b43568b6bdf5a342e7498b651a7f610613b4848","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.18_1734550019629_0.8338995776363192","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.19":{"name":"@crawlee/linkedom","version":"3.12.2-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ff9480d12caf7c8bf0f011978a9702ad0db181ac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.19.tgz","fileCount":13,"integrity":"sha512-nVkb9kGJxOb+DqcOm7Np6cgceYwdep982CtWYEPNiCU4290JsNmKShCTEsdn7lKgJ+Pmksf79EsG2tfocfL52w==","signatures":[{"sig":"MEUCIQD5HUAjTwGkvAwXr5ibWDhrl6gytKf7C2niDC0E7Xg0dgIgHitAuIYW4n1S8AjlAr3nO+jD6H2U5iVQ3vSgAJGX+p8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0a2b49e9e31c2f349e56dfa57030aa5bd89cea73","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.19_1734578198616_0.06197656814917751","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.20":{"name":"@crawlee/linkedom","version":"3.12.2-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"99efc893782d4eae2b9ec04656d3dc098439271b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.20.tgz","fileCount":13,"integrity":"sha512-97WCdLVWAUXUU/uumJs2CPNtvA5tJsuuWaW8CM0NgVwLiRkK0Msor+swaZOZeOzvJ+Gb05MERodT3nDgFoMvng==","signatures":[{"sig":"MEUCIHp/L0cmzLkMdjPaShTxWB/1rHvQF292qUKpEGNMFPe7AiEA2VRKUloBI4SqeGKOxY1ZG6dxOrwyG6Wk1Aa3Uf/zWz0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"85b88e0d1ab307af8d09077a02d74df0aebc0c16","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.20_1734607540200_0.4066069926685636","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.21":{"name":"@crawlee/linkedom","version":"3.12.2-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"581f937515f00f01b08bcfae0e085b81034e3885","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.21.tgz","fileCount":13,"integrity":"sha512-omCT0cNte55x4EQIfArm71uR3o4DfjgRy8sOEKFm5n5RFiOx2g4NSIl8dSxVU3VVl1iglqQOudZRuqdaIgUs5A==","signatures":[{"sig":"MEUCIGmVHNpNrwkQ0CaahzKx0p8+ktz47hy0oBQlsINpAOteAiEA0VVqb+F63Mikg+sjCB5aYhBQHx7H9FyAcJpic8igNlI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2e208612ab023b5af75bb7176097cd079104d012","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.21_1734617007326_0.8494903703798404","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.22":{"name":"@crawlee/linkedom","version":"3.12.2-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1c9ecf7aab4169afe6f14331407247d1264bc168","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.22.tgz","fileCount":13,"integrity":"sha512-cUTZZrtqtgwA0PjR5zK0F6JcZIvJAwE961zGOclt6jgN2iWCLa6m/IxlsFff5oiVvD42W2yXNDSYfB/sWeKu5w==","signatures":[{"sig":"MEYCIQClOVqIUkv7A5Y67MGyIzzLnpq9MClWuYrIxeN977Uw8gIhANo2cTpxhP55CK28J1IqAt11RfVzFk+T5tG61kibgD+v","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7dab27fbdfb54fcfbeb7e2a99f71a232451ff2e8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.22_1734665887923_0.5397212580923116","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.23":{"name":"@crawlee/linkedom","version":"3.12.2-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d3ecf3d4d3b31462cfa159fa84fe1c0d49975e15","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.23.tgz","fileCount":13,"integrity":"sha512-II+F+ba4skK9TSt4y6PldraaN2Jd9Z5DesqbmzE5GDedaB9h/iu9dohbRtQ0h2RfHetL3lW8VmC2cLDq/PvpEA==","signatures":[{"sig":"MEUCIQCOYbTWQXEL++OMF8Brn7JFu05o1VofR70BgnGQFPUpgwIgc96YiiwSA/qC/iXllJjNXtJF9LRdTrN6PULD6nLsD0c=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2d7092146b88e35b5617e68de1f5a2b262b2e50b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.23_1734751919133_0.4261727801687478","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.24":{"name":"@crawlee/linkedom","version":"3.12.2-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"67439895434cc76db9de82cfb006fd99769fdd41","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.24.tgz","fileCount":13,"integrity":"sha512-+8O9GyzCDSSL+lEKmfompdlJG84vJgXsEZWpClpfH0I1XuPrLrHqD6IbB+wyW29hvGr/e8ZP34HBo1LZ+/ox3A==","signatures":[{"sig":"MEUCIQCLglXULUdrVyrid+Uu3rWvG3vr/5AzY3+y6+8QqDpQUgIgHu6JLJjWuPLMqStlQ+gVXMKF+EYqSyhyXk/znmkymOA=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"01438beddd71b62550ad46a45636b579fd0ada87","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.24_1734804406710_0.17065389337628867","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.25":{"name":"@crawlee/linkedom","version":"3.12.2-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"14a93a01a6642a257cca11a4b562d89e2efb8b33","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.25.tgz","fileCount":13,"integrity":"sha512-+ZQLj/i3lpUuOeU1+X2cDB1xQ7W/4187v9y1GI7oz4Y/6WTbOeaYCjUS7s2oRRlq5/Js1IRg3daXNQ0H/d4kXA==","signatures":[{"sig":"MEUCIHYK9lBbaAQisq2T67zBWv/7VKkuTxpL0lNF1IXpkAGhAiEAn/Cday2ikLa+SLrCUJNnz5h43YOJ6UR3RHSPIoJFJdM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"824f392bcfc3a9d07175da2585255a5163f91f05","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.25_1734841570892_0.30148519145379105","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.26":{"name":"@crawlee/linkedom","version":"3.12.2-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c84536b304bf7911c6cfce60429beaf99447fece","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.26.tgz","fileCount":13,"integrity":"sha512-tUjWKJ13svjfUsTdFdLvm4jLD2JFk5mTXjjPkzq7lKXPdNWfV/PxgKVN0Z6SSds/U1CYGUPozrloouYcY5tJPg==","signatures":[{"sig":"MEQCIB+6hXidO/Yq+hcLG+vaH3B04ZC0wkCLYZD/olq2VTGHAiAumWPTHs37kHHx/vTUYWUMAuDW00FovzWv9t67pQNGqg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ec0771c3095e9cb23bf1385785609502c1474669","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.26_1735018198614_0.5687330330952114","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.27":{"name":"@crawlee/linkedom","version":"3.12.2-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b8bd423af79f42b13b7a48ab41312065684d182f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.27.tgz","fileCount":13,"integrity":"sha512-CMVisFk7P/MTdjyM7Zly65HviDvgfTKdZo+9NRFs+uBonWAJALiKimuAzmp06ks1ZVcejwiNQrM1PQtkTkL45Q==","signatures":[{"sig":"MEUCIQDCJR7sytYMKq3hZL5piWNs2iLyhu8dRUNRihJs36oZDgIgHnRSnZqw+hqf5XV2fcsYe/ZkGy3uzm7hMt8G1JSy+Vs=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":225980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1bb5b329a05672a66a75c29511dbe1ae441b1bb8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.27_1735101507375_0.8564592517990313","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.28":{"name":"@crawlee/linkedom","version":"3.12.2-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6033fc006b88728066f7a0b755c41d873bdfc690","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.28.tgz","fileCount":13,"integrity":"sha512-rTx2P+kwPuQkpdYbUKsJZsoKZQr7V0xrh88ryC/3vo3mSTO618sIt+AFvsPXS0nOynOvv5lN6nY7IKQ/wfNepA==","signatures":[{"sig":"MEYCIQC8yK53WHxMR83xotwsAPSaMkcjzLbCu4/l2t8BF5LsyAIhAJW6bjTPGRqAGsQbCuje+9WebGIvt+DwUaYSVqeVT+NF","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5b66c44ada4e42fab788db1b16f2b55ba5fc59f3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.28_1735187885289_0.7217730391909363","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.29":{"name":"@crawlee/linkedom","version":"3.12.2-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4a38afc63b13b73aedc438e04d5226ba85ff9f5b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.29.tgz","fileCount":13,"integrity":"sha512-XGF9fuygEP587BGkWJPXDhzfyO7xs2tsNJ3TLHg2MOt/3w70DvmFAywpj+cMxF+t0gLdFJQE4GdlPC2us8hc1g==","signatures":[{"sig":"MEQCIAm4XxaSo+vtsSR/mVbWMe7LalNnRQe5YyKL/1mPSblnAiAw6aa5Q4fze0dIikk3o/3+Xwojbbtn3GUaVHV6ROmNiA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ab89f38b1538388902f4eb0d6bd8ea586366a7d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.29_1735276736941_0.09115500934181675","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.30":{"name":"@crawlee/linkedom","version":"3.12.2-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1e9b04f8ffae7d89bea53e1c4e06220a8dc71e40","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.30.tgz","fileCount":13,"integrity":"sha512-IOEF/mDJhKykhUfwQEmAmFZRpxXLlTf1ZC9uHrUOncYuxAzdMPBhaAWGYE72JRISXWaetsOvIhYVwEcyaOGE4w==","signatures":[{"sig":"MEUCIQCEJWWH9EtbN3gEpunE89n0zeqUVUZdRh2Sr8OX+h4A3AIgC4y5RNVPnyKyJR6YTrmFd2MqkG3C8gVxeNJ+dQalaII=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1290aef9e7b656c649485306ddb453accd30d04b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.30_1735444353914_0.12033627647108491","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.31":{"name":"@crawlee/linkedom","version":"3.12.2-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7a4ac2e2282ae9ceb9a6472edf238602c63435a0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.31.tgz","fileCount":13,"integrity":"sha512-epqtukiG28KOQRCh+T6Ab0z3mK1+73BHPwi2/P4wMaTh8lSpXzm/VGPK6AsVfFyUzMXc1+h+QoLYN1J54AB0cg==","signatures":[{"sig":"MEQCIGJgRoEziJ453UJmSgWqxbIkl/duNObph8a5dKg3uPrpAiBql85jF8xbvMk4san/PFS4ixeDaJfL6Ip15LMTXx1JEg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"522b87ce7b37842b170ff347f5e2a486a6397bfb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.31_1735533915904_0.7073403921767112","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.32":{"name":"@crawlee/linkedom","version":"3.12.2-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"318f44ec250d94420fb2320193e4716bdcff753a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.32.tgz","fileCount":13,"integrity":"sha512-60RlKYcELmf663p2PSMyOxvqFzyauKvShzE1PTT3RK4dB3pIXDYNAkSa5uTJ2rggo6mNu8RotQiHFb9ph76MLw==","signatures":[{"sig":"MEQCIGXP1OJA7aO/7TAgjy2t9q00mSF1/3umlbaCfbCwdUV9AiAgjqSeu4UZNDSGDwTiRVvydDCP8F8pYJcfsndxImW15A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3bd2880c519f043305f5c46c5d86969d4fb9b59b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.32_1735543972586_0.727944279406934","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.33":{"name":"@crawlee/linkedom","version":"3.12.2-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bb7f6cf1999482f84a6f87e7f5c23db49c97832b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.33.tgz","fileCount":13,"integrity":"sha512-NRnYWITEo3CCUcx2HtPfrZyMP66YiIGlD0oESjQsAmLRgRMGuj6Hq73x232bJglgnfLoXqZymmxZY9HVRBR6Ig==","signatures":[{"sig":"MEYCIQDOzAFrt/cdF0Eh0xHhwQU5UWgQ86oGjBedBzkiIEqzQwIhALJvAVp4NKW19kvZSIujBS6oMZUXk5weUljvXy1iuEF/","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"39c21071a8028b61aa8ae3cf72434a99d11fd97f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.33_1735703377273_0.01181589249034709","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.34":{"name":"@crawlee/linkedom","version":"3.12.2-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4abe6c87d0f7eeea002cfa91ce88932caaef2212","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.34.tgz","fileCount":13,"integrity":"sha512-eapNpkygVHkSL38qRhuLTVlk0/OoQ6VFxLvNT1ee9f0frceNpHZQFg94Y9dHLLaZhryKi03VYjaAJcwSbBpxSg==","signatures":[{"sig":"MEUCIQCI7xHJIUdp2py3GjBZmi2HWpLLKHvAn89ERrduzQQtEQIgGlu02uuuUzZx1Z7zHdkmxqpPWnaTgrVta9CvyPLgwEI=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ff3d4aef526dc8cd3a55db451ab714f6e3cacd25","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.34_1735940452982_0.5875603684512118","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.35":{"name":"@crawlee/linkedom","version":"3.12.2-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"432c952ee5058822112d0085212753da73bdb619","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.35.tgz","fileCount":13,"integrity":"sha512-/U5ek0m0l4G9lduNSWCZbPAuOddLZ7iXN5vtRek6QB5GBem/SA3C60F7rlzOaLKj9GETTkBDjCikE+JaRbAXkQ==","signatures":[{"sig":"MEUCIQDaKM2/aBbBuDyTXsnuKRZgXZ4YeYrizM444rNnXmsJgQIgPOznZuMWdIRJcqrUwM7SSu67Tyn+iioqoIhSaJmsDuY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b045f8eb5b97ed04090964b479219844a978a926","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.35_1736281113360_0.9493723535782679","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.36":{"name":"@crawlee/linkedom","version":"3.12.2-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ba51b467bb129cc8c8f18ad52525b2839b532a58","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.36.tgz","fileCount":13,"integrity":"sha512-bOxv8iSvd+YraaLil2Y330l+p09xiyQaHIWzebwLLSk2QKmtdVMiFApX7aoWgq75im4Yn4Sx2uuXTl3VExbQUA==","signatures":[{"sig":"MEUCIDsQ/c5Zr6PLlAgvmtCLNoVbVSx+deXhZkFLgcmqfQZXAiEAvOnbZzKNtTB2ejpCeebA9+mAbY+nKXO9HmUz/1dTj1I=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"288d6935c8cd9220d4a6c3863a4796f205809280","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.36_1736284056396_0.8118586285807303","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.37":{"name":"@crawlee/linkedom","version":"3.12.2-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8cafd1283b70194011dbd2e63dba99cd4fe691f2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.37.tgz","fileCount":13,"integrity":"sha512-uHBibPLKJRILecZMpQoMSNdjA9ladtNRKKwRBCnNU9Eh6Q8DGDMVSd7H+jUr9PspNezmL8+Js8YJlQytBN10NQ==","signatures":[{"sig":"MEUCIQC4Pxm9ZbaFQFQXmD9hIiu1dD1bsd8z+PfxIKXSiV6OygIgZCmLWBkFN4GTlvDQRY3T2pwNuHDcTfutugDWARE47fQ=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5d99e1526dd6b4c53cc2cbba2c8aa2c14b4fc390","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.37_1736298742615_0.03254033957752722","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.38":{"name":"@crawlee/linkedom","version":"3.12.2-beta.38","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.38","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1fa727f0fedf5e0b0e15b419872bf504f2d8acfe","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.38.tgz","fileCount":13,"integrity":"sha512-xBdgQWY87WX9bk18Ge1XLGuK2kB8MEvA06z5kQT9pYHuB3lEGxqy73ldP8bF5DsBBwq+6D06aIa2R0eyths3fQ==","signatures":[{"sig":"MEYCIQCESe/ZT0dCkJ3MbMqZFRkXa1kvaPjHUvU0EprSvfWPRAIhAI/8xclJJiAT9+D5+7FaY7xxpDbkdJ9562n1xtDhHL0T","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"15e9090d746ccb89b96700e131c5f372d647bac9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.38","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.38","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.38_1736311771025_0.7268256982551373","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.39":{"name":"@crawlee/linkedom","version":"3.12.2-beta.39","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.39","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e77652f2876715395981a90582840e058da9741e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.39.tgz","fileCount":13,"integrity":"sha512-JDvzwSepLObMafTaABGCVIPQhCM8aU5ORBBYHWVorG1kKucS8jpQFb44dhiY0GKE0oUR/wjixzWtZhEsEUZPYg==","signatures":[{"sig":"MEQCIHUEnn1wPYTlmT6vmuWW4tTcjxGm7g6O7mOGaiNINu9AAiAgto6TGewHW3Sel+f7R5zdUkSUUcooaP7LZaiOvUOnEw==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226010},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca417b1c1520ac0a76043d0fdef03d28860559eb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.39","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.39","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.39_1736398559750_0.17101700731411285","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.40":{"name":"@crawlee/linkedom","version":"3.12.2-beta.40","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.40","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8873d3bea04aeeaa807b7af3a6ce6e7a38731e94","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.40.tgz","fileCount":13,"integrity":"sha512-KvRT+DklayusAHojNVuCWq2rMuvI+jvUWb69GvEo6lS7CwzgJodie0nQ6DR+oAPKzfzJ4iq9/qgM8h28//HFbQ==","signatures":[{"sig":"MEUCIHrFkFrNpM4sDo/58NrHihPO7S8qibNuEDsxxobGmB4zAiEAouTPkUzLeZJftZmCKb0peoltycBpYgxGEkHIoNlB+l8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7234a86e289bb6bcca2d1688ca01febc7c104e93","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.40","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.40","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.40_1736485109373_0.06150699749118593","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.41":{"name":"@crawlee/linkedom","version":"3.12.2-beta.41","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.41","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9ae44864e4768856e2da5f00a0df55e9a007a7e3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.41.tgz","fileCount":13,"integrity":"sha512-c6vp71ROgMgIDIZrUOY3E84BtIO2eZhnuhRS2O7B6WgTzFK0jNhHKuaP6HcyVaeeoN8mJnDxrFnaFSIJKYXsuQ==","signatures":[{"sig":"MEUCIQD33F6H+dfXfYbVHscE8Tr3p7Tr+TsbNqMq+N1tV44dcgIgdEo/opNK0EeGeNLbox+Eyc6diV0RwmFcE8gHmFFvfdM=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"30b4c41d79e184726d2995287d2e63586f1e4708","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.41","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.41","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.41_1736510139013_0.6110146541635271","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.42":{"name":"@crawlee/linkedom","version":"3.12.2-beta.42","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.42","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f34bccaae4ebe1d1568e4d1aa37c45f277e7bd16","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.42.tgz","fileCount":13,"integrity":"sha512-xpjRQjCzIvU0EyVBvThmTq3NxIWZ8oST9TM0BVYq3TKa40DX86d6GMpEZT0HZ/ttWg8uTj+2bC8ZtYQ+dIEy7w==","signatures":[{"sig":"MEUCIEVI+aWJaoGqE241cxjfHa8jYY33ywIlVEXn5dD3fwBgAiEApEdKu1lPD7cb4hNFO83QVSsqm0EtMP/xnmsPUpu7txg=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"add0685e49248391946ef0273d504f7bcc6a8331","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.42","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.42","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.42_1736571248239_0.5976299229793729","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.43":{"name":"@crawlee/linkedom","version":"3.12.2-beta.43","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.43","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"48ca5e96017c3213678e67b4ed4f424edd72bd1b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.43.tgz","fileCount":13,"integrity":"sha512-jCs7QWpX05Usyp/qIALKBS4X/hsqbSf6mk1qXO1NfWtAoZtQsSqC+t2BI0nEZ6vAmzs93yQ8upkgfhCqavjB7w==","signatures":[{"sig":"MEQCIDemO7BMG2syWyqFwUzwL6dty2ih4Gn4iwxxGe0rNxLxAiAgvNVMiYfDcvzAS1QvfQvdQhguw4p0Ln39cnYh5TaNSA==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9c57c576e36049475400a82ae56a594bd7a73e60","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.43","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.43","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.43_1736782035411_0.04922154469826312","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.44":{"name":"@crawlee/linkedom","version":"3.12.2-beta.44","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.44","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b669b620357e91b74b6a8d1e8f01d649a7071c5f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.44.tgz","fileCount":13,"integrity":"sha512-tAuxt+baV6gtYaBYynoFORNwZlCih6+NI61Wxq9pGLwnaW6VyMH/9bP2nD9N/WxeI2n1AUXtyE7xzvlQWdBZlQ==","signatures":[{"sig":"MEQCIHteP3DwNFuRDEY7W/cjZsnQJ7pZCTsPHA+5EWj7zc8sAiBJn14mU/fw044GS/FGsBKTbrzgY0Y0TvU9Kj2vyrIqgQ==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0551a22284e3aa3b4f3b8fddba245ea3c2743cae","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.44","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.44","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.44_1737195862170_0.8991615161566042","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.45":{"name":"@crawlee/linkedom","version":"3.12.2-beta.45","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.45","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"64cd46a9b34b76463c70469472e9f96c5cb4fb8c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.45.tgz","fileCount":13,"integrity":"sha512-1BQNieU19qdFSwnoj+1vko78VGLFFb1WJHC0fFAEDeNAjmsrbNCcuXIupyrGnwDft8amirB5j5f4GLBkZNVLHQ==","signatures":[{"sig":"MEQCIDLPpoAgXIIq1T/reWmDn8wkC4zbulaMysp/ICK5yngcAiBXv5cBHc6U7eeUUtQ1vk6l32KWOVaYbtdX0L2trz0JEg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"311e2f9a0fb50c1bd65b821a6db5ca3667f6a073","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.45","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.45","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.45_1737367081137_0.27519857656670443","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.46":{"name":"@crawlee/linkedom","version":"3.12.2-beta.46","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.46","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"879596db2ef16b814575f6f7495dc65ab072aed3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.46.tgz","fileCount":13,"integrity":"sha512-6bnsrYSVBKtwvnfExXhlIla5VBW9TVxVgMQNsBoC5ZNYh61v1r65YKiGHC6JJa73/ID6OphtUmJqGB1zKNumxg==","signatures":[{"sig":"MEQCIHc6bp3TFfDLAL85olnl9kVRL+Ar/mA7iwaxvLpOanldAiAdE9JPCibMqJ0OtTPWuMXibO9lAQ5O4DCdbl4VHc22Og==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1eee45dfce98796ad5752a420ef5b7c027c51687","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.46","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.46","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.46_1737367607396_0.9452344869839828","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.47":{"name":"@crawlee/linkedom","version":"3.12.2-beta.47","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.47","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7bef6c69ff031fe70bc915b4f06e45afacc37911","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.47.tgz","fileCount":13,"integrity":"sha512-C3C8oLI95/FY7Cq+sQcLx0AKIYfVfIlFifuuBrnLU6n79yuVolTqHLBGjzhsg2P4LZWD4HBlmYXGKaPNotfjDA==","signatures":[{"sig":"MEQCIGIsu9t5RgiSNSSob8xwB8/axiiNdvA/vGFy97AnEQZtAiBNBYEo+Znf6GHj07G4V7+jjDxwwmWMLdI/e4JylyFE+A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"beba86fc6a786f28eef186bdc8722a073f5e0874","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.47","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.47","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.47_1737377439604_0.46232381863346705","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.48":{"name":"@crawlee/linkedom","version":"3.12.2-beta.48","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.48","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d48dce50f2e4d4c5b570e638c439b4ae4144e0c4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.48.tgz","fileCount":13,"integrity":"sha512-CpHxr583cOPHzHHAXkIQTFrV9Nvq1nd9AG0+dvhxudDli4jMMMi24LKiOpScYDIC118ihmQKSdmo/AIpzgwRJw==","signatures":[{"sig":"MEUCIATcoQBjwrefgwxGcp8Z8eKy9Eb1CJJe8BhqiGVHWFz8AiEA+Zc1RiQQm8aOy240fy09rxdKvXvWRZ4X0kXRZ84NBd8=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"87270296807162c1b27245735140e54c5375d352","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.48","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.48","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.48_1737381811180_0.739926128553716","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.49":{"name":"@crawlee/linkedom","version":"3.12.2-beta.49","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.49","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9983df8c246f87d73282b3f12dfb5e7620e0086f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.49.tgz","fileCount":13,"integrity":"sha512-FwW+BjYvUUX9cbaq6ZkwDWZWqUYvqTuZl5YZmleES56Mga4fEhUFXa/73u6+2nesGhTHK1KxtM20iqJ361SK7Q==","signatures":[{"sig":"MEUCIQChcFcanVF5rJVaddW+/uj4R19DOKvGS1+R1p/XGLF4LQIgQL3/oRi+nNIGm+Cg8iRvY8b5yhcCnDxpHh1qkpTYS18=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bc684b29349bb1a62fc7290c05b3ce0908716566","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.49","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.49","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.49_1737411601718_0.2136968899343339","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.50":{"name":"@crawlee/linkedom","version":"3.12.2-beta.50","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.50","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9e21e20a8c2ab84b39899ac26c334fc4995f6a2a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.50.tgz","fileCount":13,"integrity":"sha512-bnnZBa0Fck6hmfCiE+YiDEQOTGcwZN2eZNyW3Cs+Ti92uUf4v6QRWoiE5jYOkdf6MkRNe0k/X/O+ARr4VlJtLg==","signatures":[{"sig":"MEUCIQDeDx1O75CVR1oKBHBUp1OZ7tvtUVzBCsFQa02peid17gIgMgBIiove/H0MvgaqdQWS8AknXQrZQ8CONn2G9QQz6D0=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"970131dac90d82386a316d5c3b5ee3f9909b03aa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.50","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.50","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.50_1737447078315_0.9011100320971637","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.51":{"name":"@crawlee/linkedom","version":"3.12.2-beta.51","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.51","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"aba23170cd834e44a3a8d6e6f4ad0f1e422ab2e6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.51.tgz","fileCount":13,"integrity":"sha512-cZ8HpZkRatPc7BPCk5R2gDrcgnZwv2nqwFIlHWfefl+hP6XgKaA5qn59e2b+Vo/0Cb6fcQ/bzXrTPD4sKOa6OQ==","signatures":[{"sig":"MEQCIH1lz9qO5pcoyVpdtoiD4RAYRaYBqYEcgMUDEM2/3FBmAiBqQNXEcD8D1lpNcsxcns4gcY9NWFsX/B3rhRLUPilYmg==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57f32b227faac3d81adced1274b8618b21206793","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.51","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.51","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.51_1737472651672_0.03545188124582954","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.52":{"name":"@crawlee/linkedom","version":"3.12.2-beta.52","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.52","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2a200e2ce55c06efebbc8a7eebead14b4d962d0c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.52.tgz","fileCount":13,"integrity":"sha512-/mFbYbZyrJE+Gv9v5HlbYdta8OWd+Xd0Ms6Gtm68Nck7YVYyiG5iOVVpbXITeZe3GoSiQl4ZL50LwsOKKpC2bg==","signatures":[{"sig":"MEUCIQCP/yPsWqfOZgvv7rVRESt5PaywGLaKm32/DS780naDUgIgA6FkSve/6BxUdo2BOiefE200MmEErSlI8AH8dDCDgOM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bf135ae5b8523752214e80282ef7c779047b16d9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.52","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.52","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.52_1737501974747_0.8279415696149093","host":"s3://npm-registry-packages-npm-production"}},"3.12.2-beta.53":{"name":"@crawlee/linkedom","version":"3.12.2-beta.53","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2-beta.53","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1ed907e9944d319fec44b9e5a4fb8bf9d75ca80f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2-beta.53.tgz","fileCount":13,"integrity":"sha512-Ezw6KDzPComsN2+PSXAVtOx0Ml9tVO0Gn9jrSsar5Muyz2flp3UY27lBycsckFhmP9b3w08Vc3zH/6E1otuyWQ==","signatures":[{"sig":"MEUCICVb/qeMJX3qLxlFIFNcfhIBnIN1yCBM+FpWpFgMFNz4AiEA49/bpS7v950L9v0QfDYOCbqJcHit2fnFnHU0gUkzMgc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226437},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1a068552495e3323bc3b4b11a6f3a5f06b7a2c83","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2-beta.53","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2-beta.53","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2-beta.53_1737538129808_0.6568825852644922","host":"s3://npm-registry-packages-npm-production"}},"3.12.2":{"name":"@crawlee/linkedom","version":"3.12.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9b796c30a1a22a9b6d6c4380f1841277e0c6675a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.2.tgz","fileCount":13,"integrity":"sha512-x/xw8aFYqFv1iAuVlnn4Akh/LM5FsmSryE16f0cYFtPegboOeq+Iw3ebCBI2VGx9CLjH2xnrpv/kGzgH+JYs0Q==","signatures":[{"sig":"MEUCIQDKGcRmZp2SN3rp2dgJm1NQzSPF2hR/wKtjGXUYpq+SrQIgFxvKslYXb8yNnK3ZVF1SnZ6mGdNWhl7AhCGKPdPAgDA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226413},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0b5533547388f454c27dd0c12db46fd8917c7e4a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.2_1737965825899_0.5333616028556287","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.0":{"name":"@crawlee/linkedom","version":"3.12.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0f4128ab964f4a12b802e1ecacccd478c5221216","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.0.tgz","fileCount":13,"integrity":"sha512-Mac80ItweruO13RulzsvPZpbV9EaKJX8Ybo0GsIefdtpyrk9yoeFxB0kxnODx3rW+vZR8uqmy9sZa2j/zq+YjA==","signatures":[{"sig":"MEQCIHxqIXZCvAEmqEuI6JxHFRTpI+woymo+HOS8L0S32HTqAiBLKZBklYVSWeUbUW/ahBJriQarfv7OpdJdANWUL5yvvA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226436},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c7d5c5d0f51fb1a16667484c42cef8b5bac21de7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.12.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.12.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.0_1737966274497_0.22950352779083172","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.1":{"name":"@crawlee/linkedom","version":"3.12.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6c5b38209aab16ab7c9d79c639e54c5124e1543b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.1.tgz","fileCount":13,"integrity":"sha512-ecobCm2HN1AVMdsySW6n7UAh6ZIWJX80e8cmhVppHuUK1eHyrqQuEC93P08AeOUhzVGqnQN4kTPWs2D/eFt6Dg==","signatures":[{"sig":"MEUCIAPCVMadU8VvMM4U90oAQTPcvfp4dgMvSzwq0xLUI5g2AiEAojoSXaD6Fc3gBucG9+IwYrTAaatas8vyvn2swwy0FN0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca4ced9d2fa4e8beb91ce6a1f10ae77acf9b0d8a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.1_1738140951694_0.9657478562350914","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.2":{"name":"@crawlee/linkedom","version":"3.12.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"65c65c427fea530c750eba0db0de5713f9b44be1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.2.tgz","fileCount":13,"integrity":"sha512-4miSnICUU/tuBRM+i79jVC+4INBLyOT9QrAxr7zZTOTRKJa7MP5lc/HmFVoeO4e19YmyLMdAfybQw6rRwMVrpA==","signatures":[{"sig":"MEYCIQCgmLHTrVIeys3EZAALZMqbT2PtNi/3+8hR+gbhXKYuIgIhALPJdIaOvOQizyG8lDdfPhEmVQY9RZEPdBahqLg2JXj0","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"21a7832a581d6ed8d54e72eff567948ac515ee7f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.2_1738141409681_0.0741020578419076","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.3":{"name":"@crawlee/linkedom","version":"3.12.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5acdff7efc59e29c504c6ec528d1e28b985958c7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.3.tgz","fileCount":13,"integrity":"sha512-gy35RIGfHPpq28UI16DatWv/mE3ioFolq6uyYNWZ7uhwoS3ll1iGnnLR7JBFnKpzPfgLrveAnxOFGu5NcEq2gQ==","signatures":[{"sig":"MEYCIQC4l2h294bxsOZ7LOHPD7MrW2t3s48KaW5N/8SY0ZmrQgIhANdoPMO4v/B47+vJwVZNBnxKsKF3FNlH1MVurw3kmViO","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b80b3f22d6019c6ace26fc2888355bb7d6bf1fe2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.3_1738725275844_0.7945384184301516","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.4":{"name":"@crawlee/linkedom","version":"3.12.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b680d12ffe3238ff41d6c73cc3a51bd08d2912a7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.4.tgz","fileCount":13,"integrity":"sha512-2dIk0DEbpGQAJzf2U6HkzreY5h+mRateTqGVbsfCY4SYTsYAcxtLv2cGPETiekmhtFo8p9l+qC8Mwx9JQQoKbA==","signatures":[{"sig":"MEYCIQDX1X5PZbFX0gvqqbFDlI3rQVkzNgGyb2opMUPxIS/JvQIhANRXkY/JAeZyU0atxWoWVlN924rHx+Im5Spy5Md+CzmX","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"064cd632715ab69c063079ca34052a1720bb4b70","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.4_1738772857541_0.05292374696850932","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.5":{"name":"@crawlee/linkedom","version":"3.12.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7c01431920666906915caa67d42e9896cad1a2a1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.5.tgz","fileCount":13,"integrity":"sha512-/Wr4fGEAebreO4tKW6YI/bHv2XR8dyONs/48nJaBGvavaNZEj0AYyq7HlMJwdG5XPa+dWQP8HlmPMhhPGxF0PQ==","signatures":[{"sig":"MEQCIHKAIPMgaVtt2Moh2y3cmdkgS+vCUFiW3W9Oy+wz8aFXAiBo88F13bZ8xEYgreM4v6EmSrE3TO0prt7t2nLBHeEXpg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1e42a478e500f4fae1648b4bf980dbcb17cdb0aa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.5_1739207501742_0.881690644991834","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.6":{"name":"@crawlee/linkedom","version":"3.12.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"66a97366d5344f6769b9e77bfe13c0476311e7ca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.6.tgz","fileCount":13,"integrity":"sha512-dVHzSQcGfljhmz2GGu/vATmX5fXpank0SZbJkI3gotzCm2BIAkE34KyT3jpc5TrfarbuEJIcpZAnE10kpWbElQ==","signatures":[{"sig":"MEYCIQCF5ET0sif+6rZReTpXOruIEFqbmWjb2OE6iNoevvkC0wIhALaOWwa9eJHUwCmt/OUdt0tzHP9OiTetfSyBfQYshHNO","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226434},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ced7988196aa9807ab5f36e29bd91d989c6cf995","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.6_1739284906639_0.6535725352467374","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.7":{"name":"@crawlee/linkedom","version":"3.12.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f28287cea4822082d12dfba7c3139936de72c39d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.7.tgz","fileCount":13,"integrity":"sha512-QKHC4n3omrd6zSn3MNQ8oF1yVdeEERw9JKkkzNmjJkW4meJh4I1taH0peePqU4P0Lrvl+H8lVEY52mwHYhW0mQ==","signatures":[{"sig":"MEQCIDkaF2cLvplgV6xrjyvIqzkBRc9f1T2MsGvqsvht2J2JAiBSO9Bs5qWbwbBpA0pGi/A1XPTin9Kh7IViMzW9TvZJHA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226674},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"52e65ab5a1b2ceddcad6c322cc2f1ac290514d4d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.7_1739362519413_0.26257856017853043","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.8":{"name":"@crawlee/linkedom","version":"3.12.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e84bd8c79c33c5a10448c466c09828d5e34fc892","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.8.tgz","fileCount":13,"integrity":"sha512-8W9J8heeiGcZiouwJIWBh0cCP7edX8vNW2R//xiOwwvN/+crox4Gmb+ZwNJRWyzP7nOfoW5Ce/xeylmaMCPNtQ==","signatures":[{"sig":"MEUCIC2HsTnKBTTfcJegVadkwFtvtENTlv1Dut0B5PK4oXvoAiEAnABd7I4q++Qn3C3zJt2lld5dFhFlqLHKscN5aDSgako=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226674},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bb6e3e75781a2d81ca426937c30eb0b87393e568","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.8_1739364136570_0.7592772716398255","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.9":{"name":"@crawlee/linkedom","version":"3.12.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b949072e5393a3dfcb18769f61d5e4c0948099b6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.9.tgz","fileCount":13,"integrity":"sha512-MwkeEYCP20ouS6khzrJwFNKvOaxfhHbaDC+3LlMeH2EKtcVMoj6elK8Gdr8vwqNujz4QV+IRP32rc36B+t5veQ==","signatures":[{"sig":"MEQCIDKEIKNOOlQLYgtGqe2n/vRbuZBb8ghR4nvuwg0d1J48AiBcmHuPAC59gCHo0UwxB2qJJZS4ifIk9wlwinMXZ5ZhXQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6ccbcfcea1902cd3a59eebadf1a80787835741aa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.9_1739365074382_0.048519747035153715","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.10":{"name":"@crawlee/linkedom","version":"3.12.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"53b5dd4c412892826966ae1b2bf29a7a08ff66bb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.10.tgz","fileCount":13,"integrity":"sha512-euyrB18SQYf14CAINKcwdO59jvFGvbVYpYxize8kVvNJ46COqYcO6i8KdYrtu8HLvGdjp79dMurMJQvWJ1MoLg==","signatures":[{"sig":"MEQCICsr9B2fbAYQOgJPdwysvpLCiUU5lHd2eXGXw10+LvpnAiBCklSe288V27TGLhMppMVHWt0bkvmstJBTp/MZSbxpSQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c0ea4ed6ee7dfbcff1d61fbb7d2f2cb37875e6ff","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.10_1739367167996_0.21687818500374245","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.11":{"name":"@crawlee/linkedom","version":"3.12.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7c390f4356c03306a824ed2a5a3815fad8916623","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.11.tgz","fileCount":13,"integrity":"sha512-m3JLnC8UQQVNFgJZkZk427cIn1fJjVs5W2GTSLq9H1RPHZyvl/E0ozeoChGVziJbOHsJRfPextZ5skzNcAxTEg==","signatures":[{"sig":"MEUCIDinuUSDRkK5ozszjE0PTkYZmfTQaB7EfcXr8EFky9rcAiEA7dy+l2UIGtCVATOpq7V7YQmPRp07V4GYRBQmmEmjHzY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d98cf24f5bd1a31e0bbd5ddfd425059e037951ac","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.11_1739367790669_0.20859906481610002","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.12":{"name":"@crawlee/linkedom","version":"3.12.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"17616d367d61307f93c10d04eaac85455977d042","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.12.tgz","fileCount":13,"integrity":"sha512-UPk3V73L+ytwlO0VzjyQwWWjmLfFmwY9qamrWYJwTestNMUKwWMINulVmqcN1tK3MYj1ZWhsjHK0rBhsa2zpwA==","signatures":[{"sig":"MEUCIQCmLqcYOGKkuaXk9Cxx2EEHGD8YkXCiOAgzexSQFrtvfwIgHwZyqy/mAecMEmNWSUJip92knruypHV7D1wJ2pz7HpA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"549b02a5b0982f391a3c6b04af9a574be9972b31","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.12_1739709496615_0.6821670976477812","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.13":{"name":"@crawlee/linkedom","version":"3.12.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bbc392a43e737154ff35b476269f862393ba3b74","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.13.tgz","fileCount":13,"integrity":"sha512-wdOf/awOLLVFeStKJdigppSBEX0XCdyAJDxpYycsEh+4MTD8CIi8/w5/VFEqaqo8u0MWXk1o93dOWnRdSCL9QQ==","signatures":[{"sig":"MEQCIFqitLeDXhJUumt/KFyv784k5h8ZieSA7Zmo+ZYszIL4AiAOG258kuQvfzUanQRWVtqSqG0hzznego0OfR/sqqy55A==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":226681},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"630ba8e17488eb839c212f97df5a915df7bb4e00","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.13_1739801787843_0.3481976943288503","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.14":{"name":"@crawlee/linkedom","version":"3.12.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4fce39fb3bbd74d36aecb85d3f872172462cc36c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.14.tgz","fileCount":13,"integrity":"sha512-eDxIg//Y328WjehOaAQLM4dMvn8cPu4rH+wDAaOPIBREprRXZYCTp90wsaWeRVPu4E6ZDsopT1EvtGaFdoD+MQ==","signatures":[{"sig":"MEQCIAWPHEITRN21VuBosMyy6mkd3geMW8MBhoqrkVdsXQh+AiBB9Y4vaca1sy+zuTT9B+VcfB7L9KMO1d2DQn8vKlNlDg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1a231dbae675555036a59bbbee52e7fbc0c41b85","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.14_1739854577122_0.4582158724615846","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.15":{"name":"@crawlee/linkedom","version":"3.12.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"30d00d626b3dfebe7b96e5993971eac9345972fa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.15.tgz","fileCount":13,"integrity":"sha512-kthFFTLhYg0zi1UgLya8JcXnM7+j1iixSV8ZhHIMPhQuwl6BiXLFzvLYm99lxgSH6aQwfUYGkUbBoFDI+StrxA==","signatures":[{"sig":"MEUCIE6vfUV3JAj+nxUJ6Zq4MsmfV31JjT5iF8aFxZhO0VyJAiEAzVXtYefPwW+O5RHw/Qn8IMF/T9ab53UGwJ2GDjJRiRU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"95ce8a8bde5a71203ef7eda4e52bfee7acd77120","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.1.9/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.15_1739940239347_0.22467747500372348","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.16":{"name":"@crawlee/linkedom","version":"3.12.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"513f9d15db4fce039e2273a5799982267d39c309","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.16.tgz","fileCount":13,"integrity":"sha512-pbkSvubPvI4+2obPHUDiTdKs9qX39N0Z4RJJssj5+Isj71lJEzfKXNTh4AemHsVLGC5Z2Bku/4niAMSB44uqIw==","signatures":[{"sig":"MEUCIQDpXaQ3pLTAm4Oyu+tdH5Hj0sbfQYTI+/J0xczy+b0eHgIgDqawrbuEI8/ZZLh1ybYfHTRRdFP77/PQJa2In4njk1A=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"88ff5b9b144617560049d189ec48169aaeb485b6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.16_1740028146181_0.5395982155500383","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.17":{"name":"@crawlee/linkedom","version":"3.12.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"cd7c6e503506e40deb86579400efe1a99c3be3c5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.17.tgz","fileCount":13,"integrity":"sha512-kfxxOJvydRB6QfdCl3l0c5OhL0/AfjbQbwOWPqZkTuQIFcq7x6XAucfHkzb8dmT8TJDVWCwPMDLAp+eaLanbqw==","signatures":[{"sig":"MEUCIAbVxaHvKcJcPSV1Z4AiobG7h22mlmALNhGwc7R/ipS1AiEA8NBQ826WsDY3z9Cr7tSo6SdsGC+Dy9fHl4muXDhCStY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a201d8b33c2df985e566b540474804205b1dc01c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.17_1740060620240_0.8292439619732852","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.18":{"name":"@crawlee/linkedom","version":"3.12.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1ef2fc824757494189e3bc813c8e31d01d211e04","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.18.tgz","fileCount":13,"integrity":"sha512-5R793V2LevSFbKZrtA1U2kttXmEwcErkTBrLCjWQ35LQSJm8Vy9k/nREUSVqfWwkTSKKc+vArRhIjkd5m8We3g==","signatures":[{"sig":"MEUCIHZuJWgRtVIkM6PKYo3kU7a7vUMhbn409VLBiSEkAQpAAiEAzHFbKqw6tJoxsUiMv4M/iuKjJ8rm6+vJzN5wne0XNnY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5190663c829c65023e3a1b69e0a7a550c049fb33","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.18_1740115670813_0.9813706407529639","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.19":{"name":"@crawlee/linkedom","version":"3.12.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d12a332d8d92feefdc281723e95e60d0fdfac76f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.19.tgz","fileCount":13,"integrity":"sha512-HIkOyHZLhQbj1HQ+wbHhfMsfjZ00BR0rGJs3YT+03RgtBcq7bADNka3jbaYjJ/9StwrNNauJXCLwnHJL6Iyekg==","signatures":[{"sig":"MEQCIGb2bd5axhMc0Mfy44S3/mbm8N95UM4PxcdU5vqMPQnuAiAXA7Gc6bqMwDBR13tlV2TjHPIfqeO1xGbcPsFgO8FFFw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a84b9283a7af157c807b2e6e4fc61d76df97ff9d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.19_1740385711200_0.4787604419493048","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.20":{"name":"@crawlee/linkedom","version":"3.12.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a8337fa4c66d9a0febad183192eeb06089adcb32","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.20.tgz","fileCount":13,"integrity":"sha512-my2pqJ3bMJAeUBmIqa26PpA7Nfrgr4ybN4K5rNGLofFY0eSYWOts/EK+RoBuKbCtUUzaVYnv5cjqYSDwP6a/fQ==","signatures":[{"sig":"MEUCIQCdYYDIhZcGnpV0xwMexOh6X+lWPiLqoFRvY6ihN8y5SQIgUETg1gu1VKEMPe2pgOICh234fu/v7v9zK/rJrD/xKuc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bcdea195ded2a44097d4fc789f2cdd58f021958a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.20_1740751852915_0.6089330459342297","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.21":{"name":"@crawlee/linkedom","version":"3.12.3-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"223ec2358d9c3678d748ef936678cbe457127f1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.21.tgz","fileCount":13,"integrity":"sha512-nJbXnsGsYWs+Zh8HBLGUfIOEfzEY6rPSl50zahEVnghsfGROqbYH4w8kUGzgnPpSLFhgPkzzGrLCnCw4Zy/1Jw==","signatures":[{"sig":"MEYCIQDlhbELkQHJApiCJmDdivVmOFPK3tD9LROi2aCh6FKTtQIhAK19TI2EJ5x0SW18Dt143bthizX7fb1VT4qwEzcDwcWN","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0b88a9e602e586979148beae564471bafd7c4105","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.21_1740753599325_0.01751557704183626","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.22":{"name":"@crawlee/linkedom","version":"3.12.3-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"097216c4f85a8f08ac922b13fe9c70b316d3c4a6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.22.tgz","fileCount":13,"integrity":"sha512-PLuSSbwbWC+WY2hNVZBA1v795EF8zLW9tnR1IIqAKv7LIWRsbLZ+mqQrPj7mRz5Xbf7ujWQWJKMTWGCUdgW/8A==","signatures":[{"sig":"MEUCIQCoLR56e74/RxQ6foZnqK+gsl8ZmFOQZhql2CXYkuMqzgIgEj2E1/xhFJDqA105XFz2439e4aKvIdUuEqrWg+8obGc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dcdaafc978d3aa16af98939235ceddef58ac5606","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.22_1740755265705_0.21988674503441952","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.23":{"name":"@crawlee/linkedom","version":"3.12.3-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"58f20e6f96775823cd9ec0bdf8a0427dabedb58b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.23.tgz","fileCount":13,"integrity":"sha512-X1wjDYRbYUxYwwKPI+I1nuyCsMKwl91+SuEGly4S+56UEl0x7Hn+qvQLIV5r5Fvyw789X3dH7z7/jb/6dObTTA==","signatures":[{"sig":"MEUCIQD8R0CqrcLv2aWCif2ZucR9njH1fKhJ2v/1h246y+ZiKgIgOp8R+gR2L0eHMQqMtjSF6lii3B85tdSjD1le1oTLRGs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"869f375fbec17c5a53c2c9dfae85ec41cc6368d4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.23_1740755772319_0.3627946807719735","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.24":{"name":"@crawlee/linkedom","version":"3.12.3-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"510f4c98dfd195ff381e11d28465fa67bd2bd736","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.24.tgz","fileCount":13,"integrity":"sha512-irCg2/hpdiWiJGapOnLTEDckYJsre/vPDN64rujL90izIQJTa3GSz4pLYLF9/V6eSeHyWr0Dt49rBlvICT0SMA==","signatures":[{"sig":"MEUCIB/xz6xjq7B7qom1of+d8dR3evPhmllOmUhqwP1jChfmAiEAj/aU8mUgtZfQQ9MS7pcjIXGyG9POXR5kkbZ0AQX+Z5M=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":227678},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"220e020996acfef2ca9d1a154b06b20d4aeac090","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.24_1740776262908_0.3463384738392752","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.25":{"name":"@crawlee/linkedom","version":"3.12.3-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b2f0c1e6ece9a3b8931beabb93eaf809c58b297","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.25.tgz","fileCount":13,"integrity":"sha512-vhSpRVPndx4PLFO+GrH6UeouoPMgJir+yU9XNjDjdN59Alzbycf5NVZlQi/ZKJ8UM5LQwJne1hor243eRisMXQ==","signatures":[{"sig":"MEQCIHL77zeU0fhglhECdcWQQzAaFNj5oopINR6symZN5wc0AiASQlM7k3NqWXLmpcYNRhCGS+mXarXTtcJ83tXUly6mtw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228070},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3e391a78be2691bce5add500cc1f58fab96a6de4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.25_1740804034105_0.2620549259070597","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.26":{"name":"@crawlee/linkedom","version":"3.12.3-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"94afea61f7e579393bf0cc84310b8081956f1832","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.26.tgz","fileCount":13,"integrity":"sha512-sXFnOuAAD/sSZCEqug1EezxG9JEfRvI7I6czDLTPCR/yEq+6IDF8elTbTg+kSFvRUM+O1qg4251yU1tX4iAYEg==","signatures":[{"sig":"MEUCIQCeZvEQSmwAa8ttGXm5J5oEPnOuzHjf0QvN72cD57Gy8gIgC6bqeEum31/dk6n2gQl06eCaXVC4s6I4QLz8qZXjKMc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228102},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6d8e31f09fe39a14bde164072a5ca324740b6612","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.26_1740890577079_0.661688376795329","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.27":{"name":"@crawlee/linkedom","version":"3.12.3-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5e3ff137e6b2d3cbdaf220834e602075ae06ba09","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.27.tgz","fileCount":13,"integrity":"sha512-54GgmVjnfcHVNI9iPgWrkZ8AmIxrI7TJpluVcDwIJkT9ec+YKdSE54IxeUJPNQTgkYYylEbGX1EKqgb3Ez112w==","signatures":[{"sig":"MEQCICgQ5FTsFr7wnEyWxqfxmbYR/r1MpdCNPjLw/iCVLPzfAiBd1BlnmH4+V98V4nq10QWvmWgVK8hwHcLe85UTC0jv/g==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228102},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5a175d070ad7451bc35dedc0e75511eece6e670d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.27_1740978936368_0.12306899143340333","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.28":{"name":"@crawlee/linkedom","version":"3.12.3-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"852d40892e2916e7e9b57cf2b871f195dc8c01eb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.28.tgz","fileCount":13,"integrity":"sha512-afTWz3GTv/GW4og1BLp3TX3qZWEzgZ11YpQrc1eS2aY4cxwHpH8WXymzGAjHrg2j/+qzkdCtME5D0GY+y9OmqQ==","signatures":[{"sig":"MEUCIEZjmZCTxiPg2+99mc7lnqi7YqvjrzV26tXwX8Uyo2UZAiEA3gho2pR+cQQ8MbPfeTKm97EM7pvpRpMz0jqKZjoQfFU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228435},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c0b3349a0b2d32e993ce341603e866c0126df1c7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.28_1741015836787_0.693924789018092","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.29":{"name":"@crawlee/linkedom","version":"3.12.3-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"769566511b48e1dfc4c66f053e56d5920397633b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.29.tgz","fileCount":13,"integrity":"sha512-P6/Ht7Y/PTSukML7P1RfOR3J1vMvdV2daD+EUCYcT8MEV23FgKtn6tpAxp3jQ0fTqeWnNNHqNL3dcr3LuHeSZw==","signatures":[{"sig":"MEYCIQDzkroeQpRZ4qXvhXppEUvOIxXMskbTE07/ovyHpaRf7wIhAKICm9wf2mE5rcELabfP6tDxDy3ND6Yi+znVbXbFPoVd","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228969},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f6008f27862915ff7e85ad3bd3dc8145679f6367","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.29_1741019370017_0.30166777999507444","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.30":{"name":"@crawlee/linkedom","version":"3.12.3-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a819fb28c3908ef5b7f120865fbc311b8cbd8734","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.30.tgz","fileCount":13,"integrity":"sha512-I6j72wMfzy0XW6UNgREYaIuDXyG57kCMexEuVCuM4ObObThCqiEWQWIWTvK+skE092RPps5QaNTpE73AxUaICg==","signatures":[{"sig":"MEQCIEf0mv+XWXfTINoG1XqsobwEz96g8LMyhDLndJ3HqMXGAiAgJlFvH0Ct5Uqt0y8y8ly9lzBDzgNA+bBhp/6IYUhoZg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228969},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8a0c2d5bb2a0465a686ed27e98a844e5a8a051e8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.0/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.30_1741048180000_0.9787672160231031","host":"s3://npm-registry-packages-npm-production"}},"3.12.3-beta.31":{"name":"@crawlee/linkedom","version":"3.12.3-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.12.3-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5727c4f8fdc385aafa901b214af481350fb3b182","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.12.3-beta.31.tgz","fileCount":13,"integrity":"sha512-uCbbD25Bdt/EkfeWhL+wegQmV5CoeaqhNzivgTNbcwgm8jU4If03/goFIYL/uDEDvKN528exzR/J3bTfZZI0pQ==","signatures":[{"sig":"MEUCIQDlyultmVv60L9CeiVxPbLqDlJsqqvvVbb0EpMf6wRMnAIgO3n6Km88uq8vpDdAhgzNnuDPXcgb9qbnMxmjwMXWqwU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228969},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cbfda8b7a32a353f9708ed9f56faf23b299520ea","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.12.3-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.12.3-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.12.3-beta.31_1741062747229_0.20995966493639973","host":"s3://npm-registry-packages-npm-production"}},"3.13.0":{"name":"@crawlee/linkedom","version":"3.13.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"388d43e08acff0acd032d0515a474fdaa6cf5d6e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.0.tgz","fileCount":13,"integrity":"sha512-ZCsw7ydIhVPdc4SWtkBh/uhPMDiP1xzah/ECKNxCn1AYgR+E8mcEHl/J9XxnPl0jV87g/qXIVwHKPWMLxkkc4A==","signatures":[{"sig":"MEYCIQC28QOjMHshHT6TU4N7LHz0rHRzbCK97GUZUWJtsmOh1gIhAI2mH7TzvLF+v8ZIOMxtj4mrN605d38E1G4yANczc11g","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228945},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6d5b13ae318909a66001cfc4daa1425ca88b3bb3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.0_1741079649912_0.8720782523287327","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.0":{"name":"@crawlee/linkedom","version":"3.13.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8627aa3f3c2d7a1b7598359a81df823e6b143f31","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.0.tgz","fileCount":13,"integrity":"sha512-pPmyIIobMG8WlEBVTF6h3GAqqzPw/uoGOyeas553cTxGxG4ZxsfNXCkOd1P0SCe+Ww8UwFURQFzAJOfRmTc5Mg==","signatures":[{"sig":"MEUCIQCZbUOfl2vrDMLAHUbWIm3lAwPnRMtCXSdULEH/cxCeHwIgZwfdboYAtdE4bIw02eNiwSUm43aowlZFSkNP3zQPQCk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228968},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"710dbb0d3795120321bed881de821cf7a6895535","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.0_1741080336582_0.6580984770152967","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.1":{"name":"@crawlee/linkedom","version":"3.13.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2b82cdcd2ad0d93aa6aa49dcec7e966e77058444","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.1.tgz","fileCount":13,"integrity":"sha512-mZRcxDOXk/edhastYaFIq6FSo57XqcDn6BJdChhyMs88dDmbkNDm7RfNnBfeuKDrZk27YC7+y6SvNLT2WXQDbg==","signatures":[{"sig":"MEQCIFCCecoFGh+WeTjCvVt56kn6jcHZg6ljYjRiHrAEqsTdAiB6sgtku3igy9oymUL0RJ0H5X9VTDQ1RHxw72nDSdlh1A==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fa6a2252696f0098b81722ce8e702fb89fae57fb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.1_1741151316341_0.21616657592155764","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.2":{"name":"@crawlee/linkedom","version":"3.13.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bcf495844a37a1746c32bcbafa319bdde62facba","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.2.tgz","fileCount":13,"integrity":"sha512-7VwN4PzG7GCHdRDJ1Tq/AMJ7zqTTwuJhLHtvFCTSAmf3lnGC9avwBdOZLqf1N4t0586ouWOQLAmxE3A+fT2CKg==","signatures":[{"sig":"MEYCIQD3L8E2rKqHgt4ool4JofIB+FSwB5ZthTU+vjpTQ0winAIhAIoqIziGcBe0ZUrKIBQVzw9QMsytA0N+N4AhpMhUARKB","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"efd6140e359c38adfd0e14f276fb67fd2d46e76b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.2_1741237689226_0.8792034765170305","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.3":{"name":"@crawlee/linkedom","version":"3.13.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e1d489a1eadec0bff8ffeb9b2401d1e5854a4fca","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.3.tgz","fileCount":13,"integrity":"sha512-Tfe1CocvPFByzl47ZoAhrP21vhR3suMm4BDbAqiQ57Veg9NTicWiSGFuxhnXeI/dxUAJklCnuHlGTqPhpdnFmg==","signatures":[{"sig":"MEUCIQC2Lfr7iSDNm1L27tVv6FuSz5IHm9cWkaFXQLALTHbYmgIgMCkPyNRvikxCavmTyTLYAeTPrD/VaJIhYyLl8kLN6O8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bfaecf08ddd98f9866f067d7f8fc3bb2a56b1939","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.3_1741267944738_0.11350638972406868","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.4":{"name":"@crawlee/linkedom","version":"3.13.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ff871605b29371d0d34e32439ffeaaae9ede3208","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.4.tgz","fileCount":13,"integrity":"sha512-xkhflvrxPbZuWhVvg9yi2+kaqRjJKhxWllI11vh2xjwiiWF8XZo97oNGQp5i+5nn5ahVxAU9zknuhG4Ph63RPQ==","signatures":[{"sig":"MEUCIDIcWdzy4I5vqugcUEQRUMLN+z7XOF3LF7VRSlATfD81AiEAlQkpySK+Q1aqRKjPMdgPK1MpeWDEVRREJAho2pnIfvI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"33edbb443604ec52ba5310102ff9502df82e5a8f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.4_1741309721787_0.9227507180351964","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.5":{"name":"@crawlee/linkedom","version":"3.13.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f978c61f616c069675d2440114caeea69e7a157a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.5.tgz","fileCount":13,"integrity":"sha512-jFSP0OAWzETAD5fpzT3GgWPNMpDSbmt0SAupI5PRacMSjTMiyxTCnZYrKF7opwfwscNdl/b+vxb2QNhoBkrJuw==","signatures":[{"sig":"MEUCIQDStNu4ZTkEXWUYBOQE6viLjY+YvJT7a9Muv43EB6CCpAIgftVZX44FzSpaRg8c4L30n4wzGMmeLnSP2jNog+WtYww=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f4ea9a499ec647841a59ec06596d92b7074d4fb3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.5_1741322827968_0.6164437294050176","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.6":{"name":"@crawlee/linkedom","version":"3.13.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1cd4a7d82eb81c99cd66716fca447796e47e924b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.6.tgz","fileCount":13,"integrity":"sha512-ndZU3H1e3BpdXDDT2GWaJ7PHvTrsyYvCUtD/RB0abTfVeAZonGzXCWfd7V0/yzsTKN/AYgUHOT7tvTssCVAKMg==","signatures":[{"sig":"MEUCIQCU/KeQfZZtWdVC9E15Bran+T/uR0NO2q09s2A1yx07AwIge4vc+VB745uA0X1nkAGu/8GjNDyTqKGTQE7vASJmeT0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c2acaa7f4a99dfdcab6ae9e9558d9102c968a878","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.6_1741353599128_0.713718238699478","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.7":{"name":"@crawlee/linkedom","version":"3.13.1-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"02e32cde616e919da3cf74bc7981f6310ae60cc7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.7.tgz","fileCount":13,"integrity":"sha512-SP9kEtv8YAHfdAAt0+Cp2VTeteBHzC1DzQitHzbk2ftmW/OgGG7U55bTu/n5xYZurPxb6dR2GtYiU940d0SyuQ==","signatures":[{"sig":"MEUCIQCOwQafKsPbTOdQ7aFOLCx6W2z4RYfyuNL/AYD4UZYMbQIgOJI5tQuzPwUpAAiJ4AS9+Dl7pf+Q9ZxorpVOLbwCuW4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"16c9ff5e4b67f815ba6344038a32f2acbc6d3763","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.7_1741409852672_0.9895215012748872","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.8":{"name":"@crawlee/linkedom","version":"3.13.1-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9b727e01a7673b9f79840a8a9a5f1aab0789c5cc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.8.tgz","fileCount":13,"integrity":"sha512-eiL3zQWPl3sXl/R74/ka9LKJP5iMSgasVn0bqSlqM4dDB8/Izb6+BOwWhruHAMjNIhjwPuYpqHpOEFFT9rQUqA==","signatures":[{"sig":"MEUCIQDynkKZzBMqv58SZVf/9aRje6PAcOqPHsySFe/f5SdW0wIgFUsM4TRd6XLjD3lkT41gGK3n0Jrh9N1Q2wQch09ijS0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e68d5841418c0700536e18aa028f2b6629dd465e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.8_1741496173789_0.11693224398442048","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.9":{"name":"@crawlee/linkedom","version":"3.13.1-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ed92d4003495582beb9441264a8451f86c714177","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.9.tgz","fileCount":13,"integrity":"sha512-fi99JtwOqPlg7ab6IrnPUmhpL6y7CBhLrkzun/vUk6mA/lH7fGLEWkZ9TCR2/HYriGMrzr3qB7RRrFf0CogC3w==","signatures":[{"sig":"MEQCIBqLOMba13ZBj4BvHGBi3DU+pMVbD4ZxWaoPjDCjN/DUAiB0YBXZN82u6e8sLGBPH+YM42RUrLRiVjV+PhzySg3NSQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228970},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9f66134ed6b75312a1a1b06c16444fe89b2d25b3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.9_1741583753964_0.5151319156402927","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.10":{"name":"@crawlee/linkedom","version":"3.13.1-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6d297ea029e51c6a3b5a3737fa3b4f2d37615d14","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.10.tgz","fileCount":13,"integrity":"sha512-xg4CrNxZtmjutBnqhuvEti6Q8sVOecYlZXyMnd3S/86SQsYDJTWfzkA6ZaKlzWz0hWgZksuLSrON1UtbVBhnYw==","signatures":[{"sig":"MEUCIQCry8SRnIq0v3OBEM2fN6ZnJPbB93HwIgw4xdQDNULKYAIgIk+Rw1CzLY3nEeoExu7L3o605dFC1HsAx4yA9uaLTPI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"02aad397e89bde6ab5f6e7ef9e40777e8fe263ee","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.10_1741667684414_0.21572519051147543","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.11":{"name":"@crawlee/linkedom","version":"3.13.1-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2490bb814e361f8f854fab0135cbdb95762216ef","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.11.tgz","fileCount":13,"integrity":"sha512-uFnC6wWXtnB5XOyMbGR1DMy6PFZLXCnaGgPxZhRnLYP3NVnCkplHh/g2Q4uW3y+tjO0FUxKGmYAWe3CJ5MkZiw==","signatures":[{"sig":"MEYCIQC0wuUIUYG0wLi8Db4eXfghZ2U4WsTFRvyL+5ztatIpDAIhAJSnSMvAghSWwGRasYrPk0OIp73p1y9TZIdjs5HzfmAC","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9c59fc73c403ab7157a76df33922fb7187692a8f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.11_1741755313180_0.5265040543317654","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.12":{"name":"@crawlee/linkedom","version":"3.13.1-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1d6c3b745d21432df2abcc349dd08c8399d8b3f8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.12.tgz","fileCount":13,"integrity":"sha512-L5toG8Bx4xIEC6h4j163+v4gzIF2MngUrNCPHm0PJ40qnrBxCXtJy9fiWsO2m6sejL80mEmuBKr+I97V+1dMLQ==","signatures":[{"sig":"MEQCIHrrE0qfolbEq1Sjc4IzaTHwMHdOtGYgwhNrHZLZ8V4pAiB67D3sWtueu4K64wsgwJ8qZ9yG6TbyjB5Nz+C3m8ji8A==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"505e96995f20657dc13640b808073db8492f75d6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.12_1741842521969_0.026624482518013748","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.13":{"name":"@crawlee/linkedom","version":"3.13.1-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b5226b3e42dc62585f7479d57d2a863e90b1b0b2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.13.tgz","fileCount":13,"integrity":"sha512-7CWYtAjdjEYI929Tg7/pg0vd8Y57meYbKLZ5gzmo2j3FpJDl/tPyvgJ9bZMB68bXaXMVh1BwdxDj4mMQ2NtVMg==","signatures":[{"sig":"MEQCIHx0+UdT2SeOVqxThz/Ma2dIvFisEC5qkKSB0aTDxd+XAiAc+fylfqXmzwyL7/ZZaxrthUIRk+z83e5lYu/kmgMrVg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"40612825a502a25e183bb6267c3e814f4ed1f0a9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.13_1741927591271_0.5500058207244833","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.14":{"name":"@crawlee/linkedom","version":"3.13.1-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a8671b8a393032ad5dd1eb9e0c7483f23b4f852b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.14.tgz","fileCount":13,"integrity":"sha512-+HNYbUqKMrpdB4v/TU/8xBcpsa1e+uAVRefXNyAb8hVXOLjmZc/oZSkrHajP6yj/p1ZGO6ZNM83UcIkzHdWC3Q==","signatures":[{"sig":"MEUCIQC57L+fbHcQDzrHtZdfj3EaB0+b4ZOr+2Ak11U1LgvUEgIgATtwuMGx3JZeNH+8Fuxb4eXWzTigsCUmPmXzEzVdc3w=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d4cf624c09aee91911fd1326ad82198b833599ef","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.14_1742014809415_0.5165345736608555","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.15":{"name":"@crawlee/linkedom","version":"3.13.1-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"129a17022002283feab867e9246de6a3737f61f4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.15.tgz","fileCount":13,"integrity":"sha512-NoJ/peOuzcuZ4EcZ0SCusf2zFNl8245ldlBwV/L+yia+Rkq3lgNg2qcY1WyczAqdTMvyUR61DLjrUEpW05mWcg==","signatures":[{"sig":"MEUCIQDPjBkhyPuMiL4rfMzxcpFO9KYmmHoxCNOIYfgasr4EPQIgXz9jMwEqDYcd+OW9dhSAMEUVIJWeaE3A5eCNqLlVZic=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a20474445ce94de826822812d604b7032adc7614","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.15_1742102107207_0.3330710502141896","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.16":{"name":"@crawlee/linkedom","version":"3.13.1-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b815f701fe2ffff4c89d6abf474b07f783e870a3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.16.tgz","fileCount":13,"integrity":"sha512-N4+tWvPuJbIxhG7zmYPTuK6ds5V3rgTuq1r99yp9TTTvgeVheTp7o1VOZsRKt7q1Ynld/ZikAOac1oJZUfAzEw==","signatures":[{"sig":"MEQCIDNw8L00d7hov/ieYrD+BqKVuaRPHq8xpnAmreySiKipAiBUd6W8Eu5gkTS+8cDZsc7cEUKbcJ1/tJGzUz58NAdHpA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f5a14319812cf3189399e76d43c635bf0a231d9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.16_1742188648284_0.12888382869216874","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.17":{"name":"@crawlee/linkedom","version":"3.13.1-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"76354d5d93c438922a7f2764f81ca7c61e075bf2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.17.tgz","fileCount":13,"integrity":"sha512-StpzJZb9iZSPzlKJ42V50lVpUHqTrO8S4Q3uTQHuoSxbhXJHpHcGyKAckJJI+RGODdaQYaT5thbkyKjE5m4tfQ==","signatures":[{"sig":"MEUCIQCXoquKS6pxs/Zff5T/AFbBdYeI0/N+a6FtRMf3QTi0MwIgQTngGEYko87RJsZa33UOV8nNIy/ox6wi4+k8v9rl/nE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"369cb281663f0f9a18db69af7d9534cc46de34a8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.17_1742249153366_0.420654098657667","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.18":{"name":"@crawlee/linkedom","version":"3.13.1-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c2a6f517df597f66ead2b8d19ded3cbbdf132df5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.18.tgz","fileCount":13,"integrity":"sha512-Nrqd9GcCXumliJpzMbbeCnclbD2r9U0WyF0TU2kU37eVR8OVpvVTTbajbwzfKW7NATRakaYBwPEzre5KKUcBqA==","signatures":[{"sig":"MEUCIH8aZlsuRHw/akFlvK/dsolWxzIf7fetLyMMfYi6aB/9AiEAqUNcjSR8iZtFgrmoR/Y15ZIDSm+g2rw8iXtSfS7MPy0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eceec7bad0071c3a1a18c4d0f97971e97d4c4b14","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.18_1742273671017_0.8593793826917699","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.19":{"name":"@crawlee/linkedom","version":"3.13.1-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dd14f5dccc163ef568c41a3ff94953d3d800a48c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.19.tgz","fileCount":13,"integrity":"sha512-f1QTx+PLLGaK0pj/ofXZq4T+el0zIV82znX/tLa16sWGo3JaxbYyX2ljaUF3ID6Nfvvh48FBJO3aRj76N+e4Yg==","signatures":[{"sig":"MEQCIAGZLVHWVdMAB3rPcUcZUCGPXvaVaExBHBLCsvPMA5xmAiAlWEgsMV2YmyeNDnsrcP478p05rXIpTqTHjJkSnw+HNA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b6ec962096f1d098108b40f22f39c1221e4cbe4b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.19_1742298408680_0.9432696018514657","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.20":{"name":"@crawlee/linkedom","version":"3.13.1-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e90c584fae38428fdae8bbc52c4417abd36f18e4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.20.tgz","fileCount":13,"integrity":"sha512-/fODD9Rj9UUhufJLf7tgdt+VN3CdE7a+LbrK2c0FB889W3F+2+vB4fvjhAWzDGRD6exfC0RHoxqvFHIZ1PiCbw==","signatures":[{"sig":"MEUCIQDnHo+4Y+o4+a2a5cl4S2Ik6mYNctQi8+M/CZtmvpyo9QIgO6RJrkGAqfb3D5y3Ozvkm8RwBxmgc+qmELn5RDRaLcs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"999055f1aa09dd41c86422c4785e83e12ae15ebb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.18.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.18.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.20_1742360874393_0.4049145953973503","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.21":{"name":"@crawlee/linkedom","version":"3.13.1-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"247d946e8fb2460d9aee632c50ceb53e667b4016","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.21.tgz","fileCount":13,"integrity":"sha512-xdyfqo3dnBXQpxEjsoce/vvVbz9CXsgvz+pxtLvnK96y1SqsGsxIqJLEcrhyDGvM9j8ZWbJcUkKvDnW1bhuJrg==","signatures":[{"sig":"MEUCIQCFrsWa1YuVYueSsjU1q3OvG5iIgFm/okylxL15WLuDzgIgb89M7mQaPHDnKLJNLRpZrJkgPT+7YkpNNU5fiIaQxjY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8e6d63778e4768a559ecaf55f7902a82c1b811ba","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.21_1742445827090_0.738581612621958","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.22":{"name":"@crawlee/linkedom","version":"3.13.1-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"07b4879ad7520d6b5afdc033e1dee7a7b7eb588f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.22.tgz","fileCount":13,"integrity":"sha512-pEaCrYGjaZzRcTZNsrTMHNNjtZxsDL4MGiDHKau9ZiwRK4td86PuCqS4dCOUsg+J6iGE4ZXy8WJyGuzDuIEOig==","signatures":[{"sig":"MEYCIQDyYQSzQk6WPxnQeEk3vOSYAiU29MmLwXRzSh+2yGy6ZgIhAMzxqdYaIOFdkvS62TqFhchqqNulQa01qDTT5PkgcHHO","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9dbefeb0ee48e525cc3fe9d052e59fc4376f8747","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.22_1742531622880_0.5754828880409566","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.23":{"name":"@crawlee/linkedom","version":"3.13.1-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6c5137b06aefa76ee6751635d79f310df496bbd5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.23.tgz","fileCount":13,"integrity":"sha512-C+w4Yh4r/XuUoA43bDQJrqtEt7XLeT6hQG/KWm6Jk+pJlLvjDEm3NOakMxhOUG6CzYEA9i5HuVcSkXNJ5pdZcQ==","signatures":[{"sig":"MEQCIFNn6KJe376R8PkwA9F7UHoaUWXY2ZQr295/OLGaZ8iJAiAsOOnjTA4pX2vVyFzwFmhVBM4+EtbMwlMuv8ZEVN3HAQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bf71fd837d1e12c7962fb935a9d46991aa5b134a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.23_1742618349625_0.28631113483136983","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.24":{"name":"@crawlee/linkedom","version":"3.13.1-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"266e6d75c26dabc8b6d77d5de7852e486e812d9d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.24.tgz","fileCount":13,"integrity":"sha512-otn1SiPgW1qjGUbJB+3O534Il7soPICKlQMEG/a/dV0bgHrqQa3X6VMHVIHAht/s7Pp5tV7Am5Wy/PFGQ2TyQQ==","signatures":[{"sig":"MEUCIGDuGJf9cG96rMnOc+bAAtPEUW0i7mOMqDqmOtMfdD5nAiEApEu8P5Lk6rtZpG80IG6JqlQ++IlgVcsbeHLfM7kf8Og=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5f11490f970e4b16a4fab6466d079d65f7eebb1f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.24_1742705297298_0.3695905156167003","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.25":{"name":"@crawlee/linkedom","version":"3.13.1-beta.25","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.25","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fc07d0926f91a1741d043508620dfa4878f7e107","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.25.tgz","fileCount":13,"integrity":"sha512-89jZmt1oq4p2REUURUtMfVDPdPwZ8E5RyNooVsiST6QG+L2Qed6OH+M8uuDxYfCiJ9eNXU2sq+FXr+KCG4g/Pw==","signatures":[{"sig":"MEUCIDiIOr7ch5Y8YTw+h5BPc4BSDQllq+x5vVKRMpNN1wUJAiEAo9VFOrwGT1gW6GN3QfSNU+m3JTe83QBgGSTS/ijqe1c=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228973},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a08cdb80005597209e6267452db2c74fb9035187","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.25","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.25","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.25_1742791492990_0.5868230989903078","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.26":{"name":"@crawlee/linkedom","version":"3.13.1-beta.26","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.26","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4bb96e1849680f3d0979d2ab105bb95b06395351","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.26.tgz","fileCount":13,"integrity":"sha512-z+dNdYOF08Fl7sEmWHVrGv4MV35WFQ0InhZfEB7qecZJp0uttgs/8nk7L887iLTtl7evypbgAs2o32paiYfO9g==","signatures":[{"sig":"MEYCIQDWXSPrB9ZQykeolusAAm9RQIaAj2vkr9Y+9TmF/9hAVwIhAMZVSO1oZmraDI+GmhWAI6lwnTjOHqxWjoLZ3XVSmcUc","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228985},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"85af45d9f807b8bdda5966acd3e332af2851f637","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.26","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.26","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.26_1742823535903_0.23303809056724023","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.27":{"name":"@crawlee/linkedom","version":"3.13.1-beta.27","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.27","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ff2e979716b23cba2ea4da8cc0c0634be45a6c27","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.27.tgz","fileCount":13,"integrity":"sha512-HdpDERXOevRx6OgrmmwLiw+VE5lO3xhhyqSXfUK+7a5Tca+MoFDgSS0zgBF0lrNSWsKdtMpY2z9+YTXrHtzpCg==","signatures":[{"sig":"MEUCICcH+DuiynsV7qvKizAJ2cJqB02TYaN20llc+PAJwI+UAiEA+AGyLi1abLh9QUJ/RfomC6zBQfD2GRCSA2PTGnj4UxQ=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229093},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4bbf6ad21a096a63c9e4e34d516d6106a2636fe1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.27","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.27","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.27_1742877146189_0.7649491319475386","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.28":{"name":"@crawlee/linkedom","version":"3.13.1-beta.28","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.28","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"810327f0d6719931b0b0f195016dc1f14c280d59","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.28.tgz","fileCount":13,"integrity":"sha512-LpiOxMViy9dooFtbUkfht2dXhKxz9DNjYRe8XBD9SX/91glx5FDyq2nmvIzQ7r5P05kEBWWkPmOdG9EdSmZf2g==","signatures":[{"sig":"MEQCICzPlLm/0U9m7tww+Hk9SrdHz0WeNUwLXEufcq3C+RnqAiBUi8QkRBrowBX++WU8h2fn377pUu13FZRYu59VJSyNZQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229093},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80d95b1523926bc907c4590bdd8446423e4c2e68","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.28","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.28","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.28_1742964239729_0.4605623598337749","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.29":{"name":"@crawlee/linkedom","version":"3.13.1-beta.29","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.29","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0ecf43fea38248f32662911c5ecef932710dfe77","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.29.tgz","fileCount":13,"integrity":"sha512-dOfNgwn784EE9ZWVg2CxWGqCX2DNjKiNRy3CF4Fd33xBR/GLEQS7Ntw+5sIFqapbHN/4Rv+bMLnpgTMOo2ozpA==","signatures":[{"sig":"MEYCIQD2mHxHf87729V/n3hWqKnFh+xnRJBlVADjWMsC/6DrngIhAN7SnEMIdvpNKOqY+bGYQhaF2Wc9gA17/Xa1YMf3aUiR","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"643d53348c9e6eef6dc694b62fa85e66038f9bdb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.29","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.29","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.29_1743172200319_0.7633735261227077","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.30":{"name":"@crawlee/linkedom","version":"3.13.1-beta.30","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.30","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"22672d09e960cb42c220f95570e8a489838fbd3a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.30.tgz","fileCount":13,"integrity":"sha512-34koB64TvnzpvJ4ho/JoPGQPUYNSFHrwuMbL+X//g/HLSRtW6na0qibRGqJ2Agu+7YEEdwEBnbyJTTl7B20FZQ==","signatures":[{"sig":"MEUCIQDDlwSxApdNqccRhedEOCnk521OFcMFIfWJPP0E6dtZnQIgEEZSsSpi6qUMWlnHeT3BGbKgfPkImxh92TLxESN8iww=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0800c07cc95a07a8a003aa4016a04e6481d73e9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.30","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.30","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.30_1743349595691_0.17465784647446458","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.31":{"name":"@crawlee/linkedom","version":"3.13.1-beta.31","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.31","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"40d1fed46f168aa3c1a5a04b862b7c20be215c62","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.31.tgz","fileCount":13,"integrity":"sha512-+bOs7LaTgqTFy0vPlFeXPrQmk2W6K7IZ4+ya0BURq6QVNQkTK7O9IlTVtC2e81akmOFmecwcEVDeu+865CVVxQ==","signatures":[{"sig":"MEYCIQDoOARcglzOJO4c1XHhleiz+Ss2odZdjxHEtL9k/+nQPgIhALiD95rwoxAMQkBErq/dcYBjbUaV7dU+8ftkBtnq4BVi","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1266d560a54eaab590820bcbc621ea4d421a9665","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.31","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.31","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.31_1743397412263_0.11807911159879869","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.32":{"name":"@crawlee/linkedom","version":"3.13.1-beta.32","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.32","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3672ca522d49ca7acd243204b5a84aedef9977df","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.32.tgz","fileCount":13,"integrity":"sha512-+9yCgEKa3Jkdgl6JcRBZTBnh1UEd0c4I3JyS8Gub1LUoaMF5yJB6OrGm5osyaybXU0iuI4VraDf9lEq99V5xiw==","signatures":[{"sig":"MEUCIAtYmdsGXfqj19rfpnzplY8S6ncV+8iELs+0A7yWqr2WAiEA0kfFaodm+LBcB2RIANs6cursSvfLRPt0+Hd+KShrcnQ=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"404b915e400094b31163ab4499666409a900619b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.32","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.32","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.32_1743506913389_0.05339587507173915","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.33":{"name":"@crawlee/linkedom","version":"3.13.1-beta.33","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.33","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6b1d0dc7c74468779c208c5e4a9a0aa0d63f2494","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.33.tgz","fileCount":13,"integrity":"sha512-3fA972JNNFz5Rvqj05DNvHooXthln6muRUTho05/Er1qChi34v9e9aI48YPWXH4dRa/JNm4eJUsQEY1zKN9iGQ==","signatures":[{"sig":"MEUCIQCbQvclQ4YQtLLqMbBxNCU2C0PX3aM2hDtqdcA4XVPn+AIgRJukcUfZ3GDnCWAUq2xyDIX/RJmzVsAJUYaFndVDJtg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5cbce6c9c71212bcf1c473a370ba8cb04bc4c9a2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.33","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.33","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.33_1743588223722_0.22713552073759957","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.34":{"name":"@crawlee/linkedom","version":"3.13.1-beta.34","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.34","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8abb2758008e0c5ce3f07147f2902c193b6f3b1e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.34.tgz","fileCount":13,"integrity":"sha512-1K7KPBOnTE+GhV/bJZu9gttarvGW+5Z19Q92Cj7kZTmduxFrtQIbvHrLAMJUQLK7oDnmwkWhhgtg0W1+DFpBtg==","signatures":[{"sig":"MEQCIBPhNRfx9ZLoqfnvzN2kt4Yt+KBJadfpfSQ1bZE4HoGTAiAyckZyPhBE90bsZuIhAe2fiaJV+5imSWDM5RbK6ci5QQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b9d55d95d33ae756a7d8472443e0515718e878f4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.34","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.34","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.34_1743600871545_0.6923616576195657","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.35":{"name":"@crawlee/linkedom","version":"3.13.1-beta.35","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.35","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ef1e43b1a88f2935dcbbeea9ea042fd937e263db","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.35.tgz","fileCount":13,"integrity":"sha512-rZgDOyFngNIEwC0tXmGZ5oxkkvuTaO0M2R0vHZUo0NwD5rkP+ZxPaEtL/+J13R4ldE8P6Pfslz2QGYFYLD5kng==","signatures":[{"sig":"MEQCIHi/+qCNW8jjIzJXB8vIVUtOTUOzLrXsVJv2K5nXimXHAiBXy9EdKL8JmEPKV+2l6HzyU0u+jIBIh6os4yQnTgMD/g==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":228891},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bec4352c775b63443ff9bc35291c282c91276c53","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.35","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.35","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.35_1743609678445_0.944284437723659","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.36":{"name":"@crawlee/linkedom","version":"3.13.1-beta.36","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.36","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9a786bbd75ac09b723d6d7fc5809e3f6d4bc424d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.36.tgz","fileCount":13,"integrity":"sha512-/UsrJWwNs2pZF0Ot3b9ixbnO7SSkV1Kw52R7wYWcUSxpuwALzPbb7hQPFXwBmlf0Jen2/ACn5KCSsXE/v9hHdg==","signatures":[{"sig":"MEQCIDll3+zqLztPUbqGIE6ssH+uHkuX7Sf031r77Jrqz/HGAiBXCX7wK/QJMJtBzI2LDNY6VHwdMyeNVkaw9ohYJSwBBA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229250},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fb090448ce0e3d7f3497d4415313c33e2389bae0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.36","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.36","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.36_1743753811011_0.6660627413483633","host":"s3://npm-registry-packages-npm-production"}},"3.13.1-beta.37":{"name":"@crawlee/linkedom","version":"3.13.1-beta.37","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1-beta.37","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7da8a22314bfc053a4cd6a180afa9057327a5d3c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1-beta.37.tgz","fileCount":13,"integrity":"sha512-k2Oa+qRSwjDiue3AyLYC8oNq7i/ZGk2jMMmvnyisNhqhagRm8EA94q/BBbOjD3gIiRKp0VIqpxjE9lIm9VKOgg==","signatures":[{"sig":"MEQCID1Ig5E+fRm5QsM48Oe98OIiFJgdY1X60NYJz0Djo3odAiBZ02fwUxij0BsDzpMUdzVL64pq7QAeX4rchcBGII+RPA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229256},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f69267d6ef883e536245e482b7af10e39ea4008d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1-beta.37","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1-beta.37","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1-beta.37_1743759760501_0.5518585573214214","host":"s3://npm-registry-packages-npm-production"}},"3.13.1":{"name":"@crawlee/linkedom","version":"3.13.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"11dfa8787825a30a816206fd585ebbcabc40d795","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.1.tgz","fileCount":13,"integrity":"sha512-A9V1q+HD3zINqy3n1cTfGlY2JX8NDFNdTROPrJG9sHHN0vD5z3geI7o9MO9VJByHrYEdQvrH6umOl2oe5J/7Bg==","signatures":[{"sig":"MEQCICga4K1sxbN2Vpdw376Wz2Kc2xP2aa2gRZBqN+9WJL1TAiAd0qIbXV6M2pMvJRTYFaa84Wj5NHHHpwIECDBdgWJvsQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229232},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"99af95e0dda511718b45cd41452589260c69909a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.1_1744008954565_0.2326093066395467","host":"s3://npm-registry-packages-npm-production"}},"3.13.2-beta.0":{"name":"@crawlee/linkedom","version":"3.13.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"905c1dfec6146923047b980fa1649044a9e65f08","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.2-beta.0.tgz","fileCount":13,"integrity":"sha512-omE7uUXM/TPBZz0M0gVvEHNAYqKj5hcLlJBz88ZsYa5bHsuLn4rcT8qOegReP24i118Zbt95keyPCO+JeAy6Dw==","signatures":[{"sig":"MEUCIQDaEgg3vkDfmaP47XZPgxvj0lImXCAiNhrwkUkP155i5AIgS5c0DsdxZ3kYdZ87qFu9gtEHnmvBdjhDIUehW08eIJI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229255},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5decdceeb4642c5fff872f9ac27e78bb9485735a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.2-beta.0_1744009412832_0.31109995613012975","host":"s3://npm-registry-packages-npm-production"}},"3.13.2-beta.1":{"name":"@crawlee/linkedom","version":"3.13.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"546dc591d1ce12585f2b5ff47bacb72e087979f4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.2-beta.1.tgz","fileCount":13,"integrity":"sha512-gB+SPAGq4GdohxYZXu4+2ieLpKOHiP2wJ0+2MGD+IeP1nIZxBGT6IiIRksiQfyqo1IT25dLkGmjQLNpeEv+SGA==","signatures":[{"sig":"MEYCIQDEUKbusQTpL15KUWE8+a5uGHiaMo1P4gIG6YW/Akt4rwIhAKaCTQf3bZZt/HiMuljXBcvNfLNP82ZZBk+DvRjG4Q+u","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229570},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f0a13bd9ed473836487a6255d0a8f45c2f17d0c8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.2-beta.1_1744040134018_0.6672225594013492","host":"s3://npm-registry-packages-npm-production"}},"3.13.2-beta.2":{"name":"@crawlee/linkedom","version":"3.13.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7393fd83a6d28ea353c60ccce41fc1bf0798739a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.2-beta.2.tgz","fileCount":13,"integrity":"sha512-/OzBZK88LEZH7vXOD+BQzNmKI06/e2hNqGeF2MqC1aKQFioQo8yydx38GqZQSoix6L+mCEd4bAtkq++1B0r5Aw==","signatures":[{"sig":"MEYCIQC0bEm5q5seRBBNRAE/8svN3PvM6eL6lzLK5s96koTbkwIhAPZKbxpT3yxW7tkwG44zUg3bJJYUHQxBImTbCkMkwr01","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229570},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"058c1a8f4a550352648a67df2e62bc5381d0570c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.2-beta.2_1744095199017_0.8929525600625094","host":"s3://npm-registry-packages-npm-production"}},"3.13.2":{"name":"@crawlee/linkedom","version":"3.13.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"140ecb63dacc73c0092183b1438477899c654e65","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.2.tgz","fileCount":13,"integrity":"sha512-azj/4YeKTSZxijIubpO4P7V88ssykGePa89pNFLiTjQGrwfHrBZLtfjjfeeFA9P3WVzQDMbEGT2hlzOquj3djQ==","signatures":[{"sig":"MEQCICfxeQIrzvfVpmxzPSOGlTWnezxPukdwvjYxagWSsZLtAiA10IzeWLyDS23yr6+KNO4ZIzL5e4eaM8+aLszusut/Jg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229549},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8b882b31c821195c7ed9d24b913408748a6232ff","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.2_1744107302855_0.9015287123855795","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.0":{"name":"@crawlee/linkedom","version":"3.13.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81d4ee82545af538d80236cc929e5290c863821d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.0.tgz","fileCount":13,"integrity":"sha512-G/jQKbqeEucjZMS1fqCVqAUE/DqKdD2QouqfDHWkKy2U68PPkO6UNGvlczlBEpU1kZ+vZJH1MzMBkvT/PCu2nQ==","signatures":[{"sig":"MEUCIQDRsRuGyzjUQli1w1dD0YgLLqGKS6eDCkggKuSwceMhowIgAIdC8ed8+u987s1ewjxFkarVGgMEom587uKIhMMN/2o=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229572},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"825611e9eace6bf38382c3e77d4bd41a4743062a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.0_1744107749018_0.9740969394044741","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.1":{"name":"@crawlee/linkedom","version":"3.13.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3abc69e0d4c5bdac7d08b733dcacac5ab9e6caab","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.1.tgz","fileCount":13,"integrity":"sha512-Nmp90YUWmx4804dK0xqCcFtxfXLuJ3iwyZdPSiaSZPSw/CrbmrKdDmTbhKY0ue01ORc6Bizwh6Hw7C9Tc7qbeQ==","signatures":[{"sig":"MEUCIQDx1IhCGhtbnM0EUAxRiPp6y/TV+zgRHIMC/gZIU/r/agIgR2y0RXkWEiqrBRs4/p1UBvBhjCRerY3bdD1U79qTImM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229570},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"567f06687f93731833e17c3ee4ca1c990172ddef","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.1_1744273695068_0.22353642162457787","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.2":{"name":"@crawlee/linkedom","version":"3.13.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"00fe7d5d9ffdd4ea04d8eb31f64de50cc081ed72","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.2.tgz","fileCount":13,"integrity":"sha512-i1F4VcxglcT7srm1yyN9mPKWNORRF2j0RhvMUqBVe9MqnB5pfdm5KXBzvmMalljCPeOQdmNQm3PfHYKFbZc/4Q==","signatures":[{"sig":"MEUCIC9PyYA0/laVWUpbxIUQf7dI28ODatgyosIiKuBo0D0mAiEAtW0TH2CajZNM3jR4422SpeYunhMmPHTZgFvb+MDFJyg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"bfb6e956758ecb9ca621b382a752552fc9c65c5d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.2_1744289067676_0.6650124838514011","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.3":{"name":"@crawlee/linkedom","version":"3.13.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ac893d392214b75728766541732c7fefa4efc35a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.3.tgz","fileCount":13,"integrity":"sha512-mlCCdWD/WFoVhC1Wk6uEeC3vAqNCXZJSOygSUccDEpM2i+PlkbshJrgByMOFak5WYkROOCTG92wJ8k/z9Os5gw==","signatures":[{"sig":"MEUCIQD9qQvPaFZdOZfZsGNw9bSQu5q5H8eOsoMtU4n9UrAdgwIgYzf80Gcyat8KqXmhFnHiGOa4I2glTX18uQm6fvP0sVM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ecbf7e9cc3057d8c3bd3a358cb2b45707d24cf03","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.3_1744300289767_0.21317195343334228","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.4":{"name":"@crawlee/linkedom","version":"3.13.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fb0e04682ad9eaa75c24042781bcba72a8eca6b6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.4.tgz","fileCount":13,"integrity":"sha512-PyV+MOJYUDcCEPFbXDJ9mX7BdV/0ojxY9dg0nGM5zFZHYwzYVaQH1bqUGoDc3GqzjIVA3w1MuZ8HKbyegunMDQ==","signatures":[{"sig":"MEUCIAgi4jBVQYxrlvrQRnRv5kcM5N29vncuBHm8NmrOV4ItAiEA8lIhdph0xYIbDVLEteLEL63pHIXtLtOJDuqLi2iJVGk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca9d0aae2667ef3b87ab91deff21bc63f2116e52","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.4_1744617275960_0.7954030085207233","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.5":{"name":"@crawlee/linkedom","version":"3.13.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"378a0d2d5fd494302077408cfbda1b93467bc55e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.5.tgz","fileCount":13,"integrity":"sha512-wOb0+0F0XXgsmawalyXTXBUbWQ5SsLDm0SL11o7E3hYtlatAFPbV/iaCkn4quwsbzkmZhBXYJ3yFVCxVPd/mfQ==","signatures":[{"sig":"MEQCIFslXQYriQPNPdV7A+SxhS6IqmiyiZTdVxKeCxTJayXHAiA71crY0qw7Dj0V4UXh5Z4t5PKAcep3/IB4simcvrbXEg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8598debd43601b90e599b18c2526742d19c36793","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.5_1744633602453_0.161122535132185","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.6":{"name":"@crawlee/linkedom","version":"3.13.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"af720ad44534b39f0a5ef80827aa51d27cefff08","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.6.tgz","fileCount":13,"integrity":"sha512-DoGan4z/ZAcxaDtwsmdnr29zfKdRppg5QPqCNgcstBv/hmdmfQRl8gAyYAveMiAwsSxHwGao7S+V5UWyZFJ/qw==","signatures":[{"sig":"MEUCIFUGQo9xwrCyZp3UYQnJrxLKXszokKrETn5cXm6kFgweAiEA9vMzWfGxw7hLFi42DIQHnmkEhBM1gFIh+9wg7nswXRM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6c82bb1db22cdbf5a6b7973f35be640c4d51f3fc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.6_1744708915298_0.25746255269672","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.7":{"name":"@crawlee/linkedom","version":"3.13.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"138395225a8471e26fa79cd4bdbdb6ce87d44c66","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.7.tgz","fileCount":13,"integrity":"sha512-qDKNGybWOn/i/LVampGkCXy2QYXAtvVpDODxsEerZfJtWaH3HnQbAqKqqqqkn0GHB+A5n5OL4KbmMMq3/Sc+eA==","signatures":[{"sig":"MEUCICH3ZZ6gP2F7DkNyoDa2MJIOd48q7YiD2tWdEX/0fiIXAiEA1vfc99B3+2fL6DZCNpkT3KL0BggH7Wx3pR4nXqUikDo=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7685c45dc629bb8503d87e1e2883e51a2a1004e6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.7_1744805097470_0.6679258459433512","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.8":{"name":"@crawlee/linkedom","version":"3.13.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c855ffcdc361692350fd8097b4133b3575efc830","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.8.tgz","fileCount":13,"integrity":"sha512-ycHLxI0EEFIB9eOdSaokxM6lySTNc8Y9feE3X0/hX04x76zBqnLaqaTyCnSoXQdpxAjnmDTxnwSnoMdWrro6Gw==","signatures":[{"sig":"MEUCIGHwPWIaZj1HoPbKSbijqTa9X42AU8sAYZBAsn9QtGsPAiEA8BhvDi/5HlbFP2/betO3VTxD/L17TeKTTdLiQpqgXso=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0bcd58dd82d533da05a2bd7a524624fa441e7a71","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.8_1744963169364_0.2992814755716633","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.9":{"name":"@crawlee/linkedom","version":"3.13.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"34dd31d7bffb73a6f5b96008a55f5cdd880fcd64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.9.tgz","fileCount":13,"integrity":"sha512-LTcvmSI4816ITTfy68TUfzd/QI2EZGnYuwefEwd4HxzC+UhJ3Q203wibci8SNtwDwfObugCGk0siHILDZTM4WA==","signatures":[{"sig":"MEUCIBYlmEqjTl8LkqHWWzQho/6NLy/wD7lEO+hy5qWT6A/lAiEA1HqtKS4kf4jkxaQt1oYLyLf+wjxt992viBHQwKdcwUk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229574},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b15fa18267747df8d3e9ef4dde29e139187ab684","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.9_1744963838404_0.5925160656395743","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.10":{"name":"@crawlee/linkedom","version":"3.13.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"13bc82cca4e4c093eecfc205d8c5fd436b78ac7f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.10.tgz","fileCount":13,"integrity":"sha512-fWHzXKBouP3hlfkxdz3XlGW52kkNZuuRCb9+nsvCzi22k3XhUvfIxqI6hOZv9evGkNQk1cKAExLLaXbuxCcKBg==","signatures":[{"sig":"MEUCIHDn2ovHEQDxII9cB8v+tzHIcDAvp/6JNOYAFw9TbRp2AiEA2D6Bwt8HCFNLF/Yr4y70DV7LWyP/5PlbGR7Zrn2sMfw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229577},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8b5ea22bacda6c73baded73d90521d6d73df188d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.10_1744964502272_0.588345043705403","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.11":{"name":"@crawlee/linkedom","version":"3.13.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eef2c015472e9e3646c7da2fd66f249f489151cf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.11.tgz","fileCount":13,"integrity":"sha512-9exN+e3HNEACbOdfvMD1ImKt7AxXeVKdcinj+UjaPNKI0O5r0wHYbeHaOnZgtVRGDNxdR7u1FudOb+z07f9EAw==","signatures":[{"sig":"MEYCIQC71S/M+vwy+iJXK9/RXBJG4PRd+rdQgwc030PK8oXHewIhANVZ9y/cPZei60hduImJtiz1HXwXzB8fuGoLqHw8QToj","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229577},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"181ad7bb9e703d47c2f05030c0f52cce9d1ea4e1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.11_1745491002569_0.25088396711497984","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.12":{"name":"@crawlee/linkedom","version":"3.13.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2b735c681e60984c45a3e6f4312d8fcfae90723a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.12.tgz","fileCount":13,"integrity":"sha512-4ihaQPhsO5pKnjiCGnzkn0uRnlKZ1ED+X4D9TPmX1MnaxplHiWOpB4oBiqU3hsRATKy7kzq3WkNBJYBhU3M3NA==","signatures":[{"sig":"MEQCIBPqnAXK5+aTa62ky2smY1XOzNpd43wSHnpQNbJMfozNAiAUDRiuWWrYaPHpejoMg1nPAb8O2kBcvV9E0QNS8E/ZwA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229577},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fac14d5b8671e2984cff9dddb6031f6ed5b1a372","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.12_1745925286409_0.17253657497516262","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.13":{"name":"@crawlee/linkedom","version":"3.13.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4a01beaa87ac035ff0a456a514728cbdedcf0ab7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.13.tgz","fileCount":13,"integrity":"sha512-xkOEcKN1WI/PLi8igYTlglDDiK5ULlXuEkM/ieS0ovZnG5bXhrKUgfJkBNEcE3jGD58K45rLUxPopt31q4BqAg==","signatures":[{"sig":"MEUCIDHZbhHKkLQY9YmIIGg5PtDvAbcw1t5vr/0eTvttJk0QAiEAoEkGi4xYP4eEgkEIUMeMpKnHo7ADGlxvyD2+1ZMONg4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229448},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dbeb9038f0ef619689f9067563cddcb375207ab6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.13_1745926287747_0.013289042894003122","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.14":{"name":"@crawlee/linkedom","version":"3.13.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2b243d85a7ce5bdf82272b969770e9407fafa565","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.14.tgz","fileCount":13,"integrity":"sha512-Pz8AUEDup6vXJOuKB54MH5hCzo+54s3R6BrJrbbgbdaJtr2j/cjVMBmFF0seS8ypjSCly0Jvt+TlYdIadXebcg==","signatures":[{"sig":"MEQCIDwcE2a3WncyuIniep0/pi9Ie+5SJaArumLBkg9iJt+FAiBXhpeW98EPssdcEfCPFu+fnZ3UO3NVpRmavS1rE+89RA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229448},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d674153898c9175c06767a98121892d0b6fd86ff","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.14_1745928097149_0.7279267924528163","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.15":{"name":"@crawlee/linkedom","version":"3.13.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fc1ef7eaa1f891bd587a297ac50bdac4f9c240e4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.15.tgz","fileCount":13,"integrity":"sha512-DEAd2YJLlDjtyDGO2BxY5pzPP6dD4W3+TL29rB2kVhHWB51lahE67t8unJ52VVqrZlYGT1yQfgaSVlmz+Y8r7g==","signatures":[{"sig":"MEQCIDvdqnJLbsBL0IhZY+1MdDQ/Ep0gaWrnyRk8UIEwrpyKAiBKa4pr9IxmD9oZ4Q4FS/VbtOwHYL2d77MaHdnKrhq1hg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229448},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2e087e23d071f9a08bee66f6b77118e28aefad50","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.15_1745932162476_0.17604023628609378","host":"s3://npm-registry-packages-npm-production"}},"3.13.3-beta.16":{"name":"@crawlee/linkedom","version":"3.13.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e267109603b1c2a5280ab965863cb0626d36958d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3-beta.16.tgz","fileCount":13,"integrity":"sha512-0N1fKT6wRVLPZFoXNzP1VSB/yWih1updNNu+W4d88ZinGtE9x8xSx6Norrd+/lZHVhFFnEnzq62SQAR8uJfj3Q==","signatures":[{"sig":"MEYCIQCccNq0sL/S2aryqU6zpbXYZD5Ya5EdqR5fkjPLmRpxkgIhAIfNjxI6DC2bNRz4SsUei7Foi3CaBQpLpykL9p5ks0Yt","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229448},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6719c89b9e19fc436dd132cacf3fbd441c586f1d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3-beta.16_1746428123730_0.888784620779909","host":"s3://npm-registry-packages-npm-production"}},"3.13.3":{"name":"@crawlee/linkedom","version":"3.13.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"63394e6b7898ef35951bdd30c6f7ad6602dc2443","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.3.tgz","fileCount":13,"integrity":"sha512-DddZjm+l7R5pN0ovF8FCr8B1OndG+2ayuWjshE1kG3VTN7t0dckF/9L2t408EQC7CJvH6qQKu8pwwvJ7ccBjGg==","signatures":[{"sig":"MEUCIQCfsDmIsyzMtSfpvymRI3WScWCatyuAlnWEyEtDIl7vVQIgXXqoixUp6EwCtkk92tcZgSvbARIGzO38niQMT2vkpuA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229424},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"279cadbd3cd6342f36cc4d841e07b999e472420d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.3_1746429002364_0.48615775256177796","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.0":{"name":"@crawlee/linkedom","version":"3.13.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2174d8a335569bfcd8ca29c802c168fd789600c3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.0.tgz","fileCount":13,"integrity":"sha512-3dntKMobAviBiCx5X4wSntiEyAYiHK1LlIUj3MYahcyvZ6N82LhXQ6aRJDaRzExnXtYGlsr4cFEYWCawC+wvTw==","signatures":[{"sig":"MEUCID6q31eRBLuso/uCypiUE2c09K9ZtX4Dq5hg+niqCmlBAiEA9rOrOIm/m+erOAnF+UgKFiqpdegVUPEOZFa3yB4o28A=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229447},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b3fbc8e24cbfcad4d1f8574367a54492ab51014e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.0_1746429448792_0.5447825566048328","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.1":{"name":"@crawlee/linkedom","version":"3.13.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c05dbca1ad421e81593d5728183b5830a6bf582b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.1.tgz","fileCount":13,"integrity":"sha512-we2v51rYlpaRo6GoBcCz0qHDkaYtP/294mJILRoRZs4t2EJ9F0CrSEOKwZN2gMdslG+P3H5q3rEIlpA10h7xSw==","signatures":[{"sig":"MEQCIDMccgXyMJgoc6FuXdRtXEofbK+CZko397/yKA4R/OAwAiAzFsgCP+7LjkL+NBan+IK7BJ8Wq9x5Ml1xfPUqQld+mQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229445},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"78ec3cacb6edf5948d460b04c6e63f0fad31205f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.1_1747065368826_0.10523935246851579","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.2":{"name":"@crawlee/linkedom","version":"3.13.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47b6de04679881fbc7270d08a468824d8c764cea","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.2.tgz","fileCount":13,"integrity":"sha512-v4HhiN08DZ1Icyuwpawur4r/0CNIbF4cOWEhyDMKgZfm0J2DmmKO+WeDdteUUiJzCCPcN/JaHHTGs28kxLlHQw==","signatures":[{"sig":"MEYCIQCVqBVbaRefqDv6KSVeOXvA8Xs+T1pE1BtEEd8v1lesnwIhAPqWrj84/qdw+oI9r/nDpDUmxvqbCmHy0WUs2Q9+Z8xN","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229445},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"370a7a75a92006dd50c967c76352f34d08985241","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.2_1747067631398_0.991138914948074","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.3":{"name":"@crawlee/linkedom","version":"3.13.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a5cf74c7dfa732d88a6be041243ac987f8a8bb89","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.3.tgz","fileCount":13,"integrity":"sha512-3c7KTSNZZC89XTCAivTA1GNKFGXCiFLr+ztlNFwXxhhxoRfoFIU4qSbpGfcaxH28kLclN03dAHvL4jOOcuRG8Q==","signatures":[{"sig":"MEUCICmkNJ+6tETsv3UKWUb6UHsfjh9qz2Z0y+5ebjynfbcfAiEAkFgIMxZJvacfAQla0EXVpiNMWzpUSl1h7jW8q0Y0WfU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229445},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8e1cc91314d1e3d51ceb55e43e2f34c205ef265c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.3_1747136555253_0.9584497918860728","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.4":{"name":"@crawlee/linkedom","version":"3.13.4-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"72f0c6804a28c32cc11c35d74fde05bef9228a64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.4.tgz","fileCount":13,"integrity":"sha512-uPbEcSpFdnhYuyWMRAUcYTLx6jQLtxHP1OeWIWSwi4Eehhq9eDmVIrkZOxj25M3Qok3IhSL+2e/4VGav9uGXlg==","signatures":[{"sig":"MEUCICXtuhVFcD0Ccy2F/y1u9lzU0VZUd5esdXPrb79bMPZYAiEA/1ki9Q/OjAGMnZIJgpGgTlzJTw+4PTAiaGmd1dY6m9Q=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":229445},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"95772684199954d6a4afca744ef9710933ca65d2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.1/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.4_1747214362858_0.13193846715390367","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.5":{"name":"@crawlee/linkedom","version":"3.13.4-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"eb0c1c9a3d63663decd00c2ede817d8d280c90b0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.5.tgz","fileCount":13,"integrity":"sha512-BJhAW1HUe10OSJ//UhvczuuJJZiA2WzbGfhB/A7VUZy7F/994sqb1UKL77bcVslVkmJHv0PRuE7lvlMlmd9Gxw==","signatures":[{"sig":"MEYCIQD+PcIuDvfOxW08JF2xBWuKITMNM2iVR6PDhowz8p+BIwIhAIyCI0pqGVBcmdBTOX5soUxROoO9e0rc3oIylEFdilIw","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f6d22b3b7829b4e3aa2adb185bb51763298ee0c4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.5_1747215440430_0.8151536731725186","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.6":{"name":"@crawlee/linkedom","version":"3.13.4-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ad602e311625f599d6fc4ca2dbeaffcca5c023e2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.6.tgz","fileCount":13,"integrity":"sha512-CXi8qeYJNIG75wYdUWO2Z5aUrIhMKwYVu8g6S0fXccN1ndwfHSLA3p2RkbMbdzuNuaNqarlZPx7yKGLkUB9e4Q==","signatures":[{"sig":"MEUCIArWor0GB5g9wrU3MiEjnEoOE2EEjYpkK+BKzsYJLixXAiEA192rFue1tLHajrzp/vsJq+cly7/suEUNglTOfnVkjtg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a2a299e1a2dca257a270814ff1c485d5b0967411","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.6_1747215931640_0.820847347052758","host":"s3://npm-registry-packages-npm-production"}},"3.13.4-beta.7":{"name":"@crawlee/linkedom","version":"3.13.4-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f47869fe1084411f5b078aeab3f65790a690ba25","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4-beta.7.tgz","fileCount":13,"integrity":"sha512-jJywE0j8lpbr2//0fbkVydSNP6jhaSkHzgM842RB3S535tkKzNx4vxp1OsV42DNjC5PoQuVuOMz4ZG3h0ppQOA==","signatures":[{"sig":"MEUCIQDulRY9/6vZPnRD9Dk/wUGWltFH0jsmlh+D0AYlW0pcHAIgfw7msoLElKSRh/bgAagrXJbefBu2+vHzsZQi4/h6VIY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d3a0b8080ef5de6126a836938902ebfa34f56e4b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4-beta.7_1747225977406_0.5774614187262268","host":"s3://npm-registry-packages-npm-production"}},"3.13.4":{"name":"@crawlee/linkedom","version":"3.13.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47a56779ac34a43ab91c1de8ec9c1731595e1720","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.4.tgz","fileCount":13,"integrity":"sha512-xwXxA5eDWvVG7WzywOavRHTv1Bwxcba7wWK1Js2e7LfpDFpDP7udLs8APzOVWLqhnHQ+tc2ir46lHzUSFbOTGA==","signatures":[{"sig":"MEUCIQCycC42T47VeTsMhicOdlGNnqYzAcks1WIm9y3EvmVSeAIgM263P4NK3CfyPou4LnaGsRIBBGyNwqFCA2VOb2GyreQ=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230487},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d9ec02e95404a99f859c3dd85f9c687988e47855","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.4_1747228790990_0.13921553320039415","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.0":{"name":"@crawlee/linkedom","version":"3.13.5-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f3774d3dabeb535ab5ec6956330f42fa87ebaebd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.0.tgz","fileCount":13,"integrity":"sha512-YcYzAT0SxyU0mNTDh2YXGzjiSNW/m7yKYcLdh4bLyzbPUbZVzBup29eoXtjbU7P7dokUDTNsgfrpwAXsojn6Kw==","signatures":[{"sig":"MEUCIQC4q4nn60rDOpfqh5tsiZFA8C1sv0y6KIAM/fwkB5URBQIgAx0k8Y7U1SumD8PTgYC77FHmAjSLaeNH2n7gne5m/eA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230510},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b0cc6b05f456f6c70db4a1b975d7e88423d7d9fd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.5-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.5-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.0_1747229263256_0.7962805610582753","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.1":{"name":"@crawlee/linkedom","version":"3.13.5-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"096062a4383a9b501bf096f8203d3a0d73fe0e54","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.1.tgz","fileCount":13,"integrity":"sha512-FNbcbeLx8BuVaVxXMFhZ+duwAeVTrPSkwQNxXflxsKjvgktIq9/NLI+bxGC3ku8nS9JRxXMoEzHLz72aAczYhg==","signatures":[{"sig":"MEYCIQDCRCMxGijnmr0jAgLESzVfUGSp99sdRSSbAIyWznSR7AIhAOXbC6H8yUq/5br4n6U+NWQ2S/+smJwfXch5YHpB4+vN","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c0944da41472399bcb60eca5bf0134faef1f3ce0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.1_1747233671117_0.30531552718090427","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.2":{"name":"@crawlee/linkedom","version":"3.13.5-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d6113a09432c3818a8031d3501525dec8378f4e6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.2.tgz","fileCount":13,"integrity":"sha512-48zYjub43PKn0fucaiyA0i3/w1IIEFqQMpN4hdlYDCjraG51VpAUo7nvCHbqWEjj/NA2O1kE9KrwboagS/MUDg==","signatures":[{"sig":"MEQCIGSPnUSnhOlAXRqQOh0gFVXec5HkQvwK7E7bt1Wuuh+KAiArjVKonwZJyT9j1cpLFJJWSNB0/8bpmNohfKlc4dc/Yw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1de9465e2fb9ab5c7296242f56074c58dbb5e163","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.2_1747307797416_0.5909773851184286","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.3":{"name":"@crawlee/linkedom","version":"3.13.5-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"872249c714fc3afa7ef7ce9879db3850b56e840f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.3.tgz","fileCount":13,"integrity":"sha512-5Tp4R0ur6hsjaJ61OHgollKJOzlKAsUmx8uDjwXVUlMXCBa4jlS+YysB5JCzXFFQ38hn9rx/5aErQq98qYO2mg==","signatures":[{"sig":"MEUCIBhfhsq7fKvzaX1Q1Qa2gb1NIMhMlbCajwU0Xb3LeapSAiEA5Ti8r8C5TC2VlV28R3AzsgS1YDgfkg4QlzvGHpTtxo0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e5d1d6bfd31d85d50246983380c53bb14a2423e0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.3_1747323141136_0.886756026423976","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.4":{"name":"@crawlee/linkedom","version":"3.13.5-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1bb44976ea2b57ff78e4dd614fd8109abca470dd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.4.tgz","fileCount":13,"integrity":"sha512-G6s6/ZQqbfTs4GAWIbgCsf3rW9tbLkthepowHTeliGj0X4K+HOKHJ1rVihoTr12lLLq3WwyxEFJwbSzfma3Dsg==","signatures":[{"sig":"MEQCIBsFAT5X8Wt0AlBqcUCZoELGAK4nDJYnnNvTcqRpacJ6AiBUztraTK9QfMuddn7/oRLxalXOG8EUJcu9DpuZ3PMuGQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"615a033344dec4bc266f91bc3fb79a648d89cc8b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.4_1747380708233_0.5071512882013931","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.5":{"name":"@crawlee/linkedom","version":"3.13.5-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8e72ba24d2812f3a95f9bfc97838e076297dad91","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.5.tgz","fileCount":13,"integrity":"sha512-ox4omBFydJL/wRN5l2A4U2lx1y1fDgOIOr/akehI1HCq3rDYjDLZo3tBcEeFyGzwPoKdu2F+eGdxTBLtGfMM7w==","signatures":[{"sig":"MEUCIQC2nWTztmgK13qqirjQQNx4BrHgetele6l9PipM+PzC3wIgc5FNwLDne1K8fHgvo5F3Pb8jybWcCgihD5tiI/6HRzk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230508},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"773b8755154d823c3580cc507f81482fbb44587f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.5_1747381756329_0.8974375659853451","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.6":{"name":"@crawlee/linkedom","version":"3.13.5-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5d45a7de25ccb529ee4c96c184fe4fe331c9017e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.6.tgz","fileCount":13,"integrity":"sha512-mMfGLYk/CpWQVPbby4ZU0Z18bQ9KRY5wCzpa/ldKHQJPvE1uMtMYhVdplhIQd2uUepjSdrTjc6LHqDXIAqEHGQ==","signatures":[{"sig":"MEUCICe4LWE0pcnwbcl8END0GyrVQ+/RyVuijVu87uk8ISanAiEAkPJhEAPL7i3gltLWBXNUgPa3wyhq1baH9oenYQx1ONU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230626},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f5487c288d839d5bce47ab20aeaa89065bc42099","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.6_1747396528346_0.07363206498701302","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.7":{"name":"@crawlee/linkedom","version":"3.13.5-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6d01cbeaa1f3451e7865866fcec9e8ebe0ebe3b7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.7.tgz","fileCount":13,"integrity":"sha512-odRqUdZGfJZckgLXi19DcgQrh9nqkV0VS72Ef9r65YANVakZDnNqvRg25QK4Xp7PouCpfZGoVqpuRw6kmn2GTA==","signatures":[{"sig":"MEUCIQC5nhFYnwmT1/48NOmriR+Z74FTTMyJFiGugw/3P2zwpwIgYAiU//xNdmOBxMzYZfj28ObODC3VHV/5XvDPR/is6d4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"20d955daba865f1ec9a86bd8e4ad3592d4555c7e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.7_1747456388200_0.7044848191689601","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.8":{"name":"@crawlee/linkedom","version":"3.13.5-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4fdc55a73868136787f0e4c7113fe21e2a922661","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.8.tgz","fileCount":13,"integrity":"sha512-7IY4/dMAZRHE1dxMN2Nu5vMqg4ieC9kfmAIXqMeJJBorrmJfguGKD7Enes5VBHf9T/ZeOipcrWQadGmCPUQmpg==","signatures":[{"sig":"MEUCIQDiIHvn3I57/88au61rxGh73E6lAJieIAlydObRpVE3zwIgLO25Fsf55VU3+ruMKt+KnCynXow/tiPNl15Kmp5t5NQ=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"30605fe0e9cdec53f53eca1e1b33b29c943f3108","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.8_1747630450829_0.9387171571168227","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.9":{"name":"@crawlee/linkedom","version":"3.13.5-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dfd0356f167c61deac29f84d3f74dc8b767f5c7c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.9.tgz","fileCount":13,"integrity":"sha512-B228NLmbIbdgNjLC4bQ4Ei3/tXfnBjdmpGDvRYc7i5a2xbUuJ+x2YilZa6VjGUPKT4ISgdf7a8+h2n8kmdQSIA==","signatures":[{"sig":"MEQCIExPScfjoDAOSPP15yeMZSRWj/py2mAm5qx2mRNXfvIKAiAY8rE+3MeKtNncCs03yRaM/ag7djC1yu7aL10c67UOoA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9f6a1cf84da15353e25fc8120ee48e305de61c9f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.9_1747660345601_0.2750635489815587","host":"s3://npm-registry-packages-npm-production"}},"3.13.5-beta.10":{"name":"@crawlee/linkedom","version":"3.13.5-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4dda1df2ea1cf6ffca9d54f8fa675078ec11eca6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5-beta.10.tgz","fileCount":13,"integrity":"sha512-y+iFN++iFcxfCzFNYm3KaitRlhRKHYSi4raijs5EPt4iQFU/R62MVdJW1YeCSIC3I8A2DqbSK5pVLFV2t2lyGA==","signatures":[{"sig":"MEYCIQD0IEKJD+NzOqEbzHutrOEIOmhJ3U58r+W2i+vERlronQIhAI0VAsZgTvHGGRkgd4nBfUYquuIj7+jSsrQRvw5vI8Aj","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230866},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"33b30ae0f8db03f2eec9daa1c31983dd06bfd5e8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5-beta.10_1747715804272_0.5291075703378625","host":"s3://npm-registry-packages-npm-production"}},"3.13.5":{"name":"@crawlee/linkedom","version":"3.13.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27b3f1a6cddf8fc0ec13f4c2c749bb81473c0352","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.5.tgz","fileCount":13,"integrity":"sha512-QLon9gmDOPcEnXm5R7ctacsefg2HgCMdUtU77rdEC3SNV6xORKJh+yRT3P4WJVTfqfTauW6A7Pda7mV3XCJ0tA==","signatures":[{"sig":"MEQCIFJU1xCY9iwlb2MtbuTatBFaD/iHD8PsULj8YV5I+TpkAiB5fOlTr4v+AaZu29WWau/u23v/WMEnhKDyG63PoNgLpA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230842},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9fa523ae118432eea6314dfe9182b22db3f32565","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.5_1747729833906_0.7038101464953099","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.0":{"name":"@crawlee/linkedom","version":"3.13.6-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3167d35eff389233e35757b6b50e293ee6bef286","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.0.tgz","fileCount":13,"integrity":"sha512-SsP3h3jD2jWuIaVUCl9SoiG1fBy0YrcpItQTsb2nWENzeE6FviWuENCWZdTOwdQY8Y9OCA+BfD+o5ehK/RgIow==","signatures":[{"sig":"MEQCIBJdvctx/eCo2KnIJfcx+kEf0hEcJe0f7ZHSsF2hxmt4AiANIQ9J3SvHXVlWcfo0qNo2XrmuEVg/Jx2Ry5aJiX8naA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230865},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"595148da5825258b9c92e49071ae6c76bc824c86","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.6-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.6-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.0_1747730377391_0.5921288376422742","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.0":{"name":"@crawlee/linkedom","version":"4.0.0-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dd872856fc3b96058b88ddf19748449c638153c9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.0.tgz","fileCount":12,"integrity":"sha512-UsuSd7wwxmk+PM/6NA7//KPHTZPdshEa7x6Nl/MKlBEY5/DMzLZom+s5JWZhy4QzqWsyfQ0lQprbRKKmrGbWaQ==","signatures":[{"sig":"MEQCIDHitRYQRdnUiGRazmK0OEX4a3Vj20pShV2dAW2DEBESAiAwaYGaWiDqJcrs+rqw7gfGgbx64AkyIdTdCfhjbbVvSA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"927bdafa403ff347327158b01d20b817378168a7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.0","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.0","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.0_1747748456781_0.9756475436268381","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.1":{"name":"@crawlee/linkedom","version":"3.13.6-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f2b590783bf49d299c048f96b3384b585a706dea","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.1.tgz","fileCount":13,"integrity":"sha512-U+Nq9cQW5AIwzgKYVhGKuw75MOVi3uq3/nOvJwy606/6HAgg3jMGImy28DoNRoXY1d5MyVSBGSu/yALVHAHY9Q==","signatures":[{"sig":"MEUCIEZZuRXuUkVq8ZmoGhfGOQ1GcG7rZoR7Ln5fajDxAZjGAiEAkjRv47lsbh8h2UcvavB6r5oHEPUN98JgBT8rqOC7H+E=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e623121780524ad22a7b275a27f492525dabd539","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.1_1747803515812_0.4294131454501735","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.1":{"name":"@crawlee/linkedom","version":"4.0.0-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7f791f2d2ba3410a19e6613fe04a0f22b591ab58","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.1.tgz","fileCount":12,"integrity":"sha512-W88+FBJiMbkBfjUC4HF5ptGie/4yuO5+rIxvWjrxvQu4TxIc3z6X/izNmUa4MxEpW0FwPajUhzmfc2xWHempWA==","signatures":[{"sig":"MEUCIH4httxiBDgY0DvevO7dY2NxBR9i6tg0breMg+E5TJ/vAiEAmE2K5njKMJcXOyabFVaCMfiUlxqvCfKKpV7YkSCSLqI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"4375a5af786811feda9dc872bbbb3406b2f13974","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.1","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.1","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.1_1747815813223_0.8434183244984086","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.2":{"name":"@crawlee/linkedom","version":"4.0.0-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"221791f3c36f683bb4668153765e16205818398a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.2.tgz","fileCount":12,"integrity":"sha512-CdpIEmY+iH/IAYvRYy8T/eCpW4gkoOOG53lH32N2w0Z7gi8uBOx5yPaInwK/cxb57GDVbeFzW8x4ITpHs0Oipg==","signatures":[{"sig":"MEYCIQCAigWELfwnrrmzoOhyZXpTt5QCBiRUWRG5qkYnGLMdswIhALvtgOZ6XDKfPisDh5umAMT8NI39WxxhzCaBBb8nWXuP","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"0a8cbc26ed71ee063e03766cdbd9b40acd7950e6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.2","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.2","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.2_1747820405234_0.8021558664312316","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.3":{"name":"@crawlee/linkedom","version":"4.0.0-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2556e495a118ce8bee6325da53b5dd659ae95966","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.3.tgz","fileCount":12,"integrity":"sha512-/fkuMXjZXL2oiDZ9lGeE7qBL4dLCQjhG6Kk1j1ha9SqUOH+QueX2wHca6jWurx1RSoVbZHcRVsH9BfpJ2MnOTQ==","signatures":[{"sig":"MEUCICLeXe3Xn9kd/NAjmQ43/995QP7/aOKZo0Nkt93dXz5PAiEA5oZeWhHlmQDPnr5VNlJFdp9oJZNoFXxSnwzRGOhqvUE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"d7e3e59cc704c531cb10a63bb1ff81bedc548c8a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.3","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.3","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.3_1747827342867_0.16198117412211577","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.4":{"name":"@crawlee/linkedom","version":"4.0.0-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2c55874d25ae2e78b18eade8830bb438b5117c6d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.4.tgz","fileCount":12,"integrity":"sha512-eOGSsQs2NylAvMG+OiQwe+CiBHGR5f+OtcMo0+vSKh+jno8IlnoSCSvkLQ8pYUo6lWtXe4m2VDfV06Yc9jTrSw==","signatures":[{"sig":"MEUCIQCqpQB0SuhH5WF1CPsTi6zArLpoR1p4XehE+87rXRkIDwIgVKX5D6NiQhxUQ+HbbHcOPdFfWt9JSEku0gsiPE+k7rU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"3880cdebbcddf9e2a242bc89751e36e2ef5ae897","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.4","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.4","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.4_1747829772614_0.4000969780882617","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.2":{"name":"@crawlee/linkedom","version":"3.13.6-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dac4a08c5fea2349744dfdf01d18b5de1ce1a024","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.2.tgz","fileCount":13,"integrity":"sha512-eHlUCQwNUEp1JRTj71joQzhrR2Puq9ka+dUPZmy1gOA+IDniPScdObXKaFTIg2mbQ3GE+h6u7MhZglADEEYesw==","signatures":[{"sig":"MEUCIQD0r+tVOaLPDtnYGROlAbK78rE67zHVEfCFcxlfbB6eRgIgSSAWBa7LE+RmIz6nAh05RH0HKZdWOArxRT5ahIa9qvw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e6ee9c956eec84e4033e1555b7fd3059aa73b1ff","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.2_1747854526733_0.19695177003994901","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.3":{"name":"@crawlee/linkedom","version":"3.13.6-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4c036da4acc118b1415c407f713406f7b8b20024","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.3.tgz","fileCount":13,"integrity":"sha512-hae5grzzuDbCACKKfTSrnSh2ZaMUJtAPuu1V4ZQcDK+SR4+meNm/StF29B9QKnFDbTMe6HCpRou08NwVaVy8RA==","signatures":[{"sig":"MEUCIQD2F0zfHmSE98lMj3sBap0HQYlKW0jach4PknnkJRwiUAIgVvhasiJkDaY/gQXyksdOW24ecvQ0J5MlV14xikMW7eI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0c77fcf48a2beeb17f46e09633801a8390934673","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.3_1747888863178_0.6574368651306464","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.4":{"name":"@crawlee/linkedom","version":"3.13.6-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0f29e67b79c312d0b53151c8e2bc17589414e06b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.4.tgz","fileCount":13,"integrity":"sha512-ZgHAp/CpD/ho8XyRoTBbDCTPuLtDRB96ddS+RRj5w2SH9oZlSYEhzk0clu9a2rZRe9RAeJ12ljS0HmeUZN3cgA==","signatures":[{"sig":"MEQCIFIke8tiQ5Cg9D6kik8FFnmT1qWSqJCGwU0Dht4Z6bjTAiBMP4Fz67MK68J93BAD0e2+NvhCKH7bTi2vjzn/pvW/xg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d73ed187e9c86df7abab9c1de50116f58f211e04","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.4_1747975244576_0.10781379572763017","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.5":{"name":"@crawlee/linkedom","version":"3.13.6-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7b7b6c04fd5553a64807a3badde96aa07b9d5913","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.5.tgz","fileCount":13,"integrity":"sha512-mnXlmbjLCmtsw+EUjdvyUcyo1p+2Z3RNljJmTBXCZ7Byw9ZicHb/YaPhGL13sfnrX098STtWSQuV4mQeMC34CQ==","signatures":[{"sig":"MEQCIHXm8OqMjOhJWyb6fgV6ktC9QetOXn7flPnnQaO2CcWOAiBd95tblNdIJRP7WxG1AcpAeYSF9WFwrlMS4XPEowvFnA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"114f4ec2e545dd573ac7ef08fb9c76330023e7b5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.5_1748354425374_0.5506153712246267","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.6":{"name":"@crawlee/linkedom","version":"3.13.6-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6b5e5e03683678f714ce51054cc6709c71c1ab51","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.6.tgz","fileCount":13,"integrity":"sha512-8VL54qh+3mo9kbB0d6sql8PoDQ/uqS9E2GS6/ksDivFR3juVOtKVM83pOJ5KYExbnbY8XLES0YrQtG/kVu/H6A==","signatures":[{"sig":"MEYCIQDB1FFguxKjx2uueM0YTO4CoWQB5E8/c83ipsv7tAQ0ywIhAJMaKTywJkEiGOsK3MBysYkn4ufAjEHq1aKFa6EgrQcm","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"6757e3515eca9c7e5cef66dfc2220096577dacd4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.6_1749039715034_0.5863489220649576","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.5":{"name":"@crawlee/linkedom","version":"4.0.0-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bfa39051006e1ce190005aa9f7aac5d2182ad771","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.5.tgz","fileCount":12,"integrity":"sha512-35eYwEHf7ilvpY/qjVJM+IpvfUvv0QZulx1uVVHVLf8E+u8ymklKbFovJ073mrMFwsGMpoQkL2eEc5ywoaPU7g==","signatures":[{"sig":"MEQCIE6PXloawxgusKwN5C3MExdm57wy2tSV26j1ij/E3lMaAiA/47xnnfa+iTB2+z+yHzgUUgy+0K7aoxeQfFWC88LOfA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"9db9799f5eb88ab29f6156ee1574140b438aa199","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.5","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.5","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.5_1749046039846_0.04146920135951526","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.6":{"name":"@crawlee/linkedom","version":"4.0.0-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6e051ecf0345f61d28d1a8e3ef302ca7078b5445","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.6.tgz","fileCount":12,"integrity":"sha512-Vbpz6ezYGR7Ezh8gtO1DGJlKEbMzCJdWJeXXQPQIxiDxbZEaN8d1sB0/Ywb9c87adU6vk1hEQpJJRm3pzJ+Flg==","signatures":[{"sig":"MEQCIEDhosfWZUyNHuuGzuwgGjnSnlzrfeyY1tpBlwtv/DtYAiBscgv8VhczBPfrwCWnC/Y9iRByKlUYW+/fyoi09az2QA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"e82777976478391d607a30206afb8e863e8cc993","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.15.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.15.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.6","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.6","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.6_1749047396429_0.8385122157688036","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.7":{"name":"@crawlee/linkedom","version":"3.13.6-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"98fab0330e18995bce6786f4767620f07e0b40d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.7.tgz","fileCount":13,"integrity":"sha512-7A9rItq3tIlOjzxLPHQqQ/t1/xMb83+qHpqgM4I6X6e3zbU7mf6InMUQ+hfaYDe1K1n93Ug6sHkMShYkcQBGQw==","signatures":[{"sig":"MEQCIGnq2FrlVIBf/a66RgCatCoWaUd3/n9V8ajldzgOM69DAiBD8MczQ6LwYPe2K1CnBXSGIIqeKAIAwqhUW/TjXA078w==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"03fbf6218465f69ba83a38229e93fc684e29cdf4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.7_1749125621705_0.022499601187393248","host":"s3://npm-registry-packages-npm-production"}},"3.13.6-beta.8":{"name":"@crawlee/linkedom","version":"3.13.6-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5d132029a5e2d0433ba336a121f1fae03f7bbd6c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6-beta.8.tgz","fileCount":13,"integrity":"sha512-fC0DfXPfbjg6WwMStd4NNM5iJZTAc3Cyx+PqYQLtpHGms6XbdXdlQ5Ol3B/Q6B8+FDf7GJ0+b14zgYkkoRZeHg==","signatures":[{"sig":"MEUCIQD16MAr4gM3vrWE1wpOxoIXxgGZL9CurhiHRZZ6GK6KAQIgPjDBhVbzAcbF1prR3y283tuzm8hSB3qByo/Rkp9OVX8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a3cd07897543d3b49083393462714a6514d4d454","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6-beta.8_1749127334753_0.6363882379496593","host":"s3://npm-registry-packages-npm-production"}},"3.13.6":{"name":"@crawlee/linkedom","version":"3.13.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7b890107a0ac1fdb4cae1a5ea3010b0b6a1b23c4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.6.tgz","fileCount":13,"integrity":"sha512-/0sYZ9xnxYd6NtYhJnK34ei9Jh1Z/opNv791P3wbazKIiqzN7yaPz8t25CY8Z/XkHUqAGUrzqk7cTW816b3vqw==","signatures":[{"sig":"MEYCIQDMVrRspc17ddQ01e+vkR6NtM6r/JVBKrSss5E2802orgIhAKU25gY7bcKipM8Ah6E9fE4ssKk++WumiI8OMnPf5JNa","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230842},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dcb9938f78d10f037f9e0b1181353a7fa2c99c3e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.6_1749136034331_0.3106452879876467","host":"s3://npm-registry-packages-npm-production"}},"3.13.7-beta.0":{"name":"@crawlee/linkedom","version":"3.13.7-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.7-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"523f67191668a23cad4edcb42aa74afd063ebfcb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.7-beta.0.tgz","fileCount":13,"integrity":"sha512-zFp6T1yeQuyPHjtgk9fOgOtCUDZxxgjxpjiL5FXs3bIgv3izFif2xa5r/wDUEQdOuV6EqxEIvoqoOqxY0i1EcA==","signatures":[{"sig":"MEYCIQC1oECPoz9vLd/AFdRc0JkD0yNTvrnieECKpIi3ge8wDgIhAMAGarNJ88UCAzcKVm6ltMarxjirJp/EqK6rci0QZuiW","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230865},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1a2ad0ad41a2ebe4768dce27460af5a8eda99db2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.7-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.7-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.7-beta.0_1749136518224_0.3905645079051594","host":"s3://npm-registry-packages-npm-production"}},"3.13.7-beta.1":{"name":"@crawlee/linkedom","version":"3.13.7-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.7-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3b5fa42eea7f878af1233961cfd5dad091227319","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.7-beta.1.tgz","fileCount":13,"integrity":"sha512-9ENzreFyIwiVfvofHmy34EB/J3VodIPeZWONTgeTZRuCw298Q/8LfnPSCbWjfNwzwe6z453sDmUFHAMSTRC6EA==","signatures":[{"sig":"MEUCIHnrf9FAxNgHLePwwMnvVtcKDSJrt01mPoP3ggDrlgLbAiEA5bBYlzOiUJOKKBmoZDGAJ/UWgzRLl/Mk4+5uQEQsvZc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ae2f9a3e4a1fc8ba2a8862502f079f9068117b05","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.7-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.7-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.7-beta.1_1749210443315_0.021245543043017845","host":"s3://npm-registry-packages-npm-production"}},"3.13.7":{"name":"@crawlee/linkedom","version":"3.13.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5ddb1942a08021f181fc30340fc660d506fc9b06","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.7.tgz","fileCount":13,"integrity":"sha512-ctMyzWKCiUB6tG3yps5RGQjFy2XtotWRM6DG05vf75wXSs+FBfbmHxDk0PL4IxwbNQsvJkOTzxYtWrACjYCuYA==","signatures":[{"sig":"MEQCIF6PbhzhqUd71LrNwgO2NB6Rd551jPlNemdcjii7293bAiAy4j5XvO1iYdY4ngOSJNE2Vk+N68oP107nIJHFRUq7JQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230842},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f357979b66b4348730ce587edec6dcbb4e1ff26d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.7_1749210480785_0.003546913031824861","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.0":{"name":"@crawlee/linkedom","version":"3.13.8-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b0947442cb18d1d8495dfa9fec11b59641a66610","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.0.tgz","fileCount":13,"integrity":"sha512-oidOU1DV5hcaCpM38/S+qQzk0fO/vwXFJ/SeBvLTwpLqtqNH9l12gKl/kYva0ectkMDtA2s0hCLWF1hNiv3WkA==","signatures":[{"sig":"MEQCIGHEYOJ2ip+fPHhNxxTcN0XW3WXc00eF/GdFUp71OAhJAiBTc8q7sn5oQJHm1odqlL2POl/OHmEXisDSsxivQe8rXw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230865},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"92a5d634b4c32cfa7b506449e631873526437d67","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.8-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.8-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.0_1749210949147_0.8551540285965851","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.1":{"name":"@crawlee/linkedom","version":"3.13.8-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9a5a7f43fd585377ffbcdd584aed57b90f056a23","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.1.tgz","fileCount":13,"integrity":"sha512-Dry7cT3Z0Cc/J3RPLAvbZMgjkTvP4ZEIJiuM4v9ZAj8ISlxkg14DpfLxXzUID+vfFX1J8X/jlNdZmgE97vB5cQ==","signatures":[{"sig":"MEQCIHWl5/GmT6HIoxFbLNj2aQr+Rdtew982h0X+toKmpaZfAiAcAeSxvc77T8MmKXQz6hpVAxyGsD6RX5ZA7W47sSfeNQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"79fd7915d42684a81abd23e45d273915feb01273","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.1_1749458781727_0.5633573527430973","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.2":{"name":"@crawlee/linkedom","version":"3.13.8-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"945d9bed1563180ab5b704bd24e3fdde3024ce51","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.2.tgz","fileCount":13,"integrity":"sha512-t6yUDIE1ugKAINe/YSMJx/MS+nb3fQYdJflKbl67sNCqWeIDtzdAWYelVKJm6CCzj37+gXPcOqiI86qVu9CqsQ==","signatures":[{"sig":"MEQCID3MbMuyvMFWym0vkX3cXBZ3MUi0yA4CzmmiEDtc67oBAiA4PVxFB6Dkbf+l9S1jFLwq9OxPYMOgLhTX1tDqJ8xDKw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":230863},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"02fdfb992b310c9a4b19c016cd2040850b0bc158","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.2_1749549334652_0.6719324592103124","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.3":{"name":"@crawlee/linkedom","version":"3.13.8-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"745832600b1ad2c76430691ae3a858be9d6ab1d7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.3.tgz","fileCount":13,"integrity":"sha512-UUUD+GBoazxilIuT+/qnwmn76C1seacthquZ0d5n7wlcFQpCasvwyh3MsScqGNyCH/KSmDocQwDMtWemcbZnVg==","signatures":[{"sig":"MEUCIGJo10fu9tceOYiv8I3YRfaSWw1PP9WKOSVg28SxEgENAiEAwOu42+IA5rV7Ru+dxE1SiZCzEjYaBAufkdMmO9uRKo8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231012},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"267fdd451657f67fd1ae4254e78fa16ddcc44a91","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.3_1749643383573_0.8128718001093345","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.4":{"name":"@crawlee/linkedom","version":"3.13.8-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"454fcdc1496df6024cffb7cc94eda5573a0100b8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.4.tgz","fileCount":13,"integrity":"sha512-9r6ADuT5Rt/FniTUIqPl0xOcM2aTgqJM8/544sUuHMxmFbWXE0p4qwfhhF5WAbiIaxGQ9TZaSjLrW0mUQMeiXw==","signatures":[{"sig":"MEQCIFQdwJz9bkaNY026iIjFXBA1oKBfSKEXyCR7cenhylC8AiAstj44w/b+kscFVLXQxWq9PxnMTRyreC2YKB0x7gSNtw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"22f32845a348e6996d5df7ff7af71a450203eed4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.4_1749650046312_0.6752444568173648","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.7":{"name":"@crawlee/linkedom","version":"4.0.0-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7f323554d87478a5e252f39a148dc27b9ce4b36f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.7.tgz","fileCount":12,"integrity":"sha512-HSv+N66IpBsdp9/Re0Xs//Fuyw3F1gGbKaoRqkz3AzAzLOYeoYXP6xGimnyfHNIPAjweVWIrhX1x+FaL5hOK+g==","signatures":[{"sig":"MEQCIF2xMqjpU+FUvsyO/5WvzmSksYh77dP9bYtxGdOOouUkAiATTxVh/wa9ZiQqNJdRZ9edPsFXuMQWNEWvbp+pSIQhYA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"1ad22599eee4d19b2051d923b43ef335b151ecdc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.16.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.7","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.7","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.7_1749651543039_0.8057826320902017","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.5":{"name":"@crawlee/linkedom","version":"3.13.8-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b198f7b8064d29581b2ef7214c52ffb7d927ee52","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.5.tgz","fileCount":13,"integrity":"sha512-xwWqqJazeieM5BJbs+ieSvRJeJEQHptuPzn7q8HiomhkTwx+k8ys/dtRZkwCA2RM70YZ9H+zkQZQdTBMoeLXbw==","signatures":[{"sig":"MEYCIQCIHk0TUpxiZjhmLPNBfg1cYK0LtU07qX9Leh2vbyZIOwIhAKo8IuciwMgHY4PjEmd72GMsHWtb3eP/XvgGrQW8SpZu","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"58bc65d990b2910f9bfe307c16682304e199d886","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.5_1749651649096_0.739971861236665","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.8":{"name":"@crawlee/linkedom","version":"4.0.0-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c95e4a5c7862ec239b8720b7233af1a99035866c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.8.tgz","fileCount":12,"integrity":"sha512-Kh5Dq45ajpXb67U8coMo1/L/VdaxbJukFxdgUH7IUulElbOG+lS86xqhALX6/w40I1+D76yw12/d4HXs4f+krQ==","signatures":[{"sig":"MEQCIEv06IngQDGG6Wmm75jLub34YeVVxTdb2NwD2ZMRemQyAiAJhdvSz3W+X4MgSdQXzyeakdYtjVH0Ft7f2rBLdny/SA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232723},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"a0f673e03208ad1dd8956ce3b49a2d1c9e3b2ed5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.16.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.8","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.8","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.8_1749653823786_0.7556849930600167","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.9":{"name":"@crawlee/linkedom","version":"4.0.0-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"7c7542dc45f00983532df581aa48a3f9956fed99","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.9.tgz","fileCount":12,"integrity":"sha512-qSn6J60qZkP5RWeWdhrZCo1Kjs9hJMQDvHOMjeULoTFtU6t69MF2mJf1l5njvOmqr0/qJVDvyfKRanvuFgceSA==","signatures":[{"sig":"MEUCIQCeFk3JN/MbJnoRT0NE1GCLGvG03StlsHSi83CAzDz/YQIgHk23F0iFK6Zt7zJhqsFADBwrjERbSsJDEEdzOOQ66MA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232563},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"d2489f2800cd7d9f15815fc6b5e195dc243703d2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.16.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.9","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.9","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.9_1749654970571_0.7272523281533485","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.6":{"name":"@crawlee/linkedom","version":"3.13.8-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e17bbac86469a91d1cf8057fee6cbe2edc08646c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.6.tgz","fileCount":13,"integrity":"sha512-rCN2RBYimjkGV3ukP6G8PHbUa6ZVtfL/sOFz/wrIwwxG/djOmto6839q6gE7yczIe7FTNksXYkJdE8AV5uea3w==","signatures":[{"sig":"MEUCIG2qCejoQkXXvfBRVgAx38A6USmouAY+o0SoXeowqjV4AiEAxPc0Y/weY5MwEkPp46dbx9OyipqF4jApTeKb+xDK5Vg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"490162642c009eff9fec48510363b7b6082e1f86","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.6_1749655532882_0.16490328342681426","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.7":{"name":"@crawlee/linkedom","version":"3.13.8-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"113f2c168e46150cc5e17ad739a5c76e6f7299cb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.7.tgz","fileCount":13,"integrity":"sha512-gTGty3r49g6ErvAvU8AhokTP9V4hZlW3CvOGN9zIK8/+R4PgdPIVsw/UUK90iU5VXSyKIstdI2rzQVNt9hshvA==","signatures":[{"sig":"MEQCIEuFB6L4Ti1gebjADu6YpzSpJnrWDqVg/w5Vt7Ij4m7EAiBvX5kW8ByL173S+Jsa1sLWOKAXCxPeY+x612PEdVT1Kw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"25c3783893bd97d34c4166df30f0a0cf42a73974","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.7_1749721467846_0.04097666822620849","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.8":{"name":"@crawlee/linkedom","version":"3.13.8-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"44abd905cb17ca6020881b6bda9ffefe64b1024b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.8.tgz","fileCount":13,"integrity":"sha512-+7tncnazJ6SVZLHnXM3F7Kg9wbXLR21sqXOxNUfQ/T4KW8nLA/HQIV89yFO/RZvfdYzl6pJZe3Sq4IPBoLiNsA==","signatures":[{"sig":"MEUCIFf4ax7zt+4o4LqRaRJ3IEnze0Jmdk1ROelUTAdz3mefAiEAiUoIhTC1b5Xr32UQ1bCPXzteFbtxGxnHfgTQwf9hsZE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f25cb0e087827b0a9c748040a8c529c08a8b72a5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.8_1749732323390_0.10263535039755234","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.9":{"name":"@crawlee/linkedom","version":"3.13.8-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f75fa91dffe6394625e485eedc8a8411e41adfeb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.9.tgz","fileCount":13,"integrity":"sha512-adyrxPO0s+u8TTFdaPKHM1RX/63SOOo5UiZaE/dgUkwGQ/lTmbEn8SD/jzMHQDau30mh3JQjnJkQOyTqXOzMYw==","signatures":[{"sig":"MEQCIB5FOf9ww136ftz8NXOABDML+QJ3rhxCIJDHjwcWC4kQAiACD+xzWL3C8Ih7s8OpsspocCxAWRR6vm/I1nUX71arcA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"92a72ef0a801fea8eb4192885ab2af62db34e7d8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.9_1749785096207_0.9729139089582672","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.10":{"name":"@crawlee/linkedom","version":"3.13.8-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"28a4e9f0f0f09d4428f9e58d6154abe69faedffa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.10.tgz","fileCount":13,"integrity":"sha512-cIBap/AZMKqh19LCdHCj5What/DKbP0oVQ73kbgNjG9ksSCxNL51hypyhFTemtmsEdNhPHpsJzwXMH9NWz8nKw==","signatures":[{"sig":"MEUCIGr92zL2mBLTFCUP62FENoJnNUb5U+7ZIqqAPh+ZRKODAiEA4hyCCbfXansrYPNrPgN2CF1WqCfMTPhu/UyIa6LLvNM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232551},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96c374b426eb10d089ef3a0f5f38f6d3b0a93e2f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.10_1750045575820_0.27388635502335457","host":"s3://npm-registry-packages-npm-production"}},"3.13.8-beta.11":{"name":"@crawlee/linkedom","version":"3.13.8-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d2ce4b3c182728bd550d4cfa50fcf22bb83fabf3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8-beta.11.tgz","fileCount":13,"integrity":"sha512-C5LZ8RkfjdSHEsOPY3MZW3CFqYW6Xpso6kT9Yoi6yXHMrgTyqrXspUre4NnYEB6d4ytOdxBYKfFRthTC1ihSZA==","signatures":[{"sig":"MEUCIQCDZG6KC5EcBRpZqILDluWt9aGhoA2lamTWoMqvfip9UQIgZ3/d6cXU4VOkvnxyaUEKqqpDWV/2a3yloGXpu9Gni/c=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232551},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"39d4245d9040470d6dd97ce0564cfa558459d064","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8-beta.11_1750075789345_0.4740570578565182","host":"s3://npm-registry-packages-npm-production"}},"3.13.8":{"name":"@crawlee/linkedom","version":"3.13.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ff5fa8005380c222e537a606eb420d1c4a499f52","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.8.tgz","fileCount":13,"integrity":"sha512-h+AAaQWBhPl+257NTSlh5yrDHWWaXGUWTRyiFsl4ENO4bt6k1V/4WOb2uupK0bfEV3B0T0AT6E//3wwI5WBTYQ==","signatures":[{"sig":"MEYCIQCN5vUjcVcLzfgX43wbgDtVrO35BMXHr147QAPtekaUrgIhAK0XbBSJMPDAzjmbVN+tYA5z0qMHMdU3utKBDT+X2MKz","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232527},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"039b51e924245d8d9cd377266343f070e0388c0f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.8_1750111122288_0.2823249878447949","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.0":{"name":"@crawlee/linkedom","version":"3.13.9-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d0ecfc5d00861ffe8c4ce20857e9de77f1201c36","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.0.tgz","fileCount":13,"integrity":"sha512-ePEPa5zTLVCejM5myA7eafFFJhxxuTGkdzC+fisWjfqiKNXlfaL6CqwY5adSpM4Bd6Hc5euJTdz5mDCyh2wD/g==","signatures":[{"sig":"MEUCIF44ImOTHU35uyq0yIubPVN+H57gvn05xcdKx6pXU/dLAiEApPeTkj11oS4xfUTrjqwXvIa6FbHlgMVe+SWQ/2nfGOw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232550},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f18d0382d8a95e1b2e3864d33dc19939938d392c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.9-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.9-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.0_1750111612940_0.4731532757668886","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.1":{"name":"@crawlee/linkedom","version":"3.13.9-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ecf54aeaa5ecd16ce0ba472d634f6714ec424388","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.1.tgz","fileCount":13,"integrity":"sha512-562PcmE/mY4i3mV02hrsA57nSlUho9yO9RmnpliBbkkqFjMGC76RRXqxPB8Jt75uq8358lShlR6jEgB94GZ2Hw==","signatures":[{"sig":"MEYCIQD3c17eR0DIWKutUg9eMnJIt60Dq3LesjUF6oihqnNXPAIhAPNAJVBO1TnW50wa7R0gUhoZoLhokl92wqhBLS8xIeTD","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"00b1e56e0b9c1fbcfc081cec01df19dfd240517c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.1_1750170563094_0.11254583131555163","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.10":{"name":"@crawlee/linkedom","version":"4.0.0-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f4262d97b1c7b39bc9f5b8e64cda8bce9eb6197b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.10.tgz","fileCount":12,"integrity":"sha512-YqqEiwbHH3fDEOQRN0VWmzJdP9Argv/mymcs7AQK6kM9beldamu6H3gebFRBA/YYOUT0E2IZ9WBHz6He5DwB3Q==","signatures":[{"sig":"MEYCIQCwi+i09m9EF7XEHgG2GzI4tBTzsjnrLcQwSecvJq/j5gIhALVIUSI0MUxzdgHqex32vZgtErl08+KIbfjOZeaK/MGT","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232566},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"b35240c5780d87a6d96046a286e0c9cf78be9e4f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.16.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.16.0","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.10","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.10","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.10_1750173159898_0.9179257404348817","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.2":{"name":"@crawlee/linkedom","version":"3.13.9-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1de4f15815814ba2bdcf60e32bdeae07879d489a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.2.tgz","fileCount":13,"integrity":"sha512-oKyBIUmIbctpS8dXd/+IylZzIXGOP6WDZaeSz6UvHC/PzkEaUZXjDwERSHx4OZeFhTIns8KpCWJiTuJKs9cxew==","signatures":[{"sig":"MEYCIQDLHwQdVOqaU1yVxlXIrsfBwGW3JuBER0yq//Ek+k4HrwIhANcPAVCQZEIJ2zlHi8jIfrs5Wet6xmCTwrQUMytb4k2G","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"375ac3e334533a116fa019c138f9e74ad146d232","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.2_1750229297542_0.10311671076604023","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.3":{"name":"@crawlee/linkedom","version":"3.13.9-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5d400e3652557b12873a19f2ec3f401f0731f033","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.3.tgz","fileCount":13,"integrity":"sha512-GRG9uQBpcsosl/jM1SxEKAqXl1dgFTkvWNBK4gYBmk8DiJLLr9PSy9XtDur/jmfl0il+cFHgawRl4UWt5tJdzg==","signatures":[{"sig":"MEUCIQCPELAa3wIv1HxXM5NMwmAHmP+SAlyq7RSSTEq1/q4mtwIgVGZO01iAXULOVTJNXohEuQOXYQ4GIZbbAAMrX4CkQL0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232548},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c596b0054d5184616e0f72c582a06ef036d4d7b6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.3_1750307749540_0.25312225824968415","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.4":{"name":"@crawlee/linkedom","version":"3.13.9-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f94379a675267036f4e3f12daa390bc59bd5d237","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.4.tgz","fileCount":13,"integrity":"sha512-gSlpVD53bCaEJFsqfQqpnzUsqBEfkqt9AM4g/JGhmbmbcZitZH8fUKQn8tqUMeB81ELVZMhXxTwtkw4qFBgepw==","signatures":[{"sig":"MEYCIQCxQ//QEIqhcOgGN4oRrGMnfdypw/LqjCk7579xF/oLtAIhALDIeCXLNCsfkn2DJEKWAiGMhtMyQY5GXbDux0AyJfxe","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232701},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9acab99afe77011fdfa5ab5ced0e75ed16ce1c9e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.4_1750667210556_0.5350104699911107","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.5":{"name":"@crawlee/linkedom","version":"3.13.9-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9f173f08030112a98270c09639db20d1ac2b1b30","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.5.tgz","fileCount":13,"integrity":"sha512-QJNDL/BynLMbxH+/96110vu2KmM/sK6brMcraT0qVO4aFDXqEZ98dSstzW9gzUNqRQKplq4YOaNbYBkxI9UrnQ==","signatures":[{"sig":"MEYCIQDH/sittxrGj4gGnJ0lI+M+CNxOhQwHgCc76/Uufi00BwIhANnyk8mV0Q0p2gF0ARp7AayvV5i1AICe7j9Nhx9M70fg","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"44f16b09435cf432acc59845302f9c794ce52d0a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.5_1750851848117_0.07460635272826366","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.6":{"name":"@crawlee/linkedom","version":"3.13.9-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"92a740a8f87c204666f0507f23e4ee84abccaa10","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.6.tgz","fileCount":13,"integrity":"sha512-XpNo2mq3gW2vmZj4ERBn2HeULg0p6n+ojZQD3Tkxr0wqVFcEHECWZSX74w4F1VFsMduSFz272vwqprxohWMebA==","signatures":[{"sig":"MEUCIQDAN8tEP+f0KfBhvsvHpMxiXgAGdEQbglnVe9GdMnowJQIgeowscnAH3yEVrESH8AzT2fU+QnUZowpS73dRbdy5jY4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"189bd3d79107908ac333c3064d5e7241c4b82979","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.6_1750876951152_0.29078828749241015","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.7":{"name":"@crawlee/linkedom","version":"3.13.9-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"06c6f4e147239fc64b414bed9eb79aaf8ca50f2a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.7.tgz","fileCount":13,"integrity":"sha512-l4zu/RUOBLD25x9IS8gZDnqRzqbBDk+myL6vzpm0USxXF3sbJQeS+QGuVKVa71hhg7UyBvNSVDx0moWYC05/5A==","signatures":[{"sig":"MEYCIQDcS1DVx73lbGCRjGOLPaSBMOwPmu4DNGcKMkjo1SURzgIhAPg/OLx3oDPMFW2g9MWId9oNpWdm6cDSE39+hJ03ORgT","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32ad7f7acf536aee8b9dd60ec920a3a73badd59d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.7_1750932101030_0.04690713518309009","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.8":{"name":"@crawlee/linkedom","version":"3.13.9-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c0d387a181fc73ad2e86c6a4739a471e9338f743","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.8.tgz","fileCount":13,"integrity":"sha512-LR9HDHuJFuX9LbiHrSaWyFYNTE9wdXdJayg0L2e6jUtacceDYYq07AWOVT3yaaYl1d8+q2h+rD9FujtIwO+m1w==","signatures":[{"sig":"MEYCIQCrREes1wRbJjbRWvj1t5N8ChUjaFaA9NmqRjZrmwgk8gIhAPJqOqNU0jGTEx4tuhHvFh/7KGPJS4nA+S6u/asE0run","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232705},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"251efa5b96fb468489cc04620a19dfc8857a0ee1","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.8_1750937613002_0.9094667947433301","host":"s3://npm-registry-packages-npm-production"}},"3.13.9-beta.9":{"name":"@crawlee/linkedom","version":"3.13.9-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8cd64ab2112d993032e4421c2b0bace5588b0183","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9-beta.9.tgz","fileCount":13,"integrity":"sha512-dFdFdIR5JK5T3cBH2o8pZkcZQh3awawWFHnJq2yc9HTxCLYz1k4f4qBzk7rmtJ7ASTLZVXH9TiFUJaAb33hCfg==","signatures":[{"sig":"MEUCIF6cxMCxuJ16aCX3xI2HOCzQv44EkPvj5/jIlI5pLga2AiEA8VNTQ+PVHP9M1ndgtNaqlXgnNDoh1gpHnGrwBOTD7RI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232708},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0f929387ac0e0f76349c7cb97e9c6ad0492beadb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9-beta.9_1750948298860_0.6306097706516689","host":"s3://npm-registry-packages-npm-production"}},"3.13.9":{"name":"@crawlee/linkedom","version":"3.13.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c9a9e6f6d1b756c87f037171fceffcb25a0cb777","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.9.tgz","fileCount":13,"integrity":"sha512-LRFUN0Q+9zeQ1e3F5wecyoYx/vgPrxNWQBvbDRSMy1WaZcH9TCL0mIYAhffGo1PSQOCUF3v4S5j94rxmcEoiKA==","signatures":[{"sig":"MEQCIHA6aqIxtvvt08tnqpGs2maTjfExZ9W4BHH85I9NntGUAiBYipjgqbeBgBXLvhqLQE6XahJ9Wf+Z0kGwpZ0jH62k9g==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232687},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"371eab1afca23ed0619cf7d32134b8c33d17dfe0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.9_1751010377971_0.9059983344339673","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.0":{"name":"@crawlee/linkedom","version":"3.13.10-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"af1bf02199f5c2c3dcca0b4ee3e899d343d17db6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.0.tgz","fileCount":13,"integrity":"sha512-XUHXhGmAuUkB+G7RniXgP/jKhK8qsHJj51VtkMZNUwC7iKGnKRKspR4knkzunbCB8naUy1YEwxUD0C8Rs6YgSA==","signatures":[{"sig":"MEQCIBFlZf0pbyi3bCmAZSvX0oyxHy3/XtW24SFluOFNATABAiBFGUlXdZJIUj134gUlNd7xkf+d54pXPLQXWC+UJKmDjg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232713},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a749de7713561dc807102beb0f52c4d4d20cbdd0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.10-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.10-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.0_1751010918953_0.8833857169376698","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.1":{"name":"@crawlee/linkedom","version":"3.13.10-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c906b4f29328317d9482d4b0f9638493a9429251","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.1.tgz","fileCount":13,"integrity":"sha512-UH+/opZoLnRp6dLanR5pueCPUzt7O7TZNM5Y7DYU7ir7Z3igbB48NaGKPWDwHojdn7CGriBq8vMga+rwNj+Vvw==","signatures":[{"sig":"MEQCIHT93KKLlPPy+1cdV5VP7U4RASyajH1mgIgVwV7fBZduAiAPdTM/uKltgE8+FqkWwAnLlobJ74+DQ2bob4/F8SGgCw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232711},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dfe62cba16be908e8b76ab714dfb93ca877a093b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.1_1751290735772_0.9405473325797924","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.2":{"name":"@crawlee/linkedom","version":"3.13.10-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"c1e7d126a05c9d99ceabe512df38c854fa87ec0e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.2.tgz","fileCount":13,"integrity":"sha512-KJxT1g3kDvUSpNdmQ2B4/ita7d+tviyyfjLT+txLgDH8gk3ssqCU51VzzqubyLlgm/i9HlpsQnmM75OJy7Xeow==","signatures":[{"sig":"MEYCIQCryixTd7qa0H4Hr0jkadqYC2wsfJONz+iKdL4GTCqTPwIhAP2x8kKY9rDfsUpxTD3XRwn7wxBVS79Qmmz987Fh//WR","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232711},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d82ea4fc6143c7413db8a3ec71e8b4277219a63e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.2_1751292996031_0.07565541010398946","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.3":{"name":"@crawlee/linkedom","version":"3.13.10-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b50197ecf34ce4449270531a994280811491fd1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.3.tgz","fileCount":13,"integrity":"sha512-Hzu9ZD7p4QjkA998tZKQcPkGXsM0x5GePLTH9ITOL+W2sQny2HULAOKFkyevOLY1x8/Rhm0d7diatZkyvSjnyg==","signatures":[{"sig":"MEQCIDmKYHfg98OqNPUrhgC9hJhkJJW7PcQlTqgaILwViBHxAiBrV84gEXxQlnnl73WS77gcGcjICF7MQ/nJrsgd0CQEyA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232711},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"842144063e7a7f410d8b74304107aa782d486ba5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.3_1751312131263_0.4815010608854102","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.4":{"name":"@crawlee/linkedom","version":"3.13.10-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ab5edc9ad2997f4dca69a8d673d61655bdf926b6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.4.tgz","fileCount":13,"integrity":"sha512-N/z/+LRURS2A2z2W7lVHZ4Tc0kLlwcofISbhaOEzGGxswiXDZchcyhwPJ/UBteHU9Z2yOs3LTxksOzGS97sZ/g==","signatures":[{"sig":"MEUCIQCPJs1WhD1m7BO99UETJzDjxIbs7mNLPejJbU8Ff1OBPAIgG/8g8ZgAhr9ncJuCROUq7Ty8Kw6sqsSHxmznQZYVLd0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232711},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9028393021214670bc9dd251ada6c9e2fb70ebfb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.4_1751330737073_0.4011528374995603","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.5":{"name":"@crawlee/linkedom","version":"3.13.10-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9cb9e65bd453b62614662772b3e376f4fd917899","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.5.tgz","fileCount":13,"integrity":"sha512-AH1lTFVgvJ4DqxK8XGRej8HcCR0pXKXNvJDQNpx8lvWrFTWslp9o/CXb4sN40bAIQDlgu9NNSUN0RC7Hkxds8Q==","signatures":[{"sig":"MEYCIQCRaoM8Nmkzm7B4Uxj83w+opgf8avXl8e2D52uAs0DR/gIhAIgI/nB91gDlUsflFL9hOuYkY6R0VLlv9TRmhY6mfNeS","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232711},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1f03373245e8c3224472ca9c85411d6da12a71d4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.5_1751366169887_0.07032820819295571","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.6":{"name":"@crawlee/linkedom","version":"3.13.10-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"25eb19aba7f0de68ab3a6e820a1049822532dbc1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.6.tgz","fileCount":13,"integrity":"sha512-XZPskAFKSxb7WimPZ0nWcH5+PNn29+BSc7VdQv0Kdp+3rXMXFjp2NqD1ECykZ/z6BVS/qlZ1RvgpuFHU7LdWKw==","signatures":[{"sig":"MEYCIQCFnMilgW5vPVIh+rKUU+Bmbc1KYDg6j+NKi/SLFyoJCQIhAO1rNEtXjQb68SyZKU6tZtzEdmACLwD7ipAYw0Zb10rT","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232966},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ad74fdad16ed275abf34448b818e7f9f6d4f6e94","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.6_1751368851655_0.4161322708029289","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.7":{"name":"@crawlee/linkedom","version":"3.13.10-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"411dfc5759a5223f0c75fa79b86c12b18b5729dd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.7.tgz","fileCount":13,"integrity":"sha512-yqRF9sUVq6W0RmkAR0Y8C2CBrDXsXB8choYI7teNshFf1GKPfpBhMbNmH3u5XchqVIUDPi+UWjA5lb67uQ1FTw==","signatures":[{"sig":"MEUCIQDDedasrofNpzjkI4niPOMDbg8FULmrHS0hFZT6vGK5AAIgeXIZA7x5xIiB6sqJS2YKnKb9u9Dxq4smhV92qIPuIQ4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232966},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dbedb78b4b96a40d4b70e707e2d05c427afdf8f0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.7_1751374959760_0.9696402888980644","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.8":{"name":"@crawlee/linkedom","version":"3.13.10-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6752d561261782cdc0af9315adad13d039647f75","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.8.tgz","fileCount":13,"integrity":"sha512-qRYLPAO7MVFie/tZMgiaSPdnWKclzkdq4dFGlUOk05NeqATb3v1vkEsekqsYA7ofLLTPq/Fl18B4tlCgbHo4kA==","signatures":[{"sig":"MEUCIQCpOUdceMm/5+P2WNtmvW9leKBpgA1nogwf2BWlDzMfXwIgOE3Zu7/oDTOZKbPuBGh2Vd2ZSEB2E6ebJ9e+ZEtpuR8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232966},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ecd7f1111ec401ebab00965180fe6d5b479c4166","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.8_1751405883461_0.9783633721491294","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.9":{"name":"@crawlee/linkedom","version":"3.13.10-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"35811a57524d53114889aedce0d3f8bafdc6d234","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.9.tgz","fileCount":13,"integrity":"sha512-sBMJ9d6ApYOnfTDy61N0tQCxxqJ3wQQiD4CMQ/NSiVhE2om+I83Z5nb3InTj49zYVYI1r6c3IHurXvlkgR0/MQ==","signatures":[{"sig":"MEYCIQCH0Gi9pNu7bG4nF8+gEUu87wIftPcubiNein+fvIhsJgIhAKBZTPSRB9qU969ekXq0E/pinK+9f0QEa/yBzuOf2Apg","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232966},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"839fe6682fbf950428e0fccdfc05ba73ea664b8d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.9_1751543769600_0.8668584920935267","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.10":{"name":"@crawlee/linkedom","version":"3.13.10-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3605286bf51b0f6476f561f9bce88ceb0ce4bf76","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.10.tgz","fileCount":13,"integrity":"sha512-Ohmh9wboBfdmy9Y82hSBw2ddCNXqKUqePs3Kdy8tvZHysVSjClrDq0KziYruETMohmnokNQKjG3dSIlqTmcF2w==","signatures":[{"sig":"MEYCIQDXK4FcGP+NlpksSBXEk7JGGmXPzKrPz27L7mtFq7kingIhAMw/ow1t2eulkt5LAICpJYPFALTiOUl3y72b8vWx+HSy","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232959},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f3be8e741926aa1f23190f30dc3d60ae470565c4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.10_1751568245023_0.07019825881859387","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.11":{"name":"@crawlee/linkedom","version":"3.13.10-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f537bd2a411ecf6ebde7fc334410c8f565e8bfb2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.11.tgz","fileCount":13,"integrity":"sha512-T6g8zJAyepUl6D/eHWyNnyMCZvJ1IXyZoawWE1XIs2DeJvRMjEqS4+ESIHIzKGBBg8ctVINoWxAuZcUN1nEnlQ==","signatures":[{"sig":"MEYCIQDTCt6GdAB2GV5gkOyX7DCUmItlYrn6p9Q1dxqSKTLOuAIhAMYkIEROr9TXz20j0u5D2fnNZA2NjZppmDUuxkY4fmpd","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232959},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cc6a45033a375801610298bcb6c86e560220350d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.11_1751933345525_0.6253920546535248","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.12":{"name":"@crawlee/linkedom","version":"3.13.10-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"be0b0f6648eba48af05c69a946e6528ca1639bf0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.12.tgz","fileCount":13,"integrity":"sha512-OerNyLZGWjbRMBoaX0bTLYMyz87s6UQQeUNiU2QzjAmler9EqKyLJouvj4GiEJO14NljquGvTRcEzPjiStE8MQ==","signatures":[{"sig":"MEUCIDp+PT0s8kp4cxyY3PRHY3GVGfyubG3onYMETRNDjSA4AiEAgel5SwgS7yVxHtILx+SWdD0NXxqqC4qvhxtijeFQ2EM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232959},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"73bd7358265758d4d961b2ebceb4eab9d5cd8185","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.2+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.2","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.12_1751948666623_0.7988683971421495","host":"s3://npm-registry-packages-npm-production"}},"3.13.10-beta.13":{"name":"@crawlee/linkedom","version":"3.13.10-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"78eeedc97a4f71c9c1686fcebc61f63e44391288","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10-beta.13.tgz","fileCount":13,"integrity":"sha512-IbGIcxgAu6HlVw2+8KhiKzCOV63W2/+FBpYCt6dnbGlwQ6G7V7kExP+/zAZM73XfnLMHxODC2dT7yO59ILJi1g==","signatures":[{"sig":"MEYCIQCDRqecWlbHFHWuYBdjwv5nvvalGoSko07MsNwn09/8uAIhAOpv2G6S6+5spvp6MFF2yYPDy8ThWgM/mPEf3Ycz5aFx","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232959},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e897153372f06ce790ebaa165b5100003d8dde33","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10-beta.13_1752054342433_0.6054927378664547","host":"s3://npm-registry-packages-npm-production"}},"3.13.10":{"name":"@crawlee/linkedom","version":"3.13.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2f545e4fcf2636a52942306df619809cbc3b84be","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.10.tgz","fileCount":13,"integrity":"sha512-NeZ/HPBmvOtnqbLf1ZImTN4WulllRTTpnq617wMPaF+Gqkj4h9073DKdB05SpLl9Abz4LdD8Xdw8UTDjkyOAFQ==","signatures":[{"sig":"MEYCIQD7+Lrr9Y0Ayht+CaKNvwb+TlY15wcaOvdBvlLed/1yCQIhAOWLNB/eyQwalwZtm5f7Ji4NwU7+oY2UZpMt0z/hnnWl","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232935},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c81d2b4b26563a14f3e479598c278de61eed066a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.10_1752061923633_0.2100392063180998","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.0":{"name":"@crawlee/linkedom","version":"3.13.11-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a28ea07621f3f4dcc0a62c775579bf98293cf2a5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.0.tgz","fileCount":13,"integrity":"sha512-27Rf9xq/tDS0S33UG548co18FNB8nXMaJZ3I4b1a3l7c/6eWZxY3458eT6d3/1KOvPNLhyoCb6L1lc2E/c5AHg==","signatures":[{"sig":"MEYCIQDxKXfxnp3hIrXLkjm2fZ2sO79jAhHVAzASYCnZnzdXugIhAOKkST9bsdmIV+eU2XHONtN6T+C/OjjX2BCQ1cvPkNgD","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232958},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b5342339f10b05f190a0aea217d66c2bd5da5936","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.13.11-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.13.11-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.0_1752062360454_0.6802447004464927","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.1":{"name":"@crawlee/linkedom","version":"3.13.11-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a718d27c7f0d664aad34f3cd3a5a224b2381aa48","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.1.tgz","fileCount":13,"integrity":"sha512-3ShO1UwMvgPXCz2k6GtVvGrC98+zf54wBSRcNB2i+21wdlGbR3yAka5w1TJBGVuTPbILERS9zy93cVjqgTSv5A==","signatures":[{"sig":"MEUCIQCsHq6UWuVADr3k1+sMaIngzgFij821I4mX9GZFqAo9KgIgQKv/DRVPTLn4MCEgoTmIGsfyvdJrxnDyAjHP/ExFNr8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232956},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e9dc4ee9089ec6ca1df9aba4a81356092a87be51","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","actor":{"name":"apify-service-account","type":"user","email":"service-account@apify.com"},"email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.1_1752109466843_0.1162123764981211","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.2":{"name":"@crawlee/linkedom","version":"3.13.11-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b669d7950ef54822cd4d3df1d71d0efb549256e0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.2.tgz","fileCount":13,"integrity":"sha512-cnNC1q6ILDVnS8gqX3AIMqvRGgE44s6fY+Iz3WlVZznh9dpNSqus6YypS/jgOT7lkxF6iEUnWba5WkpBAzxTag==","signatures":[{"sig":"MEYCIQCKxra1rcQQlZBudIMj4MlNpVpYHlpMCW1Ng8oRZJI06gIhAORQhHelR1u4dvKGt/oFwQtzG41fiRmpd8P6mRDI29ql","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232956},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d9c97e8b2bc9a5bc809883d8e322e7c38bff3c5e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.2_1752498279738_0.534634942990782","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.3":{"name":"@crawlee/linkedom","version":"3.13.11-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"14b8bfad89b7e85badfeb9e41e6d958e10f8734a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.3.tgz","fileCount":13,"integrity":"sha512-2cRyJ7Lzd5XBBMQwARvzgqr1vwAMf5OKhix1UpjB4pJWWppNJO+ZTPIB6Lf3KJS1njLbvn6PY3B2OfnI0k0pHw==","signatures":[{"sig":"MEUCIHyc2jYAMPRmHcs8gzor8i/mM+DaF37Jz1lRLZYUDKolAiEAmnxSZ5bAOH0JvTlbmBHtJ5cujNjp9LMsIQikD02kQZs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232956},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"df9a4c484593a7fc01e49b1341f4d780cdc6f274","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.3_1752647304380_0.710863532874233","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.4":{"name":"@crawlee/linkedom","version":"3.13.11-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4016a5bb00c2403db5ffb72637254a5771efb6af","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.4.tgz","fileCount":13,"integrity":"sha512-xql0QOS+4iarc4P4NgcB+ffi9X/6DiRnpUk7rdA2sHEwMgusXCXZiSc9do3GOGudBVvIneHUH8r3dRu2uspIXw==","signatures":[{"sig":"MEQCICJ+bYzfJafMfjhMYYPGOIURakG7go4m5iElaxwPYlOwAiBd3+HHlBEw+4Qwpa4AuJJrtIUGYutVzD3Tr6rxcdnE8g==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cdf793e1445a3f4f5999bfa40f447815227c7828","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.4_1752744661467_0.004554492159797974","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.5":{"name":"@crawlee/linkedom","version":"3.13.11-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1055ff2a732afb7bf8eeac3c78a7a5180fd4220d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.5.tgz","fileCount":13,"integrity":"sha512-ERA3xhZwbCg3gutKdjN6MZyV+nU+cK7mB3Zl62TABZkPgsIqG94cdBZBG8CmUhUDajgc1FyeQ6h2Ks58k+9iUw==","signatures":[{"sig":"MEQCIDnfQTr2NvM1AzxwVCKeczmILaqyWsT7Ea0vBOLch3xyAiAe/xAQO68EzGlUXRUkoKEjipLqEOG4kS8iBO7/UG99YA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"00449bc666fb30ed355cf17043ee0e7415496b61","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.5_1752759854359_0.6600339349460866","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.6":{"name":"@crawlee/linkedom","version":"3.13.11-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d6027f25fbefbf9ce4f8a94c3858626584a5dc4b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.6.tgz","fileCount":13,"integrity":"sha512-gi9GSu+5iPaIkSdaHnPlFUOXOpjfa2edRVIdOv+dm/SOtlRXxZ86NEi5z87wEYBGR3PSanK+KhaPO53+SDfQwg==","signatures":[{"sig":"MEQCICj0Q2aaNWkMAtz3UGDqy8wl5Trap6l4aENpjOGaWq8WAiBqJcKhZnSsJJCe2UPW6i3TVOknxdSgokQQzl8XmqBU+A==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d7dbef3e1b6f8b49162c9dce2f5b1b989e872edc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.6_1752841792480_0.635776027423048","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.7":{"name":"@crawlee/linkedom","version":"3.13.11-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"bcd2066dc4b0789d8f2dfb235f909243c6e160fa","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.7.tgz","fileCount":13,"integrity":"sha512-WnS0pHsKu04M6QmFResFvcOVAhif8/oE7kSraZqosgHD4w3g+Yapfs6b9Gqo1jIXmYch8LTgYkjNrWFdMiMeIw==","signatures":[{"sig":"MEUCIQC1pFUpWUvzqDuBfX2Kj1OOuo6lyu8KiuX4GKLNxHf+dwIgXLbWfzEWwEk/3hZLDGzBLuqV1dKqKrueFATbe4CLXAI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"57f53b5f48cd7d3f6e22fd49b91fe66abf8ef61f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.7_1753099383602_0.464644324154023","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.8":{"name":"@crawlee/linkedom","version":"3.13.11-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e4c3c1bb9088dc175e8bfbaa94ae38676b847f3e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.8.tgz","fileCount":13,"integrity":"sha512-aUp/9dwr/FL1o7RxzXyfP25T+KkTzyqqpaDpvoQ3tpBm8sgbqLgXnTGlyXtRxCRG+gH4pjrlMHQILy3a/neI3g==","signatures":[{"sig":"MEYCIQDWo68siJrg+rO8HuVy+uUimLPK1jwvIEHolU7UYfjylgIhAJqcPUAdI2Yypgy9PLQ7aGboNn10YrQrmggXX6b122Ve","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a19200fc47689eeeb35fbb7ab6b343c9e58d89e2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.8_1753167891240_0.014470064581809439","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.9":{"name":"@crawlee/linkedom","version":"3.13.11-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"92c237c2665da83113d1604e72bc9ad0ceeaf35b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.9.tgz","fileCount":13,"integrity":"sha512-mkbtuKdMkbsabauOH4+9uKetxCI/nx8uFvYXb5M8B7e4rZzMn1mN2e0rsiWH+7bonx8PYxtVMjjDjegP9ykA7Q==","signatures":[{"sig":"MEQCH2lKgcurz2lwe+E6jrpEicTWUJcYxgD55jEwO0HfMxkCIQCQnjhKlqwQoDIuJ1DbX1BVCeccwjc+iz4VQAEsDfwDZA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233991},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"053f695f0a914c8bbb261b2a5ba1773ad052f7a6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.9_1753174483200_0.4826838219943288","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.10":{"name":"@crawlee/linkedom","version":"3.13.11-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"933e48bc55071ddc585eb8ac3b6bb7de940d9c46","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.10.tgz","fileCount":13,"integrity":"sha512-8XBF+7V9USZ35ZRX/beXCiSMby0m6xxLQE5Nn59BcXa3nE3FWRE4k21Im0ImpnnVgKKjgfxz+1bG1uJDh+IeXA==","signatures":[{"sig":"MEUCIH5BdpPeZx7oGBvpMv8RiRRvahhJZLkk7iWBEx2JBYdOAiEAgp8RuRw3cMvEeU8CmRVOoX6yOR6O5ZnjHM+dQ5gqTM4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233994},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"237c4f47adecd98dcea514a2d158db9c3c7a2b86","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.10_1753293563055_0.2268568773688422","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.11":{"name":"@crawlee/linkedom","version":"3.13.11-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"af00be71a16051f09f126cfcd63c7e5a5806f44a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.11.tgz","fileCount":13,"integrity":"sha512-jjEiQNEO4D/vkXwolKhHzUoJHUksUY3k7hD0UravxZe9E5yIgvu3iVM7l6OtsCoH0ujirxdn1iJhQndXJ+k11w==","signatures":[{"sig":"MEUCIQCeUGdRCLuc11+z+FmMi7H4tl0U8OZzinRX68a3Nx/UHAIgVNoX3lyYHhTs45mQ3umdeZq3e2cJe9RjuqZrZNUi6jU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233994},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e8f543089302587758e41e6cd46354eed45f8432","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.3+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.3","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.11_1753294411099_0.9299333234262022","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.12":{"name":"@crawlee/linkedom","version":"3.13.11-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e303afb6b029f318fd572255e482262577131ac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.12.tgz","fileCount":13,"integrity":"sha512-7REVp7cgIyruKByBzBVdezaebYf/DTMqFtyw99yZ9otRCrsk5ctYia1kXdMXPwOYkJGe8Q/0ymdvbc6r5mI/mw==","signatures":[{"sig":"MEQCIADkGZoRb3DCmVaOSPpF9lDjzLbip9o9/XPTCbGl96WsAiAUpBf+pQWX2k49MM265/fIOju90GixGXwYK1ODfAbwzg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233994},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"eb55424f088d2d76408350ae75de584410483cc5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.12_1753351127066_0.2743772939313267","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.13":{"name":"@crawlee/linkedom","version":"3.13.11-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fa1c1bcd46b2971586975493524eb9ad188967e9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.13.tgz","fileCount":13,"integrity":"sha512-fr6zlY+KAIr+Ln+tj/yQ4V/MAEAFm+LY00qo0ktQ8gWGYnkF6tNy/uCMNvJi0a5CuNkz0GuGdK9ov2PKFWB8YA==","signatures":[{"sig":"MEYCIQDTP9SFx7zl2bzncg1kBqDYpShwL8FR4OcUVsPlCcUu0gIhAIEmECfVSt63SiHovEyYqGvfFnpJeG8ADpL7v+N8aZDo","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233994},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"44caeede3358e58a743312bd615ecb020e5a4d4e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.13_1753380768705_0.9190596141993959","host":"s3://npm-registry-packages-npm-production"}},"3.13.11-beta.14":{"name":"@crawlee/linkedom","version":"3.13.11-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.13.11-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"991c05f67cddab022eba396dabf710494e65a86d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.13.11-beta.14.tgz","fileCount":13,"integrity":"sha512-F2im11/XfZJYiej+l4LeNix7XViH4JuY7hN6UJKSKaCJU9R1S6z2p+fwzYls1eOYisxW8edQ4RpvFzBb2kC1Pg==","signatures":[{"sig":"MEUCIFOVlX3glmu2Ow7E54dMZ6v9TvhhthPpIjsL+NnoG5oUAiEA31mxDdL/axkaNEJxaLZgHDcao9XaFAoSLfWPpPWc/ao=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233994},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5de8548802d09be4ab084f11d1f361151888572f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.13.11-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.13.11-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.13.11-beta.14_1753434889103_0.5845000324812282","host":"s3://npm-registry-packages-npm-production"}},"3.14.0":{"name":"@crawlee/linkedom","version":"3.14.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"891f069a1a706a1dbf7c57ed2a3dde821a7d6d25","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.0.tgz","fileCount":13,"integrity":"sha512-228fE71a65x96RivxP2uoOPQFIb2wE42HOI+1dd+ziDhPhZQSjVbt1savyC7OxNLf6mGa00BrwfCp61DCkzsIw==","signatures":[{"sig":"MEUCIQDAOn/evCeJ0NjgBl/Iig3p2IwuE1qNGFvaKw3X70vBsAIgdsTISbKqqrjVQcyPQio4k/TcH1GqAVg7Re6aCW6/cs0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233967},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c53f3141fd38a0dd9d7679e4d0553850f3ce9554","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.0_1753436104064_0.04491538555131225","host":"s3://npm-registry-packages-npm-production"}},"3.14.1-beta.0":{"name":"@crawlee/linkedom","version":"3.14.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"87629170441b68122b3fc90d3f2212e26f046d2d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1-beta.0.tgz","fileCount":13,"integrity":"sha512-bzCBTb2GmWjjBLUACwZLz3nJjTgfmJL1HdCXEHJ06EpYb8vwlf22fyqWDmtHNwjYi6ZEVvpsSu5p1bwfF3Dl4A==","signatures":[{"sig":"MEQCIEcTGh3DI86eP2mGduT1c59wtyhWALQv9K0GmBa1cDY+AiBv42tXLwxR0HH83hngv8uO2ddKfGnxWo5SEsuVLyMz7A==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233990},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"80a6cb22edd2d243aac1963165f527aee5e0f63a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.14.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.14.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1-beta.0_1753436546485_0.7853619988506273","host":"s3://npm-registry-packages-npm-production"}},"3.14.1-beta.1":{"name":"@crawlee/linkedom","version":"3.14.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"29b68e32d29d35a3a57d4240d3746e0a648f6d45","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1-beta.1.tgz","fileCount":13,"integrity":"sha512-xDVD8JA10mtg4nUim0cZUjAZlqg9EEHEA3MKw0k2hHB9Fl8sZcdxckeo9dwyUDCGquELSshZBB6Xv6GMocT8JQ==","signatures":[{"sig":"MEYCIQDd36o49KdS8YiQlr77PHzdewQbuSh7AczTyrVMhmXuZQIhANEuwQbjxK+lVH7yoN+b/riMaWCgPwRmfkhSGrtzie5a","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233988},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"91971f3a7325875e0feb9f9b47b2c5ca57ca8e5b","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1-beta.1_1753515366132_0.09112030823805206","host":"s3://npm-registry-packages-npm-production"}},"3.14.1-beta.2":{"name":"@crawlee/linkedom","version":"3.14.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"032a59d221f5b2033a43e1d69314e3468d358065","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1-beta.2.tgz","fileCount":13,"integrity":"sha512-2xBXgig4oe7cimP4UiFZV3Es4tuz7rTOqRsnbFRm3gXL/pnqleilV8ubZyekb9gkTQa5CX4DBkhrDOTLRW76gg==","signatures":[{"sig":"MEYCIQDOLbxUDgynWCgqxtJDNwcELWmpxNBLLz74565IWB72XgIhAMhEmYPYftIWlAu5yKEKOtOO6HSaS+hxsbMgVGT/G2jB","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":233988},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"076d9c55853fbc69fd61472995fd5cbd15947544","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.3/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1-beta.2_1753716228715_0.08850746291659517","host":"s3://npm-registry-packages-npm-production"}},"3.14.1-beta.3":{"name":"@crawlee/linkedom","version":"3.14.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b5928c949efa70d714d31008f3bb3f5d7673039d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1-beta.3.tgz","fileCount":13,"integrity":"sha512-0W6lKH9Bl0x7b5lG73zbHloJaeGhDZ6+/nqveNTqXtJYG0Yx6A+1VAgeWHfXzfn6WywrT6Lo/YT044e0gEPKag==","signatures":[{"sig":"MEUCICBFzkkIljQm5ikXpbIBX6xsr3q9rot82/5OTVDSyTtqAiEAw9xJsBL28RXU/q3f59HHjR3RJQ8WStEytMrQpM9pex4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"76af3b1bd5f85f37b9e3a6e9723af512df5a0e85","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1-beta.3_1754131203579_0.8854095879787194","host":"s3://npm-registry-packages-npm-production"}},"3.14.1-beta.4":{"name":"@crawlee/linkedom","version":"3.14.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"deaef1e2bff53ac71e35ece1cb38ce79fd920825","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1-beta.4.tgz","fileCount":13,"integrity":"sha512-Wr6ZvMjZNo0uG13e9hAkAlt8SjMwe1Fb5D7p9F3cB4/ADetSxFyHtRA6m0DGAXm34GvxkzN09axLZyKEZWRT4Q==","signatures":[{"sig":"MEUCIC9ZtAiNljo/mMTDPjw7utQs4C2QCGvT+VwifVbJ/PErAiEAs4dk+/ObT5RoSGm+Pzu/BVMkBuwgSRfaul+RfyXb+Gk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"86d1ea860a541586d7b14e1cf27b35b29c8535e9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1-beta.4_1754393702366_0.2253645056013729","host":"s3://npm-registry-packages-npm-production"}},"3.14.1":{"name":"@crawlee/linkedom","version":"3.14.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b479f861bf7cc2b8948517bd6486bc9c4bb999bb","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.1.tgz","fileCount":13,"integrity":"sha512-1orSRAnul75s9ADzR2B2IkFzFB3z1SZgbLMHQ4cjQ6nZappSWCxZhAZao0eDOIGCEQAbxwqtRmVKeZhd8ZS8HA==","signatures":[{"sig":"MEUCIQDK9sZO30wzGOQIW4UopBanCUuygkZsDNhxmGx4sySs9wIgK/V2h0kSeT7aDC4nffxynmr2AxkH8mawCOMSNCWisJs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234361},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a59c0142d74e48ee429ec61efeef296940d4df29","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.1_1754394824427_0.13570363305301125","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.0":{"name":"@crawlee/linkedom","version":"3.14.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b109692508c79b6adaf465e1cf936dc218e02060","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.0.tgz","fileCount":13,"integrity":"sha512-EVUgEZ7uYeglbnr5tzXKiUf9jQCkgVpvKttJHON2CiHZfwl1IJ9R766wAgrKVDtmigapimItn8coFTiZ9Psndw==","signatures":[{"sig":"MEUCIQDag87M6XjQwlBN98bVXLT8u+g/e5GD+tTvNXc+8B4S9gIgEapc03EHWrJn3a+ifyCKOcEtDyzfOSx5XWfGQztycgs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234384},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"72fcb61b1960c1e02e9d9ba4ba49e9f6af5b5ed0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.14.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.14.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.0_1754395268050_0.16999720933963092","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.1":{"name":"@crawlee/linkedom","version":"3.14.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d5c0189549238aeb446579078e55d02a3337fc4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.1.tgz","fileCount":13,"integrity":"sha512-2pfcvlSUpE4xekHm8oyfpcFaxpEdhb9Yi7lByY12rrGzJh2alsudshslKWCJNjIHx9nc4ovpQaVsotvmZ4/6wQ==","signatures":[{"sig":"MEYCIQDEYmSXqqGDV9gHs5nTV7Mod+X3edbKZMiDKrnIRrXPhAIhAJq0duoHXUYcNZgjDyzOsjG7qCN6sXpa7e4+IDEnphbZ","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f270530e524e6ddec951697b38ef8ddd8b068052","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.1_1754718314308_0.7580234221729376","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.2":{"name":"@crawlee/linkedom","version":"3.14.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"af6c8097a95a62e25585c46499eafbffdb21c2d4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.2.tgz","fileCount":13,"integrity":"sha512-jTxLHJhVwRjc+HExLCC3LbTn7GTBJNSOdEYhnnA3Me3+IhswU6jVBIYoVtZioEEBLxyoQ7s17b0e2bUuPof/7g==","signatures":[{"sig":"MEQCIGHnTqtOEuqlqV4gVApfifTBzSSlLzcT9+wmvPAFiTKCAiAoFgawKN2G5Kw5UMXOEFhA2tMCe9PbgzfHeul+KTNBFg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"95f6dced4c666338be4c28140dc2d88179c2306e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.2_1754804683336_0.5377631763800776","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.3":{"name":"@crawlee/linkedom","version":"3.14.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d28b2d61994aaacb4d5bcc4957ede6baab2dd7e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.3.tgz","fileCount":13,"integrity":"sha512-hAr3qqyPF3nINJNSqQSGx6WliYU3AQhMaI674aLY2GZo9C78dx1/dT8rrQwZkvvvv3XW7Az3ebOMN7nMk+4HwQ==","signatures":[{"sig":"MEUCIQCAYwEtWgt+0U69V4YEtFDUkrCepiATurojChzCBc1spwIgdV/svuOU5Me25rJwtWbflnxREJTWl9IjFlZHvH5ruso=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2f6b0f83fbe49a4be54df8497783ee53e69fd395","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.3_1754998489539_0.8738861792943318","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.4":{"name":"@crawlee/linkedom","version":"3.14.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2e56c91d8cb9774897a52038cf93a90d619d880c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.4.tgz","fileCount":13,"integrity":"sha512-bM2BNfkV7bgjUJdtbalTY1yPjB5IehfGd9ouC0kVFldhYkVKKFCAEMD7cQkVIHoFxfzckX87SuiaYrhzD2S+TQ==","signatures":[{"sig":"MEUCIGoPSSn/FIQdMbYj8zrk2z5Qm4I8LKFshG4zIbbGIrSKAiEAkkuVIv9eyYR4+/YpqRSwkCrf7jyCCG5hLW7M4r48oSg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9231e089a54436dfa4deeabcab4b081bcfd7e428","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.4_1755003161151_0.6687240967637902","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.5":{"name":"@crawlee/linkedom","version":"3.14.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"23347dd3fdc58a140f910a6a28f0d50d696545fc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.5.tgz","fileCount":13,"integrity":"sha512-bxcndx0C4591wccszWaGc34B0a/wG99fM1pQzUUSnGSQ6JhHkMtY55vct9fSBXY5zIGrSCtehUavHsIU93445w==","signatures":[{"sig":"MEUCIQDnQHesJrJtR8VVT0eHQXiLmqwLZRAMN8Lln7+J6y9rJQIgfYIh4oBpxBvGCwgTGl1thrC0zG0hsaMH5A3SI5qeIPo=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234382},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"93a5aadd7e14a610c8233f25f47a62cef02c8713","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.5_1755074762199_0.6446331377905565","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.6":{"name":"@crawlee/linkedom","version":"3.14.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5789d7cac7841f15f9c5f46f2e7006a6fa7da425","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.6.tgz","fileCount":13,"integrity":"sha512-YAYK28FneRe9Lu66sHp3F4cd0KWkPgSsfJpFQzNSZwWQD0f99sLI5uY1Hx65z/4Ir/nuyPagJ3kPp1CmqHffLw==","signatures":[{"sig":"MEYCIQC6vGRAsi6hmlMKa5cZWR3xg7/SCFk0wCZ2dofHpOO8mgIhAN8q2DsnvxNx6Iq+E7qRbpxYtc3uvr0ZZuWFsFKAKyQ+","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231164},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9ed75021c9aee8d03a5bebab49069fe4d7617b63","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.6_1755634136830_0.9390826314589664","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.7":{"name":"@crawlee/linkedom","version":"3.14.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"508b526677bdd7579d65919d2a6964d25aa3ef5e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.7.tgz","fileCount":13,"integrity":"sha512-rdkyX9Gq02uw1QbDK5e6XgL4iPais/yRQXHS3Matm6RrHT38FCYl/fh+C7Z0IeVyEInMEMHvdp93GsCa3c1pDw==","signatures":[{"sig":"MEYCIQC9vv8EIOUpBG0h3lBM8rn2cHUNeR4ht6MPT8or/s9udAIhAKWqFdhLfdVL5O1vFNWA0doUnHSAuUPDI/Qf9DLFlyxw","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c8933c93e07e82a41782c3b126e246deec30dfee","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.7_1755684479229_0.26372763174553104","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.8":{"name":"@crawlee/linkedom","version":"3.14.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4879b9b8e419395119e0da63af3526c7fda54d07","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.8.tgz","fileCount":13,"integrity":"sha512-OVHqZbxeJLZimOKxtIARadp6ABWCTKgVJR9BfLyDRsmx7epW3fKTQrni4Q1NyBqi7L/Z0RLD7aS9QWJm2WtGVQ==","signatures":[{"sig":"MEUCIHo/aw9hczGuFsbfXT5zhK7CI934cHYLPnpFfh4rJJD7AiEAjhFoDF0G9rwQXhv2SJtd5+VRVskojd31/wYb3Toie+g=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e8a28783d2d1c7abe49f3f970b984180d3e4f279","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.8_1755687162344_0.9194798813605563","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.9":{"name":"@crawlee/linkedom","version":"3.14.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fbd9e6d5547d5c891ae8b848e0af7c95c1fe149e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.9.tgz","fileCount":13,"integrity":"sha512-py/Taj4WP7dMxY+qHm5KOtRO5yZYCmSPhoOghHIjaz53xjq77IBnoHi9clerZDFKmTWvoRNcSfumIzX/jqCX3Q==","signatures":[{"sig":"MEQCIDNc3tXz+m69LeTZIzWDqukqtC83aNzH2dWNmgPkkJokAiAfJiqmTpPEbL1aLqv+QXuaFGSs9lOrDwaBw/LRQpTERw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231160},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"38b81e0bf94dcbf5f8ce55bf827ce98fa3364593","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v20.19.4+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"20.19.4","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.9_1755762393884_0.07952629676225298","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.10":{"name":"@crawlee/linkedom","version":"3.14.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"83b695e65aff893bed3ee17b812927b254ffecbf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.10.tgz","fileCount":13,"integrity":"sha512-1edDXddATkM9DvnO6HeiuULJdI7xye/q7VYPdPL5GEfMXU83YO5q9KVzy8fymhltkGOxvekw2jlVoNXXW15BAw==","signatures":[{"sig":"MEUCIQCYqbYz+cI/WYYrZEaa18/CGapBuIid5VM+IT2qmd/35gIgSCiolTEIS85akTZFdtg1FUM9oY8NL1JuU95VITemUl8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"03f2b3b000ab3cef6efa9fbb7453bd7b2e5eef01","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.10_1755782090405_0.8578866767941715","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.11":{"name":"@crawlee/linkedom","version":"3.14.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fa18833c09948ed16b0786dc643b4b51b12bcc40","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.11.tgz","fileCount":13,"integrity":"sha512-163kMvI7I2S2DX/zNKOtKb8wtp0dchHSsFCzaAtRx3OoLRA2O/jJ0seabZomMiV+x8oVxapOl3bPfAVsNTzniw==","signatures":[{"sig":"MEUCIAp1EMU2P9sAZp6rnLA38aTOmp3PC4IAJDhNYY6CJWqaAiEA0ULBhA/Iu2Vtj3s7dS8hAQIEiup28sDeHmdScARO79g=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9fed9683960f0f9113f84ee656a7ecd28ba4df62","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.11_1755880723816_0.3762884027079927","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.12":{"name":"@crawlee/linkedom","version":"3.14.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1d4ade8314e5d4587cb2aa879daa6b76319585a5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.12.tgz","fileCount":13,"integrity":"sha512-rhWXBG4e6YKulMak1Apk2G6agwoxKqVD0x97rJZjAbDB614YiTt/4ihXlf7bvrRlmuZQVB9MWeH1wxMSLJZGVA==","signatures":[{"sig":"MEQCIE6y8gd9bb/H4I+PsXOVBea/ihmhnEfhn0/x3ost0FS4AiA8HfYzmFhXd2t37seCCBFZ6+6xTCeuV/g94pREzjk1Ag==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f32fff34cba4293a40d84e4b89db586da6356dfe","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.12_1756184321169_0.7182547974089586","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.13":{"name":"@crawlee/linkedom","version":"3.14.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fcbb71ce960d68a7d5d1c3935428cef75527e82f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.13.tgz","fileCount":13,"integrity":"sha512-QFXbwoqFfPaUI9tY4oZ3thg6dIjmvA7x2cczJiXeoGotBdG4UGHSiGtpSrpO/7rqCCmawuKp+KifQA62AzaR2g==","signatures":[{"sig":"MEYCIQCPFxPtYV/sCxdruwXPRXBhB3z407MhCWU1I4j+oLuRjwIhAJkZdm5lhYGegeagWIfgQ4xVtizOnvv4IN3cjY0uQG/m","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231163},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"33dea0b9d606898e581081946011e0af787aba8f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.18.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.18.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.13_1756203830298_0.9938770526555727","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.14":{"name":"@crawlee/linkedom","version":"3.14.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9184391315fac6118571d99e463f16a69f3f907c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.14.tgz","fileCount":13,"integrity":"sha512-priJXQpcEIuh56PFrGu4LpNdh1pDV6Tx7noK51VoZRdfDKXsG5Z7ywQU9tU3dilBWaD7fibrgEf1pPwVVYesFQ==","signatures":[{"sig":"MEQCIHxRMD2JtNATHcl+yzE8EKW7RMcm5ikLkwx5zE8s2RxhAiBfuzU3Zj+PCo4kQEc/VeNqgQB8g0YkmZ9l3hBdu8x0VA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231656},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"0ec311da7cbe7637bcf42311532a386688da0a68","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.14_1756961339949_0.108385411738527","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.15":{"name":"@crawlee/linkedom","version":"3.14.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ed274057d5d1e5d6f2b928402eb27c438eb55fb4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.15.tgz","fileCount":13,"integrity":"sha512-oh2SqjhnxvDAPNYYGmpQC3sbgtTkM4S9ii94UlAQs7hW0Wdp73LySd+Ji19H2lHM2CUZbt0dI7Q8/qrFNaLHOg==","signatures":[{"sig":"MEQCIHjuo5BcFyZ/yrYtadqQ6OPtrqmuQgXuEar1iSP+3vwzAiBkmhepCUR1FqhROR6K0XZ6OvrRCRTceuE4mn5fcZwzcA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231656},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dc4db20fedeca362abb69241b6ca40553c0ed176","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.15_1757411270099_0.4398356471447309","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.16":{"name":"@crawlee/linkedom","version":"3.14.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e9b6e056bc163bd147a43d937375a00ed8153dec","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.16.tgz","fileCount":13,"integrity":"sha512-+9GtzN0EhfWyJEBzaTYB6tRVX2Y4h0pR2PwZDG0AYXEUgxzY07VZICV1voGoY/Q8g5T6Fm2qQF+9C4iy7An+FA==","signatures":[{"sig":"MEQCIGJEEfjArtHc8EerxCI+nsGBi2e2Uvf3maGAFCOuVxMgAiBW/gMrSbugMznq+xKXbhwoV5IB8jXcxm02zzHB4ueYDA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231656},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"94c9ac00f09f640cd1d5a22a57aeee9388c33c2e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.16_1757508216745_0.010817896327674603","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.17":{"name":"@crawlee/linkedom","version":"3.14.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc354e628fa01abbdfa5c7388ba729202ed63c61","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.17.tgz","fileCount":13,"integrity":"sha512-ow8/MHmB57PypInjXxOoAEEIC1BQMoydScRmAp5vFAwPdvHeHddL7wovYs8RNBJ0NqCr3YpEsTrhCcSJyUJn+w==","signatures":[{"sig":"MEUCIQDO6Z7Za6oxzNB3VyqTRIBZsNjmj+GQuQgM2DToHn3L/wIgYxOS8vIUoG8OrNBa7Uf9BXsKqF58oQ2j7kjzA1Gvlc4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231656},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b63f6edd0147298b280f99092d29ecacb3fbfe48","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.17_1757814793586_0.8319240215962653","host":"s3://npm-registry-packages-npm-production"}},"3.14.2-beta.18":{"name":"@crawlee/linkedom","version":"3.14.2-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.14.2-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"5b6e9677398d7ef9e455471f4dfc37501093718a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.14.2-beta.18.tgz","fileCount":13,"integrity":"sha512-4OGnzD+fLJbZXAAsIGpoDU7j/bEhPvqtpkMIyzL1Jmt72JRspg0Coviir3Tt/dbB9ufR4fhILFj4ZBi1pQAzww==","signatures":[{"sig":"MEUCIQDpyHm570oUW3UCjZbys+FQiQWkJLYk9q60cAxwAjImgQIgZtmQm3dObi4+fjD4Rj7pQhLwN9Ur1bO/NLWFuuOi0wQ=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232122},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96c5b137ccb466a8564c634e3ac0bb2888a46273","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.14.2-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.14.2-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.14.2-beta.18_1757844761339_0.6052812568689945","host":"s3://npm-registry-packages-npm-production"}},"3.15.0":{"name":"@crawlee/linkedom","version":"3.15.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9d577f82159372a10fb0441acedc14c0f7b6857f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.0.tgz","fileCount":13,"integrity":"sha512-tI9xIsRYQWRPu90qrOlwkiKMDWpD80mXru9A3D53ux0QqrN/ia51sPE10YAHgChPzyZsAncX7As7+V/gDGOb8g==","signatures":[{"sig":"MEUCIBrPwKq9v51+MXtEpxCp56WZM4A3+05pA2cYhJJ6tEBvAiEAvmbTPZwaDE0Cw7vuTxtL2SF/GdshwYXXFE4gVtZHpWM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232098},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3f9be81397a419efbe56b75bf9fd3042e3af19fc","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.0_1758113319478_0.021570809360586418","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.0":{"name":"@crawlee/linkedom","version":"3.15.1-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"81628bfaa813b9c933ffc7afdce9be51a68e8e4e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.0.tgz","fileCount":13,"integrity":"sha512-k8tjbIKQpceyLV+mnRllyZJFbB0KOrvhMTFSpJgdYCI9hekpdSAH2Zxrm+PDiSZUBSGxCxslSfK5IUGjArqliA==","signatures":[{"sig":"MEUCIG9yOjCPQQAXnQsTZL/hHzg3GebcD3qtuwPJ1rx5fFHiAiEAre79xh1aF7+rNpCTi14lI5x5Phnrv0DbfD9CO/rcd5I=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232121},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cff131ba0eba0905072de3075c0d6b7cc610bb42","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.15.1-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.15.1-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.0_1758113907014_0.7022604159694883","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.1":{"name":"@crawlee/linkedom","version":"3.15.1-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc63ec135a77845c45ca7cf2948c744a4e2d2acf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.1.tgz","fileCount":13,"integrity":"sha512-VQRyL6g0CYN9GK3XJPO6amGxDqbFXmL92RkyHQFJXX8vRjPliJcH0d5sYHQYfjKcM5QNHuWIO7T4GIjXs6ULjA==","signatures":[{"sig":"MEYCIQD8SDP1Z/bVcDsM0V6F+GuhDQ8rn5ob68XJNkEX5lZPsgIhAIz20Y+NLGK2KxegN4eX6UH3Jb9XVGCmhliebVXgCt7R","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232119},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"75a35701e82f07ca0ec0b7607c9681f2be7c2e1c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.4/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.1_1758638777071_0.9509357957048694","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.2":{"name":"@crawlee/linkedom","version":"3.15.1-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b05d98cd3c3809f984899ec3eb3bfe0c705c5d88","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.2.tgz","fileCount":13,"integrity":"sha512-8Cyl9G43mmp9NuxLiBgulyws4nzikIwTWkqy2In+uPbfL9u5LUTpuNjhKWEL1nAta5Lnck1vZpNiTb214zknfg==","signatures":[{"sig":"MEUCIQDbCcB3PBsbWMKgykQBbwOzFxbRgr+f9Abk5mezZGWeaAIgUF4z0IRdhXkxQLfhqCTleT+epS2mDrHUzPSsG81eLPM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231967},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"244b147da4ddf02ba29b61d7c3967976f2682cfd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.2_1758798043087_0.10497091924293178","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.3":{"name":"@crawlee/linkedom","version":"3.15.1-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a7307596be93fe253d1280389359aaf2de229e28","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.3.tgz","fileCount":13,"integrity":"sha512-U7xiCAmA9J3rn1JIuyrb8tMcQlVgZnyGRvokAZiSYhT/tprHEnUoz+JYN8qAj/6yvxwDXCQJC7dvYF4EuPywIA==","signatures":[{"sig":"MEUCIQC6350LYqQhWNELy9yHPdfrBHrq8wXEi3jgSztBFh4ErAIgfqYMgYddGMphi1o7T9qI2/4f6nDCoSqdp4Jwl5ZdIU0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231967},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"deea0536daaf6aee6f5fcdd6f9d4aeb7b16bc911","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.3_1758802111899_0.3172163691358185","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.4":{"name":"@crawlee/linkedom","version":"3.15.1-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4b69974d3df458fe1220d2facad761b88de6536d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.4.tgz","fileCount":13,"integrity":"sha512-bGkyugWT2B1JYbLSpftQ2HwSQEfMMs7CQREGMg7WTN9QNdK402GMNKLUOKTnLJu+Z6LYhU3TG2TBgw3aH2grMQ==","signatures":[{"sig":"MEQCIHv8e/HEuQSgvmmRLQvaolcXL9KRZCFMmypNWMVFd19tAiAT86lfTpcrQtOqlww/WWnZbh29p8CMR6hjIl+XzmC/Fw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231967},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d49a090230a914043d1f5754e01c7f2e3cfc206a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.4_1758868851653_0.400479182778152","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.5":{"name":"@crawlee/linkedom","version":"3.15.1-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ae5e78085d328e4e814c467512346c3fe9a77702","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.5.tgz","fileCount":13,"integrity":"sha512-EgeRI9rBrcYK7GHSCmsXe+Bq1ZrDg2B4ULQ5R8tnEqcfSHOctBrO+pgA7VpM6S/HpX6Kc6WyzV9AyoiGjBYfgw==","signatures":[{"sig":"MEYCIQCz3oa5BWv1qceNUYyPjcVI/7ja2iNgD8KpRo3b9yhE0QIhAKdEJD926as3JH+xjeURCVUfF70czgvAq+Fg5er+UIK0","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231967},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7246e99640ef585a4abc8bd560bf1fe16e600cdb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.5_1758873096221_0.9330729533824433","host":"s3://npm-registry-packages-npm-production"}},"3.15.1-beta.6":{"name":"@crawlee/linkedom","version":"3.15.1-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8652cf23a21b7a7c82784f3defa860dc62ec990b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1-beta.6.tgz","fileCount":13,"integrity":"sha512-87Itqd34cMJz4vgepUu0uVcUYk4j/I0gyN8nw513P5FbYWBE2C3gv/YkCqFRTBao6xM9lf2tF03nuEarIkw9pg==","signatures":[{"sig":"MEQCIHmwnBkHnetIsUhVoqzmij09WXNILitn3yBuok8EmwKaAiBBTvRNYEEY+s9L3MP3q16/h1SCKGVYHZLhjWBqBlZfYg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231981},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"537226bd4d9b4e38719f33a18e3c768c966f3c75","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1-beta.6_1758876706979_0.6471045247386735","host":"s3://npm-registry-packages-npm-production"}},"3.15.1":{"name":"@crawlee/linkedom","version":"3.15.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3af70798df8465a882b800a84cbe1c2f53051bc6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.1.tgz","fileCount":13,"integrity":"sha512-xGnRCG+RX6OQ3PSy8YpqaMk2aGy2IvEmli/NW0710ENXzphadVTuvf8Lv7Sioksu0bA0zljIFNoWvR2lrVqN4Q==","signatures":[{"sig":"MEUCIHezZUvw/5J2jR5CMpybUEGSxm9OXPRx9cqvfH2jtXk7AiEArxwj0CBEWpNCsLjEZ5SNcBu+iarVLJkU7+Ol5Zi3FgE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231960},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"fae891db4507829734fb2802d1e94f7278f42ab2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.1_1758892785611_0.049703321124423994","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.0":{"name":"@crawlee/linkedom","version":"3.15.2-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"675d092c4ad25b83c3a9709282436eb0dda7fa98","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.0.tgz","fileCount":13,"integrity":"sha512-ZnZbhHVmtQVvFiBitf/KD9S1zBqq98HVOQicDmDdxe9nO9gpcj0CBlMTqYXoVN2bcxuSRXFxdt1mttK9IlVFqA==","signatures":[{"sig":"MEYCIQCTAqIZ2jnDVPu78vIK1JPzFXn55fn384FySvL7DGjvkQIhAIpVoPQchPq527qn9BcoiEzEUSyiXlQA4klCCE9Ev9rG","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e43bd997f48888c4c1cc428e4398a6b739e6ae29","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.15.2-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.15.2-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.0_1758893291280_0.2149705548172347","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.1":{"name":"@crawlee/linkedom","version":"3.15.2-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc5a2c3e4ab071e745cea6582d269316b538702c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.1.tgz","fileCount":13,"integrity":"sha512-CMWlfxZ5nNvM1XiOcsiPiZ/ddauhuVBIyVArLwVeqRbzYIrq1/OlkjjOaB9A1xLouZj7lkgDIlYthLDA61Fb1A==","signatures":[{"sig":"MEQCIBwGUUTtcv0V5OgRp2q6maM+T/us7YqACG56BtCcydz3AiAh1sZfhSdobuTmGIGUA1ukiqmLGTNxVj7si8fgf7374Q==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231981},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1e2c02b9613155f0e7a0e5bf775b85c37d212198","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.1_1759133281270_0.2736586382964601","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.2":{"name":"@crawlee/linkedom","version":"3.15.2-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8b6eb9423baf2d99617f0cbb51138b31991608bc","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.2.tgz","fileCount":13,"integrity":"sha512-fXuGip3kJGZIuqkBV9BbHraOIieMvc5tNAlYokpO2zI5KBCl34jGq4J4agsU8X4C6DGCgGiN06ygtlfhea38ng==","signatures":[{"sig":"MEUCIQCXE8CBIbueKSnFiTRIry6Y/gRwPBQKI7nlf+I+UGDfOgIgKEJSb9a52N8iLN4iSuigE1qjZm983IlbkJTrQsfGvEs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b1e56fd1679ace465783a460227599fc3a8eaf1e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.2_1759203619413_0.7505640007934138","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.3":{"name":"@crawlee/linkedom","version":"3.15.2-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b12c79b4b71e17cd1b4d401a72601b78fbb864b2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.3.tgz","fileCount":13,"integrity":"sha512-VyG7KU6QApZRmpZHTYsXv+gJEGHsAC3vwxfJLItmCJsmvbZLzJ7lWesRt6Jn0Ra1Thq5FBezHNaLb9odmvNVgw==","signatures":[{"sig":"MEQCIHDw7Ek7NuyLhAYuaV9MlXAChGNiqZLSn7AtiY3xKX/cAiBuKwMzdUqwb4ENItKcyKKefVfAH07iYCoHKoLrUkAO2g==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9e861b0ebcefde7219bf1a5580c1cecb9d11d795","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.3_1759227283257_0.8458053103752969","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.4":{"name":"@crawlee/linkedom","version":"3.15.2-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"881138913224323cca17e9b0fb6314a882313c63","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.4.tgz","fileCount":13,"integrity":"sha512-/cG9h55QCQweOE/bvp+ZAMRoM+pn4mShmlOQyAz8C31M6HbrsgmWVDhXGDxjZuDzHuC90anBtmwPjzl0uzWqEA==","signatures":[{"sig":"MEUCIQDA2/6zSvwURo3Rqg90qt7lJpC8iWRpqANbzEnh2FdwqAIgVQhoO5KIWmvFEVaK+EZmD8fqjmLRFvYH/mmHiK5k7Pc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aa9af90b95008f722f2cd5b46c8b281ed818d491","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.4_1759290880851_0.8848562115993932","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.5":{"name":"@crawlee/linkedom","version":"3.15.2-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"42bee9438de7d37a0f790a3f9a823c0c31e3535e","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.5.tgz","fileCount":13,"integrity":"sha512-klv7r+xE5Jjnr/E+rhq2ZzSFbF3kGLv7HYNtCws0iNfYlZMM3tP9R9cF/rYwoPL9uG+lqzFUJr/3AkGbEIoqgg==","signatures":[{"sig":"MEUCIEg4dskn8mSn2bEohmlIQ7/GOkz+A0cWkejIp/UQvqWLAiEAg/P5yqSsIA2cxvlENGn1ibzxjRLScXNVZtN0Xva9szg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e1924c587a4f1ddee8629138d9206bc5903c4678","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.19.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.19.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.5_1759387499272_0.033446835586001145","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.6":{"name":"@crawlee/linkedom","version":"3.15.2-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d81cd769a20e496c6eaa86ccb101038e0114d674","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.6.tgz","fileCount":13,"integrity":"sha512-JvQ9GQ3LvqFs9n/+QfU3L4CHCGA3O8tEMJ4c2ulTjtRoNaD0PICv7d4SPJEkumZq+OoFQHzOaaeeLgE/Ynx/Vw==","signatures":[{"sig":"MEUCIQDLaWGw1F152qLgTi9H8vyGW1fTYCYRtPN6KExCr6g8/AIgbGk9WaEk42XxRht5wgNu1PbpA0OQUENJmOkJiplyxmo=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8bb4045a9d68c268d1078441d825420bc575b745","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.6_1759760642945_0.24197655163474963","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.7":{"name":"@crawlee/linkedom","version":"3.15.2-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ef2928f817088e4b46ba7978460cef51b3738067","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.7.tgz","fileCount":13,"integrity":"sha512-FN0frmOibWDtxOHiRjgofbmeLqdqFYz478AlcgQYV1r4ZHi/0nRSTavfaE8HHISI2SBG3L0+XKwvrTC0lhqWRw==","signatures":[{"sig":"MEUCIGNEtD1f2S5yqnnE9UNrKXBCGT49s48+oWhNPuqhMcw4AiEA8i/7mz9qYomqibADU489b0jUKSraRMEf3MhyT0wjfiU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c8332113fa5a7dc28511307a24efe479a02866c0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.7_1759905904291_0.3122531213017601","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.8":{"name":"@crawlee/linkedom","version":"3.15.2-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"e3525716cfcfd7401a9e1ab16deb9d1a97a3f5a8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.8.tgz","fileCount":13,"integrity":"sha512-p8WybYW66S7SdCTb3XDhsrJc2etYlrWiPgyXdI/dFhAtjvQ4HXmTy+cRmopFwIVzCKWL6QKGs9lHh/+6lPPI4w==","signatures":[{"sig":"MEUCIQDlaed412l27Apm80HPqEB/XYnEAcQ0NxqLnqTZwtjxjgIgAua9HNm5P6m9rRvDrO5Bki11uUa2BK3HQsepLuHsvKY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"dc5eba92da55a813ecf9190780c44b1eaa11a4a6","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.8_1759923611895_0.6066437898642205","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.9":{"name":"@crawlee/linkedom","version":"3.15.2-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"fbd695f29b23a45239283c226ad8022c5c663e70","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.9.tgz","fileCount":13,"integrity":"sha512-Kyk1H/8Md0pvD6t7d8LcHSxJTa26DfkqerNWIVgq9xbOIbwg7emFrHZ/EC0qaENmZyvQ7gmDiYq06DWvegwRUg==","signatures":[{"sig":"MEUCIQCiFUBrMR7TxApL9XFohLJeYnC7LbvBB7KVsIl3X4VGdQIgInAh0JimUeDZzbVNiBYiASlwc5TcMhrfC9Yg+acOfvE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231980},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9d76308bf0205cde334d326611dc824d5e8c72b2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.9_1759927354092_0.6587893228986876","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.10":{"name":"@crawlee/linkedom","version":"3.15.2-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"55220dcfa682e0d28ab0f0c523b9a4e2aa1fb443","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.10.tgz","fileCount":13,"integrity":"sha512-W756KLqmbXqH9GXFqQS6NqRynd1a+IRLzdHc5ImjtPQEM0J0IsYzMS6JEQquX6sIDQinr1qCD+m4lLkuTTqEvg==","signatures":[{"sig":"MEUCIQCrm8d9JCmJjA/CSf6lhGgr7cYKvXtU9Fpt8/g6PxgjIQIga2cyPdXlIwPcb5aTI2Y6j4TDI9aIwZjegzrtSnWHWCE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"64ac4d06a0dae949f6fa46d05bd52348f526a084","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.10_1760083857647_0.34654160833902514","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.11":{"name":"@crawlee/linkedom","version":"3.15.2-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b6cb6f0bc85cf2351b9eb9fb4fef078bbabe11e8","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.11.tgz","fileCount":13,"integrity":"sha512-IKzINSEZ3Os2mJyzGClRrm37toJsaJFIS56O1rVnWmro2y/xFKt5BGAhGPuObi0NUJgP5w3lbYZlX8GAnPwzlQ==","signatures":[{"sig":"MEYCIQDiQ9ijfaooJjBC0qG3vDD5Md8e7Z8XWmX/+3pmn3vmGwIhAK+UrCJptouLjUuMfueGR2pl7dshuKH3BFFApFOrKFXB","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"03246a0456fe0e95663a54d32f2687073b1f15c5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.11_1760336175795_0.46579115060882725","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.12":{"name":"@crawlee/linkedom","version":"3.15.2-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b1144364fbc464f98333147ac3d4acc1fac10b8b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.12.tgz","fileCount":13,"integrity":"sha512-7Cd1n/kdh+50ssLjNimcOeTvBdR9qtj/Pj6r/zF8pQ7GqLnnCVk0G0r2aBFDngFXSHtL2th93s/wPAxhtpeNoA==","signatures":[{"sig":"MEQCIHn7ourrEaUGmpg/iWXScHfAVlBjvRZtvsp61lm9wg3kAiBsOcPHYVy3YVT6MCjB0CYwN8D1g/rvp6lfzxdjgALIAQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e45622bc1636e7be6edb7127f98c5c09271926ab","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.12_1760473362072_0.49635267994419907","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.13":{"name":"@crawlee/linkedom","version":"3.15.2-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"63daebe7a490a385639a4089a94ebac84002366c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.13.tgz","fileCount":13,"integrity":"sha512-KnfBwyJYKXAWO1tA70Nui9+AkI+PlQ06U9DADmReO8dV7/3nG1iQO5azHcSM4EAVNXKAxBthavW4Q+sXmPYeuA==","signatures":[{"sig":"MEYCIQCTKiGkPIb1uvtXg29qAyGh75PP2K/k+I7LHf2CeKR4rAIhAK2HFFKFbWLohkkjzfVPPmD6DsVSAw03XRm14qpcTEZ6","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"1b14d881dda00855f8b6438e30d1cfc499cbbb99","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.13_1760513145600_0.5187888047051836","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.14":{"name":"@crawlee/linkedom","version":"3.15.2-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"318fd5a0e2ab775c39ef8bab596c719ba9f53d64","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.14.tgz","fileCount":13,"integrity":"sha512-FlGCqLBrGrlSXSwiEZiXR1Dtg2itOkmY2+TCIkQ+itgkmjH0doVCFFlvoZqlklivO9/ThyhWDEseq6ceCZ5qIw==","signatures":[{"sig":"MEYCIQDKUoGm8XHhszJu/8J7VGy7Ra9Z85ta8/ayoY29YhWKDgIhAOpguPcgrlzD4Nkbz6GLQBbJofL67Yw56wi7F4SlpO8L","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aaac0eee7e9b60dd70c19c3e15dadb2764854e5f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.14_1760624757897_0.6133674625955536","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.15":{"name":"@crawlee/linkedom","version":"3.15.2-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ba11185719429d9e4920b0a08da3101d81fcdfd0","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.15.tgz","fileCount":13,"integrity":"sha512-c5MOgawiUwQXH4reuSGTKIVBBYDBUZVxwfhsBOOmTYgvwnx+zIlvFL6JpoXOGNlU9HdCN3Tkd22zsh713ELh0w==","signatures":[{"sig":"MEUCIApN3i1wb+FLhsHWlMkhxfU87aK0/1L4I5WNG+RWF4o+AiEA6bOempdmj9GkHq5xnfrCtEtat55gmSrI1j1RGPrh/7Y=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4b257ec8646d4897cf15f3ef8e2e2b4a493f9cfd","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.15_1760657163640_0.6666370407008901","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.16":{"name":"@crawlee/linkedom","version":"3.15.2-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"028c12f61f0d285dad9756d0e2774b51df1d02d5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.16.tgz","fileCount":13,"integrity":"sha512-9yjOiZeXCzmOOXUd/w7mUdbkYvZVKmU3SoiGrEe+QdWqzJufHCJHwaA+3Zw3n1sZ9+U2kfoY0c/TISgrNLvSKg==","signatures":[{"sig":"MEUCIDDCFYMxNWa343c29hPlkudZAPlsjnsR+5utWoNL3qpLAiEAsT3du29H/j9ZdR+NB4ranEFPVr1vptwNX/VISPiuqm8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e2dcad10aafde124de57df353851feb057468ab2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.16_1760944122146_0.6848055210423443","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.17":{"name":"@crawlee/linkedom","version":"3.15.2-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d0675d779aa3c6583bfe02b2d87aed1a4e64e124","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.17.tgz","fileCount":13,"integrity":"sha512-tjq/hLifTrCUQbTosViBaV1i98PzNsrulyml5Mz4AP4oGyZvN2MrcB1aWU1d3xHbMThUaaqLDk7aNkQf5dswAg==","signatures":[{"sig":"MEYCIQCdaJ7FxMxDjKHQHrIqFOYR+0Bh8I6htTAdP9EgzadKRwIhAMSpK0bnadMFi2ntivusuuRnkP9MtfbebLj8FZThsGo/","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231983},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"94089726b8317fd28ef6fefbcbaadf63c484be55","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.17_1761028718184_0.9788487575076239","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.18":{"name":"@crawlee/linkedom","version":"3.15.2-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a907ed6719f7c967953f6a876502882ca19f97fd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.18.tgz","fileCount":13,"integrity":"sha512-YXvltt4bFsmwFmi0E2vGxRCwbZw51S32hrmURHSSBhiSO0GuW+EMd3nIF2l9HQFcPQm55yJKl7+7iYxa7mvw0w==","signatures":[{"sig":"MEUCIQDTekSoBJrxbkVhiaVBzLmYqu/RGt83ST3YjFoRzj8KaQIgfc63XHfeBp6xGnq/HPIZmoHUmK60sqonalG1UmzW0O0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231987},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a2c12164a23716ded9380310940a48dffd1649fb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.18_1761039551506_0.09144001155099102","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.19":{"name":"@crawlee/linkedom","version":"3.15.2-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"68b628d282963e9203ffbe6477eacab2017c2e04","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.19.tgz","fileCount":13,"integrity":"sha512-+/snMsLvzilexwXwIXGed/GTvL+wj9VO9SjN/R0DVH5DnbrRg7zUIAR6UJTVcH7b6SoZkXdvKOX/Fk3qcCw2RA==","signatures":[{"sig":"MEQCIGAXMF2NygaeoqrUXChY0zoBYUyNbrztTWk/rBBjn1GAAiA0kgesLpjE6j1fWjuxsSZfF7KNOmIBgSoirdLhQzw6HA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231987},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"aac45d2552f28b8d8e20bd47003eb3e7b206d5c8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.19_1761098961240_0.2708650078973205","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.20":{"name":"@crawlee/linkedom","version":"3.15.2-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f68c6869370954b6bcb01624599daea3fe14b0b1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.20.tgz","fileCount":13,"integrity":"sha512-vOJOfWad+SB3t0P+pTK6DwdPWsCjHhsFuVeDlZlrVEJtmeSsNTo9ao+J6OSik9eafUuwgh3Z/6tjh6lTYcCr+w==","signatures":[{"sig":"MEUCIAwtusn9Fp58k2RNdhZVDf5hmBuaowThcBfx2Hi2d9hBAiEA8KilS395NtnCwqxxxg8F9go8Naxv/U+fayaqAKiVP5g=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231987},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f6615958e4058fb65f8231b39a7cd096c6fbcd54","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.20_1761177309707_0.2907675014510731","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.21":{"name":"@crawlee/linkedom","version":"3.15.2-beta.21","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.21","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"083b863287535284f776c684107cdfa474185c34","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.21.tgz","fileCount":13,"integrity":"sha512-jOe5fpC45YFYlw/DEL01bsSPAcuQsyGfBLyx9xUlUKfeMZh2UoS1t/lgcnoYyPjlU3/P9BtshlRFBcphi4n/7A==","signatures":[{"sig":"MEUCIAkdpjjthDUZRioZD3d9v059tS2WeI5Jc1etof6+6atYAiEAjnFU3zETKXYiWZRtcyPv8pvYs0n8Eb8H+6DXZlXdmwE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231987},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4826998e9e31a0cdf86bb1b58c5b12a01abaf4ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.21","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.21","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.21_1761212953029_0.9312173770896304","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.22":{"name":"@crawlee/linkedom","version":"3.15.2-beta.22","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.22","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"12afc651405f3d6499bc36856832f5c471ec3dac","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.22.tgz","fileCount":13,"integrity":"sha512-reGFBljb82mjxeGv5dspUifybTdxoKg2kYW+WAQiMXiedcN2VIGzvGAxPrgq3tjWad1pmiBG7ZHX3bdG/IauXQ==","signatures":[{"sig":"MEYCIQC+cvhTOD08Knia3BS4y5V3IE4fK4t+cV/h+WuvOYrryAIhAPBRyVX2GWxL1TNSs9pKDQdYZcCJQEiGyerYJ2JamngL","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232008},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"40de97a774f6967ab1173171d51acc9a4b66b1f4","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.22","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.22","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.22_1761216456355_0.17013063512010906","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.23":{"name":"@crawlee/linkedom","version":"3.15.2-beta.23","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.23","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"2ff6753914347f837fc1e32ecd3afd8cc9fdf959","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.23.tgz","fileCount":13,"integrity":"sha512-UPp59rPvlZFDT6tQvHUHraUvqcK3U6a2tP9wZElji/PEyOnv0O82eK0S0095z2XxZKH0OznlvdSdnGl6+bxLkw==","signatures":[{"sig":"MEQCIBWouH+yqT8NAhbwm1nDmVl42bAJxYBF4nesj0ASiID4AiBpNawbnw+bjiWoeWIsvXXkYdYzp1lXTLukLbHgXztcqQ==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232008},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7cb32e9c2c5af53bbebfe9f17ddcd60132ea0bf3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.23","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.23","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.23_1761217176625_0.7154090483473876","host":"s3://npm-registry-packages-npm-production"}},"3.15.2-beta.24":{"name":"@crawlee/linkedom","version":"3.15.2-beta.24","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2-beta.24","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"40f790b7b713bfddb0f930b8d04b4abcae11abf4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2-beta.24.tgz","fileCount":13,"integrity":"sha512-G3uA0fyRmVhbYl3VkOvjzzdy5LcULD+XfQnC5w+WPyAlteCIzHNO7GxTs1sXHjzaxaESautUNGHcmmR0ndokjw==","signatures":[{"sig":"MEUCIFqeR/eWIjfoHMkVtHdKEBspR3nsrjPAKgYTqj4h1DTTAiEArkbAllWJRUIA6S62KLVNayRsM5j0DykRTx5VyB0mu9Q=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232008},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2da80542697b24f8ad8aad1f253dd71f31c0d91c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2-beta.24","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2-beta.24","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2-beta.24_1761224094151_0.06129977066035508","host":"s3://npm-registry-packages-npm-production"}},"3.15.2":{"name":"@crawlee/linkedom","version":"3.15.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"dc73997662eedfca8d58d4e4e6a3b9eeee108d8b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.2.tgz","fileCount":13,"integrity":"sha512-skYcxuBckeB8RfQRsco5CMnKMqTIqLWtTCQLNSTHweQE5z5WR61mbOGcS5Bg1nd/OtMq6tUtJx1RLB+X9rW6SQ==","signatures":[{"sig":"MEQCIBlHepF7zNhfWa2Vd9yECFST1dz3zwkrqupM+DvrB+IpAiBiuUnjsV1KeTpnltcsmiKIFNNO/J5xWnEb2m8cbZH8Qg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":231984},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c7d788f757a8e1a6d5bf9b2c71a13f63168782d8","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.21.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.21.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.2_1761224732626_0.7423188780294272","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.0":{"name":"@crawlee/linkedom","version":"3.15.3-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4d3a780ec3191a0fd1f761d2b5c42f65090c9695","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.0.tgz","fileCount":13,"integrity":"sha512-0bqD+r97I+TwH2H9DpMx1z6BGFGEq0gEOE+Iq/Zz5m3G/Xq7UrhkUXkTqRiwO8ciSVTjkZcE4qEHtDmPgViDqA==","signatures":[{"sig":"MEUCIQCgfiytPMm2TUPGhh8Xu5bC8qNdSUQeb3KJOkEBdynV8gIgF7BwYfdRkol2aoE3nvHOg3FCc2pWa6/rgZXEO+OMxuk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232007},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e7762f941a500e985fc91f61aba6353fc62ceffa","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.20.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.20.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"^3.15.3-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"^3.15.3-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.0_1761225350824_0.966649030273079","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.1":{"name":"@crawlee/linkedom","version":"3.15.3-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9a790911f36a97f583155b9f5ec113371c487800","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.1.tgz","fileCount":13,"integrity":"sha512-XGcd2RAuJTuA+8MOlPfz9TSps1QGlx4X1mOYh6ixJVxsYf/IApwloUN6yBe/sovyAoPs9WMFehDKgz0EsJ7ZLw==","signatures":[{"sig":"MEUCIE5G7SAQtNYmo6D1cz/loB06nHqj67uADJfN37Cf/p61AiEAj2mmo+7qu4IZqLxc8SHaaBGiJgIAhBartaOnahyM+Zg=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232005},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c0eba80a4ad38d12ad4a3dc7bdb5a70b11131094","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v22.21.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.21.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.1_1761299813941_0.440748989674145","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.2":{"name":"@crawlee/linkedom","version":"3.15.3-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3e8da689f0221f11c93eaf76bd123dc729d66d8a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.2.tgz","fileCount":13,"integrity":"sha512-Cb9ti29EEeV2mfsN4n9C9XbXNhp487EnHtJtIadaveq6AoKL2WuIuPp5gjvbXx+Uv8B5QdW909VVsq56TTAmmQ==","signatures":[{"sig":"MEYCIQD0RF/DtB9FUcThfqkaPKbPT5cU5fEjChiYDHPou0fPagIhAN4lXa5gkg70DIkGEWlp6yhai6uUvmYCFbcRv6jeaJqI","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235229},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32e449c00c44f86d708204d12d82fed38242b1de","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.2_1761638678268_0.4035733352866253","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.3":{"name":"@crawlee/linkedom","version":"3.15.3-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b3987a7bcc013bc4d4d2e552dbaaf68270e3a923","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.3.tgz","fileCount":13,"integrity":"sha512-mmQ2RDNoIwzRvg31mehtLppwJEQACHusZFcW1WSiwQX0gpOmAC5hUXrx99YUhiV3lJuATe1YXkA/lBGTJ+kDFQ==","signatures":[{"sig":"MEYCIQDt/2rNDm3QDBJpwWAG5Ha6QLsIKwGnv3ZFg4CjgUbxjgIhANyEY6hUkixYgVMrsL8eDnAYrnNQ42Qs2dmBrV3V2HSN","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235229},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"69d8b099dd87fda5ec37ab32d684fb5f8c8d31d3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.3_1761725911508_0.1858820050426535","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.4":{"name":"@crawlee/linkedom","version":"3.15.3-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"46ee1771f11490f6dafa8f9703bf3d76895fcb65","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.4.tgz","fileCount":13,"integrity":"sha512-4mzw6aBv3UrNS5I1avPk4mzrXBVQh8nrlZL4e3W01MK6Lw8xzMq0FWgkjVPUV+5HeAQIDy2InlbbfMQEqtWo+w==","signatures":[{"sig":"MEUCIA0NNx9BayuqhjuWJn6cHoy0NG8elPd92AEEwTVulrnFAiEAoIDvo0LNvpZCy+AbyeCx3rutSKy5ec89eMI69gyoHf8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"87daadcc596455d6992b6943389576c13c824423","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.4_1761753187756_0.3613654708475378","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.5":{"name":"@crawlee/linkedom","version":"3.15.3-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9885860e0aae0453d382fa58edda229a08ace157","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.5.tgz","fileCount":13,"integrity":"sha512-e9DA0eWvaGQGrcPt6TBiD6KricKATn99p/+j/mq6hEpwivfGaWpXDw9aUz3kDSiWkO0Dr4Fj1CZv5FIeQu+pbg==","signatures":[{"sig":"MEUCIHtTc4JW+3YjHNGdtif0LsSkD42hUmw687LxBxcmS+vjAiEAlqkAyhuc0qJEamPBIc7jFDiTh7fq3jl0zOCdJOqteWc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cef9a849d01965f2a05fee8846a4373330f8c3ce","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.5_1761853691894_0.48530812038504023","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.6":{"name":"@crawlee/linkedom","version":"3.15.3-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"972cf4752f150dd00d5bc5fc965db25e6b8a9a7d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.6.tgz","fileCount":13,"integrity":"sha512-LYiaWPEBbJg8zYswvyZF+bbJ2f0ypx8QnU4ZY0IiQqT8uYcY3rHJ+uwuyY3FYoD4Rfcvzlvl0vwbuMmW5VZANQ==","signatures":[{"sig":"MEUCIQC+W6Q6/gHQ5pR+RALWIwc+0/gPAihY2sOIEYveQjXI3QIgJiayRde1UXrcspsHlbFVxdLUTh2134BXBr5DB2+eGGk=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"4fa6bccf28e93b58d0e8c6ffb3957c8bd1869443","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.6_1762163695846_0.3401865474096233","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.7":{"name":"@crawlee/linkedom","version":"3.15.3-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"be569ffe9cc77450dbefa7c0c4bde5a9d11d980f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.7.tgz","fileCount":13,"integrity":"sha512-OEGKaZMKXUFWM+vy1eMgIIbt4hKBWG8ONypqr4uTO5qS+OKNuNFOVoeb+F1tBqXY6VAGLKlCwmWkhrDRFokgAw==","signatures":[{"sig":"MEUCID0PCOhOI+xQn09B2djbRk3dFgTsm5XSyr2aFrGXOQ8LAiEA9d7C9jdVopshvln4geQ4WLNwZ/54MkFsRaY0bg93b28=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c9a1cd9e5c1d50b7194cbf67aff2f694493522b5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.7_1762267678580_0.19062382274140366","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.8":{"name":"@crawlee/linkedom","version":"3.15.3-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"87e5cbacb3f37c7a0fda5faa6e473507ed3271cf","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.8.tgz","fileCount":13,"integrity":"sha512-/QD49pdwzVG5bDuNGsQ3fJItGhUSfpJ3NE4J1Yo337y8a3pE545stLloTcHb3iXJKxQ53WSKwd0MLf5iyim+EQ==","signatures":[{"sig":"MEYCIQCRnsqKJZKz2+fOYoiV7AJCH0XV3IYFQEff1+6cM1dHfwIhAIWo0n7Aj/KGSK3ne7vORmkFOhUevGcjdmil1WzLFObf","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.8","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"32979607bb425fa5d82f03bdb47e7ae82f300094","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.8_1762355973771_0.8936052728609014","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.9":{"name":"@crawlee/linkedom","version":"3.15.3-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ceed22b852f396ac5c502ee431acd84c778cf796","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.9.tgz","fileCount":13,"integrity":"sha512-ZSH0/Ciq2uMMx38MjVXFcNPZcLjq+bd15Vym4z9IOg0VCenIYWlVIcAJzbYy9NyGbZxck/ULC24y76XejmwarA==","signatures":[{"sig":"MEUCIQDUTOZrqfCa6ZZ9pMj0GRJcEArELfhy8Q76Usni+ZhndQIgML/Yb/q8ihOzaHptHyLdpCfYmU1ext+ILoTRyUHO7lA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.9","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235459},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"f44d7261482857ac45858fc758ef8a085371cf3e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.9_1762358546011_0.5244867122349028","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.10":{"name":"@crawlee/linkedom","version":"3.15.3-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"56697ccc84bf6f363cdf10305f990237235aac30","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.10.tgz","fileCount":13,"integrity":"sha512-UkReTpz7uoHjZBoX+IG/Yql50xIgQOSDzUQ5XOO4EdmHu7UZB2b+UsY89VQR96koMlzXZjyTNmG13aqK0jCb4w==","signatures":[{"sig":"MEYCIQCbSas4vy9eulwrn+3Sn3Ep7kkg6N3RHeUVxqxtw8XNNgIhAPg9F6ehnzPTtNpVqk1lnjfcyV6NBk+NN1RCk6SGHZ26","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.10","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2e5da33296d7129a4395473bdae2a225ac639d83","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.10_1762415565941_0.307860701572235","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.11":{"name":"@crawlee/linkedom","version":"3.15.3-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"1c260ee897280131e511dd3f264fe0311644faa3","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.11.tgz","fileCount":13,"integrity":"sha512-QXUM/FDNvG7QYYFxR+wZHoqpLWJ0yyep1u3ujQYYZx+DsTo7aD45SBgbR4mMFPzR6neH3d/rm0yhThu8cWBm2g==","signatures":[{"sig":"MEUCIBbsnHTmLQpiMHuchboeF1aLnw5hw+eqEvGTnWSIQRlSAiEAsY+SHdW/Uv44rCNfBK33Dkixtahs2FqfB4snuLijjtE=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.11","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c872bda47bc417f49ce5852754c9495b3f39138f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.11_1762447390155_0.4769525499268077","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.12":{"name":"@crawlee/linkedom","version":"3.15.3-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"efceafd32e9bbf110ebbc5005cf946d9eabe750c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.12.tgz","fileCount":13,"integrity":"sha512-OYknB1YATj1CBB5QBRvgNICtKR3DHn6ut7ATOFoqildj+/HIruUcasvjQIrcFyKKwixzSo7bb04JO5X6GzeFjw==","signatures":[{"sig":"MEUCIBc0gwPS7tMpuiE0EOhzc1niBit5WJqXvhrvpn+2IoXjAiEAiN6pFOfllaGNLQC+tiSLbEHVAASOQlrp7ZwUur5zrHs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.12","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"a9665b5cf38cb1d5e65a5b5d22ab7e5932330a7a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.12_1762448000250_0.7359082462231474","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.13":{"name":"@crawlee/linkedom","version":"3.15.3-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"529529c6b48455eebdd5082794de3d92a5d8ca20","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.13.tgz","fileCount":13,"integrity":"sha512-ozOtLXaruiOT/AHKQVI4OJndJu49Vo974Ps2f9lbSw/tQ54i3nYelEgdYju8UjtOlnzhzVNHJyjLR+AgbzQMSA==","signatures":[{"sig":"MEUCIA1KBRag8yo4tYWLK+kx7eVANqRG6UUq9wQ8EU8jj6T8AiEAsTe2xT/NWFJWnXnORzURN3WdVIu92XaQ4hyxAdoIMz0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.13","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"9b4ca4a04cf735771f101250b69346350047344e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.13_1762448947789_0.20679632136335058","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.14":{"name":"@crawlee/linkedom","version":"3.15.3-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f5259dac5de5ef66417ad38f837b8daaf8850412","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.14.tgz","fileCount":13,"integrity":"sha512-9euYdLV7NJtJqL0qha37uZrDFf9AiVo3ECoggjdrdmGJjL4DQ6Hsi5xwhZX6Tqjztq11pMsLK4Xb6symvgBi/w==","signatures":[{"sig":"MEUCIQCdZNjHZjD36NRaReFkhlZsUZtOZUWB6l40I93iDptvKgIgGMLqiNFill9K8D3gMdyOU1AbXxkR2JMtnBlKnlKH2Iw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.14","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e0b38b0ce95790b0026d24acd5602fdd69ec0190","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.14_1762449704643_0.9599524676985622","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.15":{"name":"@crawlee/linkedom","version":"3.15.3-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"27163e6c796aeadc210221d892d9a747b9dac8fd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.15.tgz","fileCount":13,"integrity":"sha512-FjG62FmuQfmpL60Ay78l6OlsUfY7+iF+1irLic+06uW2s4+a2YxSW+mBK/mecckCBiQ64D4kuRR1Tk8Jlja1Mw==","signatures":[{"sig":"MEUCIHtMHyEFCZCE2ID//m6kBfz+3RUwnpfjTGFrjwFxoo06AiEAxY8hPLVbaPb/tw+MOw4qT1Mjnn/ppjtWTpD5w80kFsc=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.15","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"217843dc1819487bd3a99232919959375d2f2abb","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.15_1762506673085_0.9259947390606642","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.16":{"name":"@crawlee/linkedom","version":"3.15.3-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8447a1518f090c8cdd04405d5b04a6364dc055b4","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.16.tgz","fileCount":13,"integrity":"sha512-E2rrqgjYWFl4x4up5RGMhizE1Bd/ZANKxR5KbHOn86yIgwbiTMan+rSqdwHM6PWLl/pH+SdALtNkz5aSm1bDGg==","signatures":[{"sig":"MEUCIAZMJRhodSAQgKQXBDCr15dEQNmrWyZKsDS4VH4Qcu3/AiEAocKAk3t93EIy15bb/SRjWZCzvdvJ3/ZG3YhKpe+8NEs=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.16","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d9c9f62ebe56afac02cc4fbdbd2ddd6599f003ec","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.10.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.10.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.16_1762507925620_0.02900043092927751","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.17":{"name":"@crawlee/linkedom","version":"3.15.3-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"06c133d852e69fcf956142f087e430a34952d6cd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.17.tgz","fileCount":13,"integrity":"sha512-Rxs3RXD2YZn/RDmsESyJz2VAuATOUNhynwoU8Wq72LPBNlMHAVS+aCgbpS7igMuvWx6h6KtRNHLDz8esHOzoYQ==","signatures":[{"sig":"MEUCIQC8RkwgfPFQfLSQhIENrEwkTI1ipl8kVcZO0rm/CTyHLwIgVexnQ+ANMPnWYIZGJQyTdGqoWz5WUTDe19Xu8lAji4A=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.17","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5c4c7c226b836f68b8c2966c1d8256d024025205","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.17_1762572126207_0.2693494802769578","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.18":{"name":"@crawlee/linkedom","version":"3.15.3-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6ff38c1d61d9408bc58c0660f03e92d671fcb00d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.18.tgz","fileCount":13,"integrity":"sha512-ujCZRREaeplg5fpkyaVrYclBzlVleBBXO8mFhgaSPPSudmiSChMp/UUuzU09elgWNvVARhzVuZ6pd7R2GPA2Qw==","signatures":[{"sig":"MEUCIDd+NUVZyCEKK3Hx5QovPoeRR1MUiFGjaDK9d4J3dwkeAiEA2D1Lp3wvgnNkO+6MLKDmvKcvU3REeKJssUnytzbm4YY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.18","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"616e6ceba91199038bf46370abbe21f80b3b4ff7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.18_1762775977765_0.7438379800087453","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.19":{"name":"@crawlee/linkedom","version":"3.15.3-beta.19","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.19","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"83d676ae12c8dffb00d5ebdcefab43184ace91e7","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.19.tgz","fileCount":13,"integrity":"sha512-AHgq84L4epcLlcpTmw2yxKDSUPKQ+yLpTSNitE+fOjZZy4Pfyrb/XJNWpFQCzi2VXD7JUFcW447oHYxbNwhpEg==","signatures":[{"sig":"MEUCIDtNGmH73WJsK54LYhxGaBkm4dJFoePQBQOoGYDbhFLtAiEAyH39NWCzT48MRzgt+XF5UNtXFhyHtI2myUETyY1wFdM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.19","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"5dea5a598a20cfe1592068e3309428fb200fe210","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.19","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.19","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.19_1762779266266_0.9637037107686135","host":"s3://npm-registry-packages-npm-production"}},"3.15.3-beta.20":{"name":"@crawlee/linkedom","version":"3.15.3-beta.20","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3-beta.20","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8f0130a134da93ceab292d10c848273a10746b65","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3-beta.20.tgz","fileCount":13,"integrity":"sha512-j5juhoKtPDSriWiZn0srj3IwxTXREdFDf4qwSm6ia+MENbBeML666oFX/awOpYk6wqW1YdoL264O2vIcOM5qeg==","signatures":[{"sig":"MEQCICiA8LCTMPmhPl4qejZzUscCCFk+MQNu+ggQa7EfdrAjAiAjAMfFcJ8oQyi4rgE7jps9BXtyiMSiEQCoI7VFpXVrbA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3-beta.20","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235462},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"96ba88c7a5886c4ca10b81df335a187634e62a2d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3-beta.20","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3-beta.20","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3-beta.20_1762802893388_0.9731987058978899","host":"s3://npm-registry-packages-npm-production"}},"3.15.3":{"name":"@crawlee/linkedom","version":"3.15.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"47a5461af4aac0d32fa8f02b1cafed94be016599","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.3.tgz","fileCount":13,"integrity":"sha512-pCmfjMuRDAdDqJiHL/Ph9rOZC9I4tFxXhveNUS0X3suOj/5y67m5t9CsV6Bv3XuwAEVXDc8MNOCz0FUN9dl3jw==","signatures":[{"sig":"MEYCIQC+LplWuYTgj4YKbLJfCMqZQCTXmxzWDyhkp/BxjEaPugIhAM3T3Q08rxlIRMNUOqLQYJrXqiaKwBGj5apcD9PCHd4U","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.3","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235438},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"615c8f9f691fab70d15be84c2ccff29daab4e55e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.3_1762803085439_0.46803398599814483","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.0":{"name":"@crawlee/linkedom","version":"3.15.4-beta.0","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.0","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"30d1bf6331735eaed0102f1a606eebdf5e9dfb09","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.0.tgz","fileCount":13,"integrity":"sha512-5b+LrOjMxLYyoVpjjvLUSU3fBnZxPYDyZS8VDdECwEvkIvgMF5PE8Nc6mDF1YbzPukgE+jY9erVQSulJw1pCGQ==","signatures":[{"sig":"MEUCIQDpWbXrbxm3/eAu1mo3xSeI61IlcW6ydb0VvZEQ0nFsVQIgLUBw5DbkrPTCd0tMoij6AlH2DlOW+wyQfI4r4g481iI=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.0","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e0d7c395611567dea3bdc1f5d96685cbfe5f866c","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.0","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.0","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.0_1762942611227_0.09170269237446727","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.1":{"name":"@crawlee/linkedom","version":"3.15.4-beta.1","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.1","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9984024649dd5c80ecbc67ea835ab676df097e1a","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.1.tgz","fileCount":13,"integrity":"sha512-r+xM+ZBIVAr5X95jB+eeBfpJuwX97bGw1y++t0yDXmYhVVlrnWyFnVARffXN/Dc+z5qUvUfu+6Gj/ibkOzIOPg==","signatures":[{"sig":"MEYCIQDkWJFyi+GM0lq3dNvHLvhM6culzfX8uPffyiB3dWa8DgIhAI8XzrlV2Glqc263oVcda1piMX8sSl9WN9DSIi9Mvrd4","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.1","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":235463},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"78e17d130c72511e924a585aae832c46abf12e7a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.1","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.1","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.1_1763031347693_0.3524872725574737","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.2":{"name":"@crawlee/linkedom","version":"3.15.4-beta.2","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.2","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"d7f8cb61ea37b37a86e53a6aa6b68c022fca1890","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.2.tgz","fileCount":12,"integrity":"sha512-yCK7ApvuO1Ih4ICBOl6d2y9NstEzLrl4EOtJQTOt/GQSAy0aD3vDg/QkdFzF73R0RNGGBBp2m0SSiqZ2P0Wk+w==","signatures":[{"sig":"MEUCIQDu09eJPPK2Lm8LQrmJZEvfbxztPsheD3Prz0u4nK5bygIgNBlYlqfIvYwhknOzFSM94dD8c/nhZzsVDatNzTzvOK8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.2","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"de7edea47c80239242264cf53379ebc72cb810a2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.2","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.2","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.2_1763045897325_0.25353829154114393","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.3":{"name":"@crawlee/linkedom","version":"3.15.4-beta.3","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.3","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4dae1ebd047e8ddaab32cc6b350ecaae32616ad9","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.3.tgz","fileCount":12,"integrity":"sha512-FBefPga2efrZ5UbZmnEUZHF9JJpvmGKyps6+LXedbZlT3OhzhQ1wwsQieeiQdvGeAWu4D88yZMmsRPsHMQNbug==","signatures":[{"sig":"MEUCIDQyXag6JNVLs2RaoVnpc4IltaIpwpwxKuuOd9huWHmBAiEA/RuPVdOfFBPUAa0DRp8+1JQu8elM3583zpvc8iq5mGU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.3","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"8098a040ac9778438a45d56bbf9b12a051b3a248","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.0+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.0","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.3","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.3","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.3_1763112212783_0.4735855949214631","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.4":{"name":"@crawlee/linkedom","version":"3.15.4-beta.4","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.4","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"878a717d0debebb301922082dd0665eb6344bb7c","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.4.tgz","fileCount":12,"integrity":"sha512-TKQMhc/8KXRvKdz5gT1IMQkv8/1SDiHrWZccpCxtdYuyelcFpXE6FxMEex22cR982MvRdRZDKAcBusm7We+bsw==","signatures":[{"sig":"MEUCIHkdMtteOUpXon9XJRRZjaDcQgx+8njlUamsM2cg114QAiEA4a6uNF/oP/byxN2m3Q3jP9DWvBRGHzk/2nss+UsReoY=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.4","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7947097140a40118876d7e8e0ac6ee7a70cbb79f","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.4","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.4","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.4_1763535943647_0.6010390780027761","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.5":{"name":"@crawlee/linkedom","version":"3.15.4-beta.5","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.5","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3f2dbea7ce1b8283e7827c709434ce937a4b8990","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.5.tgz","fileCount":12,"integrity":"sha512-hxo+8TZAKsSiYFO6cRA5q+YIeGfoQ5JTWRz6n8YCjuF9RUXzGcB7RUrzHQBOQWvAVGBLpo1rlCkmPM+1uf7pBA==","signatures":[{"sig":"MEUCIQDW2OyDPPEAVvDPaV72DOp16Aef/JrNnsYZq0sfqB1E9wIgcs/VwaYBG3TYXprlkgAjFjyRc1yZnLBTuWJ692Zof2M=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.5","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"3b48453c979d0ab7e7391a07015beb7664ed6406","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.5","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.5","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.5_1763555476333_0.3661863078758807","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.6":{"name":"@crawlee/linkedom","version":"3.15.4-beta.6","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.6","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"4353bf72f7e38064540a5f45af2a79f64ce59015","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.6.tgz","fileCount":12,"integrity":"sha512-6oOltyE845vBiCvO+HJzi63qnVPNLUDasxZAgcsSfpF1UYpqW8Pvm9DTE/wQh0ofxSI1vtHtWPgGGptzeKvLSw==","signatures":[{"sig":"MEUCID2XWR1JzTuw4gNDCwwjb4xhXlJVc/hGqwXhUKOounWRAiEAza7WmHd+OVYsfjim67GbyhtzwEyjgRB9jwGRgPLD1xA=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.6","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"c721afa79de602069b8d71d70b4bc77d3cf3d4ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.6","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.6","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.6_1763741886903_0.5341172168571382","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.7":{"name":"@crawlee/linkedom","version":"3.15.4-beta.7","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.7","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"f11ae1ebe98e9ee5e87ead99e2443fa4055930d2","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.7.tgz","fileCount":12,"integrity":"sha512-Sm/FZR222v2XkJXEbGtDq9fzP9n096of/b7Jk6CdXkHVNgdgzwm0rc6uJG9ZdJCVz9Lrk76QNOl2l/U/TOmUMg==","signatures":[{"sig":"MEQCIAl34qM+6vqGbR+W3EVWqZ+rMwZFzrQZbeURKplXzvCDAiBEoITCJNWKcrYRwPH4IAtXbgshk98ZilxmYZcR5gN8pw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.7","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"82216842e6a1b3a1402d6ead7d6a6e8b1f1bee42","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.7","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.7","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.7_1763743526973_0.4450289552841913","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.11":{"name":"@crawlee/linkedom","version":"4.0.0-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d69f8fdf2bc116798f12b33a6b2338f550f3a2d","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.11.tgz","fileCount":12,"integrity":"sha512-iQ/r0gIf3NhLpl+F/zjkgPTSrQkA3dyjQvMDypCZRnJ8rDk27fbP7RJYexDnQgiSopGXYlTnD0j86kRo1VdPVw==","signatures":[{"sig":"MEQCIBfLR1xuPnea5RxkB4T7waJfiWgYanDylER4qzVm3WTGAiBOMdbdTYFNC4JAyawh15Vu4FihJTCpb20lo7DFX756bg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232763},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"790ff75aeb412a1fd306891c85b5cc15c337cfaf","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.21.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.21.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.11","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.11","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.11_1763988503751_0.985119152240989","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.8":{"name":"@crawlee/linkedom","version":"3.15.4-beta.8","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.8","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3f400308797c370a0c2c8c7c02e31544ef1dbe86","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.8.tgz","fileCount":12,"integrity":"sha512-flU0XSejRtMxnXPcx0mbBtU6yvdXAzII4ft2UsZ4H7r/Py+KJo/ZcYRJYEDZ2VW/9m4Wy1jLO73/PTOmybhJuA==","signatures":[{"sig":"MEUCIBk5UuOAokHsPMeND+w4wOyn3efBRMt2vqMvOD8gZaeUAiEAhgZ1R1cu/XvY/c5ofHyINscgM9y1jMSDQw2nkJL6TMo=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.8","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e5a61207a0be4c77e1f198984104ddb7a2cff583","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.8","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.8","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.8_1763989767259_0.8524135580249386","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.9":{"name":"@crawlee/linkedom","version":"3.15.4-beta.9","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.9","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"67f59b7fae4023878953b11bc56b2af57502c5e5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.9.tgz","fileCount":12,"integrity":"sha512-LXPKJjbCIM/XJuxnXRqjslKaURhoC7fL9+53v2Ch8CtKvWBeT1Bp5taaGrrzAWwFvDCO1XRxkKH+aTX1cLfSMw==","signatures":[{"sig":"MEUCIQD+RgULZu7xoBYRtqfwdRVntFy41R5csZU8qO/9dFQupgIgePeSzMFaS83Huy4nknV3m4yGLNtVB3FOTCKulTxBtPw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.9","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51537},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"d3f533d7895728e928b76d5a3cd9495fbbeaa5a5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.9","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.9","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.9_1763991653889_0.06910018808231078","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.12":{"name":"@crawlee/linkedom","version":"4.0.0-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"75b8b9d2c960552e133483707b9db5ac012a7be1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.12.tgz","fileCount":12,"integrity":"sha512-pkslKCnNahefruS9Y5bcOU8bI66MnLEdGBkp7m3QMZNjK+fmawO7rD1Ej40CK78K8rmPgsGGHr0Q4ihan0q3rg==","signatures":[{"sig":"MEUCIQCSMDZTFLFz/pTiAjV0U9R3teoxt9MYCCI4SSylw9zbJgIgR9TKrfcDj+05j2+CllccoCp/6BL8jSZw7bgwx8m74LU=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":232767},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"06431733e5cfa6cc3a4c105427592f87424037ca","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.21.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.21.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.12","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.12","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.12_1764152688365_0.08195425132781775","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.10":{"name":"@crawlee/linkedom","version":"3.15.4-beta.10","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.10","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"6450ea377639dd7fc1169ff46b170849bf2dff11","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.10.tgz","fileCount":12,"integrity":"sha512-jaZMQepb2JG3OHtLGfy4Obe4bG1Ws0pIMnv6AVsg5J7rNWJI6yzRcU+PXs4vS5f1uZV+YZ89S/OdMBGpeSD71A==","signatures":[{"sig":"MEQCIH5LLR/AVDZrPAZcANxa1KTudZwc2/fjJiw3Bu+MDOS0AiB5/OSpNzJ5fsMKtIL0oxj1wvrPkfyeLYhv1PGvY+tpQg==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.10","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"ca140b285c9267e913cf3d52eab5765e7e1e0ce5","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.10","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.10","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.10_1764154034950_0.4593348794660157","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.11":{"name":"@crawlee/linkedom","version":"3.15.4-beta.11","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.11","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"333c06d74f9c1f5c334a109dc1fa0ba47ecffa11","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.11.tgz","fileCount":12,"integrity":"sha512-tlK3cZ0atUfFX4/Ergba48UDkQ7BAwYijPbx04NpaVJ/JTcb0sE1B+5xEnS+3ONhgL8SDA9gONAMNUH+Vgf1AQ==","signatures":[{"sig":"MEQCICNEWcdyktUeLVlhjF5w03jkOAohJmCSdoQKI2qe4ij2AiBY+Y/iPU+337NpyvxuwHLVTmATxkxcETVTSWDKvlesjw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.11","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"e444197cfce6f9d299d9af9ce55aa5a8e23a18ba","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.11","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.11","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.11_1764168681048_0.7398384996289864","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.13":{"name":"@crawlee/linkedom","version":"4.0.0-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0b4676d9de82568dde3740783b2880620532b189","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.13.tgz","fileCount":12,"integrity":"sha512-o5ut4Wr7L1VRABXnXx5zeZoL2gvA1wUypuQUx4v/AEwNENVWdBrz2zAjnPjGxelgN+t/HS4NxYMUBWHr3J7lXw==","signatures":[{"sig":"MEQCIEUdA4X98hDVSzjdKDH9Hkyq25Vc0SMxvI0MRxIPDVSdAiBP9+Uy31YiUgCIaJZvUZIPmBJTgRjKrTpVhSkl9RDDvA==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":234526},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"24df7c8dba6b6c9623c02ccc655d8ee748f003e3","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"apify-service-account","email":"service-account@apify.com"},"repository":{"url":"git+https://github.com/apify/crawlee","type":"git"},"_npmVersion":"lerna/8.2.2/node@v22.21.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"22.21.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.13","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.13","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.13_1764247706364_0.494808349871553","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.12":{"name":"@crawlee/linkedom","version":"3.15.4-beta.12","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.12","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"3f4ae0c4199625e1224899bc810e1f6417229d03","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.12.tgz","fileCount":12,"integrity":"sha512-G8s/t4XXIMxTr2exWWizUNk5ms1u9snsDicMMXZ8b6FogMnFoxM8CSC3ogCzPm2p8hW5g+/V7gpVToKCddMaig==","signatures":[{"sig":"MEQCIFXxibD5ZxnQ/ll6aiQhAgFZ1RsHx2G2EuSefw3P9vNgAiA0cw1upGa3QwlDp/YvUngSF9ypV3lJq/5Sp1/Qat6jlw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.12","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"569899042596f8d735914019f5cd34605b480f1a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.12","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.12","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.12_1764262975265_0.32854468402566983","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.13":{"name":"@crawlee/linkedom","version":"3.15.4-beta.13","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.13","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"ffd6def2abe2bb01a048aab61da8ba0541df4e81","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.13.tgz","fileCount":12,"integrity":"sha512-DPmFfX6uZjA/gB+UyvGLXiYJ54KzKuhEpn0d4U6zskiTVKTTKSdgYzcnR84ALk4j8AhuJtPqzBuC/f/Cbpznww==","signatures":[{"sig":"MEUCIDp2N0yc9MeCaHfDKV5JPlPf4jSoo7vfYthqZjbdqk34AiEA5ngYfAtpWgJLcljKmPv1TAbTu+mPrGov9G1anupB6do=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.13","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"cf8c4de9843e1fbb4a8de7e8e9d63e11f6620d1d","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.13","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.13","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.13_1764579393376_0.7996765450187122","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.14":{"name":"@crawlee/linkedom","version":"4.0.0-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"b8ab5f90822ebaf057990432640162039215897b","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.14.tgz","fileCount":11,"integrity":"sha512-mj43J8QX20UhuHUce+6h7l6XVrzLLbdQz8bb/79cpo0KLAtz8SLuIj03/OIMbY29ZI2omvdn2u4iK8FXa4MLzA==","signatures":[{"sig":"MEUCIQCxr7Op7Gyai3UPb6dzfWM8E1AKzHL1JBre159UKIB2lQIgCExq1DxW+eiksMJWwpNtkT1yT+78NIQ3R6ZSwa0JCjM=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@4.0.0-beta.14","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":45214},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"3d889c957289f962078c1e095f33897595b42632","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.14","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.14","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.14_1764602791229_0.19445172637373864","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.14":{"name":"@crawlee/linkedom","version":"3.15.4-beta.14","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.14","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9fb03106bb7c7304b0932458f4037e3a643e2c1f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.14.tgz","fileCount":12,"integrity":"sha512-QCnS8rvdePJxoCVq1DKqwPxdQDcLmeU+GajJIt1BOuIP5l9aQWf8BT4v6fabotnt1eGIZGvH1ip+AwA1cs1fTA==","signatures":[{"sig":"MEUCIQCMuJHzCV5R9j7Io+ElpvC1fdBvItbVCccT4Wnann7f7gIgD8Ze81WvQcZRKD9S9ukNA2Fk7b/zwhbiyfH+4n1Hx3U=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.14","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"2f82080db71e2bd9aa489f6e77301f372a4a51b2","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.14","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.14","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.14_1764602957445_0.04069846822744516","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.15":{"name":"@crawlee/linkedom","version":"3.15.4-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a0183f5605e57a12a9409f1dc90f2ae525d640c1","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.15.tgz","fileCount":12,"integrity":"sha512-efJvbNZToG6fDpT09qMOgDbmdt/ShfhwBtuh8nH8nna+VhBVli+mCDSl4+lYQ83aBDc9En/XMtJ8Gj5V4eI06w==","signatures":[{"sig":"MEUCIQCUoFLPD3kzaSOI6CI+qupp7AMMJxaltmH0R5kPPtQxUgIgWlSOb9JKmBNRlKwTvK1naOnq/CaaPnzsRTQotBBFNl0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.15","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"45e9936ef46861d491bc96479695ad39bb6c5ab9","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.15","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.15","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.15_1764663150324_0.3996330747476091","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.16":{"name":"@crawlee/linkedom","version":"3.15.4-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"8d354bcd75668e27617550851535803e1b8412e5","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.16.tgz","fileCount":12,"integrity":"sha512-WSrrNMxOObpVOy5gGAgwIUlXnrP3Jydtmz4VhNOjzLjIg1gb675ekpz+wFs/NvY6XfY8i5rkZVvp06Ad+k9XFA==","signatures":[{"sig":"MEYCIQCTY/zsgtKMnxri0fQE2C/CvXEwIA6urA0ZlLPPmzHIQgIhAJZdE4qHaE8WQylaWNjzvnJacY0qDVracD8cM9vbjT4m","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.16","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"acd40f299cd29cfc76dda3591315543574ad177e","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.16","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.16","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.16_1764666331816_0.9336869099595839","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.15":{"name":"@crawlee/linkedom","version":"4.0.0-beta.15","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.15","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0c1feea65c5f21e3b23d896f7fc9617ba34756e6","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.15.tgz","fileCount":11,"integrity":"sha512-vIQua/HwUxBruYnCqYj/4UFEImWbmWKIGADlqDqtUKjPz+jag/nXH6Y9aU7guA40nln+7i49WM/aApIYKncdHA==","signatures":[{"sig":"MEYCIQD/oi7+8UzQq2F8hDq8G2Vi5QRaaU6vh0u1zUKoOFiBMwIhAOKaTu4fyqRwFjeHHYub3emrZdmL5ARcfZNRd7rblVzJ","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@4.0.0-beta.15","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":45214},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"3276fd24a03ecb0204369c197db781010d6d3e7a","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.15","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.15","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.15_1764688399540_0.8140862300551266","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.16":{"name":"@crawlee/linkedom","version":"4.0.0-beta.16","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.16","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"121da765cb04ea1a5589c13b99d7cb2bbeaeecce","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.16.tgz","fileCount":11,"integrity":"sha512-6e6TBw4zjZwBMYXs/khud6OlQmKfm5g72HzMAnt0Ss9yIlCtD8PEwE87d3ARCo8XHjKVrBzgF76nQU8WlN0EYQ==","signatures":[{"sig":"MEQCIGGOPN5cuQMOfg5DGtdgsNyBlZpmB+OwbN+icSu5ccvkAiA7acOD6MWFLZtyxwvnMPDYz7TxusOfay+gG7s2QGmklw==","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@4.0.0-beta.16","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":45556},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"65b235c9bdcf0521e0fbae05c77f4adaa89c45e0","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.16","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.16","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.16_1764689364602_0.8543238501286148","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.17":{"name":"@crawlee/linkedom","version":"4.0.0-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@4.0.0-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"a94d30433d7c74e80c629909b0cce7a227a1a43f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.17.tgz","fileCount":11,"integrity":"sha512-Ke7NyWWnvkrTtvLykjmXxizDXa5hnSBFNxZXRn8hicMjJ+Ooj1WfULS6ZNTn41FabIFyV3Q3dKoITBNULfsF0A==","signatures":[{"sig":"MEYCIQD+AWKWO0J3mYswlkwg4YLdYSkwIYWeW/ZCeIPpvLnsJQIhAJP75ySK/QTbecR3WOVDomYNdyEcTq0bfeNM1Qig35dN","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@4.0.0-beta.17","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":45556},"type":"module","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","engines":{"node":">=22.0.0"},"exports":{".":"./index.js","./package.json":"./package.json"},"gitHead":"755dcbfced2107997ea4d4e9fdf1839e141d3f00","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^2.0.0","tslib":"^2.8.1","linkedom":"^0.18.10","@crawlee/http":"4.0.0-beta.17","@apify/timeout":"^0.3.2","@crawlee/types":"4.0.0-beta.17","@apify/utilities":"^2.15.5"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_4.0.0-beta.17_1764690909116_0.577417933724722","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.17":{"name":"@crawlee/linkedom","version":"3.15.4-beta.17","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.17","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"0fc7432ed9b3fc89fb5079b6fd2089fa4ed48fbd","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.17.tgz","fileCount":12,"integrity":"sha512-0wbAvzQGLBq1E5RYyXCkVcmlJ1HnmVu+KcthiRq8bym6BPLwsIELQAWN6X8OQ7Arj+DrVjiO4c6MnBd9fePjww==","signatures":[{"sig":"MEUCIQC1ODEWRcdaVcGQA/WShsC7eRalJTF8HfDSjw3TDh1KGgIgPVpa4CFjFgwXI/E/6iq4tXYwRMa91U/YBcTUvvPiq/8=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.17","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"7d210085fc141c649eee485619adea00a489a6e7","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.17","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.17","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.17_1764842727179_0.44576697620944916","host":"s3://npm-registry-packages-npm-production"}},"3.15.4-beta.18":{"name":"@crawlee/linkedom","version":"3.15.4-beta.18","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","_id":"@crawlee/linkedom@3.15.4-beta.18","maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"homepage":"https://crawlee.dev","bugs":{"url":"https://github.com/apify/crawlee/issues"},"dist":{"shasum":"9840b084aae0783e77ba81f3963f2670c9ba488f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-3.15.4-beta.18.tgz","fileCount":12,"integrity":"sha512-BDwTl69ss+q5+Ilufm93E8j+cb+Oj8KLGK8IJeLUzB9NJXhMfLtNC8Or7rC+a0ytf59bDpQYII1ep4dbIG6Aqg==","signatures":[{"sig":"MEUCIQCSK/nMjnLiAzECGdlfgJ9S0hQag905UTCO5KeWnVTwSgIgQC2oLNq2UAgqjadgaQ0lyFdf6uNi74gQ+Kw5cYlQt/w=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@3.15.4-beta.18","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"unpackedSize":51540},"main":"./index.js","lerna":{"command":{"publish":{"assets":[]}}},"types":"./index.d.ts","module":"./index.mjs","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./index.d.ts","import":"./index.mjs","require":"./index.js"},"./package.json":"./package.json"},"gitHead":"b3fd8dcd34c8c0fe0ad791195811cc3939dd3064","scripts":{"copy":"tsx ../../scripts/copy.ts","build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs"},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","directories":{},"_nodeVersion":"24.11.1","dependencies":{"ow":"^0.28.2","tslib":"^2.4.0","linkedom":"^0.18.0","@crawlee/http":"3.15.4-beta.18","@apify/timeout":"^0.3.0","@crawlee/types":"3.15.4-beta.18","@apify/utilities":"^2.7.10"},"publishConfig":{"access":"public"},"_hasShrinkwrap":false,"readmeFilename":"README.md","_npmOperationalInternal":{"tmp":"tmp/linkedom_3.15.4-beta.18_1764861718818_0.7607772104728134","host":"s3://npm-registry-packages-npm-production"}},"4.0.0-beta.18":{"name":"@crawlee/linkedom","version":"4.0.0-beta.18","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=22.0.0"},"type":"module","exports":{".":"./index.js","./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee.git"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@apify/timeout":"^0.3.2","@apify/utilities":"^2.15.5","@crawlee/http":"4.0.0-beta.18","@crawlee/types":"4.0.0-beta.18","linkedom":"^0.18.10","ow":"^2.0.0","tslib":"^2.8.1"},"lerna":{"command":{"publish":{"assets":[]}}},"gitHead":"cfaba5f4e082914d98d96d6539ab7b324d1c14c7","readmeFilename":"README.md","types":"./index.d.ts","_id":"@crawlee/linkedom@4.0.0-beta.18","_nodeVersion":"24.11.1","_npmVersion":"lerna/9.0.0/node@v24.11.1+x64 (linux)","dist":{"integrity":"sha512-WIblThefnMn2I87pa59rYMkkGor5hLmECnH8pBiue7On/kl9WSOLPs/RWHN0gooF7PGLWR5tPKIew3Xcj25LCA==","shasum":"ca8c25cbdd5e41fc81e50e9f8fecff579b6e015f","tarball":"https://registry.npmjs.org/@crawlee/linkedom/-/linkedom-4.0.0-beta.18.tgz","fileCount":11,"unpackedSize":45556,"attestations":{"url":"https://registry.npmjs.org/-/npm/v1/attestations/@crawlee%2flinkedom@4.0.0-beta.18","provenance":{"predicateType":"https://slsa.dev/provenance/v1"}},"signatures":[{"keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U","sig":"MEQCIA22eSMKoXJ8L8anTeKMLBQyXmIDSMnWUxmnDLQ5Zx2NAiByae9ez60tORQfvO8qs4QScnmQemsAtaV0qvuJP9Ag2g=="}]},"_npmUser":{"name":"GitHub Actions","email":"npm-oidc-no-reply@github.com","trustedPublisher":{"id":"github","oidcConfigId":"oidc:efb113b2-fe86-492b-99c1-0a3d7d04e33b"}},"directories":{},"maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages-npm-production","tmp":"tmp/linkedom_4.0.0-beta.18_1764933995979_0.5084887596990675"},"_hasShrinkwrap":false}},"time":{"created":"2023-06-07T12:31:19.225Z","modified":"2025-12-05T11:26:36.564Z","3.3.4-beta.6":"2023-06-07T12:31:19.544Z","3.3.4-beta.7":"2023-06-07T14:25:33.624Z","3.3.4-beta.8":"2023-06-07T15:46:00.540Z","3.3.4-beta.9":"2023-06-09T03:32:24.810Z","3.3.4-beta.10":"2023-06-09T10:43:12.478Z","3.3.4-beta.11":"2023-06-09T11:12:59.196Z","3.3.4-beta.12":"2023-06-09T15:12:40.148Z","3.3.4-beta.13":"2023-06-09T23:58:26.215Z","3.3.4-beta.14":"2023-06-11T02:09:23.317Z","3.3.4-beta.15":"2023-06-12T00:49:51.489Z","3.3.4-beta.16":"2023-06-12T12:57:56.587Z","3.3.4-beta.17":"2023-06-12T13:11:22.666Z","3.4.0":"2023-06-12T14:37:49.253Z","3.4.1-beta.0":"2023-06-12T14:55:46.665Z","3.4.1-beta.1":"2023-06-14T17:31:35.644Z","3.4.1-beta.2":"2023-06-17T01:54:53.100Z","3.4.1-beta.3":"2023-06-18T02:10:02.381Z","3.4.1-beta.4":"2023-06-18T13:20:08.443Z","3.4.1-beta.5":"2023-06-20T01:51:48.136Z","3.4.1-beta.6":"2023-06-21T00:26:49.873Z","3.4.1-beta.7":"2023-06-21T12:19:17.136Z","3.4.1-beta.8":"2023-06-21T21:27:18.663Z","3.4.1-beta.9":"2023-06-23T00:50:52.654Z","3.4.1-beta.10":"2023-06-24T00:36:35.939Z","3.4.1-beta.11":"2023-06-25T01:36:15.310Z","3.4.1-beta.12":"2023-06-26T00:32:03.147Z","3.4.1-beta.13":"2023-06-26T04:42:37.404Z","3.4.1-beta.14":"2023-06-26T22:53:17.275Z","3.4.1-beta.15":"2023-06-28T02:05:27.032Z","3.4.1-beta.16":"2023-06-29T20:17:14.859Z","3.4.1-beta.17":"2023-07-02T00:34:48.565Z","3.4.1-beta.18":"2023-07-03T00:28:24.650Z","3.4.1-beta.19":"2023-07-03T04:09:46.988Z","3.4.1-beta.20":"2023-07-05T00:33:39.547Z","3.4.1-beta.21":"2023-07-06T19:21:29.294Z","3.4.1-beta.22":"2023-07-06T23:51:36.323Z","3.4.1-beta.23":"2023-07-09T01:55:45.073Z","3.4.1-beta.24":"2023-07-10T01:35:42.417Z","3.4.1-beta.25":"2023-07-11T02:02:06.214Z","3.4.1-beta.26":"2023-07-11T16:36:25.746Z","3.4.1-beta.27":"2023-07-11T23:04:27.667Z","3.4.1-beta.28":"2023-07-12T13:50:18.435Z","3.4.1-beta.29":"2023-07-12T14:09:35.854Z","3.4.1-beta.30":"2023-07-12T14:36:48.302Z","3.4.1-beta.31":"2023-07-13T12:20:21.733Z","3.4.1":"2023-07-13T12:23:31.250Z","3.4.2-beta.0":"2023-07-13T12:41:00.464Z","3.4.2-beta.1":"2023-07-13T13:06:49.619Z","3.4.2-beta.2":"2023-07-17T02:56:22.185Z","3.4.2-beta.3":"2023-07-17T05:42:13.165Z","3.4.2-beta.4":"2023-07-17T06:51:53.149Z","3.4.2-beta.5":"2023-07-17T14:41:17.210Z","3.4.2-beta.6":"2023-07-17T16:50:34.662Z","3.4.2-beta.7":"2023-07-17T20:20:22.650Z","3.4.2-beta.8":"2023-07-18T16:27:11.759Z","3.4.2-beta.9":"2023-07-18T22:48:55.036Z","3.4.2-beta.10":"2023-07-19T12:30:08.357Z","3.4.2-beta.11":"2023-07-19T13:20:23.794Z","3.4.2-beta.12":"2023-07-19T13:57:01.191Z","3.4.2":"2023-07-19T14:12:08.873Z","3.4.3-beta.0":"2023-07-19T14:30:02.230Z","3.4.3-beta.1":"2023-07-19T14:49:14.022Z","3.4.3-beta.2":"2023-07-19T15:23:44.720Z","3.4.3-beta.3":"2023-07-19T16:32:12.180Z","3.4.3-beta.4":"2023-07-19T22:02:07.452Z","3.4.3-beta.5":"2023-07-20T13:29:48.609Z","3.4.3-beta.6":"2023-07-20T15:25:12.782Z","3.4.3-beta.7":"2023-07-20T16:01:57.281Z","3.4.3-beta.8":"2023-07-20T22:48:01.250Z","3.4.3-beta.9":"2023-07-21T08:33:02.377Z","3.4.3-beta.10":"2023-07-24T09:05:41.100Z","3.4.3-beta.11":"2023-07-24T11:38:37.887Z","3.4.3-beta.12":"2023-07-25T01:14:09.015Z","3.4.3-beta.13":"2023-07-26T05:18:32.907Z","3.4.3-beta.14":"2023-07-26T14:33:33.835Z","3.4.3-beta.15":"2023-07-27T15:51:59.701Z","3.4.3-beta.16":"2023-07-28T13:00:55.008Z","3.4.3-beta.17":"2023-07-31T06:35:56.092Z","3.5.0":"2023-07-31T06:55:06.963Z","3.5.1-beta.0":"2023-07-31T07:12:24.889Z","3.5.1-beta.1":"2023-07-31T23:47:47.028Z","3.5.1-beta.2":"2023-08-02T15:57:22.711Z","3.5.1-beta.3":"2023-08-03T17:24:36.400Z","3.5.1-beta.4":"2023-08-04T12:47:06.307Z","3.5.1-beta.5":"2023-08-07T23:23:41.386Z","3.5.1-beta.6":"2023-08-08T20:04:26.067Z","3.5.1-beta.7":"2023-08-09T15:32:41.806Z","3.5.1-beta.8":"2023-08-09T22:27:33.709Z","3.5.1-beta.9":"2023-08-11T04:37:22.664Z","3.5.1-beta.10":"2023-08-11T11:13:55.483Z","3.5.1-beta.11":"2023-08-14T22:11:05.731Z","3.5.1":"2023-08-16T08:49:43.264Z","3.5.2-beta.0":"2023-08-16T09:08:59.651Z","3.5.2-beta.1":"2023-08-18T00:49:04.317Z","3.5.2-beta.2":"2023-08-18T11:30:01.514Z","3.5.2-beta.3":"2023-08-18T14:19:04.202Z","3.5.2-beta.4":"2023-08-21T10:38:56.455Z","3.5.2-beta.5":"2023-08-21T11:11:23.959Z","3.5.2-beta.6":"2023-08-21T11:35:41.152Z","3.5.2-beta.7":"2023-08-21T12:27:44.186Z","3.5.2":"2023-08-21T12:42:01.204Z","3.5.3-beta.0":"2023-08-21T13:12:41.602Z","3.5.3-beta.1":"2023-08-21T17:23:12.426Z","3.5.3-beta.2":"2023-08-21T21:29:58.255Z","3.5.3-beta.3":"2023-08-22T03:59:49.718Z","3.5.3-beta.4":"2023-08-23T04:30:34.218Z","3.5.3-beta.5":"2023-08-23T15:54:48.171Z","3.5.3-beta.6":"2023-08-24T02:47:41.424Z","3.5.3-beta.7":"2023-08-24T15:19:29.574Z","3.5.3-beta.8":"2023-08-25T13:02:33.590Z","3.5.3-beta.9":"2023-08-28T23:16:48.557Z","3.5.3-beta.10":"2023-08-29T12:55:54.622Z","3.5.3-beta.11":"2023-08-30T14:54:48.311Z","3.5.3-beta.12":"2023-08-30T15:54:35.224Z","3.5.3":"2023-08-31T07:53:27.501Z","3.5.4-beta.0":"2023-08-31T08:04:14.505Z","3.5.4-beta.1":"2023-08-31T12:24:31.975Z","3.5.4-beta.2":"2023-09-06T12:57:38.699Z","3.5.4-beta.3":"2023-09-06T13:25:26.484Z","3.5.4-beta.4":"2023-09-08T12:14:22.646Z","3.5.4-beta.5":"2023-09-11T11:08:51.115Z","3.5.4":"2023-09-11T13:25:11.694Z","3.5.5-beta.0":"2023-09-11T13:43:39.333Z","3.5.5-beta.1":"2023-09-11T22:05:58.717Z","3.5.5-beta.2":"2023-09-13T00:58:04.295Z","3.5.5-beta.3":"2023-09-13T13:08:06.341Z","3.5.5-beta.4":"2023-09-14T10:54:51.274Z","3.5.5-beta.5":"2023-09-20T12:06:55.788Z","3.5.5-beta.6":"2023-09-20T12:32:09.851Z","3.5.5-beta.7":"2023-09-20T13:48:35.866Z","3.5.5-beta.8":"2023-09-21T05:09:35.386Z","3.5.5-beta.9":"2023-09-21T10:20:48.932Z","3.5.5-beta.10":"2023-09-21T11:36:41.153Z","3.5.5-beta.11":"2023-09-22T03:46:17.335Z","3.5.5-beta.12":"2023-09-24T04:14:12.838Z","3.5.5-beta.13":"2023-09-25T05:08:15.329Z","3.5.5-beta.15":"2023-09-25T13:51:51.108Z","3.5.5-beta.16":"2023-09-28T05:00:06.244Z","3.5.5-beta.17":"2023-10-02T08:54:14.039Z","3.5.5-beta.18":"2023-10-02T12:59:32.029Z","3.5.5":"2023-10-02T13:03:32.716Z","3.5.6-beta.0":"2023-10-02T13:21:31.271Z","3.5.6-beta.1":"2023-10-02T14:21:24.394Z","3.5.6-beta.2":"2023-10-02T19:35:19.923Z","3.5.6-beta.3":"2023-10-02T22:54:19.228Z","3.5.6-beta.4":"2023-10-03T12:42:26.456Z","3.5.6-beta.5":"2023-10-04T01:31:23.900Z","3.5.6-beta.6":"2023-10-04T08:36:24.461Z","3.5.6":"2023-10-04T10:32:02.672Z","3.5.7-beta.0":"2023-10-04T10:47:56.344Z","3.5.7-beta.1":"2023-10-04T11:35:38.298Z","3.5.7-beta.2":"2023-10-04T12:56:55.275Z","3.5.7-beta.3":"2023-10-04T13:16:29.210Z","3.5.7-beta.4":"2023-10-05T08:50:03.977Z","3.5.7":"2023-10-05T09:04:52.360Z","3.5.8-beta.0":"2023-10-05T09:18:29.710Z","3.5.8-beta.1":"2023-10-05T21:24:37.957Z","3.5.8-beta.2":"2023-10-06T16:27:37.791Z","3.5.8-beta.3":"2023-10-10T04:50:00.095Z","3.5.8-beta.4":"2023-10-10T06:23:31.236Z","3.5.8-beta.5":"2023-10-10T11:29:34.532Z","3.5.8-beta.6":"2023-10-10T22:49:35.130Z","3.5.8-beta.7":"2023-10-11T03:40:25.863Z","3.5.8-beta.8":"2023-10-13T07:27:20.230Z","3.5.8-beta.9":"2023-10-13T11:28:41.113Z","3.5.8-beta.10":"2023-10-13T15:34:00.178Z","3.5.8-beta.11":"2023-10-16T17:57:28.832Z","3.5.8-beta.12":"2023-10-17T03:52:50.620Z","3.5.8-beta.13":"2023-10-17T10:08:17.868Z","3.5.8":"2023-10-17T10:21:22.889Z","3.5.9-beta.0":"2023-10-17T10:38:32.299Z","3.5.9-beta.1":"2023-10-18T04:02:27.089Z","3.5.9-beta.2":"2023-10-19T04:26:18.528Z","3.5.9-beta.3":"2023-10-20T05:03:27.014Z","3.5.9-beta.4":"2023-10-21T03:58:53.192Z","3.5.9-beta.5":"2023-10-21T12:11:04.018Z","3.5.9-beta.6":"2023-10-22T03:54:12.935Z","3.5.9-beta.7":"2023-10-23T18:16:51.217Z","3.5.9-beta.8":"2023-10-24T04:00:45.618Z","3.5.9-beta.9":"2023-10-25T05:13:18.365Z","3.5.9-beta.10":"2023-10-30T09:31:37.644Z","3.5.9-beta.11":"2023-10-30T09:58:49.913Z","3.5.9-beta.12":"2023-11-02T11:02:23.610Z","3.5.9-beta.13":"2023-11-02T12:20:39.952Z","3.5.9-beta.14":"2023-11-02T12:55:13.576Z","3.5.9-beta.15":"2023-11-02T15:35:46.699Z","3.5.9-beta.16":"2023-11-03T03:24:04.067Z","3.5.9-beta.17":"2023-11-03T07:51:40.370Z","3.5.9-beta.18":"2023-11-03T17:28:28.402Z","3.5.9-beta.19":"2023-11-04T03:57:14.084Z","3.5.9-beta.20":"2023-11-05T04:29:48.583Z","3.5.9-beta.21":"2023-11-06T04:13:54.441Z","3.5.9-beta.22":"2023-11-06T13:08:20.117Z","3.5.9-beta.23":"2023-11-08T04:31:03.197Z","3.5.9-beta.24":"2023-11-08T06:56:32.044Z","3.5.9-beta.25":"2023-11-08T09:39:03.094Z","3.5.9-beta.26":"2023-11-09T04:49:18.753Z","3.5.9-beta.27":"2023-11-09T16:33:35.301Z","3.5.9-beta.28":"2023-11-10T03:46:11.280Z","3.5.9-beta.29":"2023-11-11T04:32:09.705Z","3.5.9-beta.30":"2023-11-12T05:14:31.923Z","3.5.9-beta.31":"2023-11-13T10:46:37.382Z","3.5.9-beta.32":"2023-11-13T11:06:54.902Z","3.5.9-beta.33":"2023-11-14T05:12:18.881Z","3.5.9-beta.34":"2023-11-14T06:23:50.450Z","3.5.9-beta.35":"2023-11-14T07:48:28.178Z","3.5.9-beta.36":"2023-11-14T12:05:03.614Z","3.5.9-beta.37":"2023-11-14T14:19:18.682Z","3.5.9-beta.38":"2023-11-15T04:29:05.925Z","3.5.9-beta.39":"2023-11-15T14:06:22.138Z","3.6.0":"2023-11-15T15:21:35.864Z","3.6.1-beta.0":"2023-11-15T15:33:52.712Z","3.6.1-beta.1":"2023-11-15T16:32:32.740Z","3.6.1-beta.2":"2023-11-15T18:22:34.670Z","3.6.1-beta.3":"2023-11-15T18:38:27.911Z","3.6.1":"2023-11-15T18:56:58.851Z","3.6.2-beta.0":"2023-11-15T19:09:05.371Z","3.6.2-beta.1":"2023-11-15T21:15:56.751Z","3.6.2-beta.2":"2023-11-16T03:31:56.785Z","3.6.2-beta.3":"2023-11-17T04:16:58.107Z","3.6.2-beta.4":"2023-11-20T21:50:37.464Z","3.6.2-beta.5":"2023-11-20T22:13:47.008Z","3.6.2-beta.6":"2023-11-20T22:50:06.276Z","3.6.2-beta.7":"2023-11-22T12:09:10.299Z","3.6.2-beta.8":"2023-11-22T18:35:42.559Z","3.6.2-beta.9":"2023-11-24T10:43:15.595Z","3.6.2-beta.10":"2023-11-25T12:19:05.695Z","3.6.2-beta.11":"2023-11-26T12:35:58.807Z","3.6.2":"2023-11-26T12:36:50.525Z","3.6.3-beta.0":"2023-11-26T12:49:21.865Z","3.6.3-beta.1":"2023-11-26T16:38:42.658Z","3.6.3-beta.2":"2023-11-26T17:34:14.552Z","3.6.3-beta.3":"2023-11-27T04:09:29.278Z","3.6.3-beta.4":"2023-11-27T11:55:41.362Z","3.6.3-beta.5":"2023-11-27T12:07:58.969Z","3.6.3-beta.6":"2023-11-27T21:38:01.320Z","3.6.3-beta.7":"2023-11-28T13:23:51.558Z","3.6.3-beta.8":"2023-11-28T21:01:46.575Z","3.6.3-beta.9":"2023-11-29T10:11:24.764Z","3.6.3-beta.10":"2023-11-29T10:52:58.727Z","3.6.3-beta.11":"2023-11-29T11:06:37.316Z","3.6.3-beta.12":"2023-11-30T04:22:38.239Z","3.6.3-beta.13":"2023-12-01T02:07:56.912Z","3.6.3-beta.14":"2023-12-01T03:20:59.616Z","3.6.3-beta.15":"2023-12-02T03:44:32.202Z","3.6.3-beta.16":"2023-12-04T04:19:13.261Z","3.6.3-beta.17":"2023-12-04T20:07:25.767Z","3.6.3-beta.18":"2023-12-04T23:32:01.972Z","3.6.3-beta.19":"2023-12-05T05:17:38.933Z","3.6.3-beta.20":"2023-12-06T00:22:09.095Z","3.6.3-beta.21":"2023-12-06T05:02:23.805Z","3.6.3-beta.22":"2023-12-06T16:08:09.450Z","3.6.3-beta.23":"2023-12-06T23:38:15.629Z","3.6.3-beta.24":"2023-12-07T04:24:48.629Z","3.6.3-beta.25":"2023-12-07T11:20:35.369Z","3.6.3-beta.26":"2023-12-08T03:53:59.870Z","3.6.3-beta.27":"2023-12-08T06:13:50.052Z","3.6.3-beta.28":"2023-12-09T04:19:18.528Z","3.6.3-beta.29":"2023-12-10T05:02:26.530Z","3.6.3-beta.30":"2023-12-11T04:41:19.256Z","3.6.3-beta.31":"2023-12-11T22:20:09.037Z","3.6.3-beta.32":"2023-12-12T03:35:55.622Z","3.6.3-beta.33":"2023-12-13T00:53:22.132Z","3.6.3-beta.34":"2023-12-13T04:10:18.805Z","3.6.3-beta.35":"2023-12-13T18:55:54.344Z","3.6.3-beta.36":"2023-12-15T03:48:24.736Z","3.6.3-beta.37":"2023-12-16T03:36:12.616Z","3.6.3-beta.38":"2023-12-18T03:30:23.755Z","3.6.3-beta.39":"2023-12-18T12:16:39.638Z","3.6.3-beta.40":"2023-12-18T23:08:38.429Z","3.6.3-beta.41":"2023-12-19T03:46:27.093Z","3.6.3-beta.42":"2023-12-19T13:19:12.137Z","3.6.3-beta.43":"2023-12-20T04:58:07.176Z","3.6.3-beta.44":"2023-12-20T10:09:23.347Z","3.6.3-beta.45":"2023-12-20T12:33:31.104Z","3.6.3-beta.46":"2023-12-20T14:33:19.690Z","3.6.3-beta.47":"2023-12-21T10:22:27.985Z","3.6.3-beta.48":"2023-12-21T14:42:09.015Z","3.7.0":"2023-12-21T16:12:17.676Z","3.7.1-beta.0":"2023-12-21T16:20:47.416Z","3.7.1-beta.1":"2023-12-22T03:38:43.168Z","3.7.1-beta.2":"2023-12-24T08:11:41.075Z","3.7.1-beta.3":"2023-12-25T22:45:50.729Z","3.7.1-beta.4":"2023-12-26T04:11:06.421Z","3.7.1-beta.5":"2023-12-27T04:05:32.449Z","3.7.1-beta.6":"2023-12-27T17:21:12.415Z","3.7.1-beta.7":"2023-12-28T03:41:21.849Z","3.7.1-beta.8":"2023-12-29T04:35:33.706Z","3.7.1-beta.9":"2023-12-30T03:29:06.894Z","3.7.1-beta.10":"2023-12-31T04:01:42.430Z","3.7.1-beta.11":"2024-01-01T03:21:57.274Z","3.7.1-beta.12":"2024-01-01T23:01:21.773Z","3.7.1-beta.13":"2024-01-02T04:24:09.913Z","3.7.1":"2024-01-02T08:29:46.162Z","3.7.2-beta.0":"2024-01-02T08:38:19.302Z","3.7.2-beta.1":"2024-01-03T04:52:20.276Z","3.7.2-beta.2":"2024-01-03T13:05:28.601Z","3.7.2-beta.3":"2024-01-04T03:49:31.989Z","3.7.2-beta.4":"2024-01-04T09:27:03.622Z","3.7.2-beta.5":"2024-01-04T09:55:06.085Z","3.7.2-beta.6":"2024-01-04T18:30:56.893Z","3.7.2-beta.7":"2024-01-05T04:22:03.049Z","3.7.2-beta.8":"2024-01-05T22:52:03.486Z","3.7.2-beta.9":"2024-01-06T03:44:07.932Z","3.7.2-beta.10":"2024-01-09T03:41:04.160Z","3.7.2-beta.11":"2024-01-09T06:41:29.145Z","3.7.2":"2024-01-09T18:51:16.919Z","3.7.3-beta.0":"2024-01-09T18:59:25.799Z","3.7.3-beta.1":"2024-01-10T21:28:12.400Z","3.7.3-beta.2":"2024-01-11T12:35:17.887Z","3.7.3-beta.3":"2024-01-12T03:38:18.976Z","3.7.3-beta.4":"2024-01-13T03:26:25.535Z","3.7.3-beta.5":"2024-01-15T05:32:30.346Z","3.7.3-beta.6":"2024-01-15T21:24:06.886Z","3.7.3-beta.7":"2024-01-16T21:43:34.630Z","3.7.3-beta.8":"2024-01-17T04:54:06.288Z","3.7.3-beta.9":"2024-01-17T09:41:47.917Z","3.7.3-beta.10":"2024-01-18T05:25:57.994Z","3.7.3-beta.11":"2024-01-18T14:01:23.952Z","3.7.3-beta.12":"2024-01-19T04:01:27.090Z","3.7.3-beta.13":"2024-01-19T17:08:53.528Z","3.7.3-beta.14":"2024-01-19T17:22:50.294Z","3.7.3-beta.15":"2024-01-20T03:14:48.087Z","3.7.3-beta.16":"2024-01-21T04:18:17.188Z","3.7.3-beta.17":"2024-01-22T04:00:03.717Z","3.7.3-beta.18":"2024-01-22T22:01:57.193Z","3.7.3-beta.19":"2024-01-23T03:30:04.111Z","3.7.3-beta.20":"2024-01-24T04:12:08.797Z","3.7.3-beta.21":"2024-01-24T16:53:38.566Z","3.7.3-beta.22":"2024-01-25T06:55:51.583Z","3.7.3-beta.23":"2024-01-25T21:05:39.343Z","3.7.3-beta.24":"2024-01-26T05:18:40.700Z","3.7.3-beta.25":"2024-01-26T18:37:34.466Z","3.7.3-beta.26":"2024-01-28T05:51:30.647Z","3.7.3-beta.27":"2024-01-29T22:02:46.686Z","3.7.3-beta.28":"2024-01-30T05:33:19.330Z","3.7.3-beta.29":"2024-01-30T12:04:21.264Z","3.7.3":"2024-01-30T14:53:24.122Z","3.7.4-beta.0":"2024-01-30T15:01:59.364Z","3.7.4-beta.1":"2024-01-31T04:22:55.083Z","3.7.4-beta.2":"2024-01-31T14:18:56.285Z","3.7.4-beta.3":"2024-01-31T20:01:45.635Z","3.7.4-beta.4":"2024-02-01T04:33:30.089Z","3.7.4-beta.5":"2024-02-02T07:07:18.765Z","3.7.4-beta.6":"2024-02-04T05:08:52.086Z","3.7.4-beta.7":"2024-02-05T03:31:42.103Z","3.7.4-beta.8":"2024-02-06T03:47:24.312Z","3.7.4-beta.9":"2024-02-06T13:40:38.503Z","3.7.4-beta.10":"2024-02-07T04:02:39.714Z","3.7.4-beta.11":"2024-02-09T15:32:46.215Z","3.7.4-beta.12":"2024-02-09T18:15:45.667Z","3.7.4-beta.13":"2024-02-10T04:30:06.218Z","3.7.4-beta.14":"2024-02-11T08:07:13.156Z","3.7.4-beta.15":"2024-02-11T08:16:48.715Z","3.7.4-beta.16":"2024-02-12T03:30:52.215Z","3.7.4-beta.17":"2024-02-12T21:29:30.631Z","3.7.4-beta.18":"2024-02-15T13:47:18.973Z","3.7.4-beta.19":"2024-02-15T14:02:52.469Z","3.7.4-beta.20":"2024-02-15T14:15:19.827Z","3.7.4-beta.21":"2024-02-15T15:44:48.475Z","3.7.4-beta.22":"2024-02-15T16:14:48.699Z","3.7.4-beta.23":"2024-02-16T03:50:00.866Z","3.7.4-beta.24":"2024-02-16T11:04:56.105Z","3.7.4-beta.25":"2024-02-17T04:43:26.687Z","3.7.4-beta.26":"2024-02-19T04:55:35.223Z","3.7.4-beta.27":"2024-02-19T14:33:35.071Z","3.7.4-beta.28":"2024-02-20T09:02:09.045Z","3.7.4-beta.29":"2024-02-20T10:34:29.974Z","3.7.4-beta.30":"2024-02-20T10:51:35.210Z","3.7.4-beta.31":"2024-02-21T10:21:18.452Z","3.8.0":"2024-02-21T15:56:05.185Z","3.8.1-beta.0":"2024-02-21T16:04:51.855Z","3.8.1-beta.1":"2024-02-22T06:28:58.046Z","3.8.1-beta.2":"2024-02-22T13:35:09.479Z","3.8.1-beta.3":"2024-02-22T13:57:04.874Z","3.8.1":"2024-02-22T14:07:51.264Z","3.8.2-beta.0":"2024-02-22T14:16:52.605Z","3.8.2-beta.1":"2024-02-22T15:26:59.881Z","3.8.2-beta.2":"2024-02-23T04:01:43.383Z","3.8.2-beta.3":"2024-02-24T05:06:01.285Z","3.8.2-beta.4":"2024-02-25T04:10:22.248Z","3.8.2-beta.5":"2024-02-26T04:31:00.765Z","3.8.2-beta.6":"2024-02-26T09:31:51.716Z","3.8.2-beta.7":"2024-02-26T15:54:54.237Z","3.8.2-beta.8":"2024-02-27T05:05:53.233Z","3.8.2-beta.9":"2024-02-28T04:46:11.751Z","3.8.2-beta.10":"2024-02-28T09:14:06.942Z","3.8.2-beta.11":"2024-02-28T14:57:09.170Z","3.8.2-beta.12":"2024-02-28T16:47:09.450Z","3.8.2-beta.13":"2024-02-29T03:50:43.051Z","3.8.2-beta.14":"2024-02-29T12:25:16.265Z","3.8.2-beta.15":"2024-03-02T07:42:27.843Z","3.8.2-beta.16":"2024-03-04T04:49:55.498Z","3.8.2-beta.17":"2024-03-05T04:49:34.425Z","3.8.2-beta.18":"2024-03-05T17:22:59.406Z","3.8.2-beta.19":"2024-03-08T04:18:45.459Z","3.8.2-beta.20":"2024-03-10T05:14:17.849Z","3.8.2-beta.21":"2024-03-11T12:37:58.576Z","3.8.2-beta.22":"2024-03-13T04:34:40.727Z","3.8.2-beta.23":"2024-03-15T03:58:09.903Z","3.8.2-beta.24":"2024-03-16T03:44:58.261Z","3.8.2-beta.25":"2024-03-17T03:34:37.250Z","3.8.2-beta.26":"2024-03-19T03:22:53.269Z","3.8.2-beta.27":"2024-03-19T07:06:49.058Z","3.8.2-beta.28":"2024-03-20T03:11:38.742Z","3.8.2-beta.29":"2024-03-21T04:32:39.948Z","3.8.2-beta.30":"2024-03-21T15:19:00.558Z","3.8.2":"2024-03-21T16:24:21.182Z","3.8.3-beta.0":"2024-03-21T16:33:32.729Z","3.8.3-beta.1":"2024-03-22T04:09:49.997Z","3.8.3-beta.2":"2024-03-22T14:51:17.904Z","3.8.3-beta.3":"2024-03-23T03:43:51.293Z","3.8.3-beta.4":"2024-03-24T04:22:00.880Z","3.8.3-beta.5":"2024-03-25T04:01:36.427Z","3.8.3-beta.6":"2024-03-25T10:57:50.795Z","3.8.3-beta.7":"2024-03-25T12:11:45.005Z","3.8.3-beta.8":"2024-03-26T04:37:04.543Z","3.8.3-beta.9":"2024-03-27T05:15:19.542Z","3.8.3-beta.10":"2024-03-27T12:11:54.176Z","3.8.3-beta.11":"2024-03-27T12:30:13.868Z","3.8.3-beta.12":"2024-03-28T03:51:34.853Z","3.8.3-beta.13":"2024-03-28T15:48:16.401Z","3.8.3-beta.14":"2024-03-29T03:24:27.229Z","3.8.3-beta.15":"2024-03-29T21:57:45.972Z","3.8.3-beta.16":"2024-03-31T05:13:56.375Z","3.8.3-beta.17":"2024-04-01T03:56:54.041Z","3.8.3-beta.18":"2024-04-02T01:17:59.397Z","3.8.3-beta.19":"2024-04-02T04:32:09.717Z","3.8.3-beta.20":"2024-04-02T10:56:08.678Z","3.8.3-beta.21":"2024-04-02T12:33:50.104Z","3.8.3-beta.22":"2024-04-02T18:50:41.822Z","3.8.3-beta.23":"2024-04-03T04:39:10.564Z","3.8.3-beta.24":"2024-04-03T15:10:46.856Z","3.8.3-beta.25":"2024-04-03T19:58:27.927Z","3.8.3-beta.26":"2024-04-04T04:16:37.274Z","3.8.3-beta.27":"2024-04-04T09:39:16.633Z","3.8.3-beta.28":"2024-04-04T10:07:08.190Z","3.8.3-beta.29":"2024-04-05T00:59:36.901Z","3.8.3-beta.30":"2024-04-05T03:15:19.233Z","3.8.3-beta.31":"2024-04-05T12:04:39.829Z","3.8.3-beta.32":"2024-04-05T17:13:38.769Z","3.8.3-beta.33":"2024-04-06T03:26:57.271Z","3.8.3-beta.34":"2024-04-08T12:24:09.200Z","3.8.3-beta.35":"2024-04-09T05:33:42.612Z","3.8.3-beta.36":"2024-04-09T14:20:17.456Z","3.8.3-beta.37":"2024-04-10T10:35:40.350Z","3.9.0":"2024-04-10T11:55:51.189Z","3.9.1-beta.0":"2024-04-10T12:03:32.035Z","3.9.1-beta.1":"2024-04-10T18:29:57.357Z","3.9.1-beta.2":"2024-04-10T22:09:58.831Z","3.9.1-beta.3":"2024-04-11T04:38:50.727Z","3.9.1-beta.4":"2024-04-11T06:59:54.321Z","3.9.1":"2024-04-11T09:03:51.077Z","3.9.2-beta.0":"2024-04-11T09:11:18.372Z","3.9.2-beta.1":"2024-04-11T18:25:53.214Z","3.9.2-beta.2":"2024-04-12T04:24:36.868Z","3.9.2-beta.3":"2024-04-12T21:33:14.280Z","3.9.2-beta.4":"2024-04-13T05:14:54.516Z","3.9.2-beta.5":"2024-04-15T15:25:58.643Z","3.9.2-beta.6":"2024-04-16T05:38:20.572Z","3.9.2-beta.7":"2024-04-16T11:09:45.513Z","3.9.2-beta.8":"2024-04-17T04:41:39.617Z","3.9.2-beta.9":"2024-04-17T08:26:18.148Z","3.9.2":"2024-04-17T13:15:25.353Z","3.9.3-beta.0":"2024-04-17T13:23:09.215Z","3.9.3-beta.1":"2024-04-18T05:20:35.810Z","3.9.3-beta.2":"2024-04-19T09:53:29.580Z","3.9.3-beta.3":"2024-04-20T05:16:06.110Z","3.9.3-beta.4":"2024-04-22T05:09:37.679Z","3.9.3-beta.5":"2024-04-22T08:10:44.768Z","3.9.3-beta.6":"2024-04-22T13:03:18.464Z","3.9.3-beta.7":"2024-04-23T05:03:42.053Z","3.9.3-beta.8":"2024-04-23T15:40:46.592Z","3.9.3-beta.9":"2024-04-23T23:07:43.026Z","3.9.3-beta.10":"2024-04-24T04:05:59.972Z","3.9.3-beta.11":"2024-04-24T18:55:09.471Z","3.9.3-beta.12":"2024-04-25T04:05:22.700Z","3.9.3-beta.13":"2024-04-25T22:54:11.140Z","3.9.3-beta.14":"2024-04-26T04:01:03.488Z","3.9.3-beta.15":"2024-04-27T03:31:57.478Z","3.9.3-beta.16":"2024-04-28T03:55:35.170Z","3.9.3-beta.17":"2024-04-29T04:30:18.063Z","3.9.3-beta.18":"2024-04-30T05:24:06.323Z","3.9.3-beta.19":"2024-04-30T14:39:44.505Z","3.9.3-beta.20":"2024-04-30T16:51:33.815Z","3.9.3-beta.21":"2024-05-02T22:31:16.400Z","3.9.3-beta.22":"2024-05-03T03:58:14.088Z","3.9.3-beta.23":"2024-05-03T07:30:36.912Z","3.9.3-beta.24":"2024-05-03T13:01:20.175Z","3.9.3-beta.25":"2024-05-03T19:27:19.975Z","3.9.3-beta.26":"2024-05-04T03:14:13.044Z","3.9.3-beta.27":"2024-05-05T04:12:30.276Z","3.9.3-beta.28":"2024-05-06T13:29:54.229Z","3.9.3-beta.29":"2024-05-07T04:08:43.058Z","3.9.3-beta.30":"2024-05-07T15:53:07.434Z","3.9.3-beta.31":"2024-05-08T04:06:44.520Z","3.9.3-beta.32":"2024-05-09T05:08:51.024Z","3.9.3-beta.33":"2024-05-10T04:14:11.452Z","3.9.3-beta.34":"2024-05-11T05:09:10.965Z","3.9.3-beta.35":"2024-05-12T04:12:31.041Z","3.9.3-beta.36":"2024-05-13T04:31:39.137Z","3.9.3-beta.37":"2024-05-13T07:31:23.923Z","3.9.3-beta.38":"2024-05-13T10:37:26.889Z","3.9.3-beta.39":"2024-05-13T14:14:40.996Z","3.9.3-beta.40":"2024-05-14T09:28:47.037Z","3.9.3-beta.41":"2024-05-14T11:04:50.965Z","3.9.3-beta.42":"2024-05-14T12:21:24.544Z","3.9.3-beta.43":"2024-05-15T14:13:23.386Z","3.9.3-beta.44":"2024-05-15T17:43:13.473Z","3.9.3-beta.45":"2024-05-15T18:21:19.332Z","3.9.3-beta.46":"2024-05-16T08:26:44.030Z","3.9.3-beta.47":"2024-05-16T12:04:04.592Z","3.9.3-beta.48":"2024-05-16T12:23:14.228Z","3.9.3-beta.49":"2024-05-16T13:24:49.001Z","3.9.3-beta.50":"2024-05-16T13:31:52.882Z","3.10.0":"2024-05-16T13:42:32.030Z","3.10.1-beta.0":"2024-05-16T13:50:48.799Z","3.10.1-beta.1":"2024-05-17T04:54:45.063Z","3.10.1-beta.2":"2024-05-18T06:59:30.738Z","3.10.1-beta.3":"2024-05-20T07:43:28.754Z","3.10.1-beta.4":"2024-05-21T13:50:11.619Z","3.10.1-beta.5":"2024-05-21T16:55:36.692Z","3.10.1-beta.6":"2024-05-22T09:09:14.920Z","3.10.1-beta.7":"2024-05-22T14:17:38.485Z","3.10.1-beta.8":"2024-05-22T15:18:24.368Z","3.10.1-beta.9":"2024-05-22T16:21:10.217Z","3.10.1-beta.10":"2024-05-22T17:11:26.831Z","3.10.1-beta.11":"2024-05-23T08:49:32.529Z","3.10.1-beta.12":"2024-05-23T09:05:54.054Z","3.10.1-beta.13":"2024-05-23T09:26:10.408Z","3.10.1":"2024-05-23T10:47:14.032Z","3.10.2-beta.0":"2024-05-23T11:48:25.823Z","3.10.2-beta.1":"2024-05-23T13:54:43.216Z","3.10.2-beta.2":"2024-05-24T04:34:43.131Z","3.10.2-beta.3":"2024-05-24T11:43:10.189Z","3.10.2-beta.4":"2024-05-24T14:53:03.207Z","3.10.2-beta.5":"2024-05-24T15:22:42.190Z","3.10.2-beta.6":"2024-05-25T03:55:47.685Z","3.10.2-beta.7":"2024-05-26T04:02:56.705Z","3.10.2-beta.8":"2024-05-27T03:40:41.827Z","3.10.2-beta.9":"2024-05-28T04:43:04.485Z","3.10.2-beta.10":"2024-05-28T18:24:18.702Z","3.10.2-beta.11":"2024-05-29T04:07:34.130Z","3.10.2-beta.12":"2024-05-29T17:27:52.272Z","3.10.2-beta.13":"2024-05-30T05:12:11.708Z","3.10.2-beta.14":"2024-05-31T04:35:59.825Z","3.10.2-beta.15":"2024-05-31T23:49:32.998Z","3.10.2-beta.16":"2024-06-02T03:27:28.439Z","3.10.2-beta.17":"2024-06-03T03:15:35.063Z","3.10.2":"2024-06-03T09:08:32.795Z","3.10.3-beta.0":"2024-06-03T09:40:02.793Z","3.10.3-beta.1":"2024-06-04T03:40:53.052Z","3.10.3-beta.2":"2024-06-05T15:16:05.952Z","3.10.3-beta.3":"2024-06-06T03:51:21.847Z","3.10.3-beta.4":"2024-06-06T09:38:08.816Z","3.10.3-beta.5":"2024-06-06T12:48:50.611Z","3.10.3-beta.6":"2024-06-06T13:08:39.204Z","3.10.3-beta.7":"2024-06-06T13:46:23.274Z","3.10.3-beta.8":"2024-06-06T15:47:55.739Z","3.10.3-beta.9":"2024-06-06T16:02:02.854Z","3.10.3-beta.10":"2024-06-06T16:54:38.179Z","3.10.3-beta.11":"2024-06-07T03:52:41.168Z","3.10.3-beta.12":"2024-06-07T11:44:48.862Z","3.10.3":"2024-06-07T11:54:03.637Z","3.10.4-beta.0":"2024-06-07T12:01:18.758Z","3.10.4-beta.1":"2024-06-08T04:20:59.526Z","3.10.4-beta.2":"2024-06-09T04:44:12.237Z","3.10.4-beta.3":"2024-06-10T04:26:21.653Z","3.10.4-beta.4":"2024-06-10T07:43:28.752Z","3.10.4-beta.5":"2024-06-10T07:57:33.897Z","3.10.4-beta.6":"2024-06-10T22:21:54.753Z","3.10.4-beta.7":"2024-06-11T10:33:00.587Z","3.10.4-beta.8":"2024-06-11T13:22:13.900Z","3.10.4-beta.9":"2024-06-11T14:02:26.704Z","3.10.4-beta.10":"2024-06-11T14:12:48.930Z","3.10.4-beta.11":"2024-06-11T14:43:31.814Z","3.10.4":"2024-06-11T15:07:01.158Z","3.10.5-beta.0":"2024-06-11T15:14:17.844Z","3.10.5-beta.1":"2024-06-11T18:34:56.501Z","3.10.5-beta.2":"2024-06-11T20:12:08.182Z","3.10.5-beta.3":"2024-06-11T21:52:45.496Z","3.10.5-beta.4":"2024-06-11T22:06:29.821Z","3.10.5-beta.5":"2024-06-12T01:52:48.564Z","3.10.5-beta.6":"2024-06-12T03:13:39.614Z","3.10.5":"2024-06-12T08:42:57.798Z","3.10.6-beta.0":"2024-06-12T08:50:31.780Z","3.10.6-beta.1":"2024-06-12T16:33:45.516Z","3.10.6-beta.2":"2024-06-13T05:38:00.411Z","3.10.6-beta.3":"2024-06-15T04:32:14.990Z","3.10.6-beta.4":"2024-06-16T03:18:42.103Z","3.10.6-beta.5":"2024-06-17T03:19:07.672Z","3.10.6-beta.6":"2024-06-17T13:36:08.791Z","3.10.6-beta.7":"2024-06-18T17:13:47.921Z","3.10.6-beta.8":"2024-06-19T04:49:04.680Z","3.10.6-beta.9":"2024-06-20T03:46:37.733Z","3.10.6-beta.10":"2024-06-20T12:36:31.238Z","3.10.6-beta.11":"2024-06-20T22:38:47.912Z","3.10.6-beta.12":"2024-06-21T12:43:54.494Z","3.10.6-beta.13":"2024-06-22T04:47:39.124Z","3.10.6-beta.14":"2024-06-23T03:26:07.560Z","3.10.6-beta.15":"2024-06-24T07:09:04.787Z","3.10.6-beta.16":"2024-06-24T11:26:12.637Z","3.10.6-beta.17":"2024-06-26T04:51:32.441Z","3.10.6-beta.18":"2024-06-28T13:54:43.094Z","3.10.6-beta.19":"2024-06-29T04:07:49.373Z","3.10.6-beta.20":"2024-06-30T04:37:04.191Z","3.10.6-beta.21":"2024-07-02T08:35:49.985Z","3.10.6-beta.22":"2024-07-02T11:21:08.535Z","3.10.6-beta.23":"2024-07-02T11:55:44.175Z","3.10.6-beta.24":"2024-07-04T04:48:06.339Z","3.10.6-beta.25":"2024-07-04T11:16:11.882Z","3.10.6-beta.26":"2024-07-05T05:10:12.119Z","3.10.6-beta.27":"2024-07-09T04:07:36.887Z","3.11.0":"2024-07-09T13:31:34.141Z","3.11.1-beta.0":"2024-07-11T15:29:20.138Z","3.11.1-beta.1":"2024-07-11T20:39:49.589Z","3.11.1-beta.2":"2024-07-12T03:17:14.878Z","3.11.1-beta.3":"2024-07-14T05:14:45.803Z","3.11.1-beta.4":"2024-07-15T04:05:11.316Z","3.11.1-beta.5":"2024-07-16T04:48:14.125Z","3.11.1-beta.6":"2024-07-17T03:45:07.172Z","3.11.1-beta.7":"2024-07-17T07:55:22.968Z","3.11.1-beta.8":"2024-07-22T23:13:14.176Z","3.11.1-beta.9":"2024-07-24T04:14:05.807Z","3.11.1-beta.10":"2024-07-24T08:54:53.513Z","3.11.1":"2024-07-24T11:07:02.693Z","3.11.2-beta.0":"2024-07-24T11:14:18.505Z","3.11.2-beta.1":"2024-07-25T03:39:24.642Z","3.11.2-beta.2":"2024-07-26T04:15:52.525Z","3.11.2-beta.3":"2024-07-27T03:40:17.598Z","3.11.2-beta.4":"2024-07-28T04:57:10.396Z","3.11.2-beta.5":"2024-07-29T05:23:40.876Z","3.11.2-beta.6":"2024-07-30T04:01:30.130Z","3.11.2-beta.7":"2024-07-31T04:41:36.425Z","3.11.2-beta.8":"2024-07-31T08:57:43.621Z","3.11.2-beta.9":"2024-08-01T04:10:38.573Z","3.11.2-beta.10":"2024-08-02T04:20:02.688Z","3.11.2-beta.11":"2024-08-03T03:40:45.723Z","3.11.2-beta.12":"2024-08-04T03:53:57.757Z","3.11.2-beta.13":"2024-08-05T05:15:03.273Z","3.11.2-beta.14":"2024-08-06T03:45:26.077Z","3.11.2-beta.15":"2024-08-06T10:20:01.994Z","3.11.2-beta.16":"2024-08-06T11:36:24.825Z","3.11.2-beta.17":"2024-08-07T04:00:46.075Z","3.11.2-beta.18":"2024-08-08T13:58:14.540Z","3.11.2-beta.19":"2024-08-12T13:07:32.413Z","3.11.2-beta.20":"2024-08-12T19:54:22.909Z","3.11.2-beta.21":"2024-08-14T00:12:33.679Z","3.11.2-beta.22":"2024-08-14T04:34:08.859Z","3.11.2-beta.23":"2024-08-15T03:54:51.056Z","3.11.2-beta.24":"2024-08-15T09:58:16.019Z","3.11.2-beta.25":"2024-08-16T03:11:17.326Z","3.11.2-beta.26":"2024-08-16T10:54:36.886Z","3.11.2-beta.27":"2024-08-18T04:26:08.864Z","3.11.2-beta.28":"2024-08-19T04:05:48.385Z","3.11.2-beta.29":"2024-08-20T04:55:42.010Z","3.11.2-beta.30":"2024-08-23T04:37:29.782Z","3.11.2-beta.31":"2024-08-24T05:44:18.798Z","3.11.2-beta.32":"2024-08-25T05:21:04.104Z","3.11.2-beta.33":"2024-08-26T09:24:56.145Z","3.11.2-beta.34":"2024-08-26T10:07:41.795Z","3.11.2-beta.35":"2024-08-26T10:28:04.990Z","3.11.2-beta.36":"2024-08-27T04:18:26.035Z","3.11.2-beta.37":"2024-08-28T03:54:05.813Z","3.11.2-beta.38":"2024-08-28T11:45:18.170Z","3.11.2-beta.39":"2024-08-28T12:05:56.855Z","3.11.2":"2024-08-28T12:15:56.412Z","3.11.3-beta.0":"2024-08-28T12:23:21.309Z","3.11.3-beta.1":"2024-08-29T05:16:09.640Z","3.11.3-beta.2":"2024-08-29T13:24:50.303Z","3.11.3-beta.3":"2024-08-29T14:14:42.129Z","3.11.3-beta.4":"2024-08-29T14:54:06.262Z","3.11.3-beta.5":"2024-08-30T04:22:48.036Z","3.11.3-beta.6":"2024-08-31T04:27:25.723Z","3.11.3-beta.7":"2024-09-01T03:54:56.263Z","3.11.3-beta.8":"2024-09-02T04:40:37.278Z","3.11.3-beta.9":"2024-09-03T03:57:05.572Z","3.11.3-beta.10":"2024-09-03T12:50:24.375Z","3.11.3-beta.11":"2024-09-03T13:00:25.750Z","3.11.3":"2024-09-03T15:12:50.390Z","3.11.4-beta.0":"2024-09-03T15:19:43.975Z","3.11.4-beta.1":"2024-09-20T12:52:24.131Z","3.11.4-beta.2":"2024-09-21T03:43:51.451Z","3.11.4-beta.3":"2024-09-21T11:29:59.667Z","3.11.4":"2024-09-23T08:15:57.294Z","3.11.5-beta.0":"2024-09-23T08:22:40.619Z","3.11.5-beta.1":"2024-09-24T15:04:13.084Z","3.11.5-beta.2":"2024-09-24T15:28:01.568Z","3.11.5-beta.3":"2024-09-25T12:10:24.677Z","3.11.5-beta.4":"2024-09-26T14:56:43.303Z","3.11.5-beta.5":"2024-09-27T09:06:37.630Z","3.11.5-beta.6":"2024-09-27T09:20:49.630Z","3.11.5-beta.7":"2024-09-27T09:55:05.721Z","3.11.5-beta.8":"2024-09-27T11:00:48.861Z","3.11.5-beta.9":"2024-09-30T10:04:11.786Z","3.11.5-beta.10":"2024-10-01T08:28:19.245Z","3.11.5-beta.11":"2024-10-02T11:36:48.416Z","3.11.5-beta.12":"2024-10-02T13:36:00.508Z","3.11.5-beta.13":"2024-10-02T22:58:33.638Z","3.11.5-beta.14":"2024-10-03T07:12:33.358Z","3.11.5-beta.15":"2024-10-03T10:17:33.371Z","3.11.5-beta.16":"2024-10-03T22:07:14.665Z","3.11.5-beta.17":"2024-10-04T08:17:37.654Z","3.11.5-beta.18":"2024-10-04T12:30:33.610Z","3.11.5":"2024-10-04T12:37:23.119Z","3.11.6-beta.0":"2024-10-04T12:44:26.477Z","3.11.6-beta.1":"2024-10-07T16:35:46.489Z","3.11.6-beta.2":"2024-10-08T19:06:31.958Z","3.11.6-beta.3":"2024-10-10T11:05:05.894Z","3.11.6-beta.4":"2024-10-11T10:42:16.732Z","3.11.6-beta.5":"2024-10-11T17:35:40.758Z","3.11.6-beta.6":"2024-10-14T09:48:36.108Z","3.11.6-beta.7":"2024-10-14T11:30:24.976Z","3.11.6-beta.8":"2024-10-16T11:11:10.473Z","3.11.6-beta.9":"2024-10-16T15:14:26.737Z","3.11.6-beta.10":"2024-10-16T22:43:34.884Z","3.11.6-beta.11":"2024-10-23T11:21:39.948Z","3.11.6-beta.12":"2024-10-29T08:06:06.475Z","3.11.6-beta.13":"2024-10-29T16:34:28.634Z","3.11.6-beta.14":"2024-11-01T15:48:16.656Z","3.12.0":"2024-11-04T07:45:09.234Z","3.12.1-beta.0":"2024-11-04T07:52:09.553Z","3.12.1-beta.1":"2024-11-05T18:26:00.134Z","3.12.1-beta.2":"2024-11-05T22:36:18.788Z","3.12.1-beta.3":"2024-11-06T04:18:58.187Z","3.12.1-beta.4":"2024-11-07T03:57:49.148Z","3.12.1-beta.5":"2024-11-07T19:42:43.140Z","3.12.1-beta.6":"2024-11-08T03:12:10.157Z","3.12.1-beta.7":"2024-11-11T03:58:12.821Z","3.12.1-beta.8":"2024-11-12T11:57:53.965Z","3.12.1-beta.9":"2024-11-18T20:14:34.413Z","3.12.1-beta.10":"2024-11-19T22:25:10.375Z","3.12.1-beta.11":"2024-11-21T17:24:44.605Z","3.12.1-beta.12":"2024-11-22T04:50:36.970Z","3.12.1-beta.13":"2024-11-22T22:12:44.326Z","3.12.1-beta.14":"2024-11-25T07:53:10.113Z","3.12.1-beta.15":"2024-11-25T08:11:30.314Z","3.12.1-beta.16":"2024-11-25T15:32:47.801Z","3.12.1-beta.17":"2024-12-03T14:56:08.813Z","3.12.1-beta.18":"2024-12-03T18:12:44.755Z","3.12.1-beta.19":"2024-12-04T03:45:13.177Z","3.12.1":"2024-12-04T09:27:29.712Z","3.12.2-beta.0":"2024-12-04T09:34:41.310Z","3.12.2-beta.1":"2024-12-05T04:33:14.117Z","3.12.2-beta.2":"2024-12-06T05:16:28.627Z","3.12.2-beta.3":"2024-12-07T05:22:01.678Z","3.12.2-beta.4":"2024-12-08T04:03:54.546Z","3.12.2-beta.5":"2024-12-10T00:26:57.657Z","3.12.2-beta.6":"2024-12-10T06:45:53.046Z","3.12.2-beta.7":"2024-12-10T11:49:26.239Z","3.12.2-beta.8":"2024-12-11T01:22:26.876Z","3.12.2-beta.9":"2024-12-11T05:08:25.958Z","3.12.2-beta.10":"2024-12-11T10:55:18.954Z","3.12.2-beta.11":"2024-12-12T04:18:02.876Z","3.12.2-beta.12":"2024-12-12T18:55:17.403Z","3.12.2-beta.13":"2024-12-13T04:27:31.441Z","3.12.2-beta.14":"2024-12-14T03:15:03.454Z","3.12.2-beta.15":"2024-12-14T09:59:31.188Z","3.12.2-beta.16":"2024-12-16T03:41:06.638Z","3.12.2-beta.17":"2024-12-18T04:18:23.738Z","3.12.2-beta.18":"2024-12-18T19:26:59.885Z","3.12.2-beta.19":"2024-12-19T03:16:38.825Z","3.12.2-beta.20":"2024-12-19T11:25:40.469Z","3.12.2-beta.21":"2024-12-19T14:03:27.514Z","3.12.2-beta.22":"2024-12-20T03:38:08.151Z","3.12.2-beta.23":"2024-12-21T03:31:59.337Z","3.12.2-beta.24":"2024-12-21T18:06:46.882Z","3.12.2-beta.25":"2024-12-22T04:26:11.085Z","3.12.2-beta.26":"2024-12-24T05:29:58.837Z","3.12.2-beta.27":"2024-12-25T04:38:27.570Z","3.12.2-beta.28":"2024-12-26T04:38:05.474Z","3.12.2-beta.29":"2024-12-27T05:18:57.115Z","3.12.2-beta.30":"2024-12-29T03:52:34.103Z","3.12.2-beta.31":"2024-12-30T04:45:16.086Z","3.12.2-beta.32":"2024-12-30T07:32:52.780Z","3.12.2-beta.33":"2025-01-01T03:49:37.473Z","3.12.2-beta.34":"2025-01-03T21:40:53.183Z","3.12.2-beta.35":"2025-01-07T20:18:33.595Z","3.12.2-beta.36":"2025-01-07T21:07:36.571Z","3.12.2-beta.37":"2025-01-08T01:12:22.813Z","3.12.2-beta.38":"2025-01-08T04:49:31.211Z","3.12.2-beta.39":"2025-01-09T04:55:59.967Z","3.12.2-beta.40":"2025-01-10T04:58:29.561Z","3.12.2-beta.41":"2025-01-10T11:55:39.308Z","3.12.2-beta.42":"2025-01-11T04:54:08.446Z","3.12.2-beta.43":"2025-01-13T15:27:15.763Z","3.12.2-beta.44":"2025-01-18T10:24:22.379Z","3.12.2-beta.45":"2025-01-20T09:58:01.331Z","3.12.2-beta.46":"2025-01-20T10:06:47.599Z","3.12.2-beta.47":"2025-01-20T12:50:39.834Z","3.12.2-beta.48":"2025-01-20T14:03:31.359Z","3.12.2-beta.49":"2025-01-20T22:20:02.010Z","3.12.2-beta.50":"2025-01-21T08:11:18.506Z","3.12.2-beta.51":"2025-01-21T15:17:31.911Z","3.12.2-beta.52":"2025-01-21T23:26:14.965Z","3.12.2-beta.53":"2025-01-22T09:28:49.979Z","3.12.2":"2025-01-27T08:17:06.079Z","3.12.3-beta.0":"2025-01-27T08:24:34.667Z","3.12.3-beta.1":"2025-01-29T08:55:51.894Z","3.12.3-beta.2":"2025-01-29T09:03:29.876Z","3.12.3-beta.3":"2025-02-05T03:14:36.107Z","3.12.3-beta.4":"2025-02-05T16:27:37.785Z","3.12.3-beta.5":"2025-02-10T17:11:41.945Z","3.12.3-beta.6":"2025-02-11T14:41:46.851Z","3.12.3-beta.7":"2025-02-12T12:15:19.612Z","3.12.3-beta.8":"2025-02-12T12:42:16.849Z","3.12.3-beta.9":"2025-02-12T12:57:54.561Z","3.12.3-beta.10":"2025-02-12T13:32:48.198Z","3.12.3-beta.11":"2025-02-12T13:43:10.842Z","3.12.3-beta.12":"2025-02-16T12:38:16.812Z","3.12.3-beta.13":"2025-02-17T14:16:28.044Z","3.12.3-beta.14":"2025-02-18T04:56:17.328Z","3.12.3-beta.15":"2025-02-19T04:43:59.556Z","3.12.3-beta.16":"2025-02-20T05:09:06.387Z","3.12.3-beta.17":"2025-02-20T14:10:20.424Z","3.12.3-beta.18":"2025-02-21T05:27:51.069Z","3.12.3-beta.19":"2025-02-24T08:28:31.445Z","3.12.3-beta.20":"2025-02-28T14:10:53.145Z","3.12.3-beta.21":"2025-02-28T14:39:59.556Z","3.12.3-beta.22":"2025-02-28T15:07:45.918Z","3.12.3-beta.23":"2025-02-28T15:16:12.603Z","3.12.3-beta.24":"2025-02-28T20:57:43.099Z","3.12.3-beta.25":"2025-03-01T04:40:34.322Z","3.12.3-beta.26":"2025-03-02T04:42:57.326Z","3.12.3-beta.27":"2025-03-03T05:15:36.555Z","3.12.3-beta.28":"2025-03-03T15:30:37.054Z","3.12.3-beta.29":"2025-03-03T16:29:30.207Z","3.12.3-beta.30":"2025-03-04T00:29:40.206Z","3.12.3-beta.31":"2025-03-04T04:32:27.442Z","3.13.0":"2025-03-04T09:14:10.173Z","3.13.1-beta.0":"2025-03-04T09:25:36.825Z","3.13.1-beta.1":"2025-03-05T05:08:36.525Z","3.13.1-beta.2":"2025-03-06T05:08:09.393Z","3.13.1-beta.3":"2025-03-06T13:32:24.930Z","3.13.1-beta.4":"2025-03-07T01:08:41.988Z","3.13.1-beta.5":"2025-03-07T04:47:08.198Z","3.13.1-beta.6":"2025-03-07T13:19:59.298Z","3.13.1-beta.7":"2025-03-08T04:57:32.855Z","3.13.1-beta.8":"2025-03-09T04:56:13.988Z","3.13.1-beta.9":"2025-03-10T05:15:54.178Z","3.13.1-beta.10":"2025-03-11T04:34:44.595Z","3.13.1-beta.11":"2025-03-12T04:55:13.398Z","3.13.1-beta.12":"2025-03-13T05:08:42.229Z","3.13.1-beta.13":"2025-03-14T04:46:31.491Z","3.13.1-beta.14":"2025-03-15T05:00:09.611Z","3.13.1-beta.15":"2025-03-16T05:15:07.412Z","3.13.1-beta.16":"2025-03-17T05:17:28.469Z","3.13.1-beta.17":"2025-03-17T22:05:53.551Z","3.13.1-beta.18":"2025-03-18T04:54:31.198Z","3.13.1-beta.19":"2025-03-18T11:46:48.971Z","3.13.1-beta.20":"2025-03-19T05:07:54.583Z","3.13.1-beta.21":"2025-03-20T04:43:47.289Z","3.13.1-beta.22":"2025-03-21T04:33:43.108Z","3.13.1-beta.23":"2025-03-22T04:39:09.861Z","3.13.1-beta.24":"2025-03-23T04:48:17.502Z","3.13.1-beta.25":"2025-03-24T04:44:53.231Z","3.13.1-beta.26":"2025-03-24T13:38:56.140Z","3.13.1-beta.27":"2025-03-25T04:32:26.389Z","3.13.1-beta.28":"2025-03-26T04:44:00.040Z","3.13.1-beta.29":"2025-03-28T14:30:00.548Z","3.13.1-beta.30":"2025-03-30T15:46:35.883Z","3.13.1-beta.31":"2025-03-31T05:03:32.462Z","3.13.1-beta.32":"2025-04-01T11:28:33.590Z","3.13.1-beta.33":"2025-04-02T10:03:43.921Z","3.13.1-beta.34":"2025-04-02T13:34:31.780Z","3.13.1-beta.35":"2025-04-02T16:01:18.651Z","3.13.1-beta.36":"2025-04-04T08:03:31.176Z","3.13.1-beta.37":"2025-04-04T09:42:40.701Z","3.13.1":"2025-04-07T06:55:54.777Z","3.13.2-beta.0":"2025-04-07T07:03:33.022Z","3.13.2-beta.1":"2025-04-07T15:35:34.185Z","3.13.2-beta.2":"2025-04-08T06:53:19.229Z","3.13.2":"2025-04-08T10:15:03.033Z","3.13.3-beta.0":"2025-04-08T10:22:29.231Z","3.13.3-beta.1":"2025-04-10T08:28:15.250Z","3.13.3-beta.2":"2025-04-10T12:44:27.861Z","3.13.3-beta.3":"2025-04-10T15:51:29.937Z","3.13.3-beta.4":"2025-04-14T07:54:36.166Z","3.13.3-beta.5":"2025-04-14T12:26:42.626Z","3.13.3-beta.6":"2025-04-15T09:21:55.448Z","3.13.3-beta.7":"2025-04-16T12:04:57.721Z","3.13.3-beta.8":"2025-04-18T07:59:29.572Z","3.13.3-beta.9":"2025-04-18T08:10:38.661Z","3.13.3-beta.10":"2025-04-18T08:21:42.470Z","3.13.3-beta.11":"2025-04-24T10:36:42.781Z","3.13.3-beta.12":"2025-04-29T11:14:46.606Z","3.13.3-beta.13":"2025-04-29T11:31:27.931Z","3.13.3-beta.14":"2025-04-29T12:01:37.369Z","3.13.3-beta.15":"2025-04-29T13:09:22.653Z","3.13.3-beta.16":"2025-05-05T06:55:23.908Z","3.13.3":"2025-05-05T07:10:02.557Z","3.13.4-beta.0":"2025-05-05T07:17:29.009Z","3.13.4-beta.1":"2025-05-12T15:56:09.034Z","3.13.4-beta.2":"2025-05-12T16:33:51.637Z","3.13.4-beta.3":"2025-05-13T11:42:35.470Z","3.13.4-beta.4":"2025-05-14T09:19:23.048Z","3.13.4-beta.5":"2025-05-14T09:37:20.614Z","3.13.4-beta.6":"2025-05-14T09:45:31.817Z","3.13.4-beta.7":"2025-05-14T12:32:57.585Z","3.13.4":"2025-05-14T13:19:51.174Z","3.13.5-beta.0":"2025-05-14T13:27:43.440Z","3.13.5-beta.1":"2025-05-14T14:41:11.305Z","3.13.5-beta.2":"2025-05-15T11:16:37.599Z","3.13.5-beta.3":"2025-05-15T15:32:21.344Z","3.13.5-beta.4":"2025-05-16T07:31:48.444Z","3.13.5-beta.5":"2025-05-16T07:49:16.511Z","3.13.5-beta.6":"2025-05-16T11:55:28.572Z","3.13.5-beta.7":"2025-05-17T04:33:08.396Z","3.13.5-beta.8":"2025-05-19T04:54:11.011Z","3.13.5-beta.9":"2025-05-19T13:12:25.790Z","3.13.5-beta.10":"2025-05-20T04:36:44.474Z","3.13.5":"2025-05-20T08:30:34.088Z","3.13.6-beta.0":"2025-05-20T08:39:37.601Z","4.0.0-beta.0":"2025-05-20T13:40:57.002Z","3.13.6-beta.1":"2025-05-21T04:58:36.019Z","4.0.0-beta.1":"2025-05-21T08:23:33.392Z","4.0.0-beta.2":"2025-05-21T09:40:05.414Z","4.0.0-beta.3":"2025-05-21T11:35:43.084Z","4.0.0-beta.4":"2025-05-21T12:16:12.835Z","3.13.6-beta.2":"2025-05-21T19:08:46.943Z","3.13.6-beta.3":"2025-05-22T04:41:03.457Z","3.13.6-beta.4":"2025-05-23T04:40:44.773Z","3.13.6-beta.5":"2025-05-27T14:00:25.561Z","3.13.6-beta.6":"2025-06-04T12:21:55.255Z","4.0.0-beta.5":"2025-06-04T14:07:20.050Z","4.0.0-beta.6":"2025-06-04T14:29:56.616Z","3.13.6-beta.7":"2025-06-05T12:13:41.874Z","3.13.6-beta.8":"2025-06-05T12:42:14.943Z","3.13.6":"2025-06-05T15:07:14.544Z","3.13.7-beta.0":"2025-06-05T15:15:18.473Z","3.13.7-beta.1":"2025-06-06T11:47:23.540Z","3.13.7":"2025-06-06T11:48:01.001Z","3.13.8-beta.0":"2025-06-06T11:55:49.314Z","3.13.8-beta.1":"2025-06-09T08:46:21.925Z","3.13.8-beta.2":"2025-06-10T09:55:34.857Z","3.13.8-beta.3":"2025-06-11T12:03:03.760Z","3.13.8-beta.4":"2025-06-11T13:54:06.536Z","4.0.0-beta.7":"2025-06-11T14:19:03.235Z","3.13.8-beta.5":"2025-06-11T14:20:49.280Z","4.0.0-beta.8":"2025-06-11T14:57:04.010Z","4.0.0-beta.9":"2025-06-11T15:16:10.765Z","3.13.8-beta.6":"2025-06-11T15:25:33.048Z","3.13.8-beta.7":"2025-06-12T09:44:28.123Z","3.13.8-beta.8":"2025-06-12T12:45:23.564Z","3.13.8-beta.9":"2025-06-13T03:24:56.408Z","3.13.8-beta.10":"2025-06-16T03:46:16.024Z","3.13.8-beta.11":"2025-06-16T12:09:49.524Z","3.13.8":"2025-06-16T21:58:42.473Z","3.13.9-beta.0":"2025-06-16T22:06:53.147Z","3.13.9-beta.1":"2025-06-17T14:29:23.272Z","4.0.0-beta.10":"2025-06-17T15:12:40.060Z","3.13.9-beta.2":"2025-06-18T06:48:17.727Z","3.13.9-beta.3":"2025-06-19T04:35:49.726Z","3.13.9-beta.4":"2025-06-23T08:26:50.746Z","3.13.9-beta.5":"2025-06-25T11:44:08.311Z","3.13.9-beta.6":"2025-06-25T18:42:31.330Z","3.13.9-beta.7":"2025-06-26T10:01:41.199Z","3.13.9-beta.8":"2025-06-26T11:33:33.195Z","3.13.9-beta.9":"2025-06-26T14:31:39.050Z","3.13.9":"2025-06-27T07:46:18.132Z","3.13.10-beta.0":"2025-06-27T07:55:19.185Z","3.13.10-beta.1":"2025-06-30T13:38:55.960Z","3.13.10-beta.2":"2025-06-30T14:16:36.268Z","3.13.10-beta.3":"2025-06-30T19:35:31.421Z","3.13.10-beta.4":"2025-07-01T00:45:37.269Z","3.13.10-beta.5":"2025-07-01T10:36:10.095Z","3.13.10-beta.6":"2025-07-01T11:20:51.847Z","3.13.10-beta.7":"2025-07-01T13:02:39.932Z","3.13.10-beta.8":"2025-07-01T21:38:03.664Z","3.13.10-beta.9":"2025-07-03T11:56:09.799Z","3.13.10-beta.10":"2025-07-03T18:44:05.223Z","3.13.10-beta.11":"2025-07-08T00:09:05.715Z","3.13.10-beta.12":"2025-07-08T04:24:26.804Z","3.13.10-beta.13":"2025-07-09T09:45:42.583Z","3.13.10":"2025-07-09T11:52:03.837Z","3.13.11-beta.0":"2025-07-09T11:59:20.645Z","3.13.11-beta.1":"2025-07-10T01:04:27.038Z","3.13.11-beta.2":"2025-07-14T13:04:39.924Z","3.13.11-beta.3":"2025-07-16T06:28:24.556Z","3.13.11-beta.4":"2025-07-17T09:31:01.690Z","3.13.11-beta.5":"2025-07-17T13:44:14.597Z","3.13.11-beta.6":"2025-07-18T12:29:52.644Z","3.13.11-beta.7":"2025-07-21T12:03:03.789Z","3.13.11-beta.8":"2025-07-22T07:04:51.411Z","3.13.11-beta.9":"2025-07-22T08:54:43.407Z","3.13.11-beta.10":"2025-07-23T17:59:23.286Z","3.13.11-beta.11":"2025-07-23T18:13:31.307Z","3.13.11-beta.12":"2025-07-24T09:58:47.229Z","3.13.11-beta.13":"2025-07-24T18:12:48.884Z","3.13.11-beta.14":"2025-07-25T09:14:49.275Z","3.14.0":"2025-07-25T09:35:04.251Z","3.14.1-beta.0":"2025-07-25T09:42:26.678Z","3.14.1-beta.1":"2025-07-26T07:36:06.353Z","3.14.1-beta.2":"2025-07-28T15:23:48.902Z","3.14.1-beta.3":"2025-08-02T10:40:03.770Z","3.14.1-beta.4":"2025-08-05T11:35:02.553Z","3.14.1":"2025-08-05T11:53:44.624Z","3.14.2-beta.0":"2025-08-05T12:01:08.251Z","3.14.2-beta.1":"2025-08-09T05:45:14.485Z","3.14.2-beta.2":"2025-08-10T05:44:43.533Z","3.14.2-beta.3":"2025-08-12T11:34:49.786Z","3.14.2-beta.4":"2025-08-12T12:52:41.341Z","3.14.2-beta.5":"2025-08-13T08:46:02.381Z","3.14.2-beta.6":"2025-08-19T20:08:57.056Z","3.14.2-beta.7":"2025-08-20T10:07:59.416Z","3.14.2-beta.8":"2025-08-20T10:52:42.539Z","3.14.2-beta.9":"2025-08-21T07:46:34.068Z","3.14.2-beta.10":"2025-08-21T13:14:50.618Z","3.14.2-beta.11":"2025-08-22T16:38:44.032Z","3.14.2-beta.12":"2025-08-26T04:58:41.394Z","3.14.2-beta.13":"2025-08-26T10:23:50.521Z","3.14.2-beta.14":"2025-09-04T04:49:00.185Z","3.14.2-beta.15":"2025-09-09T09:47:50.283Z","3.14.2-beta.16":"2025-09-10T12:43:36.958Z","3.14.2-beta.17":"2025-09-14T01:53:13.751Z","3.14.2-beta.18":"2025-09-14T10:12:41.545Z","3.15.0":"2025-09-17T12:48:39.666Z","3.15.1-beta.0":"2025-09-17T12:58:27.219Z","3.15.1-beta.1":"2025-09-23T14:46:17.321Z","3.15.1-beta.2":"2025-09-25T11:00:43.249Z","3.15.1-beta.3":"2025-09-25T12:08:32.098Z","3.15.1-beta.4":"2025-09-26T06:40:51.820Z","3.15.1-beta.5":"2025-09-26T07:51:36.437Z","3.15.1-beta.6":"2025-09-26T08:51:47.181Z","3.15.1":"2025-09-26T13:19:45.800Z","3.15.2-beta.0":"2025-09-26T13:28:11.461Z","3.15.2-beta.1":"2025-09-29T08:08:01.477Z","3.15.2-beta.2":"2025-09-30T03:40:19.609Z","3.15.2-beta.3":"2025-09-30T10:14:43.470Z","3.15.2-beta.4":"2025-10-01T03:54:41.033Z","3.15.2-beta.5":"2025-10-02T06:44:59.461Z","3.15.2-beta.6":"2025-10-06T14:24:03.158Z","3.15.2-beta.7":"2025-10-08T06:45:04.497Z","3.15.2-beta.8":"2025-10-08T11:40:12.089Z","3.15.2-beta.9":"2025-10-08T12:42:34.276Z","3.15.2-beta.10":"2025-10-10T08:10:57.870Z","3.15.2-beta.11":"2025-10-13T06:16:15.996Z","3.15.2-beta.12":"2025-10-14T20:22:42.262Z","3.15.2-beta.13":"2025-10-15T07:25:45.803Z","3.15.2-beta.14":"2025-10-16T14:25:58.074Z","3.15.2-beta.15":"2025-10-16T23:26:03.828Z","3.15.2-beta.16":"2025-10-20T07:08:42.330Z","3.15.2-beta.17":"2025-10-21T06:38:38.372Z","3.15.2-beta.18":"2025-10-21T09:39:11.693Z","3.15.2-beta.19":"2025-10-22T02:09:21.443Z","3.15.2-beta.20":"2025-10-22T23:55:09.926Z","3.15.2-beta.21":"2025-10-23T09:49:13.216Z","3.15.2-beta.22":"2025-10-23T10:47:36.625Z","3.15.2-beta.23":"2025-10-23T10:59:36.797Z","3.15.2-beta.24":"2025-10-23T12:54:54.361Z","3.15.2":"2025-10-23T13:05:32.829Z","3.15.3-beta.0":"2025-10-23T13:15:51.041Z","3.15.3-beta.1":"2025-10-24T09:56:54.104Z","3.15.3-beta.2":"2025-10-28T08:04:38.484Z","3.15.3-beta.3":"2025-10-29T08:18:31.698Z","3.15.3-beta.4":"2025-10-29T15:53:07.954Z","3.15.3-beta.5":"2025-10-30T19:48:12.083Z","3.15.3-beta.6":"2025-11-03T09:54:56.036Z","3.15.3-beta.7":"2025-11-04T14:47:58.791Z","3.15.3-beta.8":"2025-11-05T15:19:33.967Z","3.15.3-beta.9":"2025-11-05T16:02:26.226Z","3.15.3-beta.10":"2025-11-06T07:52:46.123Z","3.15.3-beta.11":"2025-11-06T16:43:10.399Z","3.15.3-beta.12":"2025-11-06T16:53:20.475Z","3.15.3-beta.13":"2025-11-06T17:09:07.970Z","3.15.3-beta.14":"2025-11-06T17:21:44.844Z","3.15.3-beta.15":"2025-11-07T09:11:13.285Z","3.15.3-beta.16":"2025-11-07T09:32:05.843Z","3.15.3-beta.17":"2025-11-08T03:22:06.415Z","3.15.3-beta.18":"2025-11-10T11:59:37.971Z","3.15.3-beta.19":"2025-11-10T12:54:26.440Z","3.15.3-beta.20":"2025-11-10T19:28:13.598Z","3.15.3":"2025-11-10T19:31:25.643Z","3.15.4-beta.0":"2025-11-12T10:16:51.462Z","3.15.4-beta.1":"2025-11-13T10:55:47.856Z","3.15.4-beta.2":"2025-11-13T14:58:17.519Z","3.15.4-beta.3":"2025-11-14T09:23:33.019Z","3.15.4-beta.4":"2025-11-19T07:05:43.822Z","3.15.4-beta.5":"2025-11-19T12:31:16.514Z","3.15.4-beta.6":"2025-11-21T16:18:07.076Z","3.15.4-beta.7":"2025-11-21T16:45:27.152Z","4.0.0-beta.11":"2025-11-24T12:48:23.968Z","3.15.4-beta.8":"2025-11-24T13:09:27.450Z","3.15.4-beta.9":"2025-11-24T13:40:54.064Z","4.0.0-beta.12":"2025-11-26T10:24:48.564Z","3.15.4-beta.10":"2025-11-26T10:47:15.177Z","3.15.4-beta.11":"2025-11-26T14:51:21.244Z","4.0.0-beta.13":"2025-11-27T12:48:26.572Z","3.15.4-beta.12":"2025-11-27T17:02:55.507Z","3.15.4-beta.13":"2025-12-01T08:56:33.582Z","4.0.0-beta.14":"2025-12-01T15:26:31.415Z","3.15.4-beta.14":"2025-12-01T15:29:17.756Z","3.15.4-beta.15":"2025-12-02T08:12:30.544Z","3.15.4-beta.16":"2025-12-02T09:05:32.003Z","4.0.0-beta.15":"2025-12-02T15:13:19.723Z","4.0.0-beta.16":"2025-12-02T15:29:24.775Z","4.0.0-beta.17":"2025-12-02T15:55:09.341Z","3.15.4-beta.17":"2025-12-04T10:05:27.330Z","3.15.4-beta.18":"2025-12-04T15:21:58.961Z","4.0.0-beta.18":"2025-12-05T11:26:36.119Z"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"author":{"url":"https://apify.com","name":"Apify","email":"support@apify.com"},"license":"Apache-2.0","homepage":"https://crawlee.dev","keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"repository":{"url":"git+https://github.com/apify/crawlee.git","type":"git"},"description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","contributors":[{"name":"Jan Curn","email":"jan@apify.com"},{"name":"Marek Trunkat","email":"marek@apify.com"},{"name":"Ondra Urban","email":"ondra@apify.com"}],"maintainers":[{"name":"apify-service-account","email":"service-account@apify.com"},{"name":"jancurn","email":"jan.curn@gmail.com"},{"name":"mtrunkat","email":"marek@trunkat.eu"},{"name":"b4nan","email":"martinadamek59@gmail.com"},{"name":"fnesveda","email":"frantisek@apify.com"}],"readme":"","readmeFilename":""}